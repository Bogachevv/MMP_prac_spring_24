{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Практикум по программированию на языке Python`\n",
    "\n",
    "## `Задание 01. Полносвязная нейронная сеть на numpy`.\n",
    "\n",
    "#### Фамилия, имя: \n",
    "\n",
    "Дата выдачи: <span style=\"color:red\">__20 февраля__</span>.\n",
    "\n",
    "Мягкий дедлайн: <span style=\"color:red\">__6 марта 23:59__</span>.\n",
    "\n",
    "Стоимость: __10 баллов__ (основная часть заданий) + __3 балла__ (дополнительные задания).\n",
    "\n",
    "<span style=\"color:red\">__В ноутбуке все клетки должны выполняться без ошибок при последовательном их выполнении.__</span>\n",
    "\n",
    "#### `Москва, 2024`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.417361400Z",
     "start_time": "2024-02-22T20:35:32.322264300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `Теоретическая часть (3 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "В этом блоке вам нужно решить 3 задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Задание 1. Градиенты для слоя Batch normalization (1.5 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Рассмотрим слой Batch normalization. Пусть на вход этого слоя был подан батч из $n$ объектов, при этом у всех объектов по 1 признаку. Представим вход BN слоя в виде $X \\in \\mathbb{R}^{n \\times 1}$.\n",
    "\n",
    "Тогда в этом слое производятся следующие вычисления:\n",
    "\n",
    "$$ \\mu = \\frac1n \\sum_{i=1}^{n} X_i $$\n",
    "\n",
    "$$ \\sigma^2 = \\frac1n \\sum_{i=1}^{n} \\left( X_i - \\mu \\right) ^2 $$\n",
    "\n",
    "$$ \\tilde{y_i} = \\frac{X_i - \\mu}{\\sqrt{\\sigma^2 + \\varepsilon}} $$\n",
    "\n",
    "$$ y_i = \\gamma \\tilde{y_i} + \\delta $$\n",
    "\n",
    "Выходом BN слоя является $y_i$, а $\\gamma,\\delta\\in\\mathbb{R}$ — параметры, которые подбираются во время обучения вместе с другими параметрами нейронной сети (наряду, например, с весами линейного слоя).\n",
    "\n",
    "Рассмотрим нейронную сеть, в которой есть BN слой. Предположим, что вычисления в нейронной сети завершаются подсчетом функции потерь $\\mathcal{L}$. Пусть мы выполнили прямой проход по нейронной сети и сейчас делаем обратный проход с помощью метода обратного распространения ошибки. Пусть BN слою пришел градиент функции потерь по выходу BN слоя ($\\nabla_{y} \\mathcal{L}$).\n",
    "\n",
    "В этом задании вам нужно записать вычисление градиента функции потерь по параметрам слоя BN $\\gamma$ и $\\delta$ ($\\nabla_{\\gamma} \\mathcal{L}$, $\\nabla_{\\delta} \\mathcal{L}$) через $\\nabla_{y} \\mathcal{L}$, а также вам нужно записать вычисление градиента функции потерь по входу слоя BN $X$ ($\\nabla_{X} \\mathcal{L}$) через $\\nabla_{y} \\mathcal{L}$.\n",
    "\n",
    "Хочу заметить, в данном задании мы рассматриваем объекты всего с 1 признаком, чтобы упростить выкладки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Ваше решение:__\n",
    "\n",
    "Перепишем формулу для $y_i$ в векторном виде:\n",
    "$$y_i = \\gamma \\frac{X - \\mu}{\\sqrt{\\sigma^2 + \\varepsilon}} + \\delta $$\n",
    "Считаем, что $\\mathcal{L} = \\mathcal{L}(y(X, \\gamma, \\delta))$, тогда:\n",
    "1. $\\nabla_{\\gamma} {\\mathcal L} = (\\nabla_{y} {\\mathcal L})^T \\cdot \\frac{X - \\mu}{\\sqrt{\\sigma^2 + \\varepsilon}}$\n",
    "2. $\\nabla_{\\delta} {\\mathcal L} = (\\nabla_{y} {\\mathcal L})^T \\cdot (1)_{i=1}^{n} = \\sum_{i=1}^n (\\nabla_{y} {\\mathcal L})_i$\n",
    "3. $\\nabla_{X} {\\mathcal L} = \\nabla_{y} {\\mathcal L} \\cdot \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\varepsilon}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Задание 2. Вывод инициализации весов линейного слоя при использовании ReLU в качестве функции активации (1 балл)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Рассмотрим полносвязную нейронную сеть с функцией активации $g(y)$. Пусть сеть состоит из $L$ слоев и размер входа слоя $l$ равен $n_l\\ \\ (l = \\overline{1, L})$.\n",
    "\n",
    "Обозначим за $x^l \\in \\mathbb{R}^{n_{l}}$ вход слоя $l$, за $y^l \\in \\mathbb{R}^{n_{l+1}}$ — выход слоя $l$, за $W^l \\in \\mathbb{R}^{n_{l+1} \\times n_{l}}$ — веса слоя $l$, за $b^l \\in \\mathbb{R}^{n_{l+1}}$ — вектор сдвига слоя $l$.\n",
    "\n",
    "Тогда\n",
    "$$y^l = W^l x^l + b^l,$$\n",
    "$$x^{l+1} = g(y^l).$$\n",
    "\n",
    "На паре вы выводили хорошую инициализацию для линейного слоя в случае, когда в качестве функции активации $g(y)$ в нейронной сети используется гиперболический тангенс $g(y) = \\tanh(y)$. Сейчас вам нужно сделать подобный вывод для случая, когда в сети в качестве функций активации используется $g(y) = ReLU(y) = \\max(0, y)$.\n",
    "\n",
    "Сделаем следующие предположения насчет того, как распределены веса $W^l$, вектор сдвига $b^l$, входной вектор $x^l$, выходной вектор $y^l$ линейного слоя и градиенты функции потерь $\\frac{\\partial L}{\\partial y^{l}}$ $(l = \\overline{1, L}$):\n",
    "\n",
    "1. Все компоненты в $W^l$ распределены одинаково и независимо друг от друга;\n",
    "2. Все компоненты в $y^l$ распределены одинаково и независимо друг от друга;\n",
    "3. Все компоненты в $x^l$ распределены одинаково и независимо друг от друга;\n",
    "4. Все компоненты в $\\frac{\\partial L}{\\partial y^{l}}$ распределены одинаково и независимо друг от друга;\n",
    "5. Все компоненты в $W^l$ и все компоненты в $x^l$ независимы друг от друга;\n",
    "6. Все компоненты в $W^l$ имеют четную плотность распределения (то есть симметричную относительно нуля: $p_{W^l}(-x) = p_{W^l}(x)$);\n",
    "7. Все компоненты в $W^l$ имеют конечное матожидание;\n",
    "8. Вектор $b^l$ инициализирован нулями.\n",
    "\n",
    "\n",
    "Подсказки:\n",
    "1. Из пунктов 6 и 7 следует, что все компоненты в $W^l$ имеют нулевое среднее ($\\mathbb{E} W^l_{ij} = 0\\ \\ \\forall i = \\overline{1, n_{l+1}}, j = \\overline{1, n_{l}}$) (докажите);\n",
    "2. Из пунктов 6 и 7 следует, что все компоненты в $y^l$ имеют нулевое среднее и четную плотность распределения (докажите)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Ваше решение:__\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Задание 3. Почему функция активации` $ReLU(y) = \\max(0, y)$ `предпочтительней сигмоиды` $\\sigma(y) = \\frac{1}{1 + \\exp(-y)}$ `в нейронных сетях? (0.5 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Дайте развернутый ответ на вопрос \"Почему функция активации $ReLU(y) = \\max(0, y)$ предпочтительней сигмоиды $\\sigma(y) = \\frac{1}{1 + \\exp(-y)}$ в нейронных сетях?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Ваш ответ:__\n",
    "\n",
    "На практике, зачастую, используются именно глубокие нейронные сети. \n",
    "Из курса лекций известно, что $\\sup_{y \\in \\mathbb{R}} \\left| \\frac{d \\, \\sigma}{d \\, y} (y) \\right| = \\frac{1}{4}$.\n",
    "Рассмотрим глубокую сеть с $d$ слоями: ДОПИСАТЬ\n",
    "Тогда будет наблюдаться затухание градиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `Практическая часть (7 баллов)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Реализация нейронной сети (3 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "В этом задании вы обучите полносвязную нейронную сеть распознавать рукописные цифры (а что же еще, если не их :), [почти] самостоятельно реализовав все составляющие алгоритма обучения и предсказания.\n",
    "\n",
    "Для начала нам понадобится реализовать прямой и обратный проход через слои. Наши слои будут соответствовать следующему интерфейсу (на примере \"тождественного\" слоя):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from numpy.typing import NDArray\n",
    "from typing import Tuple, List, Union"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.430582300Z",
     "start_time": "2024-02-22T20:35:32.386176100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.input = None\n",
    "        \n",
    "    def forward(self, input: NDArray) -> NDArray:\n",
    "        raise NotImplementedError(\"forward method not implemented\")\n",
    "    \n",
    "    def backward(self, grad_output: NDArray) -> Tuple[NDArray, NDArray]:\n",
    "        raise NotImplementedError(\"backward method not implemented\")\n",
    "    \n",
    "    def __call__(self, input: NDArray) -> NDArray:\n",
    "        return self.forward(input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.439882900Z",
     "start_time": "2024-02-22T20:35:32.397433200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.441885700Z",
     "start_time": "2024-02-22T20:35:32.404486600Z"
    }
   },
   "outputs": [],
   "source": [
    "class IdentityLayer(Layer):\n",
    "    \"\"\"\n",
    "    A building block. Each layer is capable of performing two things:\n",
    "\n",
    "    - Process input to get output:           \n",
    "    output = layer.forward(input)\n",
    "\n",
    "    - Propagate gradients through itself:    \n",
    "    grad_input = layer.backward(input, grad_output)\n",
    "\n",
    "    Some layers also have learnable parameters.\n",
    "\n",
    "    Modified code from cs.hse DL course *\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Here you can initialize layer parameters (if any) \n",
    "        and auxiliary stuff. You should enumerate all parameters\n",
    "        in self.params\n",
    "        \"\"\"\n",
    "        # An identity layer does nothing\n",
    "        self.params = []\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Takes input data of shape [batch, input_units], \n",
    "        returns output data [batch, output_units]\n",
    "        \"\"\"\n",
    "        # An identity layer just returns whatever it gets as input.\n",
    "        self.input = input\n",
    "        return input\n",
    "\n",
    "    def backward(self, grad_output): \n",
    "        \"\"\"\n",
    "        Performs a backpropagation step through the layer, \n",
    "        with respect to the given input.\n",
    "\n",
    "        To compute loss gradients w.r.t input, \n",
    "        you need to apply chain rule (backprop):\n",
    "\n",
    "        d `loss` / d `input` = (d `loss` / d `layer`) * (d `layer` / d `input`)\n",
    "\n",
    "        Luckily, you already receive d `loss` / d `layer` in argument, \n",
    "        so you only need to multiply it by d `layer` / d `input`.\n",
    "\n",
    "        NB: Sometimes d `layer` / d `input` can be a 3D or even 4D tensor.\n",
    "        So it's better to write down the `loss` differential and extract\n",
    "        d `layer` / d `input` from it so that only 2D tensors were present.\n",
    "\n",
    "        The method returns:\n",
    "        * gradient w.r.t input (will be passed to \n",
    "          previous layer's backward method)\n",
    "        * flattened gradient w.r.t. parameters (with .ravel() \n",
    "          applied to each gradient). \n",
    "          If there are no params, return []\n",
    "        \"\"\"\n",
    "        # The gradient of an identity layer is precisely grad_output\n",
    "        input_dim = self.input.shape[1]\n",
    "\n",
    "        d_layer_d_input = np.eye(input_dim)\n",
    "\n",
    "        return np.dot(grad_output, d_layer_d_input), [] # chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `Слой нелинейности ReLU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Для начала реализуем слой нелинейности $ReLU(y) = \\max(0, y)$. Параметров у слоя нет. Метод `forward` должен вернуть результат поэлементного применения $ReLU$ к входному массиву, метод `backward` — градиент функции потерь по входу слоя. В нуле будем считать производную равной 0. Обратите внимание, что при обратном проходе могут понадобиться величины, посчитанные во время прямого прохода, поэтому их стоит сохранить как атрибут класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.516021Z",
     "start_time": "2024-02-22T20:35:32.408555200Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    \"\"\"\n",
    "    Modified code from cs.hse DL course *\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs\"\"\"\n",
    "        self.params = [] # ReLU has no parameters\n",
    "        self.input = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Apply elementwise ReLU to [batch, num_units] matrix\"\"\"\n",
    "        \n",
    "        # max(0, x) = 1/2 (x + |x|)\n",
    "        \n",
    "        self.input = input\n",
    "        \n",
    "        return np.maximum(0, input)\n",
    "        \n",
    "        \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"Compute gradient of loss w.r.t. ReLU input\n",
    "        grad_output shape: [batch, num_units]\n",
    "        output 1 shape: [batch, num_units]\n",
    "        output 2: []\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.input is None:\n",
    "            raise RuntimeError('Call forward method before calling backward')\n",
    "        \n",
    "        # print(f\"{grad_output.shape=}\")\n",
    "        \n",
    "        return np.where(self.input > 0, grad_output, np.zeros_like(self.input)), []\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Relu()'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 1],\n       [0, 1],\n       [0, 0]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([\n",
    "    [1, 2],\n",
    "    [-1, 3],\n",
    "    [-2, -1]\n",
    "])\n",
    "\n",
    "np.where(arr > 0, np.ones_like(arr), np.zeros_like(arr))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.538022500Z",
     "start_time": "2024-02-22T20:35:32.412079800Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `Полносвязный слой`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Далее реализуем полносвязный слой без нелинейности. У слоя два параметра: матрица весов и вектор сдвига.\n",
    "\n",
    "Обратите внимание на второй аргумент: в нем надо возвращать градиент по всем параметрам в одномерном виде. Для этого надо сначала применить `.ravel()` ко всем градиентам, а затем воспользоваться `np.r_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.546022Z",
     "start_time": "2024-02-22T20:35:32.418361400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 2., 3.])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "np.r_[np.eye(3).ravel(), np.arange(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.547935Z",
     "start_time": "2024-02-22T20:35:32.425638300Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    \"\"\"\n",
    "    Modified code from cs.hse DL course *\n",
    "    \"\"\"\n",
    "    def __init__(self, input_units, output_units):\n",
    "        \"\"\"\n",
    "        A dense layer is a layer which performs a learned affine transformation:\n",
    "        f(x) = x W + b\n",
    "        \"\"\"\n",
    "        # initialize weights with small random numbers from normal distribution\n",
    "        self.weights = np.random.randn(input_units, output_units) * 0.2\n",
    "        self.biases = np.zeros(output_units)\n",
    "        self.params = [self.weights, self.biases]\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Perform an affine transformation:\n",
    "        f(x) = x W + b\n",
    "        \n",
    "        input shape: [batch, input_units]\n",
    "        output shape: [batch, output units]\n",
    "        \"\"\"\n",
    "        \n",
    "        self.input = input\n",
    "        \n",
    "        return input @ self.weights + self.biases\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        compute gradients\n",
    "        grad_output shape: [batch, output_units]\n",
    "        output shapes: [batch, input_units], [num_params]\n",
    "        \n",
    "        hint: use function np.r_\n",
    "        np.r_[np.arange(3), np.arange(3)] = [0, 1, 2, 0, 1, 2]\n",
    "        \"\"\"\n",
    "        \n",
    "        # print(f\"DEBUG: {(self.input[:, :, None] @ grad_output[:, None, :]).shape=}\")\n",
    "        d_loss_d_w = self.input[:, :, None] @ grad_output[:, None, :]\n",
    "        d_loss_d_b = grad_output\n",
    "        d_loss_d_x = grad_output @ self.weights.T\n",
    "        \n",
    "        return d_loss_d_x, [d_loss_d_w, d_loss_d_b]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Dense({self.weights.shape[0]}, {self.weights.shape[1]})'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[10, 20],\n       [20, 40],\n       [30, 60]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = np.array([10, 20])\n",
    "\n",
    "x[:, None] @ y[None, :]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.562114200Z",
     "start_time": "2024-02-22T20:35:32.427321900Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `Проверка градиента`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Проверим правильность реализации с помощью функции численной проверки градиента. Функция `eval_numerical_gradient` принимает на вход callable объект `f` (функцию от одного аргумента-матрицы) и аргумент `x` и вычисляет приближенный градиент функции `f` в точке `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.565115500Z",
     "start_time": "2024-02-22T20:35:32.434589800Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_numerical_gradient(f, x, verbose=False, h=0.00001):\n",
    "    \"\"\"\n",
    "    Evaluates gradient df/dx via finite differences:\n",
    "    df/dx ~ (f(x+h) - f(x-h)) / 2h\n",
    "    Adopted from https://github.com/ddtm/dl-course/\n",
    "    \"\"\"\n",
    "    fx = f(x) # evaluate function value at original point\n",
    "    grad = np.zeros_like(x)\n",
    "    # iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        # evaluate function at x+h\n",
    "        ix = it.multi_index\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h # increment by h\n",
    "        fxph = f(x) # evalute f(x + h)\n",
    "        x[ix] = oldval - h\n",
    "        fxmh = f(x) # evaluate f(x - h)\n",
    "        x[ix] = oldval # restore\n",
    "\n",
    "        # compute the partial derivative with centered formula\n",
    "        grad[ix] = (fxph - fxmh) / (2 * h) # the slope\n",
    "        if verbose:\n",
    "            print (ix, grad[ix])\n",
    "        it.iternext() # step to next dimension\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Вычислите аналитический и численный градиенты по входу слоя ReLU от функции\n",
    "$$ f(y) = \\sum_i y_i, \\quad y = ReLU(x) $$\n",
    "\n",
    "Выпишите аналитический градиент в этой ячейке:\n",
    "Пусть $x = (x_1, \\ldots, x_n)$\n",
    "\n",
    "$$ f(x) = \\sum_i \\left( ReLU(x) \\right)_i = \\sum_i max(0, x_i)$$\n",
    "$$f: \\mathbb{R} ^ {n \\times m} \\to \\mathbb{R}^{m}$$\n",
    "\n",
    "$$\\nabla_{x} f = \\chi (x), \\text{где } \\chi (s) = \\begin{cases} 1 \\; & s > 0 \\\\ 0 \\; & s \\le 0 \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Следующая ячейка после заполнения должна не выдавать ошибку :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.590116400Z",
     "start_time": "2024-02-22T20:35:32.436884900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads.shape=(10, 12)\tnumeric_grads.shape=(10, 12)\n"
     ]
    }
   ],
   "source": [
    "relu = ReLU()\n",
    "points = np.linspace(-1, 1, 10*12).reshape([10, 12])\n",
    "\n",
    "# print(relu.forward(points).shape)\n",
    "\n",
    "### your code here\n",
    "\n",
    "def f(x):\n",
    "    out = relu.forward(x)\n",
    "    return np.sum(out, axis=1)\n",
    "\n",
    "f(points)\n",
    "grads = relu.backward(np.ones((10, 12)))[0]\n",
    "grads\n",
    "# numeric_grads = eval_numerical_gradient(f, points, verbose=True)\n",
    "numeric_grads = np.zeros_like(points)\n",
    "for i in range(points.shape[0]):\n",
    "    numeric_grads[i, :] = eval_numerical_gradient(f, points[i, :].reshape((1, -1)), verbose=False)\n",
    "\n",
    "print(f\"{grads.shape=}\\t{numeric_grads.shape=}\")\n",
    "\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Вычислите аналитический и численный градиенты по входу полносвязного слоя от функции\n",
    "$$ f(y) = \\sum_i y_i, \\quad y = W x + b $$\n",
    "\n",
    "Выпишите аналитический градиент в этой ячейке (советуем выписать градиент через дифференциал функции $f$):\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Следующая ячейка после заполнения должна не выдавать ошибку :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.592113400Z",
     "start_time": "2024-02-22T20:35:32.446376200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads.shape=(10, 12)\tnumeric_grads.shape=(10, 12)\n"
     ]
    }
   ],
   "source": [
    "linear = Dense(12, 32)\n",
    "points = np.linspace(-1, 1, 10*12).reshape([10, 12])\n",
    "\n",
    "def foo(x):\n",
    "    out = linear.forward(x)\n",
    "    return np.sum(out, axis=1)\n",
    "\n",
    "foo(points)\n",
    "grads = linear.backward(np.ones((10, 32)))[0]\n",
    "\n",
    "numeric_grads = np.zeros_like(points)\n",
    "for i in range(10):\n",
    "    numeric_grads[i, :] = eval_numerical_gradient(foo, points[i, :].reshape((1, -1)), verbose=False)\n",
    "\n",
    "print(f\"{grads.shape=}\\t{numeric_grads.shape=}\")\n",
    "\n",
    "# grads - numeric_grads\n",
    "\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0), np.max(np.abs(grads - numeric_grads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `Реализация softmax-слоя и функции потерь`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Для решения задачи многоклассовой классификации обычно используют $softmax$ в качестве нелинейности на последнем слое, чтобы получить вероятности классов для каждого объекта:\n",
    "$$\\hat y = softmax(x)  = \\left \\{\\frac {\\exp(x^i)}{\\sum_{j=1}^K \\exp(x^j)} \\right \\}_{i=1}^K, \\quad K - \\text{число классов.}$$\n",
    "\n",
    "Здесь за $x^i$ мы обозначаем $i$-ый признак объекта $x$.\n",
    "\n",
    "В качестве функции потерь выберем отрицательный логарифм правдоподобия (по английски: negative log likelihood или NLL)\n",
    "$$L(y, \\hat y) = -\\sum_{i=1}^K y^i \\log \\hat y^i,$$\n",
    "где $y^i = 1$, если объект принадлежит $i$-му классу, и $y^i = 0$ иначе.\n",
    "\n",
    "NLL совпадает с выражением для [кросс-энтропии](https://ru.wikipedia.org/wiki/Перекрёстная_энтропия) (в качестве первого распределения берем вырожденное распределение $y$, в качестве второго — предсказанное распределение $\\hat y$). Очевидно, что эту функцию потерь также можно переписать через индексацию, если через $y$ обозначить класс данного объекта:\n",
    "$$L(y, \\hat y) = - \\log \\hat y_{y}$$\n",
    "\n",
    "В таком виде ее удобно реализовывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T13:13:02.970075Z",
     "start_time": "2021-03-03T13:13:02.961134Z"
    },
    "hidden": true
   },
   "source": [
    "Для обучения нейронной сети будем оптимизировать эту функцию потерь по параметрам нейронной сети:\n",
    "\n",
    "$$ \\frac1N \\sum_{i=1}^N L(y_i, \\hat y_i) = \\frac1N \\sum_{i=1}^N L(y_i, \\text{NN}(x_i)) \\rightarrow \\min_{w}\\,,$$\n",
    "где за $x_i$ и $y_i$ мы обозначили признаки и таргет $i$-ого объекта обучающей выборки, за $\\text{NN}$ мы обозначили нейронную сеть, которая по признакам объекта $x_i$ выдает распределение вероятностей $\\hat y_i$, за $w$ мы обозначили все веса нейронной сети, а $N$ — это число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Реализуйте слой `LogSoftmax` (у этого слоя нет параметров). Метод `forward` должен вычислять логарифм от $softmax$, а метод `backward` — пропускать градиенты. В общем случае в промежуточных вычислениях `backward` получится трехмерный тензор, однако для нашей конкретной функции потерь все вычисления можно реализовать в матричном виде.  Поэтому мы будем предполагать, что аргумент `grad_output` — это матрица, у которой в каждой строке только одно ненулевое значение (не обязательно единица).\n",
    "\n",
    "**Пожелание.** Постарайтесь максимально упростить формулу градиентов, чтобы получился лаконичный и стабильный код. Большие и страшные реализации часто оказываются нестабильными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.779488200Z",
     "start_time": "2024-02-22T20:35:32.452021400Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "# use this function instead of np.log(np.sum(np.exp(...))) because it is more stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.790489200Z",
     "start_time": "2024-02-22T20:35:32.550940800Z"
    }
   },
   "outputs": [],
   "source": [
    "class LogSoftmax:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.input = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Applies softmax to each row and then applies component-wise log\n",
    "        Input shape: [batch, num_units]\n",
    "        Output shape: [batch, num_units]\n",
    "        \"\"\"\n",
    "        self.input = input\n",
    "        \n",
    "        return input - logsumexp(input, axis=-1, keepdims=True)\n",
    "        \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Propagartes gradients.\n",
    "        Assumes that each row of grad_output contains only 1 \n",
    "        non-zero element\n",
    "        Input shape: [batch, num_units]\n",
    "        Output shape: [batch, num_units]\n",
    "        Do not forget to return [] as second value (grad w.r.t. params)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.input is None:\n",
    "            raise RuntimeError('Call forward method before calling backward')\n",
    "        \n",
    "        exp_arr = np.exp(self.input)\n",
    "        \n",
    "        exp_sum = np.sum(exp_arr, axis=-1, keepdims=True)\n",
    "        grad_output_sum = np.sum(grad_output, axis=-1, keepdims=True)\n",
    "        \n",
    "        d_loss_d_x = grad_output - exp_arr * (grad_output_sum / exp_sum)\n",
    "        \n",
    "        return d_loss_d_x, []\n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'LogSoftmax()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Реализуйте функцию потерь и градиенты функции потерь. Во время вычисления NLL усредняйте (а не суммируйте) значения функции потерь по батчу. Обычно так делают для того, чтобы при двух запусках обучения нейронной сети с разными размерами батча получаемые значения функции потерь у этих сетей были сравнимы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.793487100Z",
     "start_time": "2024-02-22T20:35:32.553803Z"
    }
   },
   "outputs": [],
   "source": [
    "def NLL(activations, target):\n",
    "    \"\"\"\n",
    "    Returns negative log-likelihood of target under model represented by\n",
    "    activations (log probabilities of classes, it's just output of LogSoftmax layer).\n",
    "    `activations` has shape [batch, num_classes], `target` has shape [batch]\n",
    "    Output shape: 1 (scalar).\n",
    "    \"\"\"\n",
    "    \n",
    "    return -np.mean(activations[np.arange(len(target)), target])\n",
    "\n",
    "\n",
    "def grad_NLL(activations, target):\n",
    "    \"\"\"\n",
    "    Returns gradient of negative log-likelihood w.r.t. activations.\n",
    "    each arg has shape [batch, num_classes]\n",
    "    output shape: [batch, num-classes]\n",
    "    \"\"\"\n",
    "    \n",
    "    ohe_target = np.zeros_like(activations)\n",
    "    ohe_target[np.arange(len(target)), target] = 1\n",
    "    \n",
    "    return -(ohe_target - np.exp(activations)) / len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Наконец, выполните проверку `LogSoftmax`-слоя, используя функцию потерь и ее градиент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.824488500Z",
     "start_time": "2024-02-22T20:35:32.558114400Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 50\n",
    "d = 10\n",
    "lsm = LogSoftmax()\n",
    "np.random.seed(42)\n",
    "target = np.random.choice(d, size=n)\n",
    "points = np.random.uniform(-1, 1, n*d).reshape([n, d])\n",
    "\n",
    "### your code here\n",
    "\n",
    "def foo(x):\n",
    "    # print(f\"{x.shape=}\")\n",
    "    return NLL(lsm.forward(x), target)\n",
    "\n",
    "pred = lsm.forward(points)\n",
    "NLL(pred, target)\n",
    "f(points[0, :].reshape((1, -1)))\n",
    "grads, _ = lsm.backward(grad_NLL(pred, target))\n",
    "\n",
    "numeric_grads = eval_numerical_gradient(foo, points, verbose=False)\n",
    "\n",
    "# np.max(np.abs(grads - numeric_grads))\n",
    "\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Загрузка данных`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Мы реализаовали все архитектурные составляющие нашей нейронной сети. Осталось загрузить данные и обучить модель. Мы будем работать с датасетом `digits`, каждый объект в котором — это 8x8 изображение рукописной цифры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:32.931139100Z",
     "start_time": "2024-02-22T20:35:32.598487800Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.341855100Z",
     "start_time": "2024-02-22T20:35:32.908139500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.363853600Z",
     "start_time": "2024-02-22T20:35:33.289916600Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.380854Z",
     "start_time": "2024-02-22T20:35:33.312959400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((1797, 64), (1797,))"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Разделим данные на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.539177300Z",
     "start_time": "2024-02-22T20:35:33.316852600Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.542176500Z",
     "start_time": "2024-02-22T20:35:33.486872300Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.545176500Z",
     "start_time": "2024-02-22T20:35:33.490886100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((1347, 64), (450, 64))"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Сборка и обучение нейронной сети (0.8 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "В нашей реализации мы представляем нейронную сеть в виде списка ее слоев. Например, следующая функция конструирует нейронную сеть заданной ширины (то есть с заданным размером скрытых слоев) и глубины (то есть с заданным количеством слоев) с заданным размером входа и выхода, а также с заданной функцией активации между линейными слоями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.547175500Z",
     "start_time": "2024-02-22T20:35:33.494617600Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_network(input_size, hidden_layers_size, output_size, n_layers=3, activation_class=ReLU):\n",
    "    network = []\n",
    "\n",
    "    for layer_idx in range(n_layers):\n",
    "        # Compute sizes of current linear layer\n",
    "        layer_in = input_size if layer_idx == 0 else hidden_layers_size\n",
    "        layer_out = output_size if layer_idx == n_layers - 1 else hidden_layers_size\n",
    "        \n",
    "        # Add linear layer to the network\n",
    "        network.append(Dense(layer_in, layer_out))\n",
    "\n",
    "        # Add activation after each layer except the last one\n",
    "        if layer_idx != n_layers - 1:\n",
    "            network.append(activation_class())\n",
    "\n",
    "    # Add LogSoftmax layer to the network\n",
    "    network.append(LogSoftmax())\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.549176Z",
     "start_time": "2024-02-22T20:35:33.498528600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Dense(64, 32), Relu(), Dense(32, 32), Relu(), Dense(32, 10), LogSoftmax()]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "hidden_layers_size = 32\n",
    "output_size = 10\n",
    "\n",
    "network = make_network(input_size, hidden_layers_size, output_size, 3, ReLU)\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Реализуйте функцию, которая выполнет прямой проход по нейронной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.566175900Z",
     "start_time": "2024-02-22T20:35:33.503290400Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward(network: List[Layer], X):\n",
    "    \"\"\"\n",
    "    Perform forward pass through the network.\n",
    "    \n",
    "    network: list of layers\n",
    "    X: raw data\n",
    "    X shape: [batch, features_num]\n",
    "\n",
    "    output: \n",
    "    output shape: [batch, out_features_num]\n",
    "    \"\"\"\n",
    "    \n",
    "    for layer in network:\n",
    "        X = layer.forward(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Для проверки, хорошо ли сеть обучилась, нам понадобится вычислять долю правильных ответов (accuracy) на данной выборке. Для этого реализуйте функцию, которая делает предсказания на каждом объекте (логично в качестве предсказания на очередном объекте выдавать тот класс, для которого предсказанный логарифм вероятности максимален):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.680175900Z",
     "start_time": "2024-02-22T20:35:33.509976400Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(network: List[Layer], X):\n",
    "    \"\"\"\n",
    "    Returns predictions for each object in X.\n",
    "    \n",
    "    network: list of layers\n",
    "    X: raw data\n",
    "    X shape: [batch, features_num]\n",
    "\n",
    "    output: array of classes, each from 0 to 9\n",
    "    output shape: [batch]\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = forward(network, X)\n",
    "    \n",
    "    return np.argmax(pred, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Мы будем обучать параметры нейросети с помощью готовой функции оптимизации из модуля `scipy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.683175900Z",
     "start_time": "2024-02-22T20:35:33.511490500Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true,
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.710176600Z",
     "start_time": "2024-02-22T20:35:33.515012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function minimize in module scipy.optimize._minimize:\n",
      "\n",
      "minimize(fun, x0, args=(), method=None, jac=None, hess=None, hessp=None, bounds=None, constraints=(), tol=None, callback=None, options=None)\n",
      "    Minimization of scalar function of one or more variables.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fun : callable\n",
      "        The objective function to be minimized.\n",
      "    \n",
      "            ``fun(x, *args) -> float``\n",
      "    \n",
      "        where ``x`` is a 1-D array with shape (n,) and ``args``\n",
      "        is a tuple of the fixed parameters needed to completely\n",
      "        specify the function.\n",
      "    x0 : ndarray, shape (n,)\n",
      "        Initial guess. Array of real elements of size (n,),\n",
      "        where ``n`` is the number of independent variables.\n",
      "    args : tuple, optional\n",
      "        Extra arguments passed to the objective function and its\n",
      "        derivatives (`fun`, `jac` and `hess` functions).\n",
      "    method : str or callable, optional\n",
      "        Type of solver.  Should be one of\n",
      "    \n",
      "            - 'Nelder-Mead' :ref:`(see here) <optimize.minimize-neldermead>`\n",
      "            - 'Powell'      :ref:`(see here) <optimize.minimize-powell>`\n",
      "            - 'CG'          :ref:`(see here) <optimize.minimize-cg>`\n",
      "            - 'BFGS'        :ref:`(see here) <optimize.minimize-bfgs>`\n",
      "            - 'Newton-CG'   :ref:`(see here) <optimize.minimize-newtoncg>`\n",
      "            - 'L-BFGS-B'    :ref:`(see here) <optimize.minimize-lbfgsb>`\n",
      "            - 'TNC'         :ref:`(see here) <optimize.minimize-tnc>`\n",
      "            - 'COBYLA'      :ref:`(see here) <optimize.minimize-cobyla>`\n",
      "            - 'SLSQP'       :ref:`(see here) <optimize.minimize-slsqp>`\n",
      "            - 'trust-constr':ref:`(see here) <optimize.minimize-trustconstr>`\n",
      "            - 'dogleg'      :ref:`(see here) <optimize.minimize-dogleg>`\n",
      "            - 'trust-ncg'   :ref:`(see here) <optimize.minimize-trustncg>`\n",
      "            - 'trust-exact' :ref:`(see here) <optimize.minimize-trustexact>`\n",
      "            - 'trust-krylov' :ref:`(see here) <optimize.minimize-trustkrylov>`\n",
      "            - custom - a callable object, see below for description.\n",
      "    \n",
      "        If not given, chosen to be one of ``BFGS``, ``L-BFGS-B``, ``SLSQP``,\n",
      "        depending on whether or not the problem has constraints or bounds.\n",
      "    jac : {callable,  '2-point', '3-point', 'cs', bool}, optional\n",
      "        Method for computing the gradient vector. Only for CG, BFGS,\n",
      "        Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg, trust-ncg, trust-krylov,\n",
      "        trust-exact and trust-constr.\n",
      "        If it is a callable, it should be a function that returns the gradient\n",
      "        vector:\n",
      "    \n",
      "            ``jac(x, *args) -> array_like, shape (n,)``\n",
      "    \n",
      "        where ``x`` is an array with shape (n,) and ``args`` is a tuple with\n",
      "        the fixed parameters. If `jac` is a Boolean and is True, `fun` is\n",
      "        assumed to return a tuple ``(f, g)`` containing the objective\n",
      "        function and the gradient.\n",
      "        Methods 'Newton-CG', 'trust-ncg', 'dogleg', 'trust-exact', and\n",
      "        'trust-krylov' require that either a callable be supplied, or that\n",
      "        `fun` return the objective and gradient.\n",
      "        If None or False, the gradient will be estimated using 2-point finite\n",
      "        difference estimation with an absolute step size.\n",
      "        Alternatively, the keywords  {'2-point', '3-point', 'cs'} can be used\n",
      "        to select a finite difference scheme for numerical estimation of the\n",
      "        gradient with a relative step size. These finite difference schemes\n",
      "        obey any specified `bounds`.\n",
      "    hess : {callable, '2-point', '3-point', 'cs', HessianUpdateStrategy}, optional\n",
      "        Method for computing the Hessian matrix. Only for Newton-CG, dogleg,\n",
      "        trust-ncg, trust-krylov, trust-exact and trust-constr.\n",
      "        If it is callable, it should return the Hessian matrix:\n",
      "    \n",
      "            ``hess(x, *args) -> {LinearOperator, spmatrix, array}, (n, n)``\n",
      "    \n",
      "        where ``x`` is a (n,) ndarray and ``args`` is a tuple with the fixed\n",
      "        parameters.\n",
      "        The keywords {'2-point', '3-point', 'cs'} can also be used to select\n",
      "        a finite difference scheme for numerical estimation of the hessian.\n",
      "        Alternatively, objects implementing the `HessianUpdateStrategy`\n",
      "        interface can be used to approximate the Hessian. Available\n",
      "        quasi-Newton methods implementing this interface are:\n",
      "    \n",
      "            - `BFGS`;\n",
      "            - `SR1`.\n",
      "    \n",
      "        Not all of the options are available for each of the methods; for\n",
      "        availability refer to the notes.\n",
      "    hessp : callable, optional\n",
      "        Hessian of objective function times an arbitrary vector p. Only for\n",
      "        Newton-CG, trust-ncg, trust-krylov, trust-constr.\n",
      "        Only one of `hessp` or `hess` needs to be given. If `hess` is\n",
      "        provided, then `hessp` will be ignored. `hessp` must compute the\n",
      "        Hessian times an arbitrary vector:\n",
      "    \n",
      "            ``hessp(x, p, *args) ->  ndarray shape (n,)``\n",
      "    \n",
      "        where ``x`` is a (n,) ndarray, ``p`` is an arbitrary vector with\n",
      "        dimension (n,) and ``args`` is a tuple with the fixed\n",
      "        parameters.\n",
      "    bounds : sequence or `Bounds`, optional\n",
      "        Bounds on variables for Nelder-Mead, L-BFGS-B, TNC, SLSQP, Powell, and\n",
      "        trust-constr methods. There are two ways to specify the bounds:\n",
      "    \n",
      "            1. Instance of `Bounds` class.\n",
      "            2. Sequence of ``(min, max)`` pairs for each element in `x`. None\n",
      "               is used to specify no bound.\n",
      "    \n",
      "    constraints : {Constraint, dict} or List of {Constraint, dict}, optional\n",
      "        Constraints definition. Only for COBYLA, SLSQP and trust-constr.\n",
      "    \n",
      "        Constraints for 'trust-constr' are defined as a single object or a\n",
      "        list of objects specifying constraints to the optimization problem.\n",
      "        Available constraints are:\n",
      "    \n",
      "            - `LinearConstraint`\n",
      "            - `NonlinearConstraint`\n",
      "    \n",
      "        Constraints for COBYLA, SLSQP are defined as a list of dictionaries.\n",
      "        Each dictionary with fields:\n",
      "    \n",
      "            type : str\n",
      "                Constraint type: 'eq' for equality, 'ineq' for inequality.\n",
      "            fun : callable\n",
      "                The function defining the constraint.\n",
      "            jac : callable, optional\n",
      "                The Jacobian of `fun` (only for SLSQP).\n",
      "            args : sequence, optional\n",
      "                Extra arguments to be passed to the function and Jacobian.\n",
      "    \n",
      "        Equality constraint means that the constraint function result is to\n",
      "        be zero whereas inequality means that it is to be non-negative.\n",
      "        Note that COBYLA only supports inequality constraints.\n",
      "    tol : float, optional\n",
      "        Tolerance for termination. When `tol` is specified, the selected\n",
      "        minimization algorithm sets some relevant solver-specific tolerance(s)\n",
      "        equal to `tol`. For detailed control, use solver-specific\n",
      "        options.\n",
      "    options : dict, optional\n",
      "        A dictionary of solver options. All methods except `TNC` accept the\n",
      "        following generic options:\n",
      "    \n",
      "            maxiter : int\n",
      "                Maximum number of iterations to perform. Depending on the\n",
      "                method each iteration may use several function evaluations.\n",
      "    \n",
      "                For `TNC` use `maxfun` instead of `maxiter`.\n",
      "            disp : bool\n",
      "                Set to True to print convergence messages.\n",
      "    \n",
      "        For method-specific options, see :func:`show_options()`.\n",
      "    callback : callable, optional\n",
      "        Called after each iteration. For 'trust-constr' it is a callable with\n",
      "        the signature:\n",
      "    \n",
      "            ``callback(xk, OptimizeResult state) -> bool``\n",
      "    \n",
      "        where ``xk`` is the current parameter vector. and ``state``\n",
      "        is an `OptimizeResult` object, with the same fields\n",
      "        as the ones from the return. If callback returns True\n",
      "        the algorithm execution is terminated.\n",
      "        For all the other methods, the signature is:\n",
      "    \n",
      "            ``callback(xk)``\n",
      "    \n",
      "        where ``xk`` is the current parameter vector.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res : OptimizeResult\n",
      "        The optimization result represented as a ``OptimizeResult`` object.\n",
      "        Important attributes are: ``x`` the solution array, ``success`` a\n",
      "        Boolean flag indicating if the optimizer exited successfully and\n",
      "        ``message`` which describes the cause of the termination. See\n",
      "        `OptimizeResult` for a description of other attributes.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    minimize_scalar : Interface to minimization algorithms for scalar\n",
      "        univariate functions\n",
      "    show_options : Additional options accepted by the solvers\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This section describes the available solvers that can be selected by the\n",
      "    'method' parameter. The default method is *BFGS*.\n",
      "    \n",
      "    **Unconstrained minimization**\n",
      "    \n",
      "    Method :ref:`CG <optimize.minimize-cg>` uses a nonlinear conjugate\n",
      "    gradient algorithm by Polak and Ribiere, a variant of the\n",
      "    Fletcher-Reeves method described in [5]_ pp.120-122. Only the\n",
      "    first derivatives are used.\n",
      "    \n",
      "    Method :ref:`BFGS <optimize.minimize-bfgs>` uses the quasi-Newton\n",
      "    method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS) [5]_\n",
      "    pp. 136. It uses the first derivatives only. BFGS has proven good\n",
      "    performance even for non-smooth optimizations. This method also\n",
      "    returns an approximation of the Hessian inverse, stored as\n",
      "    `hess_inv` in the OptimizeResult object.\n",
      "    \n",
      "    Method :ref:`Newton-CG <optimize.minimize-newtoncg>` uses a\n",
      "    Newton-CG algorithm [5]_ pp. 168 (also known as the truncated\n",
      "    Newton method). It uses a CG method to the compute the search\n",
      "    direction. See also *TNC* method for a box-constrained\n",
      "    minimization with a similar algorithm. Suitable for large-scale\n",
      "    problems.\n",
      "    \n",
      "    Method :ref:`dogleg <optimize.minimize-dogleg>` uses the dog-leg\n",
      "    trust-region algorithm [5]_ for unconstrained minimization. This\n",
      "    algorithm requires the gradient and Hessian; furthermore the\n",
      "    Hessian is required to be positive definite.\n",
      "    \n",
      "    Method :ref:`trust-ncg <optimize.minimize-trustncg>` uses the\n",
      "    Newton conjugate gradient trust-region algorithm [5]_ for\n",
      "    unconstrained minimization. This algorithm requires the gradient\n",
      "    and either the Hessian or a function that computes the product of\n",
      "    the Hessian with a given vector. Suitable for large-scale problems.\n",
      "    \n",
      "    Method :ref:`trust-krylov <optimize.minimize-trustkrylov>` uses\n",
      "    the Newton GLTR trust-region algorithm [14]_, [15]_ for unconstrained\n",
      "    minimization. This algorithm requires the gradient\n",
      "    and either the Hessian or a function that computes the product of\n",
      "    the Hessian with a given vector. Suitable for large-scale problems.\n",
      "    On indefinite problems it requires usually less iterations than the\n",
      "    `trust-ncg` method and is recommended for medium and large-scale problems.\n",
      "    \n",
      "    Method :ref:`trust-exact <optimize.minimize-trustexact>`\n",
      "    is a trust-region method for unconstrained minimization in which\n",
      "    quadratic subproblems are solved almost exactly [13]_. This\n",
      "    algorithm requires the gradient and the Hessian (which is\n",
      "    *not* required to be positive definite). It is, in many\n",
      "    situations, the Newton method to converge in fewer iterations\n",
      "    and the most recommended for small and medium-size problems.\n",
      "    \n",
      "    **Bound-Constrained minimization**\n",
      "    \n",
      "    Method :ref:`Nelder-Mead <optimize.minimize-neldermead>` uses the\n",
      "    Simplex algorithm [1]_, [2]_. This algorithm is robust in many\n",
      "    applications. However, if numerical computation of derivative can be\n",
      "    trusted, other algorithms using the first and/or second derivatives\n",
      "    information might be preferred for their better performance in\n",
      "    general.\n",
      "    \n",
      "    Method :ref:`L-BFGS-B <optimize.minimize-lbfgsb>` uses the L-BFGS-B\n",
      "    algorithm [6]_, [7]_ for bound constrained minimization.\n",
      "    \n",
      "    Method :ref:`Powell <optimize.minimize-powell>` is a modification\n",
      "    of Powell's method [3]_, [4]_ which is a conjugate direction\n",
      "    method. It performs sequential one-dimensional minimizations along\n",
      "    each vector of the directions set (`direc` field in `options` and\n",
      "    `info`), which is updated at each iteration of the main\n",
      "    minimization loop. The function need not be differentiable, and no\n",
      "    derivatives are taken. If bounds are not provided, then an\n",
      "    unbounded line search will be used. If bounds are provided and\n",
      "    the initial guess is within the bounds, then every function\n",
      "    evaluation throughout the minimization procedure will be within\n",
      "    the bounds. If bounds are provided, the initial guess is outside\n",
      "    the bounds, and `direc` is full rank (default has full rank), then\n",
      "    some function evaluations during the first iteration may be\n",
      "    outside the bounds, but every function evaluation after the first\n",
      "    iteration will be within the bounds. If `direc` is not full rank,\n",
      "    then some parameters may not be optimized and the solution is not\n",
      "    guaranteed to be within the bounds.\n",
      "    \n",
      "    Method :ref:`TNC <optimize.minimize-tnc>` uses a truncated Newton\n",
      "    algorithm [5]_, [8]_ to minimize a function with variables subject\n",
      "    to bounds. This algorithm uses gradient information; it is also\n",
      "    called Newton Conjugate-Gradient. It differs from the *Newton-CG*\n",
      "    method described above as it wraps a C implementation and allows\n",
      "    each variable to be given upper and lower bounds.\n",
      "    \n",
      "    **Constrained Minimization**\n",
      "    \n",
      "    Method :ref:`COBYLA <optimize.minimize-cobyla>` uses the\n",
      "    Constrained Optimization BY Linear Approximation (COBYLA) method\n",
      "    [9]_, [10]_, [11]_. The algorithm is based on linear\n",
      "    approximations to the objective function and each constraint. The\n",
      "    method wraps a FORTRAN implementation of the algorithm. The\n",
      "    constraints functions 'fun' may return either a single number\n",
      "    or an array or list of numbers.\n",
      "    \n",
      "    Method :ref:`SLSQP <optimize.minimize-slsqp>` uses Sequential\n",
      "    Least SQuares Programming to minimize a function of several\n",
      "    variables with any combination of bounds, equality and inequality\n",
      "    constraints. The method wraps the SLSQP Optimization subroutine\n",
      "    originally implemented by Dieter Kraft [12]_. Note that the\n",
      "    wrapper handles infinite values in bounds by converting them into\n",
      "    large floating values.\n",
      "    \n",
      "    Method :ref:`trust-constr <optimize.minimize-trustconstr>` is a\n",
      "    trust-region algorithm for constrained optimization. It swiches\n",
      "    between two implementations depending on the problem definition.\n",
      "    It is the most versatile constrained minimization algorithm\n",
      "    implemented in SciPy and the most appropriate for large-scale problems.\n",
      "    For equality constrained problems it is an implementation of Byrd-Omojokun\n",
      "    Trust-Region SQP method described in [17]_ and in [5]_, p. 549. When\n",
      "    inequality constraints are imposed as well, it swiches to the trust-region\n",
      "    interior point method described in [16]_. This interior point algorithm,\n",
      "    in turn, solves inequality constraints by introducing slack variables\n",
      "    and solving a sequence of equality-constrained barrier problems\n",
      "    for progressively smaller values of the barrier parameter.\n",
      "    The previously described equality constrained SQP method is\n",
      "    used to solve the subproblems with increasing levels of accuracy\n",
      "    as the iterate gets closer to a solution.\n",
      "    \n",
      "    **Finite-Difference Options**\n",
      "    \n",
      "    For Method :ref:`trust-constr <optimize.minimize-trustconstr>`\n",
      "    the gradient and the Hessian may be approximated using\n",
      "    three finite-difference schemes: {'2-point', '3-point', 'cs'}.\n",
      "    The scheme 'cs' is, potentially, the most accurate but it\n",
      "    requires the function to correctly handle complex inputs and to\n",
      "    be differentiable in the complex plane. The scheme '3-point' is more\n",
      "    accurate than '2-point' but requires twice as many operations. If the\n",
      "    gradient is estimated via finite-differences the Hessian must be\n",
      "    estimated using one of the quasi-Newton strategies.\n",
      "    \n",
      "    **Method specific options for the** `hess` **keyword**\n",
      "    \n",
      "    +--------------+------+----------+-------------------------+-----+\n",
      "    | method/Hess  | None | callable | '2-point/'3-point'/'cs' | HUS |\n",
      "    +==============+======+==========+=========================+=====+\n",
      "    | Newton-CG    | x    | (n, n)   | x                       | x   |\n",
      "    |              |      | LO       |                         |     |\n",
      "    +--------------+------+----------+-------------------------+-----+\n",
      "    | dogleg       |      | (n, n)   |                         |     |\n",
      "    +--------------+------+----------+-------------------------+-----+\n",
      "    | trust-ncg    |      | (n, n)   | x                       | x   |\n",
      "    +--------------+------+----------+-------------------------+-----+\n",
      "    | trust-krylov |      | (n, n)   | x                       | x   |\n",
      "    +--------------+------+----------+-------------------------+-----+\n",
      "    | trust-exact  |      | (n, n)   |                         |     |\n",
      "    +--------------+------+----------+-------------------------+-----+\n",
      "    | trust-constr | x    | (n, n)   |  x                      | x   |\n",
      "    |              |      | LO       |                         |     |\n",
      "    |              |      | sp       |                         |     |\n",
      "    +--------------+------+----------+-------------------------+-----+\n",
      "    \n",
      "    where LO=LinearOperator, sp=Sparse matrix, HUS=HessianUpdateStrategy\n",
      "    \n",
      "    **Custom minimizers**\n",
      "    \n",
      "    It may be useful to pass a custom minimization method, for example\n",
      "    when using a frontend to this method such as `scipy.optimize.basinhopping`\n",
      "    or a different library.  You can simply pass a callable as the ``method``\n",
      "    parameter.\n",
      "    \n",
      "    The callable is called as ``method(fun, x0, args, **kwargs, **options)``\n",
      "    where ``kwargs`` corresponds to any other parameters passed to `minimize`\n",
      "    (such as `callback`, `hess`, etc.), except the `options` dict, which has\n",
      "    its contents also passed as `method` parameters pair by pair.  Also, if\n",
      "    `jac` has been passed as a bool type, `jac` and `fun` are mangled so that\n",
      "    `fun` returns just the function values and `jac` is converted to a function\n",
      "    returning the Jacobian.  The method shall return an `OptimizeResult`\n",
      "    object.\n",
      "    \n",
      "    The provided `method` callable must be able to accept (and possibly ignore)\n",
      "    arbitrary parameters; the set of parameters accepted by `minimize` may\n",
      "    expand in future versions and then these parameters will be passed to\n",
      "    the method.  You can find an example in the scipy.optimize tutorial.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Nelder, J A, and R Mead. 1965. A Simplex Method for Function\n",
      "        Minimization. The Computer Journal 7: 308-13.\n",
      "    .. [2] Wright M H. 1996. Direct search methods: Once scorned, now\n",
      "        respectable, in Numerical Analysis 1995: Proceedings of the 1995\n",
      "        Dundee Biennial Conference in Numerical Analysis (Eds. D F\n",
      "        Griffiths and G A Watson). Addison Wesley Longman, Harlow, UK.\n",
      "        191-208.\n",
      "    .. [3] Powell, M J D. 1964. An efficient method for finding the minimum of\n",
      "       a function of several variables without calculating derivatives. The\n",
      "       Computer Journal 7: 155-162.\n",
      "    .. [4] Press W, S A Teukolsky, W T Vetterling and B P Flannery.\n",
      "       Numerical Recipes (any edition), Cambridge University Press.\n",
      "    .. [5] Nocedal, J, and S J Wright. 2006. Numerical Optimization.\n",
      "       Springer New York.\n",
      "    .. [6] Byrd, R H and P Lu and J. Nocedal. 1995. A Limited Memory\n",
      "       Algorithm for Bound Constrained Optimization. SIAM Journal on\n",
      "       Scientific and Statistical Computing 16 (5): 1190-1208.\n",
      "    .. [7] Zhu, C and R H Byrd and J Nocedal. 1997. L-BFGS-B: Algorithm\n",
      "       778: L-BFGS-B, FORTRAN routines for large scale bound constrained\n",
      "       optimization. ACM Transactions on Mathematical Software 23 (4):\n",
      "       550-560.\n",
      "    .. [8] Nash, S G. Newton-Type Minimization Via the Lanczos Method.\n",
      "       1984. SIAM Journal of Numerical Analysis 21: 770-778.\n",
      "    .. [9] Powell, M J D. A direct search optimization method that models\n",
      "       the objective and constraint functions by linear interpolation.\n",
      "       1994. Advances in Optimization and Numerical Analysis, eds. S. Gomez\n",
      "       and J-P Hennart, Kluwer Academic (Dordrecht), 51-67.\n",
      "    .. [10] Powell M J D. Direct search algorithms for optimization\n",
      "       calculations. 1998. Acta Numerica 7: 287-336.\n",
      "    .. [11] Powell M J D. A view of algorithms for optimization without\n",
      "       derivatives. 2007.Cambridge University Technical Report DAMTP\n",
      "       2007/NA03\n",
      "    .. [12] Kraft, D. A software package for sequential quadratic\n",
      "       programming. 1988. Tech. Rep. DFVLR-FB 88-28, DLR German Aerospace\n",
      "       Center -- Institute for Flight Mechanics, Koln, Germany.\n",
      "    .. [13] Conn, A. R., Gould, N. I., and Toint, P. L.\n",
      "       Trust region methods. 2000. Siam. pp. 169-200.\n",
      "    .. [14] F. Lenders, C. Kirches, A. Potschka: \"trlib: A vector-free\n",
      "       implementation of the GLTR method for iterative solution of\n",
      "       the trust region problem\", :arxiv:`1611.04718`\n",
      "    .. [15] N. Gould, S. Lucidi, M. Roma, P. Toint: \"Solving the\n",
      "       Trust-Region Subproblem using the Lanczos Method\",\n",
      "       SIAM J. Optim., 9(2), 504--525, (1999).\n",
      "    .. [16] Byrd, Richard H., Mary E. Hribar, and Jorge Nocedal. 1999.\n",
      "        An interior point algorithm for large-scale nonlinear  programming.\n",
      "        SIAM Journal on Optimization 9.4: 877-900.\n",
      "    .. [17] Lalee, Marucha, Jorge Nocedal, and Todd Plantega. 1998. On the\n",
      "        implementation of an algorithm for large-scale equality constrained\n",
      "        optimization. SIAM Journal on Optimization 8.3: 682-706.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Let us consider the problem of minimizing the Rosenbrock function. This\n",
      "    function (and its respective derivatives) is implemented in `rosen`\n",
      "    (resp. `rosen_der`, `rosen_hess`) in the `scipy.optimize`.\n",
      "    \n",
      "    >>> from scipy.optimize import minimize, rosen, rosen_der\n",
      "    \n",
      "    A simple application of the *Nelder-Mead* method is:\n",
      "    \n",
      "    >>> x0 = [1.3, 0.7, 0.8, 1.9, 1.2]\n",
      "    >>> res = minimize(rosen, x0, method='Nelder-Mead', tol=1e-6)\n",
      "    >>> res.x\n",
      "    array([ 1.,  1.,  1.,  1.,  1.])\n",
      "    \n",
      "    Now using the *BFGS* algorithm, using the first derivative and a few\n",
      "    options:\n",
      "    \n",
      "    >>> res = minimize(rosen, x0, method='BFGS', jac=rosen_der,\n",
      "    ...                options={'gtol': 1e-6, 'disp': True})\n",
      "    Optimization terminated successfully.\n",
      "             Current function value: 0.000000\n",
      "             Iterations: 26\n",
      "             Function evaluations: 31\n",
      "             Gradient evaluations: 31\n",
      "    >>> res.x\n",
      "    array([ 1.,  1.,  1.,  1.,  1.])\n",
      "    >>> print(res.message)\n",
      "    Optimization terminated successfully.\n",
      "    >>> res.hess_inv\n",
      "    array([[ 0.00749589,  0.01255155,  0.02396251,  0.04750988,  0.09495377],  # may vary\n",
      "           [ 0.01255155,  0.02510441,  0.04794055,  0.09502834,  0.18996269],\n",
      "           [ 0.02396251,  0.04794055,  0.09631614,  0.19092151,  0.38165151],\n",
      "           [ 0.04750988,  0.09502834,  0.19092151,  0.38341252,  0.7664427 ],\n",
      "           [ 0.09495377,  0.18996269,  0.38165151,  0.7664427,   1.53713523]])\n",
      "    \n",
      "    \n",
      "    Next, consider a minimization problem with several constraints (namely\n",
      "    Example 16.4 from [5]_). The objective function is:\n",
      "    \n",
      "    >>> fun = lambda x: (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
      "    \n",
      "    There are three constraints defined as:\n",
      "    \n",
      "    >>> cons = ({'type': 'ineq', 'fun': lambda x:  x[0] - 2 * x[1] + 2},\n",
      "    ...         {'type': 'ineq', 'fun': lambda x: -x[0] - 2 * x[1] + 6},\n",
      "    ...         {'type': 'ineq', 'fun': lambda x: -x[0] + 2 * x[1] + 2})\n",
      "    \n",
      "    And variables must be positive, hence the following bounds:\n",
      "    \n",
      "    >>> bnds = ((0, None), (0, None))\n",
      "    \n",
      "    The optimization problem is solved using the SLSQP method as:\n",
      "    \n",
      "    >>> res = minimize(fun, (2, 0), method='SLSQP', bounds=bnds,\n",
      "    ...                constraints=cons)\n",
      "    \n",
      "    It should converge to the theoretical solution (1.4 ,1.7).\n"
     ]
    }
   ],
   "source": [
    "help(minimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Эта функция имеет стандартный интерфейс: нужно передать callable объект, который вычисляет значение и градиент целевой функции, а также точку старта оптимизации — начальное приближение (одномерный `numpy`-массив). Поэтому нам понадобятся функции для сбора и задания всех весов нашей нейросети (именно для них мы всегда записывали параметры слоя в список `layer.params`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.736176100Z",
     "start_time": "2024-02-22T20:35:33.518887500Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weights(network):\n",
    "    weights = []\n",
    "    for layer in network:\n",
    "        for param in layer.params:\n",
    "            weights += param.ravel().tolist()\n",
    "    return np.array(weights)\n",
    "\n",
    "\n",
    "def set_weights(weights, network):\n",
    "    i = 0\n",
    "    for layer in network:\n",
    "        for param in layer.params:\n",
    "            l = param.size\n",
    "            param[:] = weights[i:i+l].reshape(param.shape)\n",
    "            i += l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Вам нужно реализовать ту самую функцию, которую мы будем передавать в `minimize`. Эта функция должна брать на вход текущую точку (вектор всех параметров), а также список дополнительных параметров (мы будем передавать через них нашу сеть и обучающие данные) и возвращать значение критерия качества (NLL) и его градиент по параметрам модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:49:44.625088300Z",
     "start_time": "2024-02-22T20:49:44.408079400Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_loss_grad(weights, args):\n",
    "    \"\"\"\n",
    "    takes current weights and computes cross-entropy and gradients\n",
    "    weights shape: [num_parameters]\n",
    "    output 1: loss (scalar)\n",
    "    output 2: gradint w.r.t. weights, shape: [num_parameters]\n",
    "    \n",
    "    hint: firstly perform forward pass through the whole network\n",
    "    then compute loss and its gradients\n",
    "    then perform backward pass, transmitting first baskward output\n",
    "    to the previos layer and saving second baskward output in a list\n",
    "    finally flatten all the gradients in this list\n",
    "    (in the order from the first to the last layer)\n",
    "    \n",
    "    Do not forget to set weights of the network!\n",
    "    \"\"\"\n",
    "    network, X, y = args\n",
    "    \n",
    "    set_weights(weights, network)\n",
    "    \n",
    "    activations = forward(network, X)\n",
    "    loss = NLL(activations, y)\n",
    "    \n",
    "    weights_grad_arrays = []\n",
    "    \n",
    "    d_loss_d_input = grad_NLL(activations, y)\n",
    "    for layer in reversed(network):\n",
    "        d_loss_d_input, d_loss_d_layer = layer.backward(d_loss_d_input)\n",
    "        if isinstance(layer, Dense):\n",
    "            # print(f\"{layer=}\\tdW shape = {d_loss_d_layer[0].shape}\\tdb shape = {d_loss_d_layer[1].shape}\")\n",
    "            # weights_grad += (np.sum(d_loss_d_layer[0], axis=0).ravel().tolist())\n",
    "            # weights_grad += (np.sum(d_loss_d_layer[1], axis=0).ravel().tolist())\n",
    "            weights_grad_arrays.append(np.sum(d_loss_d_layer[1], axis=0).ravel().tolist())\n",
    "            weights_grad_arrays.append(np.sum(d_loss_d_layer[0], axis=0).ravel().tolist())\n",
    "        else:\n",
    "            pass\n",
    "            # print(f\"{layer=}\")\n",
    "        # weights_grad += d_loss_d_layer\n",
    "    \n",
    "    weights_grad_arrays.reverse()\n",
    "    weights_grad = []\n",
    "    for wg in weights_grad_arrays:\n",
    "        weights_grad += wg\n",
    "    \n",
    "    # print(f\"Mean abs grad value: {np.mean(np.abs(weights_grad))}\\tMax abs grad value: {np.max(np.abs(weights_grad))}\")\n",
    "    # print(f\"Loss = {loss}\")\n",
    "    \n",
    "    return loss, np.array(weights_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь мы готовы обучать нашу нейросеть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:33.754176500Z",
     "start_time": "2024-02-22T20:35:33.529525400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.24345654,  0.0318925 , -0.1785575 , ...,  0.        ,\n        0.        ,  0.        ])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = make_network(input_size, hidden_layers_size, output_size, 4, ReLU)\n",
    "weights = get_weights(network)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:34.410177100Z",
     "start_time": "2024-02-22T20:35:33.533177600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean abs grad value: 0.15340477001013422\tMax abs grad value: 5.291832429785735\n",
      "Loss = 7.84179800521077\n",
      "Mean abs grad value: 0.07783937649530127\tMax abs grad value: 3.1555811508574187\n",
      "Loss = 4.528161491489495\n",
      "Mean abs grad value: 0.044536486850613274\tMax abs grad value: 1.5010411961140449\n",
      "Loss = 3.1760988255803912\n",
      "Mean abs grad value: 0.028259092627371477\tMax abs grad value: 0.7895081078713467\n",
      "Loss = 2.5445978117885293\n",
      "Mean abs grad value: 0.015165246868045022\tMax abs grad value: 0.41055570065473224\n",
      "Loss = 2.044048448866195\n",
      "Mean abs grad value: 0.015447990070182483\tMax abs grad value: 0.40904501382725433\n",
      "Loss = 1.8102615916378773\n",
      "Mean abs grad value: 0.011331760837494997\tMax abs grad value: 0.20678658209654258\n",
      "Loss = 1.6464966592072274\n",
      "Mean abs grad value: 0.012854064788375414\tMax abs grad value: 0.2902116257329788\n",
      "Loss = 1.4514818111190175\n",
      "Mean abs grad value: 0.01833634628122404\tMax abs grad value: 0.579517980376759\n",
      "Loss = 1.2918698869386742\n",
      "Mean abs grad value: 0.00940146721570531\tMax abs grad value: 0.3057787626584435\n",
      "Loss = 1.1323128232555983\n",
      "Mean abs grad value: 0.01047925394132103\tMax abs grad value: 0.24554550948868165\n",
      "Loss = 1.0415766497326557\n",
      "Mean abs grad value: 0.01022607681703539\tMax abs grad value: 0.2662919668130094\n",
      "Loss = 0.8945428423921266\n",
      "Mean abs grad value: 0.009844060870257937\tMax abs grad value: 0.28755282057051995\n",
      "Loss = 0.7309220524062707\n",
      "Mean abs grad value: 0.015246006269360785\tMax abs grad value: 0.6174322317268321\n",
      "Loss = 0.6352986444779207\n",
      "Mean abs grad value: 0.006301211692281334\tMax abs grad value: 0.17088236945273508\n",
      "Loss = 0.5553002699162671\n",
      "Mean abs grad value: 0.006130141642715498\tMax abs grad value: 0.15530681517583814\n",
      "Loss = 0.5294588214791462\n",
      "Mean abs grad value: 0.007211954200711834\tMax abs grad value: 0.26066022376052006\n",
      "Loss = 0.4406193139644995\n",
      "Mean abs grad value: 0.008113989011478489\tMax abs grad value: 0.29442172603345934\n",
      "Loss = 0.3638924018919222\n",
      "Mean abs grad value: 0.007532638063615997\tMax abs grad value: 0.24237137155200447\n",
      "Loss = 0.31156393703143365\n",
      "Mean abs grad value: 0.0037496067353040784\tMax abs grad value: 0.12079807480780536\n",
      "Loss = 0.27577025011374695\n",
      "Mean abs grad value: 0.003149303970865288\tMax abs grad value: 0.10254645683205209\n",
      "Loss = 0.2550293265303047\n",
      "Mean abs grad value: 0.004453263968277269\tMax abs grad value: 0.13749586415713538\n",
      "Loss = 0.2310058268337779\n",
      "Mean abs grad value: 0.0055652106863808585\tMax abs grad value: 0.17138830362563637\n",
      "Loss = 0.21549877676333742\n",
      "Mean abs grad value: 0.003215563208314256\tMax abs grad value: 0.08656192457922345\n",
      "Loss = 0.19558677911930553\n",
      "Mean abs grad value: 0.0025702806377638954\tMax abs grad value: 0.05870648321412247\n",
      "Loss = 0.17124144811970374\n",
      "Mean abs grad value: 0.003305546291834035\tMax abs grad value: 0.09499206100779668\n",
      "Loss = 0.15296012644616588\n",
      "Mean abs grad value: 0.0045460451045023775\tMax abs grad value: 0.14603215758506422\n",
      "Loss = 0.14327669080762953\n",
      "Mean abs grad value: 0.002394239212516696\tMax abs grad value: 0.07964654099663757\n",
      "Loss = 0.1334005532668292\n",
      "Mean abs grad value: 0.00229905149968262\tMax abs grad value: 0.062377464489503584\n",
      "Loss = 0.12665720394159774\n",
      "Mean abs grad value: 0.002543558806309205\tMax abs grad value: 0.07397656655857363\n",
      "Loss = 0.12069685628930828\n",
      "Mean abs grad value: 0.003587271642237439\tMax abs grad value: 0.12885678787448773\n",
      "Loss = 0.10247919574828006\n",
      "Mean abs grad value: 0.004176581913676911\tMax abs grad value: 0.12213770066207601\n",
      "Loss = 0.09382424616903345\n",
      "Mean abs grad value: 0.002187573072196556\tMax abs grad value: 0.04813842880887811\n",
      "Loss = 0.08377773745481101\n",
      "Mean abs grad value: 0.0018796427698223922\tMax abs grad value: 0.049704257418766724\n",
      "Loss = 0.07637263440890019\n",
      "Mean abs grad value: 0.0019232344952003055\tMax abs grad value: 0.05237491553951673\n",
      "Loss = 0.06890459838665032\n",
      "Mean abs grad value: 0.005500227540422424\tMax abs grad value: 0.17170994731840356\n",
      "Loss = 0.06349916637363122\n",
      "Mean abs grad value: 0.0015358526246418871\tMax abs grad value: 0.05159149211647827\n",
      "Loss = 0.051315588724034425\n",
      "Mean abs grad value: 0.001278743722920223\tMax abs grad value: 0.02764798340344605\n",
      "Loss = 0.048967749101301916\n",
      "Mean abs grad value: 0.0014008092137973\tMax abs grad value: 0.03653898378086003\n",
      "Loss = 0.045552292218879756\n",
      "Mean abs grad value: 0.0016412033293371608\tMax abs grad value: 0.044956581979174806\n",
      "Loss = 0.03969086647812847\n",
      "Mean abs grad value: 0.0031728115273631373\tMax abs grad value: 0.09968135055921228\n",
      "Loss = 0.03577844295990729\n",
      "Mean abs grad value: 0.0013193581386024306\tMax abs grad value: 0.03672206930361144\n",
      "Loss = 0.029516529131101112\n",
      "Mean abs grad value: 0.000956642493774663\tMax abs grad value: 0.019101246597844814\n",
      "Loss = 0.02630855164810914\n",
      "Mean abs grad value: 0.0014082780744864708\tMax abs grad value: 0.03667107405401581\n",
      "Loss = 0.02307106870566372\n",
      "Mean abs grad value: 0.0010109311984903757\tMax abs grad value: 0.020932983470053977\n",
      "Loss = 0.020358631811751467\n",
      "Mean abs grad value: 0.0008323301501890415\tMax abs grad value: 0.02050994491825361\n",
      "Loss = 0.017901127004266076\n",
      "Mean abs grad value: 0.0008012469744264671\tMax abs grad value: 0.03843223570624026\n",
      "Loss = 0.014492728439166916\n",
      "Mean abs grad value: 0.0017351216790483534\tMax abs grad value: 0.05250738950571737\n",
      "Loss = 0.013699722213727974\n"
     ]
    }
   ],
   "source": [
    "res = minimize(\n",
    "    compute_loss_grad, weights,       # fun and start point\n",
    "    args=[network, X_train, y_train], # args passed to fun\n",
    "    method=\"L-BFGS-B\",                    # optimization method\n",
    "    jac=True,                         # says that gradient is computed in fun,\n",
    "    options={'disp': True},\n",
    "    tol=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:34.414349800Z",
     "start_time": "2024-02-22T20:35:34.393791900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['fun', 'jac', 'nfev', 'njev', 'nit', 'status', 'message', 'x', 'success', 'hess_inv'])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true,
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:34.446349800Z",
     "start_time": "2024-02-22T20:35:34.396540800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "47"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"nit\"] # number of iterations (should be >> 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:34.449350200Z",
     "start_time": "2024-02-22T20:35:34.400756400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"success\"] # should be True"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"message\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:34.451349400Z",
     "start_time": "2024-02-22T20:35:34.404539700Z"
    }
   },
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:34.456350400Z",
     "start_time": "2024-02-22T20:35:34.409176400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.24345654,  0.0318925 , -0.1785575 , ..., -0.10180675,\n        0.02298701, -0.08482258])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"x\"] # leraned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Выведите качество на обучении (`X_train`, `y_train`) и на контроле (`X_test`, `y_test`). Не забудьте установить веса!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 9 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax = plt.subplots(nrows=3, ncols=3, figsize=(10, 10))\n",
    "\n",
    "for i in range(9):\n",
    "    ax[divmod(i, 3)].imshow(X[i, :].reshape((8, 8)), cmap=plt.get_cmap(\"gray\"))\n",
    "    ax[divmod(i, 3)].set_title(y[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:35.267618Z",
     "start_time": "2024-02-22T20:35:34.414349800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:35.275530900Z",
     "start_time": "2024-02-22T20:35:35.265579900Z"
    }
   },
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Dense(64, 32),\n Relu(),\n Dense(32, 32),\n Relu(),\n Dense(32, 32),\n Relu(),\n Dense(32, 10),\n LogSoftmax()]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:35.289296400Z",
     "start_time": "2024-02-22T20:35:35.269627300Z"
    }
   },
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:35.296295300Z",
     "start_time": "2024-02-22T20:35:35.272529900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train NLL: 0.0136997\t\tTest NLL: 0.2608697\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.940\n"
     ]
    }
   ],
   "source": [
    "set_weights(weights=res[\"x\"], network=network)\n",
    "\n",
    "train_NLL = NLL(forward(network, X_train), y_train)\n",
    "test_NLL = NLL(forward(network, X_test), y_test)\n",
    "\n",
    "print(f\"Train NLL: {train_NLL:.7f}\\t\\tTest NLL: {test_NLL:.7f}\")\n",
    "\n",
    "train_accuracy = accuracy_score(y_true=y_train, y_pred=predict(network, X_train))\n",
    "test_accuracy = accuracy_score(y_true=y_test, y_pred=predict(network, X_test))\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy:.3f}\\t\\tTest accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "У `minimize` есть также аргумент `callback` — в нее можно передать функцию, которая будет вызываться после каждой итерации оптимизации. Такую функцию удобно оформить в виде метода класса, который будет сохранять качество на обучении контроле после каждой итерации. Реализуйте этот метод в классе `Callback`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:35.401295500Z",
     "start_time": "2024-02-22T20:35:35.281278700Z"
    }
   },
   "outputs": [],
   "source": [
    "class Callback:\n",
    "    def __init__(self, network, X_train, y_train, X_test, y_test, print=False):\n",
    "        self.network = network\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.print = print\n",
    "        self.train_acc = []\n",
    "        self.test_acc = []\n",
    "        self.train_NLL = []\n",
    "        self.test_NLL = []\n",
    "        \n",
    "    def call(self, weights):\n",
    "        \"\"\"\n",
    "        Computes quality on train and test set with given weights\n",
    "        and saves to self.train_acc and self.test_acc.\n",
    "        If self.print is True, also prints these 2 values\n",
    "        \"\"\"\n",
    "        \n",
    "        train_NLL = NLL(forward(network, X_train), y_train)\n",
    "        test_NLL = NLL(forward(network, X_test), y_test)\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_true=y_train, y_pred=predict(network, X_train))\n",
    "        test_accuracy = accuracy_score(y_true=y_test, y_pred=predict(network, X_test))\n",
    "        \n",
    "        self.train_acc.append(train_accuracy)\n",
    "        self.test_acc.append(test_accuracy)\n",
    "        self.train_NLL.append(train_NLL)\n",
    "        self.test_NLL.append(test_NLL)\n",
    "        \n",
    "        if self.print:\n",
    "            print(f\"Train accuracy: {train_accuracy:.3f}\\t\\tTest accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:36.999487600Z",
     "start_time": "2024-02-22T20:35:35.287296300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean abs grad value: 0.15340477001013422\tMax abs grad value: 5.291832429785735\n",
      "Loss = 7.84179800521077\n",
      "Mean abs grad value: 0.07783937649530127\tMax abs grad value: 3.1555811508574187\n",
      "Loss = 4.528161491489495\n",
      "Train accuracy: 0.134\t\tTest accuracy: 0.140\n",
      "Mean abs grad value: 0.044536486850613274\tMax abs grad value: 1.5010411961140449\n",
      "Loss = 3.1760988255803912\n",
      "Train accuracy: 0.143\t\tTest accuracy: 0.160\n",
      "Mean abs grad value: 0.028259092627371477\tMax abs grad value: 0.7895081078713467\n",
      "Loss = 2.5445978117885293\n",
      "Train accuracy: 0.203\t\tTest accuracy: 0.231\n",
      "Mean abs grad value: 0.015165246868045022\tMax abs grad value: 0.41055570065473224\n",
      "Loss = 2.044048448866195\n",
      "Train accuracy: 0.281\t\tTest accuracy: 0.309\n",
      "Mean abs grad value: 0.015447990070182483\tMax abs grad value: 0.40904501382725433\n",
      "Loss = 1.8102615916378773\n",
      "Train accuracy: 0.358\t\tTest accuracy: 0.360\n",
      "Mean abs grad value: 0.011331760837494997\tMax abs grad value: 0.20678658209654258\n",
      "Loss = 1.6464966592072274\n",
      "Train accuracy: 0.439\t\tTest accuracy: 0.458\n",
      "Mean abs grad value: 0.012854064788375414\tMax abs grad value: 0.2902116257329788\n",
      "Loss = 1.4514818111190175\n",
      "Train accuracy: 0.471\t\tTest accuracy: 0.531\n",
      "Mean abs grad value: 0.01833634628122404\tMax abs grad value: 0.579517980376759\n",
      "Loss = 1.2918698869386742\n",
      "Train accuracy: 0.518\t\tTest accuracy: 0.513\n",
      "Mean abs grad value: 0.00940146721570531\tMax abs grad value: 0.3057787626584435\n",
      "Loss = 1.1323128232555983\n",
      "Train accuracy: 0.589\t\tTest accuracy: 0.582\n",
      "Mean abs grad value: 0.01047925394132103\tMax abs grad value: 0.24554550948868165\n",
      "Loss = 1.0415766497326557\n",
      "Train accuracy: 0.631\t\tTest accuracy: 0.624\n",
      "Mean abs grad value: 0.01022607681703539\tMax abs grad value: 0.2662919668130094\n",
      "Loss = 0.8945428423921266\n",
      "Train accuracy: 0.688\t\tTest accuracy: 0.669\n",
      "Mean abs grad value: 0.009844060870257937\tMax abs grad value: 0.28755282057051995\n",
      "Loss = 0.7309220524062707\n",
      "Train accuracy: 0.762\t\tTest accuracy: 0.709\n",
      "Mean abs grad value: 0.015246006269360785\tMax abs grad value: 0.6174322317268321\n",
      "Loss = 0.6352986444779207\n",
      "Train accuracy: 0.797\t\tTest accuracy: 0.747\n",
      "Mean abs grad value: 0.006301211692281334\tMax abs grad value: 0.17088236945273508\n",
      "Loss = 0.5553002699162671\n",
      "Train accuracy: 0.826\t\tTest accuracy: 0.767\n",
      "Mean abs grad value: 0.006130141642715498\tMax abs grad value: 0.15530681517583814\n",
      "Loss = 0.5294588214791462\n",
      "Train accuracy: 0.837\t\tTest accuracy: 0.773\n",
      "Mean abs grad value: 0.007211954200711834\tMax abs grad value: 0.26066022376052006\n",
      "Loss = 0.4406193139644995\n",
      "Train accuracy: 0.861\t\tTest accuracy: 0.802\n",
      "Mean abs grad value: 0.008113989011478489\tMax abs grad value: 0.29442172603345934\n",
      "Loss = 0.3638924018919222\n",
      "Train accuracy: 0.888\t\tTest accuracy: 0.831\n",
      "Mean abs grad value: 0.007532638063615997\tMax abs grad value: 0.24237137155200447\n",
      "Loss = 0.31156393703143365\n",
      "Train accuracy: 0.909\t\tTest accuracy: 0.847\n",
      "Mean abs grad value: 0.0037496067353040784\tMax abs grad value: 0.12079807480780536\n",
      "Loss = 0.27577025011374695\n",
      "Train accuracy: 0.915\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.003149303970865288\tMax abs grad value: 0.10254645683205209\n",
      "Loss = 0.2550293265303047\n",
      "Train accuracy: 0.921\t\tTest accuracy: 0.840\n",
      "Mean abs grad value: 0.004453263968277269\tMax abs grad value: 0.13749586415713538\n",
      "Loss = 0.2310058268337779\n",
      "Train accuracy: 0.927\t\tTest accuracy: 0.851\n",
      "Mean abs grad value: 0.0055652106863808585\tMax abs grad value: 0.17138830362563637\n",
      "Loss = 0.21549877676333742\n",
      "Train accuracy: 0.933\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.003215563208314256\tMax abs grad value: 0.08656192457922345\n",
      "Loss = 0.19558677911930553\n",
      "Train accuracy: 0.939\t\tTest accuracy: 0.873\n",
      "Mean abs grad value: 0.0025702806377638954\tMax abs grad value: 0.05870648321412247\n",
      "Loss = 0.17124144811970374\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.003305546291834035\tMax abs grad value: 0.09499206100779668\n",
      "Loss = 0.15296012644616588\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.0045460451045023775\tMax abs grad value: 0.14603215758506422\n",
      "Loss = 0.14327669080762953\n",
      "Train accuracy: 0.950\t\tTest accuracy: 0.898\n",
      "Mean abs grad value: 0.002394239212516696\tMax abs grad value: 0.07964654099663757\n",
      "Loss = 0.1334005532668292\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.00229905149968262\tMax abs grad value: 0.062377464489503584\n",
      "Loss = 0.12665720394159774\n",
      "Train accuracy: 0.956\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.002543558806309205\tMax abs grad value: 0.07397656655857363\n",
      "Loss = 0.12069685628930828\n",
      "Train accuracy: 0.959\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.003587271642237439\tMax abs grad value: 0.12885678787448773\n",
      "Loss = 0.10247919574828006\n",
      "Train accuracy: 0.966\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.004176581913676911\tMax abs grad value: 0.12213770066207601\n",
      "Loss = 0.09382424616903345\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.002187573072196556\tMax abs grad value: 0.04813842880887811\n",
      "Loss = 0.08377773745481101\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.0018796427698223922\tMax abs grad value: 0.049704257418766724\n",
      "Loss = 0.07637263440890019\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.0019232344952003055\tMax abs grad value: 0.05237491553951673\n",
      "Loss = 0.06890459838665032\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.005500227540422424\tMax abs grad value: 0.17170994731840356\n",
      "Loss = 0.06349916637363122\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0015358526246418871\tMax abs grad value: 0.05159149211647827\n",
      "Loss = 0.051315588724034425\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.001278743722920223\tMax abs grad value: 0.02764798340344605\n",
      "Loss = 0.048967749101301916\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0014008092137973\tMax abs grad value: 0.03653898378086003\n",
      "Loss = 0.045552292218879756\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0016412033293371608\tMax abs grad value: 0.044956581979174806\n",
      "Loss = 0.03969086647812847\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0031728115273631373\tMax abs grad value: 0.09968135055921228\n",
      "Loss = 0.03577844295990729\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0013193581386024306\tMax abs grad value: 0.03672206930361144\n",
      "Loss = 0.029516529131101112\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.000956642493774663\tMax abs grad value: 0.019101246597844814\n",
      "Loss = 0.02630855164810914\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0014082780744864708\tMax abs grad value: 0.03667107405401581\n",
      "Loss = 0.02307106870566372\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0010109311984903757\tMax abs grad value: 0.020932983470053977\n",
      "Loss = 0.020358631811751467\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0008323301501890415\tMax abs grad value: 0.02050994491825361\n",
      "Loss = 0.017901127004266076\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0008012469744264671\tMax abs grad value: 0.03843223570624026\n",
      "Loss = 0.014492728439166916\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0017351216790483534\tMax abs grad value: 0.05250738950571737\n",
      "Loss = 0.013699722213727974\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0006163555095605661\tMax abs grad value: 0.016874499658377923\n",
      "Loss = 0.011394689849157287\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0005081843770414639\tMax abs grad value: 0.013650459250595198\n",
      "Loss = 0.010576943645339159\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0006795622849241224\tMax abs grad value: 0.01936401028489053\n",
      "Loss = 0.008827548378581204\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0006600132200556575\tMax abs grad value: 0.02053349747171103\n",
      "Loss = 0.007071766914061128\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0021055929781676488\tMax abs grad value: 0.07580258580540741\n",
      "Loss = 0.008074820165371142\n",
      "Mean abs grad value: 0.0009056474363775121\tMax abs grad value: 0.025462634364902606\n",
      "Loss = 0.00637111460291464\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0005490897248987736\tMax abs grad value: 0.019008059073641007\n",
      "Loss = 0.005379578179885075\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00041420681974087395\tMax abs grad value: 0.009404405368253807\n",
      "Loss = 0.00435141924354056\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00041550247710082027\tMax abs grad value: 0.010309408619972536\n",
      "Loss = 0.0035248138876100023\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0004338118458441641\tMax abs grad value: 0.01032274471686743\n",
      "Loss = 0.0026838425769940043\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00026025528900496594\tMax abs grad value: 0.006511581532099714\n",
      "Loss = 0.0020565314783984197\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00019121491062229875\tMax abs grad value: 0.004735348318301008\n",
      "Loss = 0.0017384568435481129\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00012724349428460402\tMax abs grad value: 0.0032171347029343687\n",
      "Loss = 0.001342020594046179\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00011018297283224168\tMax abs grad value: 0.002158761690715258\n",
      "Loss = 0.0009058483290302871\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0001458655271703046\tMax abs grad value: 0.004058473278951618\n",
      "Loss = 0.0006411691217145268\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 5.415577077344569e-05\tMax abs grad value: 0.0014017014531129506\n",
      "Loss = 0.00041089663340724024\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 4.0361210702871195e-05\tMax abs grad value: 0.0008145001310452205\n",
      "Loss = 0.00032118571565102947\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 6.81889547408574e-05\tMax abs grad value: 0.0021158070232871447\n",
      "Loss = 0.0002368204777696718\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 3.741599345277728e-05\tMax abs grad value: 0.001093200228671157\n",
      "Loss = 0.00017928632342820695\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.7395665805824252e-05\tMax abs grad value: 0.0006394664986293109\n",
      "Loss = 0.00015590869395121294\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.924838079813352e-05\tMax abs grad value: 0.00039420748880327595\n",
      "Loss = 0.00012056094037141069\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.7822324210183452e-05\tMax abs grad value: 0.0011591466710371581\n",
      "Loss = 9.16079994100605e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.1924858691365097e-05\tMax abs grad value: 0.0002879416372472044\n",
      "Loss = 5.5501044838169753e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 9.029089489003011e-06\tMax abs grad value: 0.00019214692837694905\n",
      "Loss = 4.3518253505578196e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 6.7733842832993805e-06\tMax abs grad value: 0.0001713086533130415\n",
      "Loss = 2.4618778090714442e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 3.931229558756752e-06\tMax abs grad value: 9.140578563576739e-05\n",
      "Loss = 1.3285022250382984e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.218253274530642e-06\tMax abs grad value: 4.651709113754843e-05\n",
      "Loss = 9.372004894119286e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 1.6148563595499272e-06\tMax abs grad value: 3.384657978970658e-05\n",
      "Loss = 5.850780699549198e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 1.6831690907614093e-06\tMax abs grad value: 3.672622282194447e-05\n",
      "Loss = 3.649321643669161e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 6.022913507871252e-07\tMax abs grad value: 1.4273679815677984e-05\n",
      "Loss = 1.8396471517204561e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 3.141331389249362e-07\tMax abs grad value: 7.205345460987875e-06\n",
      "Loss = 1.257677984409594e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n"
     ]
    }
   ],
   "source": [
    "cb = Callback(network, X_train, y_train, X_test, y_test, print=True)\n",
    "\n",
    "res = minimize(\n",
    "    compute_loss_grad, weights,  \n",
    "    args=[network, X_train, y_train], \n",
    "    method=\"L-BFGS-B\",\n",
    "    jac=True,\n",
    "    callback=cb.call\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Изобразите на графике кривую качества на обучени и контроле по итерациям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:37.148229200Z",
     "start_time": "2024-02-22T20:35:36.997486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.plot(cb.train_acc, label=\"train acc\")\n",
    "ax.plot(cb.test_acc, label=\"test acc\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Эксперименты с числом слоев (0.6 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ясно, что из-за случайного начального приближения с каждым запуском обучения мы будем получать различное качество. Попробуем обучить нашу нейросеть с разным числом слоев несколько раз.\n",
    "\n",
    "Заполните матрицы `accs_train` и `accs_test`. В позиции `[i, j]` должна стоять величина доли правильных ответов сети с $i+1$ полносвязными слоями при $j$-м запуске (все запуски идентичны)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "[Dense(64, 32),\n Relu(),\n Dense(32, 32),\n Relu(),\n Dense(32, 32),\n Relu(),\n Dense(32, 10),\n LogSoftmax()]"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:37.155176900Z",
     "start_time": "2024-02-22T20:35:37.146183600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:37.167184300Z",
     "start_time": "2024-02-22T20:35:37.150237600Z"
    }
   },
   "outputs": [],
   "source": [
    "accs_train = np.zeros((5, 5))\n",
    "accs_test = np.zeros((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def train_network(network: List[Layer], history: bool = False) -> List[Layer]:\n",
    "    cb = Callback(network, X_train, y_train, X_test, y_test, print=True) if history else lambda *args: None\n",
    "\n",
    "    weights = get_weights(network)\n",
    "    res = minimize(\n",
    "        compute_loss_grad, weights,  \n",
    "        args=[network, X_train, y_train], \n",
    "        method=\"L-BFGS-B\",\n",
    "        jac=True,\n",
    "        callback=cb.call\n",
    "    )\n",
    "    \n",
    "    if not res[\"success\"]:\n",
    "        raise RuntimeError(f\"Optimization failure: {res['message']}\")\n",
    "    \n",
    "    if history:\n",
    "        return network, cb\n",
    "    else:\n",
    "        return network"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:35:37.182184200Z",
     "start_time": "2024-02-22T20:35:37.153290600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:36:07.192813500Z",
     "start_time": "2024-02-22T20:35:37.156184800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean abs grad value: 0.3571221491939798\tMax abs grad value: 2.336214662771033\n",
      "Loss = 11.30880755523398\n",
      "Mean abs grad value: 0.4944266121999155\tMax abs grad value: 3.418783524981766\n",
      "Loss = 10.444915503731194\n",
      "Train accuracy: 0.221\t\tTest accuracy: 0.227\n",
      "Mean abs grad value: 0.31998064088744244\tMax abs grad value: 2.024138457038147\n",
      "Loss = 7.139882817086166\n",
      "Train accuracy: 0.319\t\tTest accuracy: 0.287\n",
      "Mean abs grad value: 0.34616119845887044\tMax abs grad value: 2.3376882697474515\n",
      "Loss = 5.548641803814539\n",
      "Train accuracy: 0.385\t\tTest accuracy: 0.342\n",
      "Mean abs grad value: 0.7622023934038692\tMax abs grad value: 6.365396934678746\n",
      "Loss = 12.921513671694175\n",
      "Mean abs grad value: 0.34447606551514415\tMax abs grad value: 2.1412232019935407\n",
      "Loss = 4.010812099840388\n",
      "Train accuracy: 0.405\t\tTest accuracy: 0.360\n",
      "Mean abs grad value: 0.7698065185967279\tMax abs grad value: 8.887323264071469\n",
      "Loss = 26.048585014898467\n",
      "Mean abs grad value: 0.23883339847610718\tMax abs grad value: 2.058992989419664\n",
      "Loss = 3.2871005886183893\n",
      "Train accuracy: 0.452\t\tTest accuracy: 0.424\n",
      "Mean abs grad value: 0.14269546681489412\tMax abs grad value: 0.839907506591252\n",
      "Loss = 2.449943350664016\n",
      "Train accuracy: 0.540\t\tTest accuracy: 0.531\n",
      "Mean abs grad value: 0.16378220037387198\tMax abs grad value: 1.1671531796368781\n",
      "Loss = 1.943143061625895\n",
      "Train accuracy: 0.601\t\tTest accuracy: 0.591\n",
      "Mean abs grad value: 0.08763607400439696\tMax abs grad value: 0.40412882345247136\n",
      "Loss = 1.2824675750171664\n",
      "Train accuracy: 0.729\t\tTest accuracy: 0.713\n",
      "Mean abs grad value: 0.05681705469625189\tMax abs grad value: 0.31275908971421407\n",
      "Loss = 0.9035818019873645\n",
      "Train accuracy: 0.807\t\tTest accuracy: 0.789\n",
      "Mean abs grad value: 0.039720925463893136\tMax abs grad value: 0.29998007814845906\n",
      "Loss = 0.5931482443240822\n",
      "Train accuracy: 0.869\t\tTest accuracy: 0.858\n",
      "Mean abs grad value: 0.041477365684407366\tMax abs grad value: 0.38588254027399166\n",
      "Loss = 0.4225036478620945\n",
      "Train accuracy: 0.897\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.01847830538263631\tMax abs grad value: 0.14934086100983415\n",
      "Loss = 0.31604284662856247\n",
      "Train accuracy: 0.926\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0107870286429756\tMax abs grad value: 0.07873530014639436\n",
      "Loss = 0.2711634750151713\n",
      "Train accuracy: 0.936\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.009915089335296313\tMax abs grad value: 0.09560302020191194\n",
      "Loss = 0.2421180152090896\n",
      "Train accuracy: 0.946\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.009240381704273675\tMax abs grad value: 0.06641116748639551\n",
      "Loss = 0.21148138610342548\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.011624140636657336\tMax abs grad value: 0.07337776751619814\n",
      "Loss = 0.18698353789475988\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.007530196207547277\tMax abs grad value: 0.05884677424484227\n",
      "Loss = 0.16379028067983648\n",
      "Train accuracy: 0.965\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0075627835263414765\tMax abs grad value: 0.07913169811534716\n",
      "Loss = 0.12001692385391792\n",
      "Train accuracy: 0.972\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.01792032757337522\tMax abs grad value: 0.17753759983664671\n",
      "Loss = 0.11429896346940441\n",
      "Mean abs grad value: 0.009013651985987713\tMax abs grad value: 0.06776668257500189\n",
      "Loss = 0.10653713609543837\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.011377774119770269\tMax abs grad value: 0.09594478046044408\n",
      "Loss = 0.0927870379641572\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.006224595128683238\tMax abs grad value: 0.04766690266718913\n",
      "Loss = 0.07684845562976374\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.004849845299228646\tMax abs grad value: 0.03562518286374061\n",
      "Loss = 0.06830827878235345\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.004152123497321399\tMax abs grad value: 0.03429353824795742\n",
      "Loss = 0.057228087372323926\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.007111413638051097\tMax abs grad value: 0.05401831573856122\n",
      "Loss = 0.043824130982573685\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00550273027773475\tMax abs grad value: 0.04720965545184036\n",
      "Loss = 0.03746972556410263\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.002695857109048836\tMax abs grad value: 0.027055765036770128\n",
      "Loss = 0.03180227090617175\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002323137580390919\tMax abs grad value: 0.020218216411876804\n",
      "Loss = 0.028920738436040434\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.002285386164782457\tMax abs grad value: 0.01942270740732818\n",
      "Loss = 0.025982413601546222\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0022779075317994157\tMax abs grad value: 0.021183907431742685\n",
      "Loss = 0.02018780769980319\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.006534806592210354\tMax abs grad value: 0.044582446832222844\n",
      "Loss = 0.01888101421534983\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0021254411611892135\tMax abs grad value: 0.021049414436790797\n",
      "Loss = 0.013341618295968676\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00143310172831619\tMax abs grad value: 0.010601716055250326\n",
      "Loss = 0.012351834790800027\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0012262287954356494\tMax abs grad value: 0.00985327237360685\n",
      "Loss = 0.011549266719230232\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0010684429940016377\tMax abs grad value: 0.010397238599311907\n",
      "Loss = 0.009991514507138026\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0010425159257447616\tMax abs grad value: 0.010788950428409726\n",
      "Loss = 0.007734999530458672\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.003103883878027656\tMax abs grad value: 0.021652856021987632\n",
      "Loss = 0.007606472964700881\n",
      "Mean abs grad value: 0.0013647290706162362\tMax abs grad value: 0.011195232380639653\n",
      "Loss = 0.006644807227460009\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0007198266079624933\tMax abs grad value: 0.006128796650690232\n",
      "Loss = 0.00582871384691029\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0006250956765183114\tMax abs grad value: 0.007186153868772921\n",
      "Loss = 0.005186584294884686\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0019448618010467337\tMax abs grad value: 0.018556264535073204\n",
      "Loss = 0.005119424545382705\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00072275805249039\tMax abs grad value: 0.005813381409284253\n",
      "Loss = 0.0044406952879362\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00046311470343218315\tMax abs grad value: 0.003954638586632619\n",
      "Loss = 0.004232652058802167\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0005260869853710753\tMax abs grad value: 0.004678962709811207\n",
      "Loss = 0.003949096883414743\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0005813987260811154\tMax abs grad value: 0.005224867167573971\n",
      "Loss = 0.003640011139915716\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0017754135017224724\tMax abs grad value: 0.01579554710987324\n",
      "Loss = 0.0038237025497668267\n",
      "Mean abs grad value: 0.0007735967090078699\tMax abs grad value: 0.006026552017732124\n",
      "Loss = 0.0034182829549664977\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0004067491460922492\tMax abs grad value: 0.0034957738879524613\n",
      "Loss = 0.0030244491734394865\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00029073420452590116\tMax abs grad value: 0.003016954119005354\n",
      "Loss = 0.0027744845001040634\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00029720582579017646\tMax abs grad value: 0.0025380918139311453\n",
      "Loss = 0.0024917166942552997\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00034356347981546125\tMax abs grad value: 0.0030323544146714887\n",
      "Loss = 0.0021259758040292807\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0014304234109290674\tMax abs grad value: 0.015630667900318418\n",
      "Loss = 0.0028389261274272657\n",
      "Mean abs grad value: 0.0003657107758439446\tMax abs grad value: 0.003729501889338421\n",
      "Loss = 0.001914849725032267\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00026368080901908515\tMax abs grad value: 0.001976215972419824\n",
      "Loss = 0.0016194592904857114\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00017770905151407208\tMax abs grad value: 0.001902509112140957\n",
      "Loss = 0.0013767390130780145\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0004929530779401088\tMax abs grad value: 0.004746630916151997\n",
      "Loss = 0.0011892184943923735\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00020033268818226603\tMax abs grad value: 0.0013641742409480201\n",
      "Loss = 0.0009456973537948626\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0001552896867358312\tMax abs grad value: 0.0012842374373287222\n",
      "Loss = 0.0008681238497978603\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0001358095051968138\tMax abs grad value: 0.0011247680589243168\n",
      "Loss = 0.0007410643484394171\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00012137118340811633\tMax abs grad value: 0.0012207285657294643\n",
      "Loss = 0.0006657744503133289\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0001162097775836325\tMax abs grad value: 0.0010944800053893989\n",
      "Loss = 0.0005940737136013266\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 8.643226192255504e-05\tMax abs grad value: 0.0007021595815494666\n",
      "Loss = 0.0005479108177399805\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 6.338315872901183e-05\tMax abs grad value: 0.0005567828562074292\n",
      "Loss = 0.000449234530906966\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 6.863322308007704e-05\tMax abs grad value: 0.0007094913588448358\n",
      "Loss = 0.0003892930014108492\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 6.733283198800464e-05\tMax abs grad value: 0.000510209053195002\n",
      "Loss = 0.0002960617211317454\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 8.557949763631101e-05\tMax abs grad value: 0.0006948426430628677\n",
      "Loss = 0.00022017048744570397\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 3.446508534390713e-05\tMax abs grad value: 0.0002923038160486492\n",
      "Loss = 0.00015380045487321846\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 2.0390268650233542e-05\tMax abs grad value: 0.00018063309252385937\n",
      "Loss = 0.00011824648191466827\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 2.9643074324490248e-05\tMax abs grad value: 0.00032548640031868146\n",
      "Loss = 8.32523409098034e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.6361186764179525e-05\tMax abs grad value: 0.00018261372671077582\n",
      "Loss = 5.314038507626047e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.0904705051784538e-05\tMax abs grad value: 9.046983913718338e-05\n",
      "Loss = 4.512027681740381e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 8.87750332653807e-06\tMax abs grad value: 6.17618870995805e-05\n",
      "Loss = 3.6821713601167935e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 8.02551254446574e-06\tMax abs grad value: 5.845314950558632e-05\n",
      "Loss = 2.9405185965351632e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 7.4013221266973815e-06\tMax abs grad value: 5.236878024557778e-05\n",
      "Loss = 2.017389744839277e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 4.041378698137889e-06\tMax abs grad value: 2.954885344407158e-05\n",
      "Loss = 1.1888016194700934e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 3.1197513394680077e-06\tMax abs grad value: 3.20877884141129e-05\n",
      "Loss = 8.149381355049394e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.569576929022878e-06\tMax abs grad value: 1.3838486332152921e-05\n",
      "Loss = 5.400362137471126e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 9.053289956782276e-07\tMax abs grad value: 8.096044025283197e-06\n",
      "Loss = 3.7892793467768623e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.5967619195314345\tMax abs grad value: 5.654473030864935\n",
      "Loss = 14.351728782081384\n",
      "Mean abs grad value: 0.4283611767234927\tMax abs grad value: 2.693488059610506\n",
      "Loss = 12.09602314787829\n",
      "Train accuracy: 0.215\t\tTest accuracy: 0.227\n",
      "Mean abs grad value: 0.339209203353653\tMax abs grad value: 2.227500155781138\n",
      "Loss = 9.607151463541904\n",
      "Train accuracy: 0.279\t\tTest accuracy: 0.269\n",
      "Mean abs grad value: 0.29272932030123616\tMax abs grad value: 1.724021271774223\n",
      "Loss = 7.58407332754104\n",
      "Train accuracy: 0.323\t\tTest accuracy: 0.291\n",
      "Mean abs grad value: 0.41625043767008\tMax abs grad value: 4.6347742956688505\n",
      "Loss = 5.164106471584332\n",
      "Train accuracy: 0.332\t\tTest accuracy: 0.340\n",
      "Mean abs grad value: 0.6719829876542395\tMax abs grad value: 9.177163270838031\n",
      "Loss = 9.103851676651386\n",
      "Mean abs grad value: 0.34055199547846865\tMax abs grad value: 3.1420352345966607\n",
      "Loss = 4.268356953459971\n",
      "Train accuracy: 0.376\t\tTest accuracy: 0.391\n",
      "Mean abs grad value: 0.2314621358450142\tMax abs grad value: 1.9326651682433518\n",
      "Loss = 3.4471383756295206\n",
      "Train accuracy: 0.474\t\tTest accuracy: 0.456\n",
      "Mean abs grad value: 0.09617502425109695\tMax abs grad value: 0.6350856422221343\n",
      "Loss = 2.306285062130976\n",
      "Train accuracy: 0.578\t\tTest accuracy: 0.540\n",
      "Mean abs grad value: 0.1442942410916003\tMax abs grad value: 1.7993837093727738\n",
      "Loss = 1.7924624625778618\n",
      "Train accuracy: 0.637\t\tTest accuracy: 0.613\n",
      "Mean abs grad value: 0.09436456873655137\tMax abs grad value: 0.6582221338511114\n",
      "Loss = 1.227008968925625\n",
      "Train accuracy: 0.732\t\tTest accuracy: 0.713\n",
      "Mean abs grad value: 0.0688423832266198\tMax abs grad value: 0.5076123676128774\n",
      "Loss = 0.8483194835446701\n",
      "Train accuracy: 0.811\t\tTest accuracy: 0.784\n",
      "Mean abs grad value: 0.03923252055052269\tMax abs grad value: 0.27259618100377025\n",
      "Loss = 0.5611138435251658\n",
      "Train accuracy: 0.875\t\tTest accuracy: 0.840\n",
      "Mean abs grad value: 0.02058842752673438\tMax abs grad value: 0.12589348497128153\n",
      "Loss = 0.3923843400351656\n",
      "Train accuracy: 0.909\t\tTest accuracy: 0.858\n",
      "Mean abs grad value: 0.015621609565087263\tMax abs grad value: 0.09555738960832703\n",
      "Loss = 0.316179858747481\n",
      "Train accuracy: 0.928\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.01945114505419554\tMax abs grad value: 0.20485404649059374\n",
      "Loss = 0.2543013427019013\n",
      "Train accuracy: 0.943\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.015691124264788834\tMax abs grad value: 0.12848385427490314\n",
      "Loss = 0.21548186495154992\n",
      "Train accuracy: 0.946\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.009613121836859346\tMax abs grad value: 0.08019232963572905\n",
      "Loss = 0.16370780890596748\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.008436425010698008\tMax abs grad value: 0.06916214092990604\n",
      "Loss = 0.13646619334139992\n",
      "Train accuracy: 0.965\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.006344694208434873\tMax abs grad value: 0.06353314379690524\n",
      "Loss = 0.11707869507440206\n",
      "Train accuracy: 0.966\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.006193220377311281\tMax abs grad value: 0.04458827767625013\n",
      "Loss = 0.09930829202428958\n",
      "Train accuracy: 0.972\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0125499475721197\tMax abs grad value: 0.10673336653826332\n",
      "Loss = 0.08779936923719465\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00604761987291912\tMax abs grad value: 0.04433136795160175\n",
      "Loss = 0.07422624768756901\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0034279098818910648\tMax abs grad value: 0.029547494455123408\n",
      "Loss = 0.06545318364458058\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.003391820388056527\tMax abs grad value: 0.031160622754734635\n",
      "Loss = 0.05937683369321974\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0110731385910513\tMax abs grad value: 0.11845010705940451\n",
      "Loss = 0.052690831562351985\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00461064422984475\tMax abs grad value: 0.034569814827916864\n",
      "Loss = 0.041940905517516815\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0033944609662566955\tMax abs grad value: 0.028535822851730137\n",
      "Loss = 0.036567652222839996\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0028028859427636312\tMax abs grad value: 0.02820535668320847\n",
      "Loss = 0.031026636271532036\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0041847009010110015\tMax abs grad value: 0.04971855029229379\n",
      "Loss = 0.028274303964846526\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.002362236021953276\tMax abs grad value: 0.022594734831647974\n",
      "Loss = 0.0247535289431426\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0021474647751971534\tMax abs grad value: 0.01618942671002783\n",
      "Loss = 0.021501662521173245\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002290559460547355\tMax abs grad value: 0.020311102028793493\n",
      "Loss = 0.01785454231909021\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00655525171535712\tMax abs grad value: 0.06582286882034186\n",
      "Loss = 0.01780804983952922\n",
      "Mean abs grad value: 0.0032903876092763877\tMax abs grad value: 0.030635562135172798\n",
      "Loss = 0.015544456660842615\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.001655643921363149\tMax abs grad value: 0.013408412336271856\n",
      "Loss = 0.013164130199698082\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0011658530347139363\tMax abs grad value: 0.009776633407190621\n",
      "Loss = 0.011820913254817603\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0013516448672734448\tMax abs grad value: 0.009495316426117145\n",
      "Loss = 0.00956417921722783\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.003521168991306539\tMax abs grad value: 0.031091180389552605\n",
      "Loss = 0.009489612699161145\n",
      "Mean abs grad value: 0.0015285583038557402\tMax abs grad value: 0.013613493494324799\n",
      "Loss = 0.008497939345543581\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0015912581187135751\tMax abs grad value: 0.014240863055685346\n",
      "Loss = 0.007414361627924956\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.000932020204816307\tMax abs grad value: 0.00734956884213872\n",
      "Loss = 0.006536532002650029\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0007979986754514313\tMax abs grad value: 0.006895232810927682\n",
      "Loss = 0.005846346566410337\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.001129521443265458\tMax abs grad value: 0.009391068056119809\n",
      "Loss = 0.0049908932251366885\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0005463597879025605\tMax abs grad value: 0.004068901029360891\n",
      "Loss = 0.004320651938583267\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00045393290183079547\tMax abs grad value: 0.0031964916368969957\n",
      "Loss = 0.00394562810582352\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0003538642866961765\tMax abs grad value: 0.0029306040155130837\n",
      "Loss = 0.003337734747855385\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0014589211421630497\tMax abs grad value: 0.012606513048156357\n",
      "Loss = 0.0034567173105586485\n",
      "Mean abs grad value: 0.0007509427962602278\tMax abs grad value: 0.005637544744417692\n",
      "Loss = 0.0030761032443704524\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0003846220411947999\tMax abs grad value: 0.0035876755990290592\n",
      "Loss = 0.002583995648089705\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0002682112462881491\tMax abs grad value: 0.0026429997727628976\n",
      "Loss = 0.0022636024022898143\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00026653663017138415\tMax abs grad value: 0.0023968615826590986\n",
      "Loss = 0.0018850363346601406\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0008925163289936236\tMax abs grad value: 0.007857392473074688\n",
      "Loss = 0.0018355728044744245\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0002892425269697691\tMax abs grad value: 0.002371254494874575\n",
      "Loss = 0.0013350205203162156\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00021633256308072394\tMax abs grad value: 0.0015139885558367434\n",
      "Loss = 0.0012069118481445901\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00020064074017000496\tMax abs grad value: 0.00162798561530244\n",
      "Loss = 0.0010532813604112797\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00018191270980369746\tMax abs grad value: 0.001912548049493558\n",
      "Loss = 0.0008639403516227272\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0004337611342350923\tMax abs grad value: 0.004331310606619832\n",
      "Loss = 0.0008388623769134368\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00013010037427697453\tMax abs grad value: 0.0011727014881964233\n",
      "Loss = 0.000637349941275516\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 9.223004204026475e-05\tMax abs grad value: 0.0007338233133592691\n",
      "Loss = 0.000589509906815851\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 8.371307718792282e-05\tMax abs grad value: 0.0007704633559310973\n",
      "Loss = 0.0005031868154552448\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.823935711129352e-05\tMax abs grad value: 0.0005671736943155284\n",
      "Loss = 0.0003938727570371066\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00024344194655159123\tMax abs grad value: 0.0015849809030809648\n",
      "Loss = 0.00038014531787460796\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 7.447840617631417e-05\tMax abs grad value: 0.0007038985552038366\n",
      "Loss = 0.0002210486244724279\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.597435703279341e-05\tMax abs grad value: 0.0005120034508019456\n",
      "Loss = 0.00018767602953081335\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.7544267022816435e-05\tMax abs grad value: 0.0003286532983215486\n",
      "Loss = 0.00014288634725503335\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.293652603726321e-05\tMax abs grad value: 0.00026325628162648967\n",
      "Loss = 0.00011493303877445158\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.749982975395938e-05\tMax abs grad value: 0.0001640070532017433\n",
      "Loss = 8.935167793505807e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.556014290454288e-05\tMax abs grad value: 0.00016786569761372526\n",
      "Loss = 7.810535030383845e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.1093064830212828e-05\tMax abs grad value: 0.00011144663573382117\n",
      "Loss = 4.9928010346131606e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.645707874214341e-05\tMax abs grad value: 0.0002898378748440657\n",
      "Loss = 4.2458499781170075e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 8.653384298574574e-06\tMax abs grad value: 0.0001047766238664\n",
      "Loss = 2.525670763719245e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 5.024998626610548e-06\tMax abs grad value: 5.8493001099466476e-05\n",
      "Loss = 1.9627539752789888e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.0238850758414833e-06\tMax abs grad value: 2.6871813603015354e-05\n",
      "Loss = 1.3565518742762643e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.9971249927500218e-06\tMax abs grad value: 1.554260891170328e-05\n",
      "Loss = 8.963452418783125e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 2.0601879733385833e-06\tMax abs grad value: 2.6027638338903176e-05\n",
      "Loss = 5.423170628415286e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 1.3221244894698714e-06\tMax abs grad value: 1.4827186279266503e-05\n",
      "Loss = 2.5240469449302035e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 6.554636055056171e-07\tMax abs grad value: 7.1693806862959685e-06\n",
      "Loss = 1.6679388087780647e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.4936746827051739\tMax abs grad value: 5.178456565274485\n",
      "Loss = 17.183946774856757\n",
      "Mean abs grad value: 0.43323892222481775\tMax abs grad value: 4.269339884976362\n",
      "Loss = 14.348720661141485\n",
      "Train accuracy: 0.081\t\tTest accuracy: 0.089\n",
      "Mean abs grad value: 0.3833611317525912\tMax abs grad value: 1.8662558850237643\n",
      "Loss = 11.381354033059317\n",
      "Train accuracy: 0.149\t\tTest accuracy: 0.176\n",
      "Mean abs grad value: 0.2835024606744536\tMax abs grad value: 1.5847208666667056\n",
      "Loss = 8.940942791440465\n",
      "Train accuracy: 0.215\t\tTest accuracy: 0.231\n",
      "Mean abs grad value: 0.5016836301365944\tMax abs grad value: 6.403884954992484\n",
      "Loss = 7.081812687140826\n",
      "Train accuracy: 0.250\t\tTest accuracy: 0.262\n",
      "Mean abs grad value: 0.30813249990030034\tMax abs grad value: 1.5160600749322422\n",
      "Loss = 3.642490754735578\n",
      "Train accuracy: 0.546\t\tTest accuracy: 0.513\n",
      "Mean abs grad value: 0.18079140337138383\tMax abs grad value: 1.373528129220988\n",
      "Loss = 2.4976074742675634\n",
      "Train accuracy: 0.595\t\tTest accuracy: 0.562\n",
      "Mean abs grad value: 0.10773561748599202\tMax abs grad value: 0.7619702546281832\n",
      "Loss = 1.460189496224772\n",
      "Train accuracy: 0.693\t\tTest accuracy: 0.678\n",
      "Mean abs grad value: 0.06676227010599252\tMax abs grad value: 0.36975387261678977\n",
      "Loss = 1.1841310773885292\n",
      "Train accuracy: 0.730\t\tTest accuracy: 0.727\n",
      "Mean abs grad value: 0.04395462590272944\tMax abs grad value: 0.3152498115994928\n",
      "Loss = 0.9194795032037674\n",
      "Train accuracy: 0.801\t\tTest accuracy: 0.807\n",
      "Mean abs grad value: 0.03163290131348665\tMax abs grad value: 0.217881010131736\n",
      "Loss = 0.6664323716550308\n",
      "Train accuracy: 0.859\t\tTest accuracy: 0.871\n",
      "Mean abs grad value: 0.029369995807199248\tMax abs grad value: 0.2513092999523282\n",
      "Loss = 0.4930050922091297\n",
      "Train accuracy: 0.894\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.018700802518959548\tMax abs grad value: 0.1544751090847612\n",
      "Loss = 0.3899206869826393\n",
      "Train accuracy: 0.919\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.016466595966402348\tMax abs grad value: 0.13420288864464863\n",
      "Loss = 0.31988895307336146\n",
      "Train accuracy: 0.936\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.01747737227875569\tMax abs grad value: 0.11600932991981652\n",
      "Loss = 0.28503440202709784\n",
      "Train accuracy: 0.945\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.01076731091961243\tMax abs grad value: 0.09583930916972679\n",
      "Loss = 0.2557125942259155\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.008735286616684388\tMax abs grad value: 0.06926609044330573\n",
      "Loss = 0.22717066416107567\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.008988538531180241\tMax abs grad value: 0.06699262402931067\n",
      "Loss = 0.18779603196337571\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00973776050248533\tMax abs grad value: 0.0749081426268023\n",
      "Loss = 0.15365787882016005\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.014450789498956645\tMax abs grad value: 0.1141925971972462\n",
      "Loss = 0.1318961320046855\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.006604618771544294\tMax abs grad value: 0.05018152910526359\n",
      "Loss = 0.11154806899233291\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00801467384190972\tMax abs grad value: 0.05475833721077481\n",
      "Loss = 0.09986502572405466\n",
      "Train accuracy: 0.972\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.007825888692862706\tMax abs grad value: 0.060533884121187945\n",
      "Loss = 0.08541190332138919\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.007580272590251342\tMax abs grad value: 0.06201712885862001\n",
      "Loss = 0.07033503963578545\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.011682697528294575\tMax abs grad value: 0.08186756625465644\n",
      "Loss = 0.061139321764315545\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.005663156818110363\tMax abs grad value: 0.03647483264913256\n",
      "Loss = 0.04509173930193233\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0034329939985960553\tMax abs grad value: 0.02176284760949437\n",
      "Loss = 0.036872837617533294\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.005533722520707531\tMax abs grad value: 0.03861567545604897\n",
      "Loss = 0.031107965498552884\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0034590371078056545\tMax abs grad value: 0.03223072799773753\n",
      "Loss = 0.025463993749209334\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.002170925659849486\tMax abs grad value: 0.015695454304169906\n",
      "Loss = 0.023191710694241332\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0018595017696354937\tMax abs grad value: 0.01282948231421182\n",
      "Loss = 0.020289468916335\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.001955128253785275\tMax abs grad value: 0.019868086538609532\n",
      "Loss = 0.01762155903637622\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0041899675463621085\tMax abs grad value: 0.03183652117395946\n",
      "Loss = 0.016127327037997456\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0017975755413370575\tMax abs grad value: 0.016442907203070557\n",
      "Loss = 0.01317732718164962\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0015212991908556918\tMax abs grad value: 0.016980043574359435\n",
      "Loss = 0.011958442119258887\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0013366382386755114\tMax abs grad value: 0.012369250979558934\n",
      "Loss = 0.010009689903665811\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0018800528061176788\tMax abs grad value: 0.01668853819740429\n",
      "Loss = 0.008562082102098939\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0010755444300698323\tMax abs grad value: 0.008225336085949098\n",
      "Loss = 0.0072240601131783695\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.000829939378362245\tMax abs grad value: 0.005819650915934708\n",
      "Loss = 0.006637771840360753\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0006671032694825614\tMax abs grad value: 0.005774727049568247\n",
      "Loss = 0.005730066365825296\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0011774324866082983\tMax abs grad value: 0.009327160621855452\n",
      "Loss = 0.005153881136457311\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0005657985719576927\tMax abs grad value: 0.00422803411176353\n",
      "Loss = 0.00460108380917691\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00044375825997026606\tMax abs grad value: 0.003975166980943348\n",
      "Loss = 0.00426584763213506\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00041566962496508096\tMax abs grad value: 0.0035509937528811816\n",
      "Loss = 0.003816239074718776\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0007898822575598545\tMax abs grad value: 0.007068873534101791\n",
      "Loss = 0.0033819015172383976\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0004861385652386077\tMax abs grad value: 0.004171161085341681\n",
      "Loss = 0.002894357737575005\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0003320890544255268\tMax abs grad value: 0.002226848965695409\n",
      "Loss = 0.002672866706479942\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00032420470399037416\tMax abs grad value: 0.00311698248364927\n",
      "Loss = 0.0023765707086606342\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0005449771144255655\tMax abs grad value: 0.0070830992933693104\n",
      "Loss = 0.0022347596137170397\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00032253307122074887\tMax abs grad value: 0.003503445879324925\n",
      "Loss = 0.0020614366325264473\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00027393764656689104\tMax abs grad value: 0.002040265210596012\n",
      "Loss = 0.0018877372943898155\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0003299303225032646\tMax abs grad value: 0.0035252660631714446\n",
      "Loss = 0.0016670054802832204\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00030085121288871093\tMax abs grad value: 0.0030597380433804882\n",
      "Loss = 0.001399558302918268\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0007050388271433173\tMax abs grad value: 0.0076494511396310826\n",
      "Loss = 0.0015271608067575861\n",
      "Mean abs grad value: 0.0003215816298531108\tMax abs grad value: 0.0036180142983227755\n",
      "Loss = 0.0012675563891405314\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0001744748452164032\tMax abs grad value: 0.002207707178391945\n",
      "Loss = 0.0010843063379802327\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00012506568735055516\tMax abs grad value: 0.0012615323368521984\n",
      "Loss = 0.0009510768882887279\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00011424461549560347\tMax abs grad value: 0.0011048029257088431\n",
      "Loss = 0.0008005597749364739\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0005695744267517718\tMax abs grad value: 0.006571339608109359\n",
      "Loss = 0.0009438857794001239\n",
      "Mean abs grad value: 0.00019682397286639315\tMax abs grad value: 0.001988333862592732\n",
      "Loss = 0.0007212856472695429\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00013405745343911352\tMax abs grad value: 0.0013963788432615613\n",
      "Loss = 0.0006331837446991034\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 7.481734131544264e-05\tMax abs grad value: 0.0007170941022813857\n",
      "Loss = 0.0005476307732032863\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 7.006734469066152e-05\tMax abs grad value: 0.0006995944701323262\n",
      "Loss = 0.0004799639192668866\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 6.656443358209636e-05\tMax abs grad value: 0.0006190579663420549\n",
      "Loss = 0.0004018832740467555\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00033140785696546726\tMax abs grad value: 0.004342183324142907\n",
      "Loss = 0.0005209981827347488\n",
      "Mean abs grad value: 0.0001260366451497231\tMax abs grad value: 0.0014114671220297375\n",
      "Loss = 0.0003688245332818622\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 7.165758921885884e-05\tMax abs grad value: 0.0007422974777463155\n",
      "Loss = 0.00028363843365355454\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 5.024542074995193e-05\tMax abs grad value: 0.0005433793020540419\n",
      "Loss = 0.00022461976248420014\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 3.52476697580244e-05\tMax abs grad value: 0.0002788228394151315\n",
      "Loss = 0.00016438591597722828\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 2.308299912278269e-05\tMax abs grad value: 0.00014212862645348817\n",
      "Loss = 0.000120734115062531\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.559049460058137e-05\tMax abs grad value: 0.00012194178694622672\n",
      "Loss = 8.213643480352305e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 9.81895065626179e-05\tMax abs grad value: 0.0011385011209230534\n",
      "Loss = 0.00013814365838661492\n",
      "Mean abs grad value: 2.227227462188276e-05\tMax abs grad value: 0.00020460115366455358\n",
      "Loss = 7.259384807395973e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 7.84992707607187e-06\tMax abs grad value: 7.360710776698155e-05\n",
      "Loss = 4.4489096009062314e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 5.4986484765599526e-06\tMax abs grad value: 4.432514730506291e-05\n",
      "Loss = 3.42400758653003e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 5.548226515859902e-06\tMax abs grad value: 5.563119756471619e-05\n",
      "Loss = 2.436940797779466e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 9.422785981812453e-06\tMax abs grad value: 7.025339179444681e-05\n",
      "Loss = 1.6982802893971754e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 3.4059383426154036e-06\tMax abs grad value: 2.258782914146227e-05\n",
      "Loss = 1.1092089333537532e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 2.183578567062923e-06\tMax abs grad value: 1.5807088923705476e-05\n",
      "Loss = 8.744350364281166e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.1769141605426832e-06\tMax abs grad value: 1.0181565269778788e-05\n",
      "Loss = 5.667668830266484e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.0940807778594882e-06\tMax abs grad value: 8.444272641523628e-06\n",
      "Loss = 3.6658296523723024e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.8423742539980708\tMax abs grad value: 10.638143088082842\n",
      "Loss = 32.19693674161906\n",
      "Mean abs grad value: 0.5688398019418072\tMax abs grad value: 3.69945041257662\n",
      "Loss = 16.957779204267307\n",
      "Train accuracy: 0.143\t\tTest accuracy: 0.109\n",
      "Mean abs grad value: 0.45064774691675935\tMax abs grad value: 2.8433215406582666\n",
      "Loss = 13.20260872131776\n",
      "Train accuracy: 0.137\t\tTest accuracy: 0.127\n",
      "Mean abs grad value: 0.4028980075744242\tMax abs grad value: 2.6174071173881828\n",
      "Loss = 10.706003947461786\n",
      "Train accuracy: 0.126\t\tTest accuracy: 0.127\n",
      "Mean abs grad value: 0.43877601721994114\tMax abs grad value: 4.139043390375382\n",
      "Loss = 8.492728860786537\n",
      "Train accuracy: 0.134\t\tTest accuracy: 0.140\n",
      "Mean abs grad value: 0.32222878047745485\tMax abs grad value: 2.489548984212938\n",
      "Loss = 6.686927492841668\n",
      "Train accuracy: 0.173\t\tTest accuracy: 0.191\n",
      "Mean abs grad value: 0.25901741017938357\tMax abs grad value: 1.4628262939247083\n",
      "Loss = 5.51808858217233\n",
      "Train accuracy: 0.313\t\tTest accuracy: 0.278\n",
      "Mean abs grad value: 0.17956895232999842\tMax abs grad value: 1.2346335482713406\n",
      "Loss = 3.612580011486842\n",
      "Train accuracy: 0.463\t\tTest accuracy: 0.424\n",
      "Mean abs grad value: 0.1519713456889882\tMax abs grad value: 1.0741069462778066\n",
      "Loss = 1.5624535449463548\n",
      "Train accuracy: 0.754\t\tTest accuracy: 0.687\n",
      "Mean abs grad value: 0.10458548592284919\tMax abs grad value: 0.6875404632785611\n",
      "Loss = 0.9738481514919194\n",
      "Train accuracy: 0.818\t\tTest accuracy: 0.771\n",
      "Mean abs grad value: 0.04220624222712318\tMax abs grad value: 0.30507519861771265\n",
      "Loss = 0.7559674657740552\n",
      "Train accuracy: 0.852\t\tTest accuracy: 0.816\n",
      "Mean abs grad value: 0.026224349265761743\tMax abs grad value: 0.21850848685881136\n",
      "Loss = 0.6722202206118915\n",
      "Train accuracy: 0.858\t\tTest accuracy: 0.833\n",
      "Mean abs grad value: 0.03036891831767795\tMax abs grad value: 0.30811949729154053\n",
      "Loss = 0.6139515311517241\n",
      "Train accuracy: 0.867\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.030911649685163793\tMax abs grad value: 0.28884291804150575\n",
      "Loss = 0.4804633674180167\n",
      "Train accuracy: 0.886\t\tTest accuracy: 0.878\n",
      "Mean abs grad value: 0.05856414707476054\tMax abs grad value: 0.42330505148407915\n",
      "Loss = 0.435568028464782\n",
      "Train accuracy: 0.907\t\tTest accuracy: 0.873\n",
      "Mean abs grad value: 0.0201131511459617\tMax abs grad value: 0.20822435547264423\n",
      "Loss = 0.26643240427304715\n",
      "Train accuracy: 0.939\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.01212095699030596\tMax abs grad value: 0.11868650464619587\n",
      "Loss = 0.23254442107147585\n",
      "Train accuracy: 0.949\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.009329721996997139\tMax abs grad value: 0.0711461043209806\n",
      "Loss = 0.20864310288465332\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.008276625186942848\tMax abs grad value: 0.05276174532880972\n",
      "Loss = 0.18927591347744321\n",
      "Train accuracy: 0.956\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.010862101787141715\tMax abs grad value: 0.08402136659393084\n",
      "Loss = 0.1578934657605013\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.014556202505628448\tMax abs grad value: 0.1341984936574467\n",
      "Loss = 0.13840010989272764\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.01025820540195593\tMax abs grad value: 0.07652878783085434\n",
      "Loss = 0.12063877312411626\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.007266748302172343\tMax abs grad value: 0.049672604713012235\n",
      "Loss = 0.10236736898394505\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.005825429618148036\tMax abs grad value: 0.044565224381893656\n",
      "Loss = 0.08141747392499364\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.005842824028229776\tMax abs grad value: 0.04264205067653242\n",
      "Loss = 0.06752843681895776\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.009882708766539666\tMax abs grad value: 0.07819763435205078\n",
      "Loss = 0.06315517373954124\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0050436294329039046\tMax abs grad value: 0.03892357042347932\n",
      "Loss = 0.04746877008902167\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0036522122338933445\tMax abs grad value: 0.0285678638761052\n",
      "Loss = 0.03991543452095374\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0033889773817654795\tMax abs grad value: 0.03201136102941743\n",
      "Loss = 0.03510917150857527\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0028210832427983164\tMax abs grad value: 0.017549012413153122\n",
      "Loss = 0.029999608700001346\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0027763621481690657\tMax abs grad value: 0.021336847385039496\n",
      "Loss = 0.024342365235125264\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0030962914873822437\tMax abs grad value: 0.025521059238318326\n",
      "Loss = 0.019204249354026842\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0040547405693391984\tMax abs grad value: 0.05038704446418802\n",
      "Loss = 0.016978123819664938\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0016239548966546999\tMax abs grad value: 0.01813939802522439\n",
      "Loss = 0.014680187768096922\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0014739878632580399\tMax abs grad value: 0.010939715281459449\n",
      "Loss = 0.013984054807390922\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.001562986037745211\tMax abs grad value: 0.013619838997709036\n",
      "Loss = 0.012838478103110902\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0013808166567163959\tMax abs grad value: 0.012926455064915797\n",
      "Loss = 0.011267081001859485\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0011360759996280373\tMax abs grad value: 0.011454478540566172\n",
      "Loss = 0.010208230170956784\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00110314919642498\tMax abs grad value: 0.008425493513558804\n",
      "Loss = 0.009339243337914898\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0011544289994486563\tMax abs grad value: 0.011358507109143453\n",
      "Loss = 0.008409414496197582\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.001023720745622452\tMax abs grad value: 0.008984316110744782\n",
      "Loss = 0.0073601655772632885\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0008328798317683621\tMax abs grad value: 0.008136134818352247\n",
      "Loss = 0.00594841043212356\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0006570368089181139\tMax abs grad value: 0.005248011116489868\n",
      "Loss = 0.005054316622907096\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0004691887880850974\tMax abs grad value: 0.00430620174606027\n",
      "Loss = 0.004388764366804807\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0005507550394895125\tMax abs grad value: 0.0052330887106612775\n",
      "Loss = 0.003868045035350972\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0018830926068719362\tMax abs grad value: 0.02542657587135259\n",
      "Loss = 0.004056239526019531\n",
      "Mean abs grad value: 0.0007158747970293903\tMax abs grad value: 0.009321713474604119\n",
      "Loss = 0.0035337138478861952\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0004726682746272449\tMax abs grad value: 0.005714766693220286\n",
      "Loss = 0.003237176782262316\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0003243861973451168\tMax abs grad value: 0.0046719891120317394\n",
      "Loss = 0.002891029509225757\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0003141822602462895\tMax abs grad value: 0.004562683528947852\n",
      "Loss = 0.00253533023012983\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00038431932314106576\tMax abs grad value: 0.003927836242178707\n",
      "Loss = 0.0020511180411541758\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0005259240990281097\tMax abs grad value: 0.0051702091562157325\n",
      "Loss = 0.001767698089361993\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0002004907810170776\tMax abs grad value: 0.0018112150106410964\n",
      "Loss = 0.001568528845884007\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0001719870289163386\tMax abs grad value: 0.0015365184650167338\n",
      "Loss = 0.0014911048936245145\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00021009177526739553\tMax abs grad value: 0.0018898794267343969\n",
      "Loss = 0.0013677840654605468\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0002141075322887013\tMax abs grad value: 0.001978729870780705\n",
      "Loss = 0.001194652903291807\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0009534965469225503\tMax abs grad value: 0.010814738125044972\n",
      "Loss = 0.0016625591896380872\n",
      "Mean abs grad value: 0.00028778260517761363\tMax abs grad value: 0.0018704066099614973\n",
      "Loss = 0.0011187702097971083\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0001866910799793726\tMax abs grad value: 0.0017143815513958746\n",
      "Loss = 0.0009328160560080845\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.000352100183968488\tMax abs grad value: 0.003419541290355581\n",
      "Loss = 0.0008684430525084029\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00012603477506504396\tMax abs grad value: 0.0010965058306464247\n",
      "Loss = 0.0007220306074991649\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 9.768279878019016e-05\tMax abs grad value: 0.0007831915562976083\n",
      "Loss = 0.0006731426593012605\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00011554829377155535\tMax abs grad value: 0.0008288104725058747\n",
      "Loss = 0.0005956159264027891\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00010362569158322791\tMax abs grad value: 0.000712623562624754\n",
      "Loss = 0.00048347914996723973\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00013911704247639685\tMax abs grad value: 0.0016028055872229017\n",
      "Loss = 0.0003892361881351393\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 6.989088898792976e-05\tMax abs grad value: 0.0005495302947558975\n",
      "Loss = 0.00029506679468070733\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 4.9406952345347806e-05\tMax abs grad value: 0.00041605470748262783\n",
      "Loss = 0.00027302139868030424\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.7250838612813135e-05\tMax abs grad value: 0.0003261615690225525\n",
      "Loss = 0.00024893411575609923\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.360101025156025e-05\tMax abs grad value: 0.0002247323711877866\n",
      "Loss = 0.00020498019120484547\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.9212084254013044e-05\tMax abs grad value: 0.0002700429245929921\n",
      "Loss = 0.00016726746892834022\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 5.701498974166819e-05\tMax abs grad value: 0.00043561108380149447\n",
      "Loss = 0.00013478548748901127\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 3.315491178679746e-05\tMax abs grad value: 0.00033190808473434514\n",
      "Loss = 0.00010127961607779822\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.841313766851549e-05\tMax abs grad value: 0.00010142686118522634\n",
      "Loss = 8.194243612484262e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.5403519675435908e-05\tMax abs grad value: 9.833561067867008e-05\n",
      "Loss = 6.635390781561896e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.1268440507002597e-05\tMax abs grad value: 8.278355222416937e-05\n",
      "Loss = 4.72410145192852e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 7.014134215662126e-06\tMax abs grad value: 5.2711096941071616e-05\n",
      "Loss = 3.2659445147710705e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 4.653123203365034e-06\tMax abs grad value: 4.122415583409273e-05\n",
      "Loss = 1.9853744438355196e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 6.149699272670004e-06\tMax abs grad value: 4.843446641480779e-05\n",
      "Loss = 1.3777832501830627e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.8860438264661955e-06\tMax abs grad value: 1.660126521028378e-05\n",
      "Loss = 7.3029440053726e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.0883013681243922e-06\tMax abs grad value: 1.189830907337326e-05\n",
      "Loss = 4.963991079812168e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 5.906566357992483e-07\tMax abs grad value: 5.617008812710403e-06\n",
      "Loss = 2.934584245182847e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.7216597672213684\tMax abs grad value: 5.512910354582788\n",
      "Loss = 24.193000783351565\n",
      "Mean abs grad value: 0.5316190815096734\tMax abs grad value: 5.122848375492421\n",
      "Loss = 14.804739384411652\n",
      "Train accuracy: 0.095\t\tTest accuracy: 0.102\n",
      "Mean abs grad value: 0.45604959919018984\tMax abs grad value: 2.390608848278237\n",
      "Loss = 12.237317502450885\n",
      "Train accuracy: 0.191\t\tTest accuracy: 0.180\n",
      "Mean abs grad value: 0.4078289281095659\tMax abs grad value: 2.2920587506241636\n",
      "Loss = 9.07757613065006\n",
      "Train accuracy: 0.216\t\tTest accuracy: 0.204\n",
      "Mean abs grad value: 0.7685284460432921\tMax abs grad value: 8.161023062997135\n",
      "Loss = 19.92165557935096\n",
      "Mean abs grad value: 0.3215689366056693\tMax abs grad value: 1.5198680603883825\n",
      "Loss = 6.967756329332952\n",
      "Train accuracy: 0.244\t\tTest accuracy: 0.216\n",
      "Mean abs grad value: 0.46613400343813693\tMax abs grad value: 4.120142995036498\n",
      "Loss = 6.349583301540244\n",
      "Mean abs grad value: 0.2544819674505195\tMax abs grad value: 1.4627645393492357\n",
      "Loss = 5.5865572733440185\n",
      "Train accuracy: 0.238\t\tTest accuracy: 0.218\n",
      "Mean abs grad value: 0.33798717573941495\tMax abs grad value: 3.3542616094425153\n",
      "Loss = 4.234886390128161\n",
      "Train accuracy: 0.299\t\tTest accuracy: 0.289\n",
      "Mean abs grad value: 0.24498052175542975\tMax abs grad value: 1.7916265236417175\n",
      "Loss = 2.85570951063791\n",
      "Train accuracy: 0.522\t\tTest accuracy: 0.471\n",
      "Mean abs grad value: 0.1488749021875874\tMax abs grad value: 1.0737396957023944\n",
      "Loss = 2.0009838250079173\n",
      "Train accuracy: 0.629\t\tTest accuracy: 0.576\n",
      "Mean abs grad value: 0.05431494611796752\tMax abs grad value: 0.37957610005046427\n",
      "Loss = 1.1496908099513872\n",
      "Train accuracy: 0.771\t\tTest accuracy: 0.729\n",
      "Mean abs grad value: 0.03809914851515667\tMax abs grad value: 0.24908666445177471\n",
      "Loss = 0.9499814470666597\n",
      "Train accuracy: 0.806\t\tTest accuracy: 0.787\n",
      "Mean abs grad value: 0.02610042064060961\tMax abs grad value: 0.1982355885221885\n",
      "Loss = 0.7172653968933145\n",
      "Train accuracy: 0.866\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.025907792832981155\tMax abs grad value: 0.15843036472020125\n",
      "Loss = 0.5552859679179059\n",
      "Train accuracy: 0.892\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.023171172142398694\tMax abs grad value: 0.2532977611959333\n",
      "Loss = 0.4098079432692198\n",
      "Train accuracy: 0.918\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.012197732054273026\tMax abs grad value: 0.09227242950701647\n",
      "Loss = 0.3277661417279959\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.01073196712840345\tMax abs grad value: 0.06833031675941457\n",
      "Loss = 0.29558184388110703\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.009189529662813013\tMax abs grad value: 0.06133427240138725\n",
      "Loss = 0.2445495141348993\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.013296117520805366\tMax abs grad value: 0.13039489778744065\n",
      "Loss = 0.17886744744987126\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.010835253022605384\tMax abs grad value: 0.07668669555969475\n",
      "Loss = 0.13435264545609435\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.006250238235251287\tMax abs grad value: 0.05144449054920012\n",
      "Loss = 0.11520691105957619\n",
      "Train accuracy: 0.971\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00617538068598776\tMax abs grad value: 0.04150054499871448\n",
      "Loss = 0.10101476462685403\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00935072403612544\tMax abs grad value: 0.06947522082956713\n",
      "Loss = 0.08388721361014628\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.012737859954437951\tMax abs grad value: 0.12078257982265223\n",
      "Loss = 0.0753655736107934\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.006018175008557976\tMax abs grad value: 0.054508287768000825\n",
      "Loss = 0.06031461816073808\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.004903892587196136\tMax abs grad value: 0.038203468868756044\n",
      "Loss = 0.050084553623646944\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.005915471047279043\tMax abs grad value: 0.04166392464004229\n",
      "Loss = 0.04025556646823858\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.008586822375686327\tMax abs grad value: 0.09514311383800071\n",
      "Loss = 0.03730136092261435\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0032660534624121174\tMax abs grad value: 0.022375968201195695\n",
      "Loss = 0.030545371510408346\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.002332580069698672\tMax abs grad value: 0.015770231682202512\n",
      "Loss = 0.028442980886370234\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00191330395529026\tMax abs grad value: 0.018686198819492173\n",
      "Loss = 0.024803466522082904\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0018974432913619159\tMax abs grad value: 0.014214868981767513\n",
      "Loss = 0.020870062331651725\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.004915063975134319\tMax abs grad value: 0.03987708960613721\n",
      "Loss = 0.020070899135638687\n",
      "Mean abs grad value: 0.002552555091475377\tMax abs grad value: 0.017901281950402147\n",
      "Loss = 0.01812966425588126\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0016727676432186616\tMax abs grad value: 0.011112564904092428\n",
      "Loss = 0.015002650018616549\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0017669462349636483\tMax abs grad value: 0.020706994692195002\n",
      "Loss = 0.013430346153305425\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0011581061820932273\tMax abs grad value: 0.009796846839470385\n",
      "Loss = 0.01223492441500295\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0012572672134145589\tMax abs grad value: 0.01055628971743685\n",
      "Loss = 0.011393273502060298\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0018135454547253606\tMax abs grad value: 0.016659220184042024\n",
      "Loss = 0.009063140186420493\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00467762513600528\tMax abs grad value: 0.04102807367173401\n",
      "Loss = 0.009979381165227506\n",
      "Mean abs grad value: 0.0018446901385574578\tMax abs grad value: 0.013248971517073339\n",
      "Loss = 0.008299355437438118\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0012683584935246257\tMax abs grad value: 0.008470019948275018\n",
      "Loss = 0.007423737601943707\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0007593608236228216\tMax abs grad value: 0.006696191323527195\n",
      "Loss = 0.006718386483689237\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0008954382730110488\tMax abs grad value: 0.009208778030205296\n",
      "Loss = 0.006267275388861422\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0007610996573251518\tMax abs grad value: 0.005586653382662498\n",
      "Loss = 0.005812812615833611\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.000736304997106148\tMax abs grad value: 0.005413932481147313\n",
      "Loss = 0.005280547443770208\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0005644685456354484\tMax abs grad value: 0.005848631221226962\n",
      "Loss = 0.004671790291155484\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0008979059528466291\tMax abs grad value: 0.01085166333872473\n",
      "Loss = 0.004158736306545079\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00044817598756233967\tMax abs grad value: 0.003954740210547531\n",
      "Loss = 0.003683450288066683\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0004812356674717331\tMax abs grad value: 0.004513322556658398\n",
      "Loss = 0.0035000168557298393\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00042094284998267257\tMax abs grad value: 0.004757749124179968\n",
      "Loss = 0.003065804608919789\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0005824558870365286\tMax abs grad value: 0.004483232994410637\n",
      "Loss = 0.0026150085507842457\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0004468666073512653\tMax abs grad value: 0.004391746576549119\n",
      "Loss = 0.002175486568426514\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00026520827490456077\tMax abs grad value: 0.0021980155619326317\n",
      "Loss = 0.0019889175693592453\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00026732818240123957\tMax abs grad value: 0.0028354002732382524\n",
      "Loss = 0.0017327145070844543\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.000264676149792516\tMax abs grad value: 0.003362824794920019\n",
      "Loss = 0.0015838840519683658\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00029014457011487235\tMax abs grad value: 0.0033898513201779455\n",
      "Loss = 0.001283450363835273\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00022514485988730788\tMax abs grad value: 0.0019711764391230906\n",
      "Loss = 0.0010287576173595818\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00013537864070740495\tMax abs grad value: 0.0013441637175972106\n",
      "Loss = 0.0008861480530365587\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00010087860442926035\tMax abs grad value: 0.0012599348762025906\n",
      "Loss = 0.0007364808727665467\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0002696331639460272\tMax abs grad value: 0.0031364140926435566\n",
      "Loss = 0.0006537193435489898\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00013992684200555682\tMax abs grad value: 0.0015023292614653669\n",
      "Loss = 0.0005398468726422708\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 9.014369984085059e-05\tMax abs grad value: 0.0009380028062490142\n",
      "Loss = 0.0004909727051718545\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 6.691453649257604e-05\tMax abs grad value: 0.0006414035555727\n",
      "Loss = 0.0004333059902902281\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 6.727766025071724e-05\tMax abs grad value: 0.0005528803545188602\n",
      "Loss = 0.0003744791313436064\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00017797920559499438\tMax abs grad value: 0.0017771930149036818\n",
      "Loss = 0.00033658399872072846\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 6.967658522967679e-05\tMax abs grad value: 0.0007648302962743068\n",
      "Loss = 0.0002341730764517524\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 4.2929780732729844e-05\tMax abs grad value: 0.00043046308442597035\n",
      "Loss = 0.00019530612095578878\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 3.31433765931284e-05\tMax abs grad value: 0.0003063898382996026\n",
      "Loss = 0.00015610813911349605\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 2.5177159519940402e-05\tMax abs grad value: 0.00019743381128264404\n",
      "Loss = 0.00011767908134769324\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 5.136390338790043e-05\tMax abs grad value: 0.0005421909295711965\n",
      "Loss = 9.971894987037907e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 1.8928714426532814e-05\tMax abs grad value: 0.0001313256060193356\n",
      "Loss = 6.436926387143648e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 1.2264479328326865e-05\tMax abs grad value: 0.00010976399613052526\n",
      "Loss = 5.468988449357184e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 7.128412653038556e-06\tMax abs grad value: 5.9234335289852424e-05\n",
      "Loss = 4.207711018340547e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 1.2824597978958603e-05\tMax abs grad value: 0.0001289037157614244\n",
      "Loss = 3.3816588788761795e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 6.338317027732196e-06\tMax abs grad value: 3.7313663949250797e-05\n",
      "Loss = 2.2817717241226588e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 4.597458691224251e-06\tMax abs grad value: 2.921622318449821e-05\n",
      "Loss = 1.763117965277242e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 4.323861109123591e-06\tMax abs grad value: 4.238553219924135e-05\n",
      "Loss = 1.0920133462789084e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 1.3860389523450687e-06\tMax abs grad value: 9.128212125962891e-06\n",
      "Loss = 5.1305079529569155e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.29794597415365004\tMax abs grad value: 15.031568469084563\n",
      "Loss = 12.68318902899132\n",
      "Mean abs grad value: 0.16997052378271865\tMax abs grad value: 5.362561651548797\n",
      "Loss = 10.443356537940502\n",
      "Train accuracy: 0.094\t\tTest accuracy: 0.120\n",
      "Mean abs grad value: 0.13535246518788485\tMax abs grad value: 3.183185183394683\n",
      "Loss = 7.443912363709808\n",
      "Train accuracy: 0.148\t\tTest accuracy: 0.167\n",
      "Mean abs grad value: 0.10236213528828918\tMax abs grad value: 2.4574150460492548\n",
      "Loss = 5.240046785159862\n",
      "Train accuracy: 0.180\t\tTest accuracy: 0.204\n",
      "Mean abs grad value: 0.07732759671174254\tMax abs grad value: 1.1018267815467955\n",
      "Loss = 3.336977477719871\n",
      "Train accuracy: 0.272\t\tTest accuracy: 0.240\n",
      "Mean abs grad value: 0.031299304606346855\tMax abs grad value: 1.6715773996745742\n",
      "Loss = 1.9633802881052245\n",
      "Train accuracy: 0.336\t\tTest accuracy: 0.313\n",
      "Mean abs grad value: 0.02046073504749086\tMax abs grad value: 0.29884640503345733\n",
      "Loss = 1.6356894304645384\n",
      "Train accuracy: 0.433\t\tTest accuracy: 0.449\n",
      "Mean abs grad value: 0.018235428211201502\tMax abs grad value: 0.22368410377923725\n",
      "Loss = 1.5173768201379791\n",
      "Train accuracy: 0.482\t\tTest accuracy: 0.476\n",
      "Mean abs grad value: 0.016487604665089566\tMax abs grad value: 0.3513670880620171\n",
      "Loss = 1.013085854095229\n",
      "Train accuracy: 0.648\t\tTest accuracy: 0.627\n",
      "Mean abs grad value: 0.011464596960277636\tMax abs grad value: 0.2856048599716063\n",
      "Loss = 0.7923110735445724\n",
      "Train accuracy: 0.739\t\tTest accuracy: 0.738\n",
      "Mean abs grad value: 0.011317298999875427\tMax abs grad value: 0.20935323739479975\n",
      "Loss = 0.655875249656148\n",
      "Train accuracy: 0.786\t\tTest accuracy: 0.789\n",
      "Mean abs grad value: 0.011451348739248546\tMax abs grad value: 0.30549709927764457\n",
      "Loss = 0.5152479555081871\n",
      "Train accuracy: 0.835\t\tTest accuracy: 0.818\n",
      "Mean abs grad value: 0.007779972304604656\tMax abs grad value: 0.13679959131878378\n",
      "Loss = 0.4151017649750043\n",
      "Train accuracy: 0.872\t\tTest accuracy: 0.838\n",
      "Mean abs grad value: 0.015047865354201747\tMax abs grad value: 0.5877759465476305\n",
      "Loss = 0.3798644977904276\n",
      "Mean abs grad value: 0.006488512005653388\tMax abs grad value: 0.2964744649588832\n",
      "Loss = 0.33979415101953725\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.009573526654396005\tMax abs grad value: 0.2699096725439826\n",
      "Loss = 0.29825454961362335\n",
      "Train accuracy: 0.902\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.0069645749507542655\tMax abs grad value: 0.17191596256651392\n",
      "Loss = 0.2588496633514085\n",
      "Train accuracy: 0.915\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.005186955352033245\tMax abs grad value: 0.12903809478306627\n",
      "Loss = 0.22354022795634054\n",
      "Train accuracy: 0.930\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.0056335632164784145\tMax abs grad value: 0.1182310491718139\n",
      "Loss = 0.18083312437097868\n",
      "Train accuracy: 0.942\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.005658681178867427\tMax abs grad value: 0.10822072740116825\n",
      "Loss = 0.16017954355561964\n",
      "Train accuracy: 0.949\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.0037855885621007547\tMax abs grad value: 0.08692005733186492\n",
      "Loss = 0.14447564630326368\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.0030058233374105348\tMax abs grad value: 0.09322234700079393\n",
      "Loss = 0.1154715185052115\n",
      "Train accuracy: 0.966\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.002960360648837633\tMax abs grad value: 0.052713021415396626\n",
      "Loss = 0.09907590932078413\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0034904605513061595\tMax abs grad value: 0.07110731265265026\n",
      "Loss = 0.08476861596906562\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0020855796315421846\tMax abs grad value: 0.04509886341512926\n",
      "Loss = 0.07341104010152533\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.002057484528993551\tMax abs grad value: 0.04678646362669842\n",
      "Loss = 0.06304828135786154\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0024870407084060645\tMax abs grad value: 0.06523954096019796\n",
      "Loss = 0.05099098334081126\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.00343167950931063\tMax abs grad value: 0.09610838716985098\n",
      "Loss = 0.04525316819272818\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.002063377696282338\tMax abs grad value: 0.044964401109389956\n",
      "Loss = 0.03922056057037423\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0014208950917339951\tMax abs grad value: 0.02981614948387325\n",
      "Loss = 0.032083224364715446\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0012514527851162688\tMax abs grad value: 0.02072749462985494\n",
      "Loss = 0.028041863169989672\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.001169129554635693\tMax abs grad value: 0.02029236058768561\n",
      "Loss = 0.02142997799432884\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.002258120475578314\tMax abs grad value: 0.06440039686503729\n",
      "Loss = 0.01707047816811417\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0008305276517228279\tMax abs grad value: 0.012345542507472343\n",
      "Loss = 0.013013305820070566\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0007424019188224686\tMax abs grad value: 0.01956018286775507\n",
      "Loss = 0.011226711444254647\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0006507322886655551\tMax abs grad value: 0.031371900174809994\n",
      "Loss = 0.008691199391899372\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0012103592015404964\tMax abs grad value: 0.03717886277950103\n",
      "Loss = 0.0074916801882026025\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0005594789981831345\tMax abs grad value: 0.009239629479148881\n",
      "Loss = 0.006067159017300702\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00036254958514297654\tMax abs grad value: 0.009165647862310649\n",
      "Loss = 0.005019077786267263\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0003362827793872557\tMax abs grad value: 0.009762918374204406\n",
      "Loss = 0.004101376705609493\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00025605430709348966\tMax abs grad value: 0.004038057100027149\n",
      "Loss = 0.002793084142515713\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0008264394439318966\tMax abs grad value: 0.03320589427094131\n",
      "Loss = 0.0027964378322758083\n",
      "Mean abs grad value: 0.0003411578676848406\tMax abs grad value: 0.015002536895271073\n",
      "Loss = 0.002275986001423364\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00019172716562717144\tMax abs grad value: 0.004155535381623211\n",
      "Loss = 0.0017408306807019122\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00011804461880849535\tMax abs grad value: 0.0019313358624650158\n",
      "Loss = 0.0013924810194357936\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00011392825806504642\tMax abs grad value: 0.002285404004077425\n",
      "Loss = 0.0010250775761133835\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 7.692102397499311e-05\tMax abs grad value: 0.0027322195861458347\n",
      "Loss = 0.0005994132591655484\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 6.538400073871631e-05\tMax abs grad value: 0.0021816292492840158\n",
      "Loss = 0.00041469880780035576\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 5.429779181982482e-05\tMax abs grad value: 0.00145253318723596\n",
      "Loss = 0.0003165151747225821\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.261652875454167e-05\tMax abs grad value: 0.0005423363190444401\n",
      "Loss = 0.0002571749506359341\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.2898835633695994e-05\tMax abs grad value: 0.0008124893189854004\n",
      "Loss = 0.00018248219913277074\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.1382598116282135e-05\tMax abs grad value: 0.0006810488560639438\n",
      "Loss = 0.00013141682373316946\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.4862456528829293e-05\tMax abs grad value: 0.0006744450476596269\n",
      "Loss = 9.02513313256774e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.066536531388304e-05\tMax abs grad value: 0.00024348971445999567\n",
      "Loss = 6.839023322120437e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 8.321807643224434e-06\tMax abs grad value: 0.00015164842062556977\n",
      "Loss = 4.256394451614413e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.1032108530249166e-06\tMax abs grad value: 0.00010091918787121739\n",
      "Loss = 2.4527805717066397e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.7807196770027745e-06\tMax abs grad value: 8.115683297149098e-05\n",
      "Loss = 1.5703760762914726e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.231960092278941e-06\tMax abs grad value: 9.260910481056047e-05\n",
      "Loss = 1.0996985035188224e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.496144857853993e-06\tMax abs grad value: 2.1500134011531585e-05\n",
      "Loss = 6.8255316883426975e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.2808026263861304e-06\tMax abs grad value: 1.587401571190314e-05\n",
      "Loss = 5.865308574379088e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.0259959581755924e-06\tMax abs grad value: 2.513765660786541e-05\n",
      "Loss = 3.4219721010885924e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 5.196988825125546e-07\tMax abs grad value: 1.971138818532181e-05\n",
      "Loss = 1.8446877779346627e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.027890921025794e-07\tMax abs grad value: 8.903337021953603e-06\n",
      "Loss = 1.3914779036398376e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.30731625519978784\tMax abs grad value: 7.654042091222476\n",
      "Loss = 13.885154110551344\n",
      "Mean abs grad value: 0.19678091697425829\tMax abs grad value: 8.093486971726515\n",
      "Loss = 9.179892226021636\n",
      "Train accuracy: 0.089\t\tTest accuracy: 0.082\n",
      "Mean abs grad value: 0.10660481845053449\tMax abs grad value: 6.872639753586195\n",
      "Loss = 6.062097719825404\n",
      "Train accuracy: 0.166\t\tTest accuracy: 0.191\n",
      "Mean abs grad value: 0.07144456822409395\tMax abs grad value: 1.4635402521047571\n",
      "Loss = 3.804594852615769\n",
      "Train accuracy: 0.193\t\tTest accuracy: 0.189\n",
      "Mean abs grad value: 0.030965808155693334\tMax abs grad value: 0.8921813236434186\n",
      "Loss = 2.317653583739337\n",
      "Train accuracy: 0.275\t\tTest accuracy: 0.253\n",
      "Mean abs grad value: 0.01983192682685147\tMax abs grad value: 0.3503101692788426\n",
      "Loss = 2.011126228383382\n",
      "Train accuracy: 0.327\t\tTest accuracy: 0.318\n",
      "Mean abs grad value: 0.01445172421261595\tMax abs grad value: 0.1875537122321211\n",
      "Loss = 1.7512651085684783\n",
      "Train accuracy: 0.411\t\tTest accuracy: 0.371\n",
      "Mean abs grad value: 0.012729215495909963\tMax abs grad value: 0.27699560149591357\n",
      "Loss = 1.3512503687017148\n",
      "Train accuracy: 0.546\t\tTest accuracy: 0.504\n",
      "Mean abs grad value: 0.05051877945990649\tMax abs grad value: 3.3382328577699183\n",
      "Loss = 1.9419067635779605\n",
      "Mean abs grad value: 0.011291021126725448\tMax abs grad value: 0.3082514946531439\n",
      "Loss = 1.0933133689919394\n",
      "Train accuracy: 0.645\t\tTest accuracy: 0.584\n",
      "Mean abs grad value: 0.014090940258096705\tMax abs grad value: 0.36127209351506256\n",
      "Loss = 0.8984780499309093\n",
      "Train accuracy: 0.704\t\tTest accuracy: 0.644\n",
      "Mean abs grad value: 0.009414769637906628\tMax abs grad value: 0.35403582590150107\n",
      "Loss = 0.7042667289721694\n",
      "Train accuracy: 0.766\t\tTest accuracy: 0.727\n",
      "Mean abs grad value: 0.009794359110491833\tMax abs grad value: 0.48671034137126856\n",
      "Loss = 0.6025300392788285\n",
      "Train accuracy: 0.809\t\tTest accuracy: 0.749\n",
      "Mean abs grad value: 0.011004644347924775\tMax abs grad value: 0.38250015679127125\n",
      "Loss = 0.5466262606217265\n",
      "Train accuracy: 0.825\t\tTest accuracy: 0.771\n",
      "Mean abs grad value: 0.0059431223725524215\tMax abs grad value: 0.2039270430242509\n",
      "Loss = 0.47757744476166736\n",
      "Train accuracy: 0.849\t\tTest accuracy: 0.804\n",
      "Mean abs grad value: 0.005036667772281526\tMax abs grad value: 0.21182993772778227\n",
      "Loss = 0.4030185340275161\n",
      "Train accuracy: 0.873\t\tTest accuracy: 0.840\n",
      "Mean abs grad value: 0.004867075554192297\tMax abs grad value: 0.11295650367410094\n",
      "Loss = 0.2964760470081077\n",
      "Train accuracy: 0.913\t\tTest accuracy: 0.896\n",
      "Mean abs grad value: 0.006424309064008275\tMax abs grad value: 0.22009100104714252\n",
      "Loss = 0.23765436953662722\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.003420670656162391\tMax abs grad value: 0.09070055809187273\n",
      "Loss = 0.1909715636413491\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.003214258087043431\tMax abs grad value: 0.08506899038133467\n",
      "Loss = 0.15847783845244204\n",
      "Train accuracy: 0.950\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.003448666123408563\tMax abs grad value: 0.09048362667132454\n",
      "Loss = 0.13667480524526562\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0025086489895613066\tMax abs grad value: 0.05058873464140252\n",
      "Loss = 0.12347639261665527\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0022536622353247072\tMax abs grad value: 0.055626278056825615\n",
      "Loss = 0.10612715243667371\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0019161392370358869\tMax abs grad value: 0.05819810312648858\n",
      "Loss = 0.09350297221223074\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0027181847823960982\tMax abs grad value: 0.12403089679418029\n",
      "Loss = 0.06759897502773789\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.002299139747042376\tMax abs grad value: 0.09482627994588344\n",
      "Loss = 0.058523164467224865\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0011761362343208973\tMax abs grad value: 0.03666947739994564\n",
      "Loss = 0.05212034082337486\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.000968068533991013\tMax abs grad value: 0.03000853777291018\n",
      "Loss = 0.04730415233721435\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0013342599216978786\tMax abs grad value: 0.03711615692941436\n",
      "Loss = 0.04063493126212712\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0012957900142669448\tMax abs grad value: 0.04069981040194816\n",
      "Loss = 0.030212559461358212\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.003961711473915057\tMax abs grad value: 0.21809031760462821\n",
      "Loss = 0.033761440455517454\n",
      "Mean abs grad value: 0.0013748403839797907\tMax abs grad value: 0.04137990402739711\n",
      "Loss = 0.024468764842529862\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.000900346903421722\tMax abs grad value: 0.03603570309293172\n",
      "Loss = 0.019856570666340993\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0006471631578302766\tMax abs grad value: 0.01846035884148804\n",
      "Loss = 0.017992194383924135\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0006307073627482763\tMax abs grad value: 0.025323861534121146\n",
      "Loss = 0.014787360028327624\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0004906684331411026\tMax abs grad value: 0.019029107202115366\n",
      "Loss = 0.01281602889865549\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0005852116024217363\tMax abs grad value: 0.021338866998495677\n",
      "Loss = 0.010135412287801111\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0006035683789343427\tMax abs grad value: 0.031016172739908848\n",
      "Loss = 0.008930641902602725\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0003309591564436641\tMax abs grad value: 0.010985472031054624\n",
      "Loss = 0.0077112975559339965\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0002484601368404893\tMax abs grad value: 0.005493723929253683\n",
      "Loss = 0.006685795318422166\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0005038944830962215\tMax abs grad value: 0.023409403319919697\n",
      "Loss = 0.005658815563202653\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00024129917398061067\tMax abs grad value: 0.007197587006781177\n",
      "Loss = 0.004485983594675779\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00022982663178508202\tMax abs grad value: 0.007434701969534734\n",
      "Loss = 0.0038582137735153664\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0002680982474438611\tMax abs grad value: 0.01112639486167738\n",
      "Loss = 0.002764239060869137\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0002757444284130665\tMax abs grad value: 0.014003653597189105\n",
      "Loss = 0.0020852061241989723\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00014827698537253333\tMax abs grad value: 0.0053848841237350694\n",
      "Loss = 0.0016240841743749858\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 8.920315821126244e-05\tMax abs grad value: 0.0016011364750419539\n",
      "Loss = 0.0012451835420006579\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 8.438390301190665e-05\tMax abs grad value: 0.002626731976736661\n",
      "Loss = 0.0009753809831902178\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00011332467653749908\tMax abs grad value: 0.005087943438041007\n",
      "Loss = 0.000693022754295135\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 9.010118944794358e-05\tMax abs grad value: 0.0025909385127991878\n",
      "Loss = 0.000455890343594727\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 4.879161414437733e-05\tMax abs grad value: 0.0019473601700383822\n",
      "Loss = 0.000373307921471814\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.4478549098024513e-05\tMax abs grad value: 0.0010795549022834386\n",
      "Loss = 0.00029527428045581964\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 2.5978899649485935e-05\tMax abs grad value: 0.0006003270784565899\n",
      "Loss = 0.00023008138972842096\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 2.26758980922804e-05\tMax abs grad value: 0.0007169930912515708\n",
      "Loss = 0.0001616454158969862\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.909784154386945e-05\tMax abs grad value: 0.0014955712589806312\n",
      "Loss = 0.00010310345874572326\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.1630568592758264e-05\tMax abs grad value: 0.0007553217701682583\n",
      "Loss = 7.124076294087233e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 6.937588451249521e-06\tMax abs grad value: 0.0003706204962160983\n",
      "Loss = 4.796063728520999e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 6.22684869009963e-06\tMax abs grad value: 0.0002586880074955422\n",
      "Loss = 3.30786463430752e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 5.108503071248541e-06\tMax abs grad value: 0.00018023305074854195\n",
      "Loss = 2.185757149209368e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.474024556794496e-06\tMax abs grad value: 7.840405052875137e-05\n",
      "Loss = 1.7507285792087597e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.7937111384693234e-06\tMax abs grad value: 3.489575350622372e-05\n",
      "Loss = 1.1333995409048712e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.290755466119053e-06\tMax abs grad value: 3.079658468389493e-05\n",
      "Loss = 7.517822625682562e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.2133462492653822e-06\tMax abs grad value: 5.1310747513099666e-05\n",
      "Loss = 4.3310007517291645e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.773927526145156e-07\tMax abs grad value: 1.5247727739403632e-05\n",
      "Loss = 1.928608195094021e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 2.207021532468721e-07\tMax abs grad value: 5.989518309266245e-06\n",
      "Loss = 1.279320992339193e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.46002768704119296\tMax abs grad value: 19.701618665848542\n",
      "Loss = 21.751581430449928\n",
      "Mean abs grad value: 0.2794628592388072\tMax abs grad value: 10.094156245200633\n",
      "Loss = 13.163234687277999\n",
      "Train accuracy: 0.131\t\tTest accuracy: 0.129\n",
      "Mean abs grad value: 0.16141532923561785\tMax abs grad value: 3.966141498340631\n",
      "Loss = 7.196163999547825\n",
      "Train accuracy: 0.128\t\tTest accuracy: 0.156\n",
      "Mean abs grad value: 0.08333075139012122\tMax abs grad value: 1.3919036152165167\n",
      "Loss = 3.649571548322158\n",
      "Train accuracy: 0.221\t\tTest accuracy: 0.231\n",
      "Mean abs grad value: 0.04554864238276702\tMax abs grad value: 0.7641486817234048\n",
      "Loss = 2.133819291323781\n",
      "Train accuracy: 0.320\t\tTest accuracy: 0.324\n",
      "Mean abs grad value: 0.01851169302886794\tMax abs grad value: 0.5138922176685531\n",
      "Loss = 1.6641737353459427\n",
      "Train accuracy: 0.425\t\tTest accuracy: 0.382\n",
      "Mean abs grad value: 0.01634930121503899\tMax abs grad value: 0.43761506053289867\n",
      "Loss = 1.5115159108704164\n",
      "Train accuracy: 0.477\t\tTest accuracy: 0.436\n",
      "Mean abs grad value: 0.02045986086855694\tMax abs grad value: 0.6744058049249073\n",
      "Loss = 1.0045194968685627\n",
      "Train accuracy: 0.652\t\tTest accuracy: 0.602\n",
      "Mean abs grad value: 0.01635763554300033\tMax abs grad value: 0.3333389554296148\n",
      "Loss = 0.7849102023753268\n",
      "Train accuracy: 0.751\t\tTest accuracy: 0.718\n",
      "Mean abs grad value: 0.009959969870208897\tMax abs grad value: 0.18154791978944892\n",
      "Loss = 0.6816909210237458\n",
      "Train accuracy: 0.793\t\tTest accuracy: 0.751\n",
      "Mean abs grad value: 0.010130314041042417\tMax abs grad value: 0.47537631542720477\n",
      "Loss = 0.5807753299198765\n",
      "Train accuracy: 0.817\t\tTest accuracy: 0.796\n",
      "Mean abs grad value: 0.00794163561874952\tMax abs grad value: 0.3662188913994439\n",
      "Loss = 0.5030162174279122\n",
      "Train accuracy: 0.846\t\tTest accuracy: 0.820\n",
      "Mean abs grad value: 0.0060028617278763945\tMax abs grad value: 0.29743401541318065\n",
      "Loss = 0.40572331628933067\n",
      "Train accuracy: 0.877\t\tTest accuracy: 0.860\n",
      "Mean abs grad value: 0.010893697401538746\tMax abs grad value: 0.6796440005499523\n",
      "Loss = 0.33006647424775465\n",
      "Train accuracy: 0.890\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.005012395389826483\tMax abs grad value: 0.24708935944542923\n",
      "Loss = 0.2600704312890196\n",
      "Train accuracy: 0.923\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.0038401477837577474\tMax abs grad value: 0.0765230106589484\n",
      "Loss = 0.24256107235659036\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.003988563104272118\tMax abs grad value: 0.1326934259598833\n",
      "Loss = 0.2130144464569623\n",
      "Train accuracy: 0.936\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.0033351998158003865\tMax abs grad value: 0.11152535064743058\n",
      "Loss = 0.18566217561593962\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.003531898889965043\tMax abs grad value: 0.11171207274510346\n",
      "Loss = 0.14789488333082326\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.00899722127341402\tMax abs grad value: 0.3227549645220207\n",
      "Loss = 0.15601426132489993\n",
      "Mean abs grad value: 0.00363926569916527\tMax abs grad value: 0.14122901080833566\n",
      "Loss = 0.12582191075901786\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.002627861363638071\tMax abs grad value: 0.05279238720599063\n",
      "Loss = 0.11058941065863884\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0021455150900965263\tMax abs grad value: 0.06490598721704642\n",
      "Loss = 0.09823721188816159\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0030442973973999993\tMax abs grad value: 0.10899582136628967\n",
      "Loss = 0.08685594992971299\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.002206100060676211\tMax abs grad value: 0.06508699880519188\n",
      "Loss = 0.07525440246948283\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0017848499333132644\tMax abs grad value: 0.04938582122080418\n",
      "Loss = 0.0631951450958536\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0013092246797358322\tMax abs grad value: 0.027084988677475295\n",
      "Loss = 0.05366651310164506\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0017912451122463668\tMax abs grad value: 0.036591210237177284\n",
      "Loss = 0.0441474522330285\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001882456760609671\tMax abs grad value: 0.07331496467622078\n",
      "Loss = 0.03729520744732592\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0010243788442880408\tMax abs grad value: 0.029204201935412576\n",
      "Loss = 0.03239282123553909\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0008079153535981545\tMax abs grad value: 0.025182163201492063\n",
      "Loss = 0.027911647097784216\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0008629251715701584\tMax abs grad value: 0.025780274397981747\n",
      "Loss = 0.02411101055910087\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002078826362973414\tMax abs grad value: 0.08880223863181394\n",
      "Loss = 0.022606874728064053\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0007604203238301262\tMax abs grad value: 0.02054828866401057\n",
      "Loss = 0.01713715542698101\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0006268974100926296\tMax abs grad value: 0.013604293103287738\n",
      "Loss = 0.01575704737399533\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0005765087275093554\tMax abs grad value: 0.01325061980652542\n",
      "Loss = 0.012836209901769287\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.001129020406596929\tMax abs grad value: 0.054190823375779205\n",
      "Loss = 0.009845454228978904\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0004946143910496542\tMax abs grad value: 0.011334572998506345\n",
      "Loss = 0.00754045137033315\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0004169851850813609\tMax abs grad value: 0.016642252173332973\n",
      "Loss = 0.006681943833692768\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.000373805849240409\tMax abs grad value: 0.012111275866545606\n",
      "Loss = 0.005283481161349364\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.000362297632140022\tMax abs grad value: 0.012093072895620274\n",
      "Loss = 0.004000535906801466\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.001338533366630882\tMax abs grad value: 0.06730519473422064\n",
      "Loss = 0.004789989762661194\n",
      "Mean abs grad value: 0.0004844700608161042\tMax abs grad value: 0.020039252896715008\n",
      "Loss = 0.0033033346990558737\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00028670464408176805\tMax abs grad value: 0.01068022219355129\n",
      "Loss = 0.002683047874477983\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00022976918192429597\tMax abs grad value: 0.007461456134260062\n",
      "Loss = 0.00219890017144888\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00020082379510989636\tMax abs grad value: 0.003262928908132317\n",
      "Loss = 0.001782536943465293\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0002531568640378307\tMax abs grad value: 0.014231005591793923\n",
      "Loss = 0.001396366360719047\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00012223863505402322\tMax abs grad value: 0.002931954443677671\n",
      "Loss = 0.0010436807570842728\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00011788502735857385\tMax abs grad value: 0.0028161892371010243\n",
      "Loss = 0.0009304933093412363\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00012999485176512268\tMax abs grad value: 0.004350156581858804\n",
      "Loss = 0.0006437955844834175\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 6.877957867411911e-05\tMax abs grad value: 0.002652136812487592\n",
      "Loss = 0.00042496784914553514\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.7534006565108885e-05\tMax abs grad value: 0.0011173899259025438\n",
      "Loss = 0.0003653495822046989\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.0544391779891674e-05\tMax abs grad value: 0.001435555638911292\n",
      "Loss = 0.00029497362010448753\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.7472763747169854e-05\tMax abs grad value: 0.0012818705503183049\n",
      "Loss = 0.00020449635163602168\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.192079039447897e-05\tMax abs grad value: 0.0015402830734961028\n",
      "Loss = 0.00015067276872006568\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.7971148668395226e-05\tMax abs grad value: 0.00106258053881503\n",
      "Loss = 0.0001163050889639085\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.6299713795808716e-05\tMax abs grad value: 0.0007756928586988978\n",
      "Loss = 9.577781002231889e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.0656162451557676e-05\tMax abs grad value: 0.0003123767933859462\n",
      "Loss = 6.627531810047254e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.309418964384488e-05\tMax abs grad value: 0.0004388739428188719\n",
      "Loss = 4.512062476002977e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.8225324444639296e-05\tMax abs grad value: 0.000736671120787094\n",
      "Loss = 3.7856930167546975e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 4.342253950348887e-06\tMax abs grad value: 0.00014563058205455297\n",
      "Loss = 2.1712380627240082e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.035715377876963e-06\tMax abs grad value: 9.9795781924697e-05\n",
      "Loss = 1.8918034344646977e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.251276249618061e-06\tMax abs grad value: 4.24941666031076e-05\n",
      "Loss = 1.4076930548179635e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.7273480932576977e-06\tMax abs grad value: 2.4015479874302973e-05\n",
      "Loss = 1.0082283637571705e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.0492251732044563e-06\tMax abs grad value: 9.295731810352761e-05\n",
      "Loss = 6.481532913940464e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.4903725062979182e-06\tMax abs grad value: 6.065884376914866e-05\n",
      "Loss = 4.301082655742068e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 9.231980759301112e-07\tMax abs grad value: 3.1169312691705075e-05\n",
      "Loss = 3.5384205340790947e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 5.170832129476202e-07\tMax abs grad value: 1.4372513299891946e-05\n",
      "Loss = 2.5232367494065657e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.7326976316505305e-07\tMax abs grad value: 1.0071798741996573e-05\n",
      "Loss = 1.7083921380128568e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.384240457752527e-07\tMax abs grad value: 5.224453540071863e-06\n",
      "Loss = 9.872144050939968e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.34896734348016745\tMax abs grad value: 11.154735468240878\n",
      "Loss = 16.06661917636022\n",
      "Mean abs grad value: 0.1621049623249429\tMax abs grad value: 10.681804138111156\n",
      "Loss = 7.812519844242549\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.093\n",
      "Mean abs grad value: 0.09735477178543514\tMax abs grad value: 2.1461147746581206\n",
      "Loss = 5.624427548024237\n",
      "Train accuracy: 0.114\t\tTest accuracy: 0.082\n",
      "Mean abs grad value: 0.06948013673801973\tMax abs grad value: 1.3904863272725412\n",
      "Loss = 4.20065893268773\n",
      "Train accuracy: 0.183\t\tTest accuracy: 0.169\n",
      "Mean abs grad value: 0.04740044673702734\tMax abs grad value: 0.8196463469250301\n",
      "Loss = 2.74771755909516\n",
      "Train accuracy: 0.252\t\tTest accuracy: 0.216\n",
      "Mean abs grad value: 0.021534478864697754\tMax abs grad value: 0.2894291284409602\n",
      "Loss = 1.9369989908990728\n",
      "Train accuracy: 0.334\t\tTest accuracy: 0.280\n",
      "Mean abs grad value: 0.015403350436888104\tMax abs grad value: 0.2843688358576829\n",
      "Loss = 1.6649565967760522\n",
      "Train accuracy: 0.414\t\tTest accuracy: 0.393\n",
      "Mean abs grad value: 0.0191593043799347\tMax abs grad value: 0.2874549354181641\n",
      "Loss = 1.310312477529461\n",
      "Train accuracy: 0.555\t\tTest accuracy: 0.531\n",
      "Mean abs grad value: 0.01710951258572581\tMax abs grad value: 0.4202460596063415\n",
      "Loss = 1.0137119112181623\n",
      "Train accuracy: 0.651\t\tTest accuracy: 0.602\n",
      "Mean abs grad value: 0.01129190820942287\tMax abs grad value: 0.28530309794883313\n",
      "Loss = 0.7192267697399748\n",
      "Train accuracy: 0.754\t\tTest accuracy: 0.711\n",
      "Mean abs grad value: 0.011278714068898677\tMax abs grad value: 0.3554142499876553\n",
      "Loss = 0.5833665031337454\n",
      "Train accuracy: 0.813\t\tTest accuracy: 0.778\n",
      "Mean abs grad value: 0.007364088703088076\tMax abs grad value: 0.12717939744339357\n",
      "Loss = 0.4606642314825009\n",
      "Train accuracy: 0.853\t\tTest accuracy: 0.831\n",
      "Mean abs grad value: 0.0068569375605943604\tMax abs grad value: 0.12034189663704493\n",
      "Loss = 0.3740353998220338\n",
      "Train accuracy: 0.886\t\tTest accuracy: 0.851\n",
      "Mean abs grad value: 0.005614806145744474\tMax abs grad value: 0.15306080028613306\n",
      "Loss = 0.3167747359261544\n",
      "Train accuracy: 0.906\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.005958357042103879\tMax abs grad value: 0.17780461355883714\n",
      "Loss = 0.2731806985433391\n",
      "Train accuracy: 0.918\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.004455532298304235\tMax abs grad value: 0.11129185492091727\n",
      "Loss = 0.22400624314497428\n",
      "Train accuracy: 0.931\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.0038203450095124227\tMax abs grad value: 0.09058834999922784\n",
      "Loss = 0.17582295243675855\n",
      "Train accuracy: 0.942\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.003449140382898765\tMax abs grad value: 0.15348173237353852\n",
      "Loss = 0.13631432026512041\n",
      "Train accuracy: 0.953\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0030920904642840323\tMax abs grad value: 0.0932300052362577\n",
      "Loss = 0.11218577290031133\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0035003452267417133\tMax abs grad value: 0.1512563633674856\n",
      "Loss = 0.09395548889269614\n",
      "Train accuracy: 0.972\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0023813019912238805\tMax abs grad value: 0.10432529863428834\n",
      "Loss = 0.08020048028789896\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002384445771462015\tMax abs grad value: 0.061300921272551184\n",
      "Loss = 0.06830540924885194\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002522571373950832\tMax abs grad value: 0.07866872280270373\n",
      "Loss = 0.05666857280678169\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.002549331638308022\tMax abs grad value: 0.09442752705371371\n",
      "Loss = 0.04933491102567076\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.001413046062203361\tMax abs grad value: 0.04100983776385507\n",
      "Loss = 0.04304769857235421\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0011354099826113098\tMax abs grad value: 0.039730180911033905\n",
      "Loss = 0.038217794413933144\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0014171325248020872\tMax abs grad value: 0.04559533513263994\n",
      "Loss = 0.034866496157500364\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00145751495927938\tMax abs grad value: 0.061195249918471695\n",
      "Loss = 0.028802172832595337\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0023243287228084924\tMax abs grad value: 0.15474908305531435\n",
      "Loss = 0.025111936758393762\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0011488039931742042\tMax abs grad value: 0.04333902584471774\n",
      "Loss = 0.0198706914416135\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0009220115783728234\tMax abs grad value: 0.028018646484275374\n",
      "Loss = 0.016154218186234352\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.001004370882727272\tMax abs grad value: 0.0503729391463323\n",
      "Loss = 0.013623087352090023\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0006727258084348209\tMax abs grad value: 0.027463031784269124\n",
      "Loss = 0.010685279711035717\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.000600678955091631\tMax abs grad value: 0.021496961073707313\n",
      "Loss = 0.008777763363189285\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0005435681922471735\tMax abs grad value: 0.01129976064410421\n",
      "Loss = 0.007212965607225191\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00047110674637350136\tMax abs grad value: 0.011313554678678544\n",
      "Loss = 0.005972479613096719\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00035547999738869796\tMax abs grad value: 0.015162119539481931\n",
      "Loss = 0.004356085377112361\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0005975635164662277\tMax abs grad value: 0.030048346040412146\n",
      "Loss = 0.0032650283436934163\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.00022428428796454234\tMax abs grad value: 0.005543404766810952\n",
      "Loss = 0.0022566898783613625\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0001743754830356351\tMax abs grad value: 0.004810812001755731\n",
      "Loss = 0.001928067942517767\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 0.0001354429152975213\tMax abs grad value: 0.0033744757999555246\n",
      "Loss = 0.0013682288788249754\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 0.0002352425494568298\tMax abs grad value: 0.010990927496413857\n",
      "Loss = 0.0012000336352388098\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 9.979008480957034e-05\tMax abs grad value: 0.0031571913520999847\n",
      "Loss = 0.0009130706505781996\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 7.816219407889147e-05\tMax abs grad value: 0.002050131056148911\n",
      "Loss = 0.0007479050159287858\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 6.149988023409399e-05\tMax abs grad value: 0.0012151449983730086\n",
      "Loss = 0.0005131840463952759\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 9.036676475003281e-05\tMax abs grad value: 0.004624558724582311\n",
      "Loss = 0.0003445334993831045\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 4.242427053415223e-05\tMax abs grad value: 0.0017447578571805106\n",
      "Loss = 0.00023268403282088879\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 2.819673900825924e-05\tMax abs grad value: 0.001074532826904041\n",
      "Loss = 0.00019538220389541191\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 1.7890939143523636e-05\tMax abs grad value: 0.0006207757436224446\n",
      "Loss = 0.0001410301536400593\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 1.2560904789200802e-05\tMax abs grad value: 0.0003970028379920717\n",
      "Loss = 9.032460976167985e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 4.586558144004375e-05\tMax abs grad value: 0.0018481249598568603\n",
      "Loss = 9.133929980352204e-05\n",
      "Mean abs grad value: 1.8779363673936066e-05\tMax abs grad value: 0.0005988595063558719\n",
      "Loss = 6.792585797644583e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 7.58035481427906e-06\tMax abs grad value: 0.0001756842333762951\n",
      "Loss = 4.1046794569106785e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 4.850160192578705e-06\tMax abs grad value: 0.0001016675522382357\n",
      "Loss = 2.8914639258839407e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 3.929137437273828e-06\tMax abs grad value: 0.00012911658573740303\n",
      "Loss = 1.8397505386140252e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 3.135415619257889e-06\tMax abs grad value: 0.00012037639850107181\n",
      "Loss = 1.1408586483606642e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.122400683596398e-06\tMax abs grad value: 7.785566403730354e-05\n",
      "Loss = 8.184175322983882e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 1.1621926627146812e-06\tMax abs grad value: 5.027332563088642e-05\n",
      "Loss = 4.688922835173443e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 5.279968831421468e-07\tMax abs grad value: 1.1779832994447078e-05\n",
      "Loss = 2.8024625263902476e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 3.272970130590331e-07\tMax abs grad value: 9.831291473807438e-06\n",
      "Loss = 1.779907716231129e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.26309193882518034\tMax abs grad value: 7.830934001854184\n",
      "Loss = 13.276908192806674\n",
      "Mean abs grad value: 0.31892604096295957\tMax abs grad value: 17.892183115634463\n",
      "Loss = 16.058905535773633\n",
      "Mean abs grad value: 0.20586184597374402\tMax abs grad value: 3.7797871008119945\n",
      "Loss = 9.516493614814197\n",
      "Train accuracy: 0.061\t\tTest accuracy: 0.053\n",
      "Mean abs grad value: 0.14627888485777632\tMax abs grad value: 2.0040592399397577\n",
      "Loss = 7.562212345394782\n",
      "Train accuracy: 0.078\t\tTest accuracy: 0.067\n",
      "Mean abs grad value: 0.2098549774524497\tMax abs grad value: 7.6558166158895995\n",
      "Loss = 6.467311582031442\n",
      "Train accuracy: 0.157\t\tTest accuracy: 0.151\n",
      "Mean abs grad value: 0.11114655096584311\tMax abs grad value: 2.8614745513383917\n",
      "Loss = 4.580652307830453\n",
      "Train accuracy: 0.195\t\tTest accuracy: 0.187\n",
      "Mean abs grad value: 0.06659681216251488\tMax abs grad value: 1.2910056715669675\n",
      "Loss = 3.7431252977935663\n",
      "Train accuracy: 0.250\t\tTest accuracy: 0.240\n",
      "Mean abs grad value: 0.04749183384003763\tMax abs grad value: 1.3128600541956998\n",
      "Loss = 2.4835007818662707\n",
      "Train accuracy: 0.406\t\tTest accuracy: 0.404\n",
      "Mean abs grad value: 0.0535989501330652\tMax abs grad value: 1.5829558118774638\n",
      "Loss = 1.5902115158656935\n",
      "Train accuracy: 0.552\t\tTest accuracy: 0.551\n",
      "Mean abs grad value: 0.02238006534593248\tMax abs grad value: 0.5956941861426112\n",
      "Loss = 1.0750477436709573\n",
      "Train accuracy: 0.699\t\tTest accuracy: 0.638\n",
      "Mean abs grad value: 0.015849066695523707\tMax abs grad value: 0.4745954229062781\n",
      "Loss = 0.9440649578191872\n",
      "Train accuracy: 0.731\t\tTest accuracy: 0.684\n",
      "Mean abs grad value: 0.014169740364913707\tMax abs grad value: 0.29584035459104335\n",
      "Loss = 0.7539054236982151\n",
      "Train accuracy: 0.766\t\tTest accuracy: 0.724\n",
      "Mean abs grad value: 0.010636939576441459\tMax abs grad value: 0.2663765211966166\n",
      "Loss = 0.5831961930743219\n",
      "Train accuracy: 0.808\t\tTest accuracy: 0.762\n",
      "Mean abs grad value: 0.01500409655125663\tMax abs grad value: 0.3833868914254999\n",
      "Loss = 0.4693510325793293\n",
      "Train accuracy: 0.848\t\tTest accuracy: 0.789\n",
      "Mean abs grad value: 0.009903470017799282\tMax abs grad value: 0.2417887541316487\n",
      "Loss = 0.36972700883062404\n",
      "Train accuracy: 0.878\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.007513230172349716\tMax abs grad value: 0.13484630474688597\n",
      "Loss = 0.319395903729791\n",
      "Train accuracy: 0.894\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.005275364069924339\tMax abs grad value: 0.10686866349900712\n",
      "Loss = 0.2751780514465151\n",
      "Train accuracy: 0.915\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.005473899661388856\tMax abs grad value: 0.15529437533517654\n",
      "Loss = 0.23565375576525116\n",
      "Train accuracy: 0.924\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.0046563717974405245\tMax abs grad value: 0.09360082336206979\n",
      "Loss = 0.19388316004621156\n",
      "Train accuracy: 0.938\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.003863602657768719\tMax abs grad value: 0.0878814031548245\n",
      "Loss = 0.15623927633540824\n",
      "Train accuracy: 0.948\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.005242603523487794\tMax abs grad value: 0.3217808033420442\n",
      "Loss = 0.12515911100360744\n",
      "Train accuracy: 0.962\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0031575507079522427\tMax abs grad value: 0.07384532036756278\n",
      "Loss = 0.09983591227910388\n",
      "Train accuracy: 0.972\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0028603245473314476\tMax abs grad value: 0.07224558857987229\n",
      "Loss = 0.087908417680428\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0034795144848838435\tMax abs grad value: 0.09770994176647367\n",
      "Loss = 0.06683740139804613\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.003564091926131926\tMax abs grad value: 0.09992835355190939\n",
      "Loss = 0.05769935751490531\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0017768388966146284\tMax abs grad value: 0.0471827092108024\n",
      "Loss = 0.05206426981973234\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0014657112632146091\tMax abs grad value: 0.04180059694401667\n",
      "Loss = 0.046094537173089756\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.001966495782599666\tMax abs grad value: 0.077374915424887\n",
      "Loss = 0.0399394438550798\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0044914331068384265\tMax abs grad value: 0.16920683821027166\n",
      "Loss = 0.036755185458152546\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00146663824562284\tMax abs grad value: 0.025329295379618935\n",
      "Loss = 0.02894237300042117\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0010678308745455964\tMax abs grad value: 0.01855214097992731\n",
      "Loss = 0.02689373264849914\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0009650852721972857\tMax abs grad value: 0.022524864573850105\n",
      "Loss = 0.024128090545439924\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001044653461078472\tMax abs grad value: 0.026033031676726662\n",
      "Loss = 0.02121623664641382\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0015202884871394695\tMax abs grad value: 0.04500605771276156\n",
      "Loss = 0.019330705674063507\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.000849555851141987\tMax abs grad value: 0.014946096368509685\n",
      "Loss = 0.017447216117479007\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0007133233825293496\tMax abs grad value: 0.01837300491853657\n",
      "Loss = 0.01582073452730182\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0006533297316789205\tMax abs grad value: 0.018272937893243187\n",
      "Loss = 0.013622777362047417\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.001107126910188956\tMax abs grad value: 0.06102941874334551\n",
      "Loss = 0.010711175949660113\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0012795601895015218\tMax abs grad value: 0.055367305996591794\n",
      "Loss = 0.009148820059206685\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0007224866031550214\tMax abs grad value: 0.026983453710956687\n",
      "Loss = 0.008095938676724626\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.000460382918702127\tMax abs grad value: 0.03263478149457895\n",
      "Loss = 0.007113829135178269\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00046199258644443565\tMax abs grad value: 0.0305807336758678\n",
      "Loss = 0.006601871168208156\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.000553747874596887\tMax abs grad value: 0.023602158307012743\n",
      "Loss = 0.005084230253519422\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.000719487340682579\tMax abs grad value: 0.037246338524020026\n",
      "Loss = 0.004347521047301765\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00032976343580807887\tMax abs grad value: 0.008497934821904442\n",
      "Loss = 0.003341294964288821\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00024015131746109783\tMax abs grad value: 0.006800302950371911\n",
      "Loss = 0.0029063060906393354\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00023806965979507016\tMax abs grad value: 0.006952356186525165\n",
      "Loss = 0.0023983042511147453\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0002110236465201739\tMax abs grad value: 0.0065731551321499765\n",
      "Loss = 0.001721101017189118\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0002792448452657845\tMax abs grad value: 0.014745924526890261\n",
      "Loss = 0.0011904279977373482\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 8.042301805956857e-05\tMax abs grad value: 0.0016691055027361094\n",
      "Loss = 0.0007850639339848371\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 7.767374773126501e-05\tMax abs grad value: 0.001641439353519524\n",
      "Loss = 0.0007314083690046051\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 9.85293566701142e-05\tMax abs grad value: 0.004049101155079174\n",
      "Loss = 0.000600758187300009\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00016098999633888788\tMax abs grad value: 0.0063057472198493805\n",
      "Loss = 0.00047494671044299736\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 7.493808760270868e-05\tMax abs grad value: 0.0019735354675115852\n",
      "Loss = 0.0003504691174819591\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 4.610650450488683e-05\tMax abs grad value: 0.0011068776946494845\n",
      "Loss = 0.0002715672560669907\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.3891485207524466e-05\tMax abs grad value: 0.0012036106180215564\n",
      "Loss = 0.00019837452192318059\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.914912875341784e-05\tMax abs grad value: 0.0008182903669400585\n",
      "Loss = 0.00013648259308506885\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 2.3513746738191417e-05\tMax abs grad value: 0.0005421024755436446\n",
      "Loss = 8.13023120003793e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.1977564427813013e-05\tMax abs grad value: 0.00021865620511830655\n",
      "Loss = 5.533271203817538e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 8.177293501469249e-06\tMax abs grad value: 0.00015779067633060338\n",
      "Loss = 3.823795143009328e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 7.76776275502721e-06\tMax abs grad value: 0.0003612896793827144\n",
      "Loss = 2.084616698831862e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 5.8570403115381795e-06\tMax abs grad value: 0.00022633179663194663\n",
      "Loss = 1.2973769869221097e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.5436851860430896e-06\tMax abs grad value: 8.450259708175474e-05\n",
      "Loss = 8.80111712925359e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.5398410026322368e-06\tMax abs grad value: 3.8157810687455765e-05\n",
      "Loss = 6.41658984995117e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 8.763502973832118e-07\tMax abs grad value: 1.6734860461575523e-05\n",
      "Loss = 4.121901980827985e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.549903426944103e-07\tMax abs grad value: 1.4621151087770588e-05\n",
      "Loss = 2.286505949998126e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 7.112775327618735e-07\tMax abs grad value: 2.979130060405758e-05\n",
      "Loss = 1.393597314041039e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 2.3780408646395517e-07\tMax abs grad value: 5.17521498522905e-06\n",
      "Loss = 8.668348730422757e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.26906215333783634\tMax abs grad value: 7.669524165923307\n",
      "Loss = 13.212731522674545\n",
      "Mean abs grad value: 0.13870041759869695\tMax abs grad value: 3.950098127208457\n",
      "Loss = 5.877674334560123\n",
      "Train accuracy: 0.173\t\tTest accuracy: 0.158\n",
      "Mean abs grad value: 0.07437119036538606\tMax abs grad value: 3.2178487217086627\n",
      "Loss = 3.5498406817966863\n",
      "Train accuracy: 0.126\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 0.05138392080177166\tMax abs grad value: 1.3072942398156102\n",
      "Loss = 2.7066454717953747\n",
      "Train accuracy: 0.254\t\tTest accuracy: 0.236\n",
      "Mean abs grad value: 0.03272721096002416\tMax abs grad value: 0.6506118459278425\n",
      "Loss = 2.1534626203127925\n",
      "Train accuracy: 0.333\t\tTest accuracy: 0.311\n",
      "Mean abs grad value: 0.023083099356040502\tMax abs grad value: 0.5414416381196843\n",
      "Loss = 1.7175933046832168\n",
      "Train accuracy: 0.450\t\tTest accuracy: 0.409\n",
      "Mean abs grad value: 0.01948982836748807\tMax abs grad value: 0.4869475326577679\n",
      "Loss = 1.3360678886293829\n",
      "Train accuracy: 0.588\t\tTest accuracy: 0.540\n",
      "Mean abs grad value: 0.01854513153134084\tMax abs grad value: 0.3904726685897094\n",
      "Loss = 1.0590417353168369\n",
      "Train accuracy: 0.704\t\tTest accuracy: 0.682\n",
      "Mean abs grad value: 0.01326202015887986\tMax abs grad value: 0.3345184776391521\n",
      "Loss = 0.8084007481361702\n",
      "Train accuracy: 0.772\t\tTest accuracy: 0.756\n",
      "Mean abs grad value: 0.013627670742616184\tMax abs grad value: 0.33960379505661176\n",
      "Loss = 0.6530020684935772\n",
      "Train accuracy: 0.794\t\tTest accuracy: 0.778\n",
      "Mean abs grad value: 0.012274537798487821\tMax abs grad value: 0.24789587539934188\n",
      "Loss = 0.5067148775208747\n",
      "Train accuracy: 0.847\t\tTest accuracy: 0.818\n",
      "Mean abs grad value: 0.009600703402603713\tMax abs grad value: 0.21569643353976933\n",
      "Loss = 0.4223816098915647\n",
      "Train accuracy: 0.869\t\tTest accuracy: 0.844\n",
      "Mean abs grad value: 0.00791666541194822\tMax abs grad value: 0.11615849925367014\n",
      "Loss = 0.36787606391096933\n",
      "Train accuracy: 0.879\t\tTest accuracy: 0.851\n",
      "Mean abs grad value: 0.009510630192837806\tMax abs grad value: 0.21395804659262022\n",
      "Loss = 0.288792993689513\n",
      "Train accuracy: 0.902\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.011154642209078258\tMax abs grad value: 0.3075930623426795\n",
      "Loss = 0.2457279127413534\n",
      "Train accuracy: 0.922\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.0066691562828389735\tMax abs grad value: 0.13771081424048787\n",
      "Loss = 0.21056142886819995\n",
      "Train accuracy: 0.936\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.004250400380904599\tMax abs grad value: 0.08576562749443299\n",
      "Loss = 0.17229453419085056\n",
      "Train accuracy: 0.946\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.003690444550279861\tMax abs grad value: 0.07586167123098694\n",
      "Loss = 0.14839288232716102\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.01097183646363963\tMax abs grad value: 0.3355970446100821\n",
      "Loss = 0.14808537658759385\n",
      "Mean abs grad value: 0.005830594022902946\tMax abs grad value: 0.18388772095026923\n",
      "Loss = 0.13204492437089302\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0032869102569071215\tMax abs grad value: 0.07503561478930497\n",
      "Loss = 0.1136470092571269\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0024159079337522094\tMax abs grad value: 0.03877451628311755\n",
      "Loss = 0.10419805077276319\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0026698305088627525\tMax abs grad value: 0.05604449097721576\n",
      "Loss = 0.08472355749532806\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0038908759426519533\tMax abs grad value: 0.07481138340667147\n",
      "Loss = 0.0724424247985605\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002441875941303913\tMax abs grad value: 0.03992239140200483\n",
      "Loss = 0.06470001659794196\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0017978413059467604\tMax abs grad value: 0.0324558802508925\n",
      "Loss = 0.055952409567368425\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.00232500873788436\tMax abs grad value: 0.04537267377617106\n",
      "Loss = 0.04751605759484552\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002929045534504831\tMax abs grad value: 0.0500058954482242\n",
      "Loss = 0.03927096235487982\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.001970548557885962\tMax abs grad value: 0.04638464942670885\n",
      "Loss = 0.034227311589740496\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0012289522863677504\tMax abs grad value: 0.02617891134175163\n",
      "Loss = 0.030900865891299263\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0009569336492814384\tMax abs grad value: 0.014451073215264053\n",
      "Loss = 0.027199430397589725\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0018140507772222635\tMax abs grad value: 0.04073245414803561\n",
      "Loss = 0.023948839550161367\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0014269656392739477\tMax abs grad value: 0.02983916266234775\n",
      "Loss = 0.020971576584977468\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0009830619603341914\tMax abs grad value: 0.018524435906906212\n",
      "Loss = 0.017668786136148737\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0008840051691747116\tMax abs grad value: 0.01403187442043173\n",
      "Loss = 0.013042982491470848\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0015422236093878881\tMax abs grad value: 0.023398415177949182\n",
      "Loss = 0.011069588784987516\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0009914323690995445\tMax abs grad value: 0.014341661859235707\n",
      "Loss = 0.008763484714281757\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0005736184166588957\tMax abs grad value: 0.01006039482921881\n",
      "Loss = 0.006502209979566418\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0005592972859760504\tMax abs grad value: 0.010445404163120668\n",
      "Loss = 0.005158062846034348\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0007482867373518521\tMax abs grad value: 0.01679589573485798\n",
      "Loss = 0.0041780156542044035\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.000438667644150626\tMax abs grad value: 0.009543616477556605\n",
      "Loss = 0.003393518024154088\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0003137867538238729\tMax abs grad value: 0.005269687153687186\n",
      "Loss = 0.002921377347043702\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.00033676887529259707\tMax abs grad value: 0.006168816896096616\n",
      "Loss = 0.0024783187520723573\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.00039795055003938773\tMax abs grad value: 0.010944457026344863\n",
      "Loss = 0.001855870236784698\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 0.00018686386173743472\tMax abs grad value: 0.004711812247436561\n",
      "Loss = 0.0013858364940783157\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.00018020792982806157\tMax abs grad value: 0.0030433716923332107\n",
      "Loss = 0.0010754251286428165\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 0.00013705273692210762\tMax abs grad value: 0.002174446697924584\n",
      "Loss = 0.0007734282736663553\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 0.00012888121414490893\tMax abs grad value: 0.0022561207664963667\n",
      "Loss = 0.0005554454727667047\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 6.942926794160161e-05\tMax abs grad value: 0.0012037038217650904\n",
      "Loss = 0.00044918732098640156\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 6.088669728960607e-05\tMax abs grad value: 0.0011311082987391608\n",
      "Loss = 0.0003773411587686005\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 5.535128018014646e-05\tMax abs grad value: 0.0009948227759446538\n",
      "Loss = 0.00030136546676999635\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 6.655500363611255e-05\tMax abs grad value: 0.001184329622493885\n",
      "Loss = 0.00023518682478284694\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 6.654721744247054e-05\tMax abs grad value: 0.0010043028676662681\n",
      "Loss = 0.00017740027013877244\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 3.372773120574437e-05\tMax abs grad value: 0.0005041891197521888\n",
      "Loss = 0.00012985684438200854\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 1.9715722290124954e-05\tMax abs grad value: 0.0004228033764554849\n",
      "Loss = 9.666305961594516e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.976\n",
      "Mean abs grad value: 1.5570942571796173e-05\tMax abs grad value: 0.00018777671000204285\n",
      "Loss = 6.966560428472796e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 1.970232333364198e-05\tMax abs grad value: 0.0006323782961883951\n",
      "Loss = 4.803704966596015e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 6.574969882970516e-06\tMax abs grad value: 0.00012385809853391623\n",
      "Loss = 2.9482411452461068e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 5.082271004177974e-06\tMax abs grad value: 8.155143625479831e-05\n",
      "Loss = 2.238874596884115e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 1.198653959915163e-05\tMax abs grad value: 0.0003503162119293866\n",
      "Loss = 1.849542640348981e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 5.247422275092649e-06\tMax abs grad value: 0.00012043011838886556\n",
      "Loss = 1.3215120754399569e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 3.7375576198406867e-06\tMax abs grad value: 9.623734893960442e-05\n",
      "Loss = 1.0743421172587007e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.2813449956386763e-06\tMax abs grad value: 4.018167266762529e-05\n",
      "Loss = 7.869073321602267e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.106344272286628e-06\tMax abs grad value: 4.6172699098791536e-05\n",
      "Loss = 6.147411046524979e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.552345192415074e-06\tMax abs grad value: 4.8428883582189916e-05\n",
      "Loss = 3.816070734979746e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 7.8750342655582e-07\tMax abs grad value: 2.229890418216403e-05\n",
      "Loss = 2.5213864138009695e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.325995708835887e-07\tMax abs grad value: 1.3473276975398517e-05\n",
      "Loss = 1.7189672762373427e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 8.106789667971889e-07\tMax abs grad value: 2.2649132555691585e-05\n",
      "Loss = 1.225331500200651e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 3.4540524201399766e-07\tMax abs grad value: 7.459142631501772e-06\n",
      "Loss = 7.216581948641036e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.2745978405248596\tMax abs grad value: 8.803721996092047\n",
      "Loss = 15.361100961653943\n",
      "Mean abs grad value: 0.1558913137918225\tMax abs grad value: 5.176185272139093\n",
      "Loss = 6.615573808633841\n",
      "Train accuracy: 0.195\t\tTest accuracy: 0.202\n",
      "Mean abs grad value: 0.08225256014384179\tMax abs grad value: 2.4138745218035225\n",
      "Loss = 4.166522265495145\n",
      "Train accuracy: 0.257\t\tTest accuracy: 0.280\n",
      "Mean abs grad value: 0.05575799387746728\tMax abs grad value: 1.5360391781803973\n",
      "Loss = 2.853226287117128\n",
      "Train accuracy: 0.267\t\tTest accuracy: 0.271\n",
      "Mean abs grad value: 0.04347039389432885\tMax abs grad value: 1.1591471263761153\n",
      "Loss = 2.2170298289398382\n",
      "Train accuracy: 0.287\t\tTest accuracy: 0.260\n",
      "Mean abs grad value: 0.024163165970424734\tMax abs grad value: 0.5623611266191607\n",
      "Loss = 1.800600919012307\n",
      "Train accuracy: 0.394\t\tTest accuracy: 0.380\n",
      "Mean abs grad value: 0.01765525601976819\tMax abs grad value: 0.33401619227402884\n",
      "Loss = 1.487581956525517\n",
      "Train accuracy: 0.520\t\tTest accuracy: 0.473\n",
      "Mean abs grad value: 0.016746931023107366\tMax abs grad value: 0.39426664004535195\n",
      "Loss = 1.2425673032429398\n",
      "Train accuracy: 0.601\t\tTest accuracy: 0.587\n",
      "Mean abs grad value: 0.01993180740125168\tMax abs grad value: 0.9631520051637316\n",
      "Loss = 1.0463862980957828\n",
      "Train accuracy: 0.632\t\tTest accuracy: 0.573\n",
      "Mean abs grad value: 0.009154823265700366\tMax abs grad value: 0.33203627449522427\n",
      "Loss = 0.8400586479747602\n",
      "Train accuracy: 0.713\t\tTest accuracy: 0.702\n",
      "Mean abs grad value: 0.0079342464202492\tMax abs grad value: 0.14930428709455767\n",
      "Loss = 0.7226166717678173\n",
      "Train accuracy: 0.773\t\tTest accuracy: 0.747\n",
      "Mean abs grad value: 0.007915670524592794\tMax abs grad value: 0.3568594914581187\n",
      "Loss = 0.5761909804557438\n",
      "Train accuracy: 0.814\t\tTest accuracy: 0.802\n",
      "Mean abs grad value: 0.01055843741872272\tMax abs grad value: 0.342851893948245\n",
      "Loss = 0.5038599662928189\n",
      "Train accuracy: 0.828\t\tTest accuracy: 0.813\n",
      "Mean abs grad value: 0.005320331259446912\tMax abs grad value: 0.2689169919354088\n",
      "Loss = 0.42779658482391575\n",
      "Train accuracy: 0.859\t\tTest accuracy: 0.860\n",
      "Mean abs grad value: 0.004687394982320829\tMax abs grad value: 0.12810554548738506\n",
      "Loss = 0.3846870679778222\n",
      "Train accuracy: 0.870\t\tTest accuracy: 0.860\n",
      "Mean abs grad value: 0.0051934233152908914\tMax abs grad value: 0.19265120843260858\n",
      "Loss = 0.3464869766674496\n",
      "Train accuracy: 0.887\t\tTest accuracy: 0.864\n",
      "Mean abs grad value: 0.013750283838836653\tMax abs grad value: 0.7221870062980764\n",
      "Loss = 0.3572339236204468\n",
      "Mean abs grad value: 0.005998906332362088\tMax abs grad value: 0.3302581342039849\n",
      "Loss = 0.32874430043488734\n",
      "Train accuracy: 0.894\t\tTest accuracy: 0.864\n",
      "Mean abs grad value: 0.004905549532540838\tMax abs grad value: 0.1559957476577305\n",
      "Loss = 0.3061211231112674\n",
      "Train accuracy: 0.897\t\tTest accuracy: 0.869\n",
      "Mean abs grad value: 0.004691931515257857\tMax abs grad value: 0.15872096507458464\n",
      "Loss = 0.2755887927670122\n",
      "Train accuracy: 0.903\t\tTest accuracy: 0.871\n",
      "Mean abs grad value: 0.004384819333025733\tMax abs grad value: 0.20950382196817188\n",
      "Loss = 0.23809835959743653\n",
      "Train accuracy: 0.912\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.006626121639656321\tMax abs grad value: 0.17312924014333334\n",
      "Loss = 0.19051290351081504\n",
      "Train accuracy: 0.938\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.0043350819377242404\tMax abs grad value: 0.07866515185048266\n",
      "Loss = 0.15740616625849377\n",
      "Train accuracy: 0.948\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.0032258962323596253\tMax abs grad value: 0.12269713993239803\n",
      "Loss = 0.13846081323925039\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.00329740416865805\tMax abs grad value: 0.1257641382050928\n",
      "Loss = 0.12606461627855922\n",
      "Train accuracy: 0.960\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.002845059841113538\tMax abs grad value: 0.06615471566779245\n",
      "Loss = 0.10020403709320222\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.003242703980394481\tMax abs grad value: 0.10269710241274255\n",
      "Loss = 0.08150418032834592\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0021064552288126235\tMax abs grad value: 0.07974169149611379\n",
      "Loss = 0.06823223804994548\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0017057907256941703\tMax abs grad value: 0.0414374902329394\n",
      "Loss = 0.05950653095883929\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0017878684446569753\tMax abs grad value: 0.03544941526789454\n",
      "Loss = 0.05292592879519051\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002063942327453201\tMax abs grad value: 0.04747294657481568\n",
      "Loss = 0.04615426316922747\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0016278039677522158\tMax abs grad value: 0.05268219228069115\n",
      "Loss = 0.038567171593336176\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0014200394277053302\tMax abs grad value: 0.041045292552297344\n",
      "Loss = 0.03219717485886416\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0019716293910061857\tMax abs grad value: 0.05132341813383377\n",
      "Loss = 0.02686707647083268\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0015397290219881666\tMax abs grad value: 0.03521716231319622\n",
      "Loss = 0.022727838780971885\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0013987051562833722\tMax abs grad value: 0.029765649372415107\n",
      "Loss = 0.019262855933976114\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002401786458197367\tMax abs grad value: 0.11280618589858667\n",
      "Loss = 0.01505862463497458\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0011220227712558403\tMax abs grad value: 0.037964855809643386\n",
      "Loss = 0.012113084239540266\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0006813068321953646\tMax abs grad value: 0.013030336855782646\n",
      "Loss = 0.010803577921400586\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0007649051923361489\tMax abs grad value: 0.026536529581515606\n",
      "Loss = 0.009262221010503833\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0007875383896404838\tMax abs grad value: 0.03306693392272468\n",
      "Loss = 0.0077029391795800945\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0014862567339401446\tMax abs grad value: 0.052677560325666485\n",
      "Loss = 0.006325976909712528\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.000571610454464752\tMax abs grad value: 0.021608337132028144\n",
      "Loss = 0.004513922795203236\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0004165151549060753\tMax abs grad value: 0.011164699528583219\n",
      "Loss = 0.0042539761242933\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00031137484084976173\tMax abs grad value: 0.007940808932080374\n",
      "Loss = 0.003749188142624794\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0003570168330738704\tMax abs grad value: 0.01000260381173099\n",
      "Loss = 0.0032638817440329556\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0003802028180606865\tMax abs grad value: 0.013971587165411487\n",
      "Loss = 0.0024237124721492873\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00137900217489946\tMax abs grad value: 0.034620533418254745\n",
      "Loss = 0.0029663914315708664\n",
      "Mean abs grad value: 0.00036824793464219414\tMax abs grad value: 0.009818969171340789\n",
      "Loss = 0.0021398184198769526\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0002575763985356388\tMax abs grad value: 0.005309318317617352\n",
      "Loss = 0.0017065564606517513\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0001677261069855345\tMax abs grad value: 0.0031056545228212535\n",
      "Loss = 0.001326520300616079\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00016629411767082197\tMax abs grad value: 0.004172807051287973\n",
      "Loss = 0.0010269529588349865\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0001316731958384828\tMax abs grad value: 0.0033874441446271985\n",
      "Loss = 0.0007678215209569029\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00017939640757762637\tMax abs grad value: 0.006952816878685817\n",
      "Loss = 0.0005066148304000656\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 6.0437056809807785e-05\tMax abs grad value: 0.002300667551591812\n",
      "Loss = 0.00031442276808075847\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.769510573169932e-05\tMax abs grad value: 0.000991831634992794\n",
      "Loss = 0.0002604660675490582\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.884372535118083e-05\tMax abs grad value: 0.00204085371203862\n",
      "Loss = 0.00020207171357441666\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.626681505048038e-05\tMax abs grad value: 0.0014219015263446757\n",
      "Loss = 0.0001646614893961721\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 3.337851576241752e-05\tMax abs grad value: 0.0007115838609724509\n",
      "Loss = 0.00013555173735953392\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.8876175984711914e-05\tMax abs grad value: 0.0003454809871750272\n",
      "Loss = 9.55943418603119e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.3002427030312363e-05\tMax abs grad value: 0.0003028636107422815\n",
      "Loss = 5.779046241867894e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.3730650573105134e-05\tMax abs grad value: 0.0005206740730174943\n",
      "Loss = 4.789204450436103e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 8.241836651578351e-06\tMax abs grad value: 0.0001694579463016044\n",
      "Loss = 2.8407992228147814e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.4311162886826274e-06\tMax abs grad value: 0.00012322530130679863\n",
      "Loss = 2.0517590429673584e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.661212100640084e-06\tMax abs grad value: 7.595797951285856e-05\n",
      "Loss = 1.2113764050596545e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.926075246781042e-06\tMax abs grad value: 0.00012177112955972566\n",
      "Loss = 7.957913167466655e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.4743651137772357e-06\tMax abs grad value: 3.562443710939092e-05\n",
      "Loss = 4.446806340331701e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 7.845868658575418e-07\tMax abs grad value: 2.019896764686208e-05\n",
      "Loss = 3.1249984590363747e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 7.037548180081547e-07\tMax abs grad value: 1.7669053891993203e-05\n",
      "Loss = 2.276726853204219e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 6.393770414892569e-07\tMax abs grad value: 2.1336101651942503e-05\n",
      "Loss = 1.1344070838182462e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 2.2470377447968746e-07\tMax abs grad value: 3.6716092023947655e-06\n",
      "Loss = 6.261686982961797e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.13281326961796533\tMax abs grad value: 4.550397190504367\n",
      "Loss = 5.21317364373384\n",
      "Mean abs grad value: 0.09287202239080074\tMax abs grad value: 4.694262712129858\n",
      "Loss = 4.559208875340794\n",
      "Train accuracy: 0.177\t\tTest accuracy: 0.138\n",
      "Mean abs grad value: 0.06116075178546965\tMax abs grad value: 1.5003967591074518\n",
      "Loss = 3.2245657856398133\n",
      "Train accuracy: 0.233\t\tTest accuracy: 0.222\n",
      "Mean abs grad value: 0.029534962275851766\tMax abs grad value: 0.9258350424387037\n",
      "Loss = 2.2069335782607813\n",
      "Train accuracy: 0.284\t\tTest accuracy: 0.242\n",
      "Mean abs grad value: 0.016821246942465073\tMax abs grad value: 0.474873186159033\n",
      "Loss = 1.7102883915145368\n",
      "Train accuracy: 0.352\t\tTest accuracy: 0.324\n",
      "Mean abs grad value: 0.013457681685249337\tMax abs grad value: 0.2913845215109705\n",
      "Loss = 1.4383446564556979\n",
      "Train accuracy: 0.485\t\tTest accuracy: 0.427\n",
      "Mean abs grad value: 0.015757916678598483\tMax abs grad value: 0.46016762491023233\n",
      "Loss = 1.241600586244575\n",
      "Train accuracy: 0.565\t\tTest accuracy: 0.524\n",
      "Mean abs grad value: 0.014030829291515121\tMax abs grad value: 0.505238068374984\n",
      "Loss = 0.9923000647645394\n",
      "Train accuracy: 0.639\t\tTest accuracy: 0.633\n",
      "Mean abs grad value: 0.012747484773045032\tMax abs grad value: 0.4416411702801159\n",
      "Loss = 0.8011863123556567\n",
      "Train accuracy: 0.699\t\tTest accuracy: 0.691\n",
      "Mean abs grad value: 0.007566316616156554\tMax abs grad value: 0.2010602765936092\n",
      "Loss = 0.6177665114698001\n",
      "Train accuracy: 0.787\t\tTest accuracy: 0.791\n",
      "Mean abs grad value: 0.0073411978722892094\tMax abs grad value: 0.2535041262976535\n",
      "Loss = 0.5262591201252924\n",
      "Train accuracy: 0.822\t\tTest accuracy: 0.807\n",
      "Mean abs grad value: 0.007093471824155782\tMax abs grad value: 0.2145526075834901\n",
      "Loss = 0.43946714887399246\n",
      "Train accuracy: 0.852\t\tTest accuracy: 0.844\n",
      "Mean abs grad value: 0.00930033873756982\tMax abs grad value: 0.4159984842091036\n",
      "Loss = 0.38983913873289616\n",
      "Train accuracy: 0.874\t\tTest accuracy: 0.869\n",
      "Mean abs grad value: 0.00517317853237224\tMax abs grad value: 0.1192143918942791\n",
      "Loss = 0.33387087390154485\n",
      "Train accuracy: 0.892\t\tTest accuracy: 0.869\n",
      "Mean abs grad value: 0.004777768315280702\tMax abs grad value: 0.17570684249739646\n",
      "Loss = 0.2955263666702428\n",
      "Train accuracy: 0.906\t\tTest accuracy: 0.896\n",
      "Mean abs grad value: 0.00517805328632592\tMax abs grad value: 0.1976533831504901\n",
      "Loss = 0.26188040420886444\n",
      "Train accuracy: 0.922\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.004395066577046476\tMax abs grad value: 0.17656138541149327\n",
      "Loss = 0.23130768562058232\n",
      "Train accuracy: 0.927\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.004113013591494039\tMax abs grad value: 0.1562776668773968\n",
      "Loss = 0.19652826755173006\n",
      "Train accuracy: 0.938\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.00403935718939724\tMax abs grad value: 0.10220324424486031\n",
      "Loss = 0.16258203426431686\n",
      "Train accuracy: 0.940\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.003921339983101824\tMax abs grad value: 0.09632007951080422\n",
      "Loss = 0.13516041587935473\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.004622523027721925\tMax abs grad value: 0.16655270352700494\n",
      "Loss = 0.10835671308383113\n",
      "Train accuracy: 0.959\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.004847966977726022\tMax abs grad value: 0.15168637260069198\n",
      "Loss = 0.09850121486988979\n",
      "Train accuracy: 0.966\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0022968774304837946\tMax abs grad value: 0.043706146054927786\n",
      "Loss = 0.09083720659455095\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002254408056812506\tMax abs grad value: 0.06124670766135245\n",
      "Loss = 0.08637737508844366\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.003100405294311723\tMax abs grad value: 0.06791061851148068\n",
      "Loss = 0.07975153524536639\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.003461155120677008\tMax abs grad value: 0.07446871333992679\n",
      "Loss = 0.06831846027569474\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.004760757498428112\tMax abs grad value: 0.1135839924371393\n",
      "Loss = 0.0517376352133864\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.003706288648859492\tMax abs grad value: 0.08290741068767918\n",
      "Loss = 0.04597516672806638\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0015582759745521823\tMax abs grad value: 0.03310903531354896\n",
      "Loss = 0.039431932580657775\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0011650215374904174\tMax abs grad value: 0.022247959129858476\n",
      "Loss = 0.037152537492930744\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0013609341751472932\tMax abs grad value: 0.025936950072591485\n",
      "Loss = 0.03318913923481602\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.001694214915550256\tMax abs grad value: 0.03556484080503788\n",
      "Loss = 0.027959770263242673\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0030933679531593766\tMax abs grad value: 0.08259347197450609\n",
      "Loss = 0.023829082212749486\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0011223301489692763\tMax abs grad value: 0.023226760180933427\n",
      "Loss = 0.01797594415452075\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0008951112191709309\tMax abs grad value: 0.02031056311390488\n",
      "Loss = 0.015970929662849662\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0008396725629675675\tMax abs grad value: 0.015004312327560424\n",
      "Loss = 0.013484733066915756\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0008645969685487231\tMax abs grad value: 0.01953403459246189\n",
      "Loss = 0.009678232579462251\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0025695205858288703\tMax abs grad value: 0.06969109971433067\n",
      "Loss = 0.010738459266712422\n",
      "Mean abs grad value: 0.0008377595543056246\tMax abs grad value: 0.018588048034037696\n",
      "Loss = 0.007814299608194315\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0005257197685078078\tMax abs grad value: 0.008526769773023702\n",
      "Loss = 0.006530444524140393\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0004267618864976086\tMax abs grad value: 0.01122715176889643\n",
      "Loss = 0.005556716873753382\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0004431945723423858\tMax abs grad value: 0.012877183805749912\n",
      "Loss = 0.004550722953608297\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0003240576540393268\tMax abs grad value: 0.008139819441285986\n",
      "Loss = 0.00391825259555431\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0004251017073909462\tMax abs grad value: 0.011941010066593932\n",
      "Loss = 0.003261977882480552\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.00034196510316467137\tMax abs grad value: 0.009943015500167405\n",
      "Loss = 0.0026297924290784374\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.00022132679777813285\tMax abs grad value: 0.005472781040048533\n",
      "Loss = 0.002103158225864076\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.0001792825016327757\tMax abs grad value: 0.004483249395102752\n",
      "Loss = 0.0015937931962760393\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.00022943491268533525\tMax abs grad value: 0.007343509142389727\n",
      "Loss = 0.0010893980171262766\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 9.23199074448394e-05\tMax abs grad value: 0.002272317078360623\n",
      "Loss = 0.0006233508437871258\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 6.573076951712264e-05\tMax abs grad value: 0.0011806021789824916\n",
      "Loss = 0.00048343471047410775\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 5.5922455749443865e-05\tMax abs grad value: 0.0017065743690170164\n",
      "Loss = 0.00032512095016627756\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0004598475672836124\tMax abs grad value: 0.022182056384485324\n",
      "Loss = 0.0006815275288971647\n",
      "Mean abs grad value: 5.420004787402314e-05\tMax abs grad value: 0.0018577631730421745\n",
      "Loss = 0.00024976576677481746\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 3.279814840703435e-05\tMax abs grad value: 0.0009316216668889371\n",
      "Loss = 0.00017821780212640966\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 2.1174437404247182e-05\tMax abs grad value: 0.000438536951207904\n",
      "Loss = 0.0001249736514937682\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 1.460808965111286e-05\tMax abs grad value: 0.0003642424944959097\n",
      "Loss = 7.894539061098646e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.279731355690734e-05\tMax abs grad value: 0.0011174354232588851\n",
      "Loss = 5.7267580471601584e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 9.720847794386467e-06\tMax abs grad value: 0.0003069809831883459\n",
      "Loss = 3.74620179299707e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 7.394280171966785e-06\tMax abs grad value: 0.00011434710820051525\n",
      "Loss = 2.9723527831141018e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 7.874976375873956e-06\tMax abs grad value: 0.00022291381366960097\n",
      "Loss = 2.009996599009087e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.696718570771868e-06\tMax abs grad value: 0.00013896660612869343\n",
      "Loss = 1.2911528420917895e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.7373266409741182e-06\tMax abs grad value: 0.00012151942624038331\n",
      "Loss = 1.0121946484499813e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.6510324393783721e-06\tMax abs grad value: 3.4590568126757965e-05\n",
      "Loss = 6.068219419014184e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 9.898375823138964e-07\tMax abs grad value: 1.7394475943712755e-05\n",
      "Loss = 4.362479824398498e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.777339301937676e-07\tMax abs grad value: 2.797716531429238e-05\n",
      "Loss = 2.3997021805456196e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.2238225771146404e-06\tMax abs grad value: 0.00012376725067453527\n",
      "Loss = 3.296589197405157e-06\n",
      "Mean abs grad value: 6.706089056058734e-07\tMax abs grad value: 2.3674462632699718e-05\n",
      "Loss = 1.8291193369345472e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.737046054829537e-07\tMax abs grad value: 1.1248742282207327e-05\n",
      "Loss = 1.2868315782253143e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.3583887648513193e-07\tMax abs grad value: 6.52583169547503e-06\n",
      "Loss = 9.108085409412138e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.2290906556008626\tMax abs grad value: 11.246618782486433\n",
      "Loss = 10.093901296489156\n",
      "Mean abs grad value: 0.17475893709838208\tMax abs grad value: 7.852739256756861\n",
      "Loss = 9.21533707609216\n",
      "Train accuracy: 0.143\t\tTest accuracy: 0.144\n",
      "Mean abs grad value: 0.1720192048256015\tMax abs grad value: 8.096103194291361\n",
      "Loss = 7.21497794904054\n",
      "Train accuracy: 0.137\t\tTest accuracy: 0.131\n",
      "Mean abs grad value: 0.07161718105281296\tMax abs grad value: 2.2672460862866917\n",
      "Loss = 4.5102344862531725\n",
      "Train accuracy: 0.154\t\tTest accuracy: 0.173\n",
      "Mean abs grad value: 0.05284539786915586\tMax abs grad value: 1.2293535264085633\n",
      "Loss = 3.584456474502325\n",
      "Train accuracy: 0.209\t\tTest accuracy: 0.213\n",
      "Mean abs grad value: 0.031611189877896996\tMax abs grad value: 0.5752246872985644\n",
      "Loss = 2.5990672277327707\n",
      "Train accuracy: 0.260\t\tTest accuracy: 0.227\n",
      "Mean abs grad value: 0.019990843190682596\tMax abs grad value: 0.2830961770305718\n",
      "Loss = 2.1120985378394415\n",
      "Train accuracy: 0.340\t\tTest accuracy: 0.318\n",
      "Mean abs grad value: 0.013860259792751534\tMax abs grad value: 0.20271432892813523\n",
      "Loss = 1.658728807780459\n",
      "Train accuracy: 0.486\t\tTest accuracy: 0.413\n",
      "Mean abs grad value: 0.01452647749188227\tMax abs grad value: 0.24121025496743617\n",
      "Loss = 1.2681906479692293\n",
      "Train accuracy: 0.624\t\tTest accuracy: 0.564\n",
      "Mean abs grad value: 0.019192261738662845\tMax abs grad value: 0.8852163566539386\n",
      "Loss = 0.9836172627064512\n",
      "Train accuracy: 0.652\t\tTest accuracy: 0.624\n",
      "Mean abs grad value: 0.01082958337388829\tMax abs grad value: 0.26373406331346877\n",
      "Loss = 0.7675005035282512\n",
      "Train accuracy: 0.762\t\tTest accuracy: 0.729\n",
      "Mean abs grad value: 0.009338160666451937\tMax abs grad value: 0.19725727130223214\n",
      "Loss = 0.6948967585178353\n",
      "Train accuracy: 0.786\t\tTest accuracy: 0.756\n",
      "Mean abs grad value: 0.007201462596656724\tMax abs grad value: 0.13824282589577822\n",
      "Loss = 0.5368037653202186\n",
      "Train accuracy: 0.823\t\tTest accuracy: 0.804\n",
      "Mean abs grad value: 0.00897225527350818\tMax abs grad value: 0.2823896325399271\n",
      "Loss = 0.4419319364189222\n",
      "Train accuracy: 0.863\t\tTest accuracy: 0.824\n",
      "Mean abs grad value: 0.005100413934292397\tMax abs grad value: 0.09827414570408415\n",
      "Loss = 0.3537840170640855\n",
      "Train accuracy: 0.889\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.004368696792369128\tMax abs grad value: 0.08905503098473402\n",
      "Loss = 0.2978705624216925\n",
      "Train accuracy: 0.913\t\tTest accuracy: 0.869\n",
      "Mean abs grad value: 0.009493317972767305\tMax abs grad value: 0.16194409557295408\n",
      "Loss = 0.24272320970585454\n",
      "Train accuracy: 0.922\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.004177887688250146\tMax abs grad value: 0.06762424844592511\n",
      "Loss = 0.18757293298459068\n",
      "Train accuracy: 0.942\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0036689150740310326\tMax abs grad value: 0.05995149340897925\n",
      "Loss = 0.16447032058163877\n",
      "Train accuracy: 0.946\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0034687144666507735\tMax abs grad value: 0.06587473037598664\n",
      "Loss = 0.12945990911276198\n",
      "Train accuracy: 0.959\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.005635585342553192\tMax abs grad value: 0.10733232151890157\n",
      "Loss = 0.11101835894951885\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0023487726000941222\tMax abs grad value: 0.03744192128482889\n",
      "Loss = 0.08832849843345482\n",
      "Train accuracy: 0.972\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0018918946314022296\tMax abs grad value: 0.024132166026232606\n",
      "Loss = 0.07640252423485848\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0020878967903738993\tMax abs grad value: 0.030757241542306125\n",
      "Loss = 0.0630683809960538\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0034509993399231987\tMax abs grad value: 0.05429486892714016\n",
      "Loss = 0.05089070128084449\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0015319693730215427\tMax abs grad value: 0.030324519821541617\n",
      "Loss = 0.039808197370695714\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0012491552794192163\tMax abs grad value: 0.019921541033241737\n",
      "Loss = 0.035490556349473824\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0013385578458034776\tMax abs grad value: 0.03144804117518764\n",
      "Loss = 0.02870945874631557\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0022032285242883707\tMax abs grad value: 0.049396091559998245\n",
      "Loss = 0.0222279119768859\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0013893875565922167\tMax abs grad value: 0.027820919324034292\n",
      "Loss = 0.017965634279136854\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0009731194288881258\tMax abs grad value: 0.015424975985347677\n",
      "Loss = 0.01592095917101\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0008478828008311694\tMax abs grad value: 0.013906330467843713\n",
      "Loss = 0.011957444758351025\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0006298142443012434\tMax abs grad value: 0.010853092832930506\n",
      "Loss = 0.009006329250140799\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0004761292441375932\tMax abs grad value: 0.00713347703075063\n",
      "Loss = 0.006470596388513234\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.00045505225042987807\tMax abs grad value: 0.010127905352994402\n",
      "Loss = 0.00414228485433374\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.00035300386279639597\tMax abs grad value: 0.008006040199463833\n",
      "Loss = 0.0020871138879157737\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0004928607939494899\tMax abs grad value: 0.01585172781744931\n",
      "Loss = 0.0016514312573736312\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00013395648397199322\tMax abs grad value: 0.0028675612262527403\n",
      "Loss = 0.0011253237113419393\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0001021181469485129\tMax abs grad value: 0.0015108681204094403\n",
      "Loss = 0.0009709420418680442\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 9.705163713768548e-05\tMax abs grad value: 0.002310749153249522\n",
      "Loss = 0.0006533649000843053\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 9.623466108173772e-05\tMax abs grad value: 0.001944482946962628\n",
      "Loss = 0.00047646400091636747\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 5.249235039337351e-05\tMax abs grad value: 0.0010127371580704164\n",
      "Loss = 0.00029748373373644565\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 3.211625867219573e-05\tMax abs grad value: 0.0007569776231587369\n",
      "Loss = 0.00020115308511133625\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 2.1594967535808674e-05\tMax abs grad value: 0.0004955109887374102\n",
      "Loss = 0.00012189770403349139\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 1.4342818790452309e-05\tMax abs grad value: 0.00030514547383006415\n",
      "Loss = 7.396254032379037e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 9.699469333925717e-06\tMax abs grad value: 0.0002576816497469332\n",
      "Loss = 3.887211642193708e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 4.771015368702409e-06\tMax abs grad value: 8.433782468826706e-05\n",
      "Loss = 2.301436210830914e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 3.0652563652270943e-06\tMax abs grad value: 5.108140784937415e-05\n",
      "Loss = 1.5088746830921636e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 1.6760135783975135e-06\tMax abs grad value: 2.3439483415356512e-05\n",
      "Loss = 7.599277274865746e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 1.39411390754635e-06\tMax abs grad value: 3.114944898919549e-05\n",
      "Loss = 4.04892982677608e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 8.093940307536264e-07\tMax abs grad value: 2.29350211891014e-05\n",
      "Loss = 2.269746633696975e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 3.497038238033559e-07\tMax abs grad value: 7.401995932777489e-06\n",
      "Loss = 1.3111044328679915e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.1935145299778048\tMax abs grad value: 5.722419290922958\n",
      "Loss = 8.335442453491735\n",
      "Mean abs grad value: 0.142204947677013\tMax abs grad value: 5.119060770524512\n",
      "Loss = 5.32628866666752\n",
      "Train accuracy: 0.181\t\tTest accuracy: 0.162\n",
      "Mean abs grad value: 0.13119095059757702\tMax abs grad value: 4.979091475217599\n",
      "Loss = 5.622973888122459\n",
      "Mean abs grad value: 0.07626329753468446\tMax abs grad value: 2.582541779790204\n",
      "Loss = 4.014625953512665\n",
      "Train accuracy: 0.181\t\tTest accuracy: 0.191\n",
      "Mean abs grad value: 0.062408337714224126\tMax abs grad value: 1.6078508767924278\n",
      "Loss = 3.4847745182311485\n",
      "Train accuracy: 0.206\t\tTest accuracy: 0.200\n",
      "Mean abs grad value: 0.04236683488418346\tMax abs grad value: 0.9508110331760599\n",
      "Loss = 2.4929526522130705\n",
      "Train accuracy: 0.290\t\tTest accuracy: 0.273\n",
      "Mean abs grad value: 0.02888345606470962\tMax abs grad value: 0.8128157387443948\n",
      "Loss = 1.9470158253476428\n",
      "Train accuracy: 0.328\t\tTest accuracy: 0.276\n",
      "Mean abs grad value: 0.02012385723767529\tMax abs grad value: 0.31601386718766333\n",
      "Loss = 1.5273977223171176\n",
      "Train accuracy: 0.456\t\tTest accuracy: 0.380\n",
      "Mean abs grad value: 0.014909392636072976\tMax abs grad value: 0.4308949900229046\n",
      "Loss = 1.1650661513371696\n",
      "Train accuracy: 0.609\t\tTest accuracy: 0.584\n",
      "Mean abs grad value: 0.014464189445013003\tMax abs grad value: 0.32219891304137416\n",
      "Loss = 0.8346996173209682\n",
      "Train accuracy: 0.695\t\tTest accuracy: 0.680\n",
      "Mean abs grad value: 0.013326104201695131\tMax abs grad value: 0.5222331703255949\n",
      "Loss = 0.6558381085916802\n",
      "Train accuracy: 0.774\t\tTest accuracy: 0.758\n",
      "Mean abs grad value: 0.008720215539906439\tMax abs grad value: 0.2650161100288963\n",
      "Loss = 0.5528511588022188\n",
      "Train accuracy: 0.825\t\tTest accuracy: 0.818\n",
      "Mean abs grad value: 0.007269297078798934\tMax abs grad value: 0.24693473205559183\n",
      "Loss = 0.4865938852661652\n",
      "Train accuracy: 0.855\t\tTest accuracy: 0.840\n",
      "Mean abs grad value: 0.007713541747637736\tMax abs grad value: 0.18888436240249112\n",
      "Loss = 0.4134180586616173\n",
      "Train accuracy: 0.880\t\tTest accuracy: 0.849\n",
      "Mean abs grad value: 0.0063933746939008\tMax abs grad value: 0.2584288981479086\n",
      "Loss = 0.3351579291405043\n",
      "Train accuracy: 0.907\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.00569097683934641\tMax abs grad value: 0.13148001684401947\n",
      "Loss = 0.2818160076455054\n",
      "Train accuracy: 0.916\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.004918608729690249\tMax abs grad value: 0.1366997259055664\n",
      "Loss = 0.25272066647841623\n",
      "Train accuracy: 0.924\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.004379292662678559\tMax abs grad value: 0.11432827263234807\n",
      "Loss = 0.1921501477284241\n",
      "Train accuracy: 0.938\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.004352003193231465\tMax abs grad value: 0.08617171756485655\n",
      "Loss = 0.15310462721685403\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.0031528355060382097\tMax abs grad value: 0.05241884149289447\n",
      "Loss = 0.12298380123335792\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.0024007632107021647\tMax abs grad value: 0.06623185988780882\n",
      "Loss = 0.09652425295893585\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.002335777376569421\tMax abs grad value: 0.05548870293890829\n",
      "Loss = 0.07775762396017251\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.0023496498706057217\tMax abs grad value: 0.06965084482241796\n",
      "Loss = 0.06344566495785671\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0016265554030483974\tMax abs grad value: 0.04059529495416242\n",
      "Loss = 0.05236031022433221\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.001496770150975018\tMax abs grad value: 0.03831297752202278\n",
      "Loss = 0.04326871976913358\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0014868199331189442\tMax abs grad value: 0.06894567946031191\n",
      "Loss = 0.03669979556768448\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.001605218036257445\tMax abs grad value: 0.047475302224639915\n",
      "Loss = 0.03142437604452701\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002024705333844169\tMax abs grad value: 0.06485747321054725\n",
      "Loss = 0.02678058103602322\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0012867515682352334\tMax abs grad value: 0.03345923698076153\n",
      "Loss = 0.022171689885384066\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0010698905057349817\tMax abs grad value: 0.03024140878866571\n",
      "Loss = 0.017921850163162754\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0009863426387512729\tMax abs grad value: 0.030447163574528674\n",
      "Loss = 0.015560071537425203\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.000717116712880161\tMax abs grad value: 0.017978080509970882\n",
      "Loss = 0.010893062523737392\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0009125660413919632\tMax abs grad value: 0.04091416352495969\n",
      "Loss = 0.007474900523262611\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00041096676799079\tMax abs grad value: 0.01659465470744537\n",
      "Loss = 0.005182067520536218\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00033238530382058044\tMax abs grad value: 0.007803373635859366\n",
      "Loss = 0.0041462224790765065\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0003152758326729054\tMax abs grad value: 0.012200950344619025\n",
      "Loss = 0.00332033723209506\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00030663097059689117\tMax abs grad value: 0.014001318595291502\n",
      "Loss = 0.0027007309950626674\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00020407572004834074\tMax abs grad value: 0.006074142677709641\n",
      "Loss = 0.0022025892514527263\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0001871992775234153\tMax abs grad value: 0.004383228131802599\n",
      "Loss = 0.0016777205746164672\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0003164696549875123\tMax abs grad value: 0.009510316216520074\n",
      "Loss = 0.001308288048361617\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00014477116936517455\tMax abs grad value: 0.005862397047256369\n",
      "Loss = 0.0009771583927516052\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00011427474907603022\tMax abs grad value: 0.003936663659661157\n",
      "Loss = 0.0007785381501882123\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0001435565201286578\tMax abs grad value: 0.006360290072237307\n",
      "Loss = 0.0005526885991457118\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 5.681456483026748e-05\tMax abs grad value: 0.002445870540227398\n",
      "Loss = 0.00035299446760085596\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 4.407797728658386e-05\tMax abs grad value: 0.00156021780597346\n",
      "Loss = 0.00029896502845300254\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.0335727584229695e-05\tMax abs grad value: 0.0006915289638833272\n",
      "Loss = 0.0002167698642871635\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.4514776540137232e-05\tMax abs grad value: 0.0005769475480148856\n",
      "Loss = 0.000143101269974383\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 7.759937530585719e-05\tMax abs grad value: 0.0032004796498125913\n",
      "Loss = 0.0001490785444976658\n",
      "Mean abs grad value: 2.7717034240170313e-05\tMax abs grad value: 0.0010772031252080066\n",
      "Loss = 0.00010443234154921909\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.4253457508614539e-05\tMax abs grad value: 0.00042279467454073646\n",
      "Loss = 6.357425454212182e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 8.037955372205759e-06\tMax abs grad value: 0.00021116891316092515\n",
      "Loss = 4.416303459293206e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 7.3820727407012355e-06\tMax abs grad value: 0.00026042351053157315\n",
      "Loss = 2.9792108001467936e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.068333962831792e-06\tMax abs grad value: 9.830630813949682e-05\n",
      "Loss = 2.0795625977533395e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.539562345994919e-06\tMax abs grad value: 4.868681263263934e-05\n",
      "Loss = 1.2550198514240741e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.165557306536371e-06\tMax abs grad value: 0.00024055580738772646\n",
      "Loss = 9.538389872995532e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.410340306348264e-06\tMax abs grad value: 4.756307582331185e-05\n",
      "Loss = 4.5134449597069345e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.141563431722419e-06\tMax abs grad value: 3.3313925024656283e-05\n",
      "Loss = 3.6430517459700536e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.763710213039374e-07\tMax abs grad value: 1.7056898048986803e-05\n",
      "Loss = 2.056970891661066e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 3.14717379903804e-07\tMax abs grad value: 1.069118515945679e-05\n",
      "Loss = 1.3082052681843655e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 4.878718035246777e-07\tMax abs grad value: 1.8269651507180854e-05\n",
      "Loss = 8.943506979082547e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.3592419119244477e-07\tMax abs grad value: 4.192200550053876e-06\n",
      "Loss = 4.2154641337488617e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.18813755428778778\tMax abs grad value: 6.06687608263379\n",
      "Loss = 6.545551996617033\n",
      "Mean abs grad value: 0.07208401104910886\tMax abs grad value: 4.276231473873657\n",
      "Loss = 4.267326314954209\n",
      "Train accuracy: 0.039\t\tTest accuracy: 0.044\n",
      "Mean abs grad value: 0.035010506438081464\tMax abs grad value: 1.0454082044784019\n",
      "Loss = 2.6970083112721523\n",
      "Train accuracy: 0.146\t\tTest accuracy: 0.129\n",
      "Mean abs grad value: 0.01660837844358053\tMax abs grad value: 0.334095810932887\n",
      "Loss = 2.3086153920755748\n",
      "Train accuracy: 0.177\t\tTest accuracy: 0.176\n",
      "Mean abs grad value: 0.01436474390240053\tMax abs grad value: 0.3204659028037009\n",
      "Loss = 2.145446482770634\n",
      "Train accuracy: 0.215\t\tTest accuracy: 0.207\n",
      "Mean abs grad value: 0.012765044621669623\tMax abs grad value: 0.33895104985078084\n",
      "Loss = 1.7361328610299314\n",
      "Train accuracy: 0.417\t\tTest accuracy: 0.378\n",
      "Mean abs grad value: 0.01538651406346662\tMax abs grad value: 0.3458678362615161\n",
      "Loss = 1.3859757050892252\n",
      "Train accuracy: 0.557\t\tTest accuracy: 0.529\n",
      "Mean abs grad value: 0.011952933610442109\tMax abs grad value: 0.21977473796512173\n",
      "Loss = 1.007782940653101\n",
      "Train accuracy: 0.702\t\tTest accuracy: 0.660\n",
      "Mean abs grad value: 0.027013973736980876\tMax abs grad value: 1.1770732854933241\n",
      "Loss = 0.9672017261763582\n",
      "Mean abs grad value: 0.010586070340348024\tMax abs grad value: 0.322475373642518\n",
      "Loss = 0.8504386020127707\n",
      "Train accuracy: 0.766\t\tTest accuracy: 0.729\n",
      "Mean abs grad value: 0.012333902895807798\tMax abs grad value: 0.39501971598359825\n",
      "Loss = 0.6725781177843534\n",
      "Train accuracy: 0.808\t\tTest accuracy: 0.749\n",
      "Mean abs grad value: 0.014255184903372702\tMax abs grad value: 0.47876159758199527\n",
      "Loss = 0.5690174132734451\n",
      "Train accuracy: 0.825\t\tTest accuracy: 0.798\n",
      "Mean abs grad value: 0.008956604230117925\tMax abs grad value: 0.18265141174021035\n",
      "Loss = 0.5176890099178802\n",
      "Train accuracy: 0.839\t\tTest accuracy: 0.798\n",
      "Mean abs grad value: 0.006425822271639461\tMax abs grad value: 0.113762274307934\n",
      "Loss = 0.49298499018691255\n",
      "Train accuracy: 0.852\t\tTest accuracy: 0.800\n",
      "Mean abs grad value: 0.006278499513719022\tMax abs grad value: 0.14326923020846233\n",
      "Loss = 0.44244642072153534\n",
      "Train accuracy: 0.860\t\tTest accuracy: 0.833\n",
      "Mean abs grad value: 0.006770995123584706\tMax abs grad value: 0.12786700335277978\n",
      "Loss = 0.3722795474590804\n",
      "Train accuracy: 0.887\t\tTest accuracy: 0.847\n",
      "Mean abs grad value: 0.008128854428389757\tMax abs grad value: 0.22032383416188436\n",
      "Loss = 0.30861982440266444\n",
      "Train accuracy: 0.894\t\tTest accuracy: 0.844\n",
      "Mean abs grad value: 0.00883145961056672\tMax abs grad value: 0.24306197145436262\n",
      "Loss = 0.2729497969546772\n",
      "Train accuracy: 0.912\t\tTest accuracy: 0.860\n",
      "Mean abs grad value: 0.004378237994064561\tMax abs grad value: 0.06776413829879122\n",
      "Loss = 0.24688926358675678\n",
      "Train accuracy: 0.922\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.0036284816272904247\tMax abs grad value: 0.0644213847857729\n",
      "Loss = 0.22558662628965265\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.873\n",
      "Mean abs grad value: 0.0040387937026941335\tMax abs grad value: 0.0920375328069586\n",
      "Loss = 0.20083493391647889\n",
      "Train accuracy: 0.937\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.0037139336128239647\tMax abs grad value: 0.07447979804291185\n",
      "Loss = 0.17444288704587163\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.896\n",
      "Mean abs grad value: 0.007099879095125886\tMax abs grad value: 0.22995727947704625\n",
      "Loss = 0.1428709049859922\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.896\n",
      "Mean abs grad value: 0.004091802091204557\tMax abs grad value: 0.09387971793546693\n",
      "Loss = 0.12617658570883503\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.0027388499072484936\tMax abs grad value: 0.04477145889240219\n",
      "Loss = 0.11947495062457952\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.0021718855215041083\tMax abs grad value: 0.04859908071227015\n",
      "Loss = 0.10825760920848201\n",
      "Train accuracy: 0.965\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.0029668498096157747\tMax abs grad value: 0.06573564268496192\n",
      "Loss = 0.09769657960313931\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.004562521957777139\tMax abs grad value: 0.14828959400416342\n",
      "Loss = 0.08486677053097803\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.002630798301587202\tMax abs grad value: 0.06604465734814435\n",
      "Loss = 0.07317532724712432\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0019481794644589082\tMax abs grad value: 0.03438972338573533\n",
      "Loss = 0.06625243448834921\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0020904559799405165\tMax abs grad value: 0.03559440926718667\n",
      "Loss = 0.05821008215113126\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0019632451501622175\tMax abs grad value: 0.035870212806369414\n",
      "Loss = 0.05072746617504094\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0028176193935892818\tMax abs grad value: 0.0633447320559365\n",
      "Loss = 0.04100904422200584\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0017462521133984148\tMax abs grad value: 0.046184403654518494\n",
      "Loss = 0.03166298054256133\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0012883563388501097\tMax abs grad value: 0.023855046040382282\n",
      "Loss = 0.02633984918441751\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0018250160579793941\tMax abs grad value: 0.047126213910187564\n",
      "Loss = 0.020431594421694885\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0012587460210892812\tMax abs grad value: 0.02552840343886197\n",
      "Loss = 0.016348112228130682\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0008157657334416321\tMax abs grad value: 0.01602158004768746\n",
      "Loss = 0.01510160616359807\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0007963881142968133\tMax abs grad value: 0.018925816777402755\n",
      "Loss = 0.012860051684766187\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0008421792575849428\tMax abs grad value: 0.022630229803665917\n",
      "Loss = 0.01078292504094766\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0016238499861378076\tMax abs grad value: 0.03200429436149814\n",
      "Loss = 0.009224142920331333\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0006341921872304098\tMax abs grad value: 0.018717408960203134\n",
      "Loss = 0.0073581496634855265\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0004997933012390671\tMax abs grad value: 0.014906795491247172\n",
      "Loss = 0.006556194139117171\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.0007406522600216073\tMax abs grad value: 0.014972854282407582\n",
      "Loss = 0.0048456546814349905\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 0.0005997394012250783\tMax abs grad value: 0.018776801179817452\n",
      "Loss = 0.0036079822471294185\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.0005124397718584971\tMax abs grad value: 0.016259299460191484\n",
      "Loss = 0.0026309282841154168\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.00025204026121525134\tMax abs grad value: 0.007284201212937892\n",
      "Loss = 0.0021740679780173273\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0002391177917339072\tMax abs grad value: 0.004795972726444544\n",
      "Loss = 0.001902451303914247\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.00024274289748170373\tMax abs grad value: 0.00394212331870438\n",
      "Loss = 0.0017024330601595786\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0002622754442087935\tMax abs grad value: 0.004884046218970121\n",
      "Loss = 0.0012131462579080823\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.00026332950125033434\tMax abs grad value: 0.006426484257529491\n",
      "Loss = 0.0007386123377539421\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.00013441672177379502\tMax abs grad value: 0.0022290683730377897\n",
      "Loss = 0.0005271168025736548\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 7.207526994387879e-05\tMax abs grad value: 0.001251450457662815\n",
      "Loss = 0.00041374640168445804\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 5.51440796039882e-05\tMax abs grad value: 0.001253097803294042\n",
      "Loss = 0.00033245742455985497\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 5.9949794864439945e-05\tMax abs grad value: 0.0013739582975137957\n",
      "Loss = 0.0002494505129281124\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 4.0972456043248975e-05\tMax abs grad value: 0.0006330427085485244\n",
      "Loss = 0.00015588262459864666\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 2.7965301874105002e-05\tMax abs grad value: 0.0004051534793568015\n",
      "Loss = 0.00011232643210639047\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 1.4473219130128114e-05\tMax abs grad value: 0.0001833011480986852\n",
      "Loss = 7.201992868234335e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 1.0132720903345502e-05\tMax abs grad value: 0.0001496408440790245\n",
      "Loss = 4.7479550907063373e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 1.729805787085246e-05\tMax abs grad value: 0.000443658290975076\n",
      "Loss = 3.357467026414758e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 4.599858196819497e-06\tMax abs grad value: 9.638989140813047e-05\n",
      "Loss = 1.8618492435070514e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 3.2418659591737062e-06\tMax abs grad value: 5.4699488087852754e-05\n",
      "Loss = 1.539961387416308e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 2.474978494860781e-06\tMax abs grad value: 3.970222917535003e-05\n",
      "Loss = 1.0363896753446838e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 5.9733915048316355e-06\tMax abs grad value: 0.0001896715855974413\n",
      "Loss = 8.917135187866037e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.976\n",
      "Mean abs grad value: 1.8930608017787283e-06\tMax abs grad value: 3.966205643034049e-05\n",
      "Loss = 5.6190622832294e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.976\n",
      "Mean abs grad value: 1.5035110269580712e-06\tMax abs grad value: 2.4112905496422698e-05\n",
      "Loss = 4.894388994133435e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.976\n",
      "Mean abs grad value: 1.106806145239491e-06\tMax abs grad value: 1.769960634432339e-05\n",
      "Loss = 3.48777495149169e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.976\n",
      "Mean abs grad value: 7.870983455875698e-07\tMax abs grad value: 1.7101008267468047e-05\n",
      "Loss = 2.380283114920606e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.978\n",
      "Mean abs grad value: 5.392556647680239e-07\tMax abs grad value: 1.2686543670677105e-05\n",
      "Loss = 1.4882967609631973e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.976\n",
      "Mean abs grad value: 3.839749448066581e-07\tMax abs grad value: 9.804921642358903e-06\n",
      "Loss = 9.242486732029754e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.976\n",
      "Mean abs grad value: 0.2821279685314148\tMax abs grad value: 8.4567824628599\n",
      "Loss = 14.928000835415975\n",
      "Mean abs grad value: 0.10252753770878179\tMax abs grad value: 2.941800078338286\n",
      "Loss = 5.296381657803727\n",
      "Train accuracy: 0.147\t\tTest accuracy: 0.136\n",
      "Mean abs grad value: 0.051421357358933564\tMax abs grad value: 2.3965909115886834\n",
      "Loss = 3.2890236568619025\n",
      "Train accuracy: 0.119\t\tTest accuracy: 0.120\n",
      "Mean abs grad value: 0.022374262052103314\tMax abs grad value: 0.5021073211492995\n",
      "Loss = 2.413234761391598\n",
      "Train accuracy: 0.176\t\tTest accuracy: 0.189\n",
      "Mean abs grad value: 0.015991386470252875\tMax abs grad value: 0.30282042189823666\n",
      "Loss = 2.141624467752294\n",
      "Train accuracy: 0.218\t\tTest accuracy: 0.249\n",
      "Mean abs grad value: 0.011471436791563918\tMax abs grad value: 0.20101781820276957\n",
      "Loss = 1.752227470512759\n",
      "Train accuracy: 0.373\t\tTest accuracy: 0.389\n",
      "Mean abs grad value: 0.016842290024305748\tMax abs grad value: 0.6869878370541281\n",
      "Loss = 1.4450431748622592\n",
      "Train accuracy: 0.488\t\tTest accuracy: 0.478\n",
      "Mean abs grad value: 0.012568020686404908\tMax abs grad value: 0.26145614102310194\n",
      "Loss = 1.1725822953554221\n",
      "Train accuracy: 0.637\t\tTest accuracy: 0.624\n",
      "Mean abs grad value: 0.013706871907278342\tMax abs grad value: 0.35091049976169664\n",
      "Loss = 1.021830643358994\n",
      "Train accuracy: 0.638\t\tTest accuracy: 0.624\n",
      "Mean abs grad value: 0.011764406235072989\tMax abs grad value: 0.366436754755771\n",
      "Loss = 0.848830821782395\n",
      "Train accuracy: 0.711\t\tTest accuracy: 0.671\n",
      "Mean abs grad value: 0.016098266348750105\tMax abs grad value: 0.6059568756703099\n",
      "Loss = 0.7651851527470802\n",
      "Train accuracy: 0.736\t\tTest accuracy: 0.718\n",
      "Mean abs grad value: 0.009294546528354548\tMax abs grad value: 0.30277373509402716\n",
      "Loss = 0.6677621120375732\n",
      "Train accuracy: 0.779\t\tTest accuracy: 0.762\n",
      "Mean abs grad value: 0.01011632080046938\tMax abs grad value: 0.275550544523645\n",
      "Loss = 0.5671509071752071\n",
      "Train accuracy: 0.826\t\tTest accuracy: 0.796\n",
      "Mean abs grad value: 0.008082125444730026\tMax abs grad value: 0.26931559710912384\n",
      "Loss = 0.4714951444064449\n",
      "Train accuracy: 0.839\t\tTest accuracy: 0.813\n",
      "Mean abs grad value: 0.010404080636221048\tMax abs grad value: 0.27939335581295954\n",
      "Loss = 0.43226133019646296\n",
      "Train accuracy: 0.849\t\tTest accuracy: 0.827\n",
      "Mean abs grad value: 0.007145778260239875\tMax abs grad value: 0.2107006854533365\n",
      "Loss = 0.39381552816411003\n",
      "Train accuracy: 0.869\t\tTest accuracy: 0.833\n",
      "Mean abs grad value: 0.006920613757497315\tMax abs grad value: 0.17882610968379078\n",
      "Loss = 0.363757051495739\n",
      "Train accuracy: 0.883\t\tTest accuracy: 0.847\n",
      "Mean abs grad value: 0.006945224342416216\tMax abs grad value: 0.20106507580413055\n",
      "Loss = 0.3167111324101242\n",
      "Train accuracy: 0.903\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.00982492608928161\tMax abs grad value: 0.3772924140378007\n",
      "Loss = 0.2659560355469238\n",
      "Train accuracy: 0.920\t\tTest accuracy: 0.878\n",
      "Mean abs grad value: 0.00414667416599923\tMax abs grad value: 0.11921131681020357\n",
      "Loss = 0.22619183751986538\n",
      "Train accuracy: 0.933\t\tTest accuracy: 0.898\n",
      "Mean abs grad value: 0.004201037231452469\tMax abs grad value: 0.09956432017943086\n",
      "Loss = 0.20850539507394197\n",
      "Train accuracy: 0.940\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.004549957771156089\tMax abs grad value: 0.1280599369830008\n",
      "Loss = 0.1831749637788764\n",
      "Train accuracy: 0.949\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.005972786540054121\tMax abs grad value: 0.14786578234984962\n",
      "Loss = 0.15682725271394204\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.0034460511858145316\tMax abs grad value: 0.12073873313194668\n",
      "Loss = 0.13486278219364425\n",
      "Train accuracy: 0.960\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.002467911423351172\tMax abs grad value: 0.0538543718966368\n",
      "Loss = 0.12636619597949242\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002574995869781309\tMax abs grad value: 0.07023625924510495\n",
      "Loss = 0.11671038069412513\n",
      "Train accuracy: 0.965\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.002527387938654975\tMax abs grad value: 0.07671645802661428\n",
      "Loss = 0.10513373332518186\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.007681983960984176\tMax abs grad value: 0.36539221738824357\n",
      "Loss = 0.11276639165217087\n",
      "Mean abs grad value: 0.0035640956909035607\tMax abs grad value: 0.13626291381441577\n",
      "Loss = 0.0976031188093888\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0021032634883743203\tMax abs grad value: 0.04351269230848431\n",
      "Loss = 0.08828315273467705\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001936987276379637\tMax abs grad value: 0.04682117449493341\n",
      "Loss = 0.08234003130566932\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0024741713174842384\tMax abs grad value: 0.10835895993075742\n",
      "Loss = 0.06950110884009482\n",
      "Train accuracy: 0.980\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.002678602649645147\tMax abs grad value: 0.09272779800456296\n",
      "Loss = 0.05890271530553098\n",
      "Train accuracy: 0.980\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0018873220307088498\tMax abs grad value: 0.048072582173511125\n",
      "Loss = 0.051805336255272144\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0016173623970032194\tMax abs grad value: 0.03546787405469161\n",
      "Loss = 0.04799171842483927\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0018915801479430124\tMax abs grad value: 0.04527567981820415\n",
      "Loss = 0.04294895334526208\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.001979675316385257\tMax abs grad value: 0.0812575188828676\n",
      "Loss = 0.03542662446014916\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.001849540876823856\tMax abs grad value: 0.047030658608776275\n",
      "Loss = 0.029663323781879768\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.001156901718851326\tMax abs grad value: 0.02966643813076061\n",
      "Loss = 0.026459561253541725\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0011331213519391536\tMax abs grad value: 0.03157738996872979\n",
      "Loss = 0.023320143938940885\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0014199147090783204\tMax abs grad value: 0.04768083752726652\n",
      "Loss = 0.02125786106833842\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.001058106615815431\tMax abs grad value: 0.027029802323878412\n",
      "Loss = 0.019032378626026407\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0007367740921690026\tMax abs grad value: 0.02122019654740927\n",
      "Loss = 0.016043638702418626\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0007642525030393079\tMax abs grad value: 0.026507845704115584\n",
      "Loss = 0.014179989062743436\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0007639224577534251\tMax abs grad value: 0.02476506014008932\n",
      "Loss = 0.01233729702811573\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0006699833332667662\tMax abs grad value: 0.018950745793419235\n",
      "Loss = 0.01001637514073992\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0010129314300100865\tMax abs grad value: 0.03353550995669865\n",
      "Loss = 0.0074002729957681965\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0010479074436118886\tMax abs grad value: 0.04248088487242638\n",
      "Loss = 0.005721318223239418\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0003971564332954993\tMax abs grad value: 0.009402415478284727\n",
      "Loss = 0.004693404040292845\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.00027571162609198993\tMax abs grad value: 0.00625295342204303\n",
      "Loss = 0.004148337447397859\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0003002172217241646\tMax abs grad value: 0.008549155825193864\n",
      "Loss = 0.003230651366432751\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.00045515952569999396\tMax abs grad value: 0.016251428348888916\n",
      "Loss = 0.0025878980906712634\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00032078039469282346\tMax abs grad value: 0.010333083328009987\n",
      "Loss = 0.0019867359157913944\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00018368734414254988\tMax abs grad value: 0.005355692659124651\n",
      "Loss = 0.0017209992844657213\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00013827859844421324\tMax abs grad value: 0.002711296884927301\n",
      "Loss = 0.0014140640857212526\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0001516177158085681\tMax abs grad value: 0.004252224308883348\n",
      "Loss = 0.0010536567617215257\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0001813782007028333\tMax abs grad value: 0.011977824928009433\n",
      "Loss = 0.0008306353482811028\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 8.083662269621398e-05\tMax abs grad value: 0.003502886862647596\n",
      "Loss = 0.0005959804830446716\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 6.893868082145308e-05\tMax abs grad value: 0.001999779678204384\n",
      "Loss = 0.0004859555769536344\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.6233488365400415e-05\tMax abs grad value: 0.0016354140852135456\n",
      "Loss = 0.00038767464730858034\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.109918550671124e-05\tMax abs grad value: 0.0022336366274253038\n",
      "Loss = 0.00028762985981890625\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.6729594405508775e-05\tMax abs grad value: 0.0016235013383260224\n",
      "Loss = 0.00019488459000480894\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.865517127209882e-05\tMax abs grad value: 0.0008745983183573839\n",
      "Loss = 0.0001376754990622608\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.890681064308247e-05\tMax abs grad value: 0.0006395937889067004\n",
      "Loss = 9.714245585797889e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.8108264774187197e-05\tMax abs grad value: 0.0012024726852040441\n",
      "Loss = 5.9757413214344215e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 9.56082239360891e-06\tMax abs grad value: 0.00027558442041662913\n",
      "Loss = 3.742449559750727e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 7.263457159775034e-06\tMax abs grad value: 0.00025075965890159423\n",
      "Loss = 3.184930999398353e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 4.838363012143354e-06\tMax abs grad value: 0.00015236680884683052\n",
      "Loss = 2.1067257282944634e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 3.08304243939275e-06\tMax abs grad value: 8.769702460333468e-05\n",
      "Loss = 1.433698198689604e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 4.209313497205842e-06\tMax abs grad value: 0.00010177291973641076\n",
      "Loss = 9.023729858299989e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 1.6030626808363522e-06\tMax abs grad value: 4.569172445317605e-05\n",
      "Loss = 5.324254497823732e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 1.1549463481994245e-06\tMax abs grad value: 2.8878864094429578e-05\n",
      "Loss = 4.0579313886575115e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 6.887140642283707e-07\tMax abs grad value: 1.6011949545126484e-05\n",
      "Loss = 2.418636442508599e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 6.080544251767802e-07\tMax abs grad value: 2.159802906543277e-05\n",
      "Loss = 1.3957624755425832e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 2.406655766097821e-07\tMax abs grad value: 7.5914805741445065e-06\n",
      "Loss = 8.733943330450732e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.2630113984517452\tMax abs grad value: 7.218407435355894\n",
      "Loss = 12.738271817739612\n",
      "Mean abs grad value: 0.16943099861201463\tMax abs grad value: 6.196643733105459\n",
      "Loss = 7.312759528795567\n",
      "Train accuracy: 0.224\t\tTest accuracy: 0.204\n",
      "Mean abs grad value: 0.12600558770713166\tMax abs grad value: 4.533024175294641\n",
      "Loss = 5.310189418738796\n",
      "Train accuracy: 0.128\t\tTest accuracy: 0.151\n",
      "Mean abs grad value: 0.05907057427194207\tMax abs grad value: 1.1287954002783374\n",
      "Loss = 3.4452054539188586\n",
      "Train accuracy: 0.213\t\tTest accuracy: 0.222\n",
      "Mean abs grad value: 0.03805356750630271\tMax abs grad value: 0.59183497937978\n",
      "Loss = 2.589355130587234\n",
      "Train accuracy: 0.254\t\tTest accuracy: 0.242\n",
      "Mean abs grad value: 0.02118987109382169\tMax abs grad value: 0.34449757749340587\n",
      "Loss = 1.9001250927599584\n",
      "Train accuracy: 0.321\t\tTest accuracy: 0.318\n",
      "Mean abs grad value: 0.016622962640812342\tMax abs grad value: 0.33749183271806077\n",
      "Loss = 1.6248049728815643\n",
      "Train accuracy: 0.425\t\tTest accuracy: 0.389\n",
      "Mean abs grad value: 0.013078357488551\tMax abs grad value: 0.2213064153571115\n",
      "Loss = 1.2539776467889263\n",
      "Train accuracy: 0.546\t\tTest accuracy: 0.496\n",
      "Mean abs grad value: 0.012657715379592798\tMax abs grad value: 0.28118332553397274\n",
      "Loss = 0.9920698890228137\n",
      "Train accuracy: 0.627\t\tTest accuracy: 0.587\n",
      "Mean abs grad value: 0.010801597064568664\tMax abs grad value: 0.24333892445566077\n",
      "Loss = 0.8526393052314032\n",
      "Train accuracy: 0.688\t\tTest accuracy: 0.627\n",
      "Mean abs grad value: 0.010239733032932997\tMax abs grad value: 0.2470680422849824\n",
      "Loss = 0.7490630284701241\n",
      "Train accuracy: 0.716\t\tTest accuracy: 0.682\n",
      "Mean abs grad value: 0.008558329995135368\tMax abs grad value: 0.1629170594448286\n",
      "Loss = 0.6008456479143739\n",
      "Train accuracy: 0.811\t\tTest accuracy: 0.813\n",
      "Mean abs grad value: 0.008282063910308642\tMax abs grad value: 0.2986736910722645\n",
      "Loss = 0.5120281594426994\n",
      "Train accuracy: 0.825\t\tTest accuracy: 0.824\n",
      "Mean abs grad value: 0.006824670833251564\tMax abs grad value: 0.20764314697430258\n",
      "Loss = 0.44853444515151597\n",
      "Train accuracy: 0.859\t\tTest accuracy: 0.822\n",
      "Mean abs grad value: 0.0068125120851286435\tMax abs grad value: 0.19337990266138042\n",
      "Loss = 0.4008250063264959\n",
      "Train accuracy: 0.869\t\tTest accuracy: 0.836\n",
      "Mean abs grad value: 0.00669971531084137\tMax abs grad value: 0.17997504533074926\n",
      "Loss = 0.33898278558008454\n",
      "Train accuracy: 0.896\t\tTest accuracy: 0.849\n",
      "Mean abs grad value: 0.005949098899270798\tMax abs grad value: 0.13856803081485802\n",
      "Loss = 0.2724935371578105\n",
      "Train accuracy: 0.921\t\tTest accuracy: 0.873\n",
      "Mean abs grad value: 0.0037857467136907953\tMax abs grad value: 0.06771967730301702\n",
      "Loss = 0.2304855978016837\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.00395145723576149\tMax abs grad value: 0.07967727226232878\n",
      "Loss = 0.20962539248608228\n",
      "Train accuracy: 0.938\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.0034360055487904764\tMax abs grad value: 0.06328691707965117\n",
      "Loss = 0.18335644021163464\n",
      "Train accuracy: 0.949\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.006451842538199865\tMax abs grad value: 0.10511503140158497\n",
      "Loss = 0.1616737358347292\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.003461951327479352\tMax abs grad value: 0.06715987921223099\n",
      "Loss = 0.130717584514454\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.003676062525465862\tMax abs grad value: 0.07557685432665372\n",
      "Loss = 0.10583428116789578\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.008744621062759696\tMax abs grad value: 0.285194766591967\n",
      "Loss = 0.10400882299985097\n",
      "Mean abs grad value: 0.0038481707643142223\tMax abs grad value: 0.11510009059552885\n",
      "Loss = 0.09301465536416527\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0026131805700023085\tMax abs grad value: 0.042611608649903016\n",
      "Loss = 0.08322769503347725\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0023079609371093276\tMax abs grad value: 0.03693771343459851\n",
      "Loss = 0.07354588215632962\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0024573221864107125\tMax abs grad value: 0.04591191173329214\n",
      "Loss = 0.06155079624568137\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.004238413127346902\tMax abs grad value: 0.1543155719314203\n",
      "Loss = 0.05555014479620157\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0016803838145234072\tMax abs grad value: 0.03131564605450693\n",
      "Loss = 0.04395771611481443\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0015298572394376296\tMax abs grad value: 0.025180602795526405\n",
      "Loss = 0.04013795804213575\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0020716631673731605\tMax abs grad value: 0.043599495287412166\n",
      "Loss = 0.035572756598704736\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.001736218360458522\tMax abs grad value: 0.031619854228009614\n",
      "Loss = 0.03034296876295774\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.002529521330574981\tMax abs grad value: 0.07612143467646923\n",
      "Loss = 0.025113214408381945\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.001455599195848811\tMax abs grad value: 0.036174458477918135\n",
      "Loss = 0.02054652497583117\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0010137692455276831\tMax abs grad value: 0.019474916918035066\n",
      "Loss = 0.018249471235989925\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0009659168557839692\tMax abs grad value: 0.015552040506705523\n",
      "Loss = 0.015788608074544366\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0014259383383276197\tMax abs grad value: 0.05012767538692634\n",
      "Loss = 0.011638715465361832\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0019319675077696169\tMax abs grad value: 0.04807138374383499\n",
      "Loss = 0.009021015216712338\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0007753198661429789\tMax abs grad value: 0.01498141513790418\n",
      "Loss = 0.006841151765816193\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0005124270313158324\tMax abs grad value: 0.010174992396266866\n",
      "Loss = 0.006000633330302089\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0004521771618209482\tMax abs grad value: 0.00892859167538057\n",
      "Loss = 0.005113086339473349\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0004652538744110721\tMax abs grad value: 0.01111142515418046\n",
      "Loss = 0.0037497669073814363\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0008222704221771475\tMax abs grad value: 0.02257750259836104\n",
      "Loss = 0.002932847056517477\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0003001531468128553\tMax abs grad value: 0.006646589805486479\n",
      "Loss = 0.002048753258526526\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0001951366612519201\tMax abs grad value: 0.004821846416085601\n",
      "Loss = 0.001806206651180627\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0002349516850096585\tMax abs grad value: 0.005359361971156412\n",
      "Loss = 0.0014268728365749875\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.00023918170292136213\tMax abs grad value: 0.005651340654077972\n",
      "Loss = 0.0011259931403525619\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00017485973181584615\tMax abs grad value: 0.004432117139534196\n",
      "Loss = 0.0008888322984643774\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 9.907765692674422e-05\tMax abs grad value: 0.0019532548815893442\n",
      "Loss = 0.0006344995612676364\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 8.836601648261984e-05\tMax abs grad value: 0.002864382379676427\n",
      "Loss = 0.0004572243568650188\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.00011719317947587031\tMax abs grad value: 0.00354720546026529\n",
      "Loss = 0.00035924837827073657\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 8.216282309559474e-05\tMax abs grad value: 0.0022285238515774223\n",
      "Loss = 0.00029020842332740186\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 6.598933469458281e-05\tMax abs grad value: 0.0014052994389321528\n",
      "Loss = 0.00025346222543985746\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 4.696474093470494e-05\tMax abs grad value: 0.0011130812216324077\n",
      "Loss = 0.00018358688388775\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 3.099057950654567e-05\tMax abs grad value: 0.0007912653771399082\n",
      "Loss = 0.00011604997291612231\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 2.3511721983982455e-05\tMax abs grad value: 0.0005118590242045997\n",
      "Loss = 7.782404710874592e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.6459784768093082e-05\tMax abs grad value: 0.000409057114795583\n",
      "Loss = 5.9887337894691554e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.4111156272287847e-05\tMax abs grad value: 0.00033966390728245314\n",
      "Loss = 4.298497889441741e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 9.271509304204216e-06\tMax abs grad value: 0.0002470370976298447\n",
      "Loss = 2.637252566526784e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 1.0992929510172715e-05\tMax abs grad value: 0.00031179881072818674\n",
      "Loss = 2.0520604523426194e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 4.419284498352113e-06\tMax abs grad value: 8.466212690199038e-05\n",
      "Loss = 1.5794182863107992e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 3.6732437996517952e-06\tMax abs grad value: 7.484019868922077e-05\n",
      "Loss = 1.3371324337047856e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 2.982145150407015e-06\tMax abs grad value: 6.122317140132454e-05\n",
      "Loss = 9.46030327558664e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 2.9707164031483516e-06\tMax abs grad value: 6.508226154408143e-05\n",
      "Loss = 6.728525246602973e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.4452882223732898e-06\tMax abs grad value: 3.1527967556269715e-05\n",
      "Loss = 4.490017087921513e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 9.51315477374621e-07\tMax abs grad value: 2.1604257074679474e-05\n",
      "Loss = 3.4863787500298956e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 6.238700120013981e-07\tMax abs grad value: 1.1166930708830738e-05\n",
      "Loss = 2.4186074758150004e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 9.913866334035958e-07\tMax abs grad value: 2.6571971019852375e-05\n",
      "Loss = 1.6085620373869456e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 4.0953761424384017e-07\tMax abs grad value: 9.233458545797356e-06\n",
      "Loss = 9.812575927618095e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.19724159704889882\tMax abs grad value: 5.008305630511288\n",
      "Loss = 8.003134177776955\n",
      "Mean abs grad value: 0.13653301674392557\tMax abs grad value: 4.411799586805594\n",
      "Loss = 6.619197410808916\n",
      "Train accuracy: 0.120\t\tTest accuracy: 0.116\n",
      "Mean abs grad value: 0.031038624444438646\tMax abs grad value: 1.2035675896500955\n",
      "Loss = 2.778286655885593\n",
      "Train accuracy: 0.111\t\tTest accuracy: 0.113\n",
      "Mean abs grad value: 0.022060516644990834\tMax abs grad value: 0.4610875452730379\n",
      "Loss = 2.3997303436225907\n",
      "Train accuracy: 0.169\t\tTest accuracy: 0.147\n",
      "Mean abs grad value: 0.01865376739442187\tMax abs grad value: 0.5142773048334086\n",
      "Loss = 1.981306834758069\n",
      "Train accuracy: 0.278\t\tTest accuracy: 0.267\n",
      "Mean abs grad value: 0.013739634919209976\tMax abs grad value: 0.2969321949863454\n",
      "Loss = 1.6705986143925624\n",
      "Train accuracy: 0.422\t\tTest accuracy: 0.391\n",
      "Mean abs grad value: 0.01953003852386132\tMax abs grad value: 0.4590864593129165\n",
      "Loss = 1.2847505961543015\n",
      "Train accuracy: 0.569\t\tTest accuracy: 0.533\n",
      "Mean abs grad value: 0.022015812975698774\tMax abs grad value: 0.9343539480739488\n",
      "Loss = 1.1374218885673057\n",
      "Train accuracy: 0.616\t\tTest accuracy: 0.600\n",
      "Mean abs grad value: 0.011687823713327867\tMax abs grad value: 0.3556909405108704\n",
      "Loss = 0.979266664746217\n",
      "Train accuracy: 0.696\t\tTest accuracy: 0.664\n",
      "Mean abs grad value: 0.009474817994632869\tMax abs grad value: 0.27971350323552774\n",
      "Loss = 0.8877410573982277\n",
      "Train accuracy: 0.719\t\tTest accuracy: 0.664\n",
      "Mean abs grad value: 0.010518635132282744\tMax abs grad value: 0.45392715566268316\n",
      "Loss = 0.8228087963865542\n",
      "Train accuracy: 0.741\t\tTest accuracy: 0.707\n",
      "Mean abs grad value: 0.008448438207850373\tMax abs grad value: 0.3413945508851033\n",
      "Loss = 0.7045191663621178\n",
      "Train accuracy: 0.769\t\tTest accuracy: 0.722\n",
      "Mean abs grad value: 0.010408700538557117\tMax abs grad value: 0.7438982671674507\n",
      "Loss = 0.5967782529968461\n",
      "Train accuracy: 0.804\t\tTest accuracy: 0.762\n",
      "Mean abs grad value: 0.007814890588729936\tMax abs grad value: 0.24177423595863282\n",
      "Loss = 0.5128769700294358\n",
      "Train accuracy: 0.829\t\tTest accuracy: 0.789\n",
      "Mean abs grad value: 0.005806156442612823\tMax abs grad value: 0.18227230976157935\n",
      "Loss = 0.475783019466601\n",
      "Train accuracy: 0.848\t\tTest accuracy: 0.809\n",
      "Mean abs grad value: 0.005770595972414077\tMax abs grad value: 0.280677064456114\n",
      "Loss = 0.43284468911193286\n",
      "Train accuracy: 0.865\t\tTest accuracy: 0.840\n",
      "Mean abs grad value: 0.0067868603785074194\tMax abs grad value: 0.19234825264723812\n",
      "Loss = 0.3961911377456077\n",
      "Train accuracy: 0.866\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.004866976401050808\tMax abs grad value: 0.13728863330625277\n",
      "Loss = 0.3634120133635163\n",
      "Train accuracy: 0.886\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.005056250892905051\tMax abs grad value: 0.261716964546465\n",
      "Loss = 0.33082336817847396\n",
      "Train accuracy: 0.897\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.0052319053566627785\tMax abs grad value: 0.21058779269723304\n",
      "Loss = 0.30177800322407294\n",
      "Train accuracy: 0.906\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.010318223687995811\tMax abs grad value: 0.7370084743900649\n",
      "Loss = 0.28171617772601415\n",
      "Train accuracy: 0.903\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.0036884705899853623\tMax abs grad value: 0.0910864709299328\n",
      "Loss = 0.24902886179608727\n",
      "Train accuracy: 0.916\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.0033277340482424085\tMax abs grad value: 0.08187549673412853\n",
      "Loss = 0.24082551337146108\n",
      "Train accuracy: 0.918\t\tTest accuracy: 0.873\n",
      "Mean abs grad value: 0.003286394654916947\tMax abs grad value: 0.11454982586595189\n",
      "Loss = 0.20433708652429783\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.015270890911198418\tMax abs grad value: 1.027491710629923\n",
      "Loss = 0.23794776807321377\n",
      "Mean abs grad value: 0.004704017340291766\tMax abs grad value: 0.26443779211677493\n",
      "Loss = 0.19145233056533653\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.0029062543093595827\tMax abs grad value: 0.10989977802737734\n",
      "Loss = 0.17715433894095922\n",
      "Train accuracy: 0.943\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.00269057739627033\tMax abs grad value: 0.05211000961801257\n",
      "Loss = 0.16728414914481823\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.003302967252911765\tMax abs grad value: 0.14204369789045174\n",
      "Loss = 0.14527499194970342\n",
      "Train accuracy: 0.948\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.005728531251005835\tMax abs grad value: 0.23691317828996203\n",
      "Loss = 0.13108160915437905\n",
      "Train accuracy: 0.953\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.0035340812700907654\tMax abs grad value: 0.1434789246305617\n",
      "Loss = 0.11536911342954617\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.002389919970325352\tMax abs grad value: 0.059583146717122865\n",
      "Loss = 0.10934833942130247\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.002497266601449268\tMax abs grad value: 0.10128527205027991\n",
      "Loss = 0.0995726089219102\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.0027260045026955004\tMax abs grad value: 0.10726544587317172\n",
      "Loss = 0.09158675749439747\n",
      "Train accuracy: 0.965\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.006428873580561693\tMax abs grad value: 0.26194667111336767\n",
      "Loss = 0.08372526383184588\n",
      "Train accuracy: 0.966\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0024141676331736715\tMax abs grad value: 0.10867496924335913\n",
      "Loss = 0.07260232508940126\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.00189085854652971\tMax abs grad value: 0.06757652829816403\n",
      "Loss = 0.0682331711143193\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0018621282065011662\tMax abs grad value: 0.05384089174233843\n",
      "Loss = 0.05837345827859782\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0038337443897234072\tMax abs grad value: 0.12703850346099335\n",
      "Loss = 0.05438731528197377\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001742767023033972\tMax abs grad value: 0.07916952477682855\n",
      "Loss = 0.04799865164157116\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.001211326326022144\tMax abs grad value: 0.024353435552504767\n",
      "Loss = 0.04457369356840517\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0013310331004006666\tMax abs grad value: 0.0357695029389737\n",
      "Loss = 0.042234251991173456\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.004310030160173465\tMax abs grad value: 0.2670642316897547\n",
      "Loss = 0.04377973914336856\n",
      "Mean abs grad value: 0.0020203900562863857\tMax abs grad value: 0.09908079585074854\n",
      "Loss = 0.040752115661849664\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0015307221900553052\tMax abs grad value: 0.06727281869673189\n",
      "Loss = 0.03819307236156992\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0014599915164749788\tMax abs grad value: 0.033676794190740676\n",
      "Loss = 0.03530022290614451\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0012476745859658668\tMax abs grad value: 0.02800656825122443\n",
      "Loss = 0.03245511820230861\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00170818624795188\tMax abs grad value: 0.05834160921002976\n",
      "Loss = 0.024470352503476598\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.005371775115271406\tMax abs grad value: 0.21359678120408607\n",
      "Loss = 0.02850874853866255\n",
      "Mean abs grad value: 0.001447640335439525\tMax abs grad value: 0.05126473890291993\n",
      "Loss = 0.02254048394351033\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0010959526163503645\tMax abs grad value: 0.03765187912756693\n",
      "Loss = 0.0210897049563097\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0009123255195816905\tMax abs grad value: 0.027041047026832646\n",
      "Loss = 0.018951710058855525\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0011107050716575204\tMax abs grad value: 0.061510049295353614\n",
      "Loss = 0.017263480988616964\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0008846316166028792\tMax abs grad value: 0.03544678945085538\n",
      "Loss = 0.015287318561562263\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0009297781918679302\tMax abs grad value: 0.03934316864057779\n",
      "Loss = 0.012622417405601619\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0008549735903946743\tMax abs grad value: 0.032425953477853\n",
      "Loss = 0.011491344531949856\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0006649234799847093\tMax abs grad value: 0.02431020811166495\n",
      "Loss = 0.010748299468462891\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0005361632569142436\tMax abs grad value: 0.014042061879483338\n",
      "Loss = 0.009762227694074735\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0008350845786111906\tMax abs grad value: 0.045224339614236844\n",
      "Loss = 0.008692651716296093\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0006003407945251613\tMax abs grad value: 0.023643481386581584\n",
      "Loss = 0.007857189169473472\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0004193338278988298\tMax abs grad value: 0.009861659485119856\n",
      "Loss = 0.007041117189036424\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0004721919164828304\tMax abs grad value: 0.023491867004669917\n",
      "Loss = 0.006477693657934086\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0004984909324302997\tMax abs grad value: 0.015531233791876585\n",
      "Loss = 0.005834760960016005\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0003637722890401769\tMax abs grad value: 0.01263994849950022\n",
      "Loss = 0.0051871309670597065\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0003476236602161861\tMax abs grad value: 0.012836736250136063\n",
      "Loss = 0.004206282794774744\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0013442438515461693\tMax abs grad value: 0.03820232991912344\n",
      "Loss = 0.004712406084235635\n",
      "Mean abs grad value: 0.0004621450571449246\tMax abs grad value: 0.015237063341642655\n",
      "Loss = 0.003793107906302606\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00027404425373718164\tMax abs grad value: 0.007252833942297476\n",
      "Loss = 0.003054044256121837\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0003517450991569737\tMax abs grad value: 0.01616330069885296\n",
      "Loss = 0.002586929908526947\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0004953440278677278\tMax abs grad value: 0.023967773764331523\n",
      "Loss = 0.0024644106165107103\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00019094896405699353\tMax abs grad value: 0.004856960093961007\n",
      "Loss = 0.002110587597749425\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00014820444601063463\tMax abs grad value: 0.0027267499312840166\n",
      "Loss = 0.001985342619769735\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00015624158140207177\tMax abs grad value: 0.004318430931318669\n",
      "Loss = 0.0017033906916207298\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00019267314952410282\tMax abs grad value: 0.009712064715675546\n",
      "Loss = 0.0014253453453488718\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00036255009091367964\tMax abs grad value: 0.01232831314342687\n",
      "Loss = 0.0012013415944285672\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00014601127349853457\tMax abs grad value: 0.0034601517490776453\n",
      "Loss = 0.0009095789616759653\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 9.879779669638003e-05\tMax abs grad value: 0.001994254958839057\n",
      "Loss = 0.000735624014982979\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 7.149353617717418e-05\tMax abs grad value: 0.002633203049294374\n",
      "Loss = 0.0005479939671431199\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00011448970439769037\tMax abs grad value: 0.00367705427949744\n",
      "Loss = 0.0004530716422379406\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 5.2126955093635414e-05\tMax abs grad value: 0.0016290996338982127\n",
      "Loss = 0.00036157577867308147\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.098177924945269e-05\tMax abs grad value: 0.0008298972778489404\n",
      "Loss = 0.00031263578124782345\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.387003606900665e-05\tMax abs grad value: 0.001698842749804351\n",
      "Loss = 0.00024160470251603016\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 7.482751498981682e-05\tMax abs grad value: 0.004104968362090962\n",
      "Loss = 0.00021182157404145579\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.9488532023003167e-05\tMax abs grad value: 0.0011290808937974937\n",
      "Loss = 0.00017147039124158867\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.3306333854705142e-05\tMax abs grad value: 0.0007639133496957302\n",
      "Loss = 0.00015510749740470188\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.2427239455130553e-05\tMax abs grad value: 0.000959644445658912\n",
      "Loss = 0.0001334144348629542\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.7344931945172757e-05\tMax abs grad value: 0.0011210060148777964\n",
      "Loss = 0.00010822580589224058\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.225992513918557e-05\tMax abs grad value: 0.0014336366701861154\n",
      "Loss = 0.00010016065873906665\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.6740199479259725e-05\tMax abs grad value: 0.0005303047687310077\n",
      "Loss = 7.564210085611071e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.0348621308804088e-05\tMax abs grad value: 0.00025039077248678853\n",
      "Loss = 6.578807314392507e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 9.897617121983798e-06\tMax abs grad value: 0.00028443848273903855\n",
      "Loss = 5.385850040041178e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 9.577755903341814e-06\tMax abs grad value: 0.00033027440051454945\n",
      "Loss = 4.131880360238994e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.6661925562437875e-05\tMax abs grad value: 0.0005794655875520305\n",
      "Loss = 3.148444401545366e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 5.21763690194355e-06\tMax abs grad value: 0.00018799361655472824\n",
      "Loss = 1.6627633278725902e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.262011405500101e-06\tMax abs grad value: 0.00014426002909144093\n",
      "Loss = 1.3623753564668036e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.6673650471337122e-06\tMax abs grad value: 7.73918526159305e-05\n",
      "Loss = 9.042598269338156e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.654580620476905e-06\tMax abs grad value: 0.0001390188867293098\n",
      "Loss = 6.114802363812262e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.3258945290624433e-06\tMax abs grad value: 5.3434835034475774e-05\n",
      "Loss = 3.7684779761375206e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.1116719009745987e-06\tMax abs grad value: 2.5700281193484832e-05\n",
      "Loss = 3.0835066754018205e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 8.121809838419275e-07\tMax abs grad value: 2.037432648300451e-05\n",
      "Loss = 2.26241597758778e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.603981573767684e-07\tMax abs grad value: 2.0583646934245424e-05\n",
      "Loss = 1.355250669592776e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.874232710918219e-07\tMax abs grad value: 1.3015893978109567e-05\n",
      "Loss = 8.417329284764292e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.41985728783292e-07\tMax abs grad value: 4.4261710657449134e-06\n",
      "Loss = 4.895323836985744e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.1756128762959508\tMax abs grad value: 4.503956638675389\n",
      "Loss = 8.23802586055541\n",
      "Mean abs grad value: 0.09098684317285462\tMax abs grad value: 2.396977517667962\n",
      "Loss = 5.020735002850304\n",
      "Train accuracy: 0.043\t\tTest accuracy: 0.033\n",
      "Mean abs grad value: 0.03185520801292415\tMax abs grad value: 0.8008160817971568\n",
      "Loss = 2.654349139859214\n",
      "Train accuracy: 0.139\t\tTest accuracy: 0.138\n",
      "Mean abs grad value: 0.017335641774620176\tMax abs grad value: 0.26812093217059313\n",
      "Loss = 2.293452079772181\n",
      "Train accuracy: 0.214\t\tTest accuracy: 0.189\n",
      "Mean abs grad value: 0.012392680315617152\tMax abs grad value: 0.17278390556023282\n",
      "Loss = 2.061074613192694\n",
      "Train accuracy: 0.295\t\tTest accuracy: 0.298\n",
      "Mean abs grad value: 0.010833633383298288\tMax abs grad value: 0.22773427657679807\n",
      "Loss = 1.7776305729907738\n",
      "Train accuracy: 0.425\t\tTest accuracy: 0.400\n",
      "Mean abs grad value: 0.020458655329710425\tMax abs grad value: 0.535613059264115\n",
      "Loss = 1.5183575176425488\n",
      "Train accuracy: 0.469\t\tTest accuracy: 0.433\n",
      "Mean abs grad value: 0.01270894064080859\tMax abs grad value: 0.2689953922142389\n",
      "Loss = 1.3246516831969244\n",
      "Train accuracy: 0.566\t\tTest accuracy: 0.522\n",
      "Mean abs grad value: 0.01200434180690844\tMax abs grad value: 0.2751036101579136\n",
      "Loss = 1.235723975744401\n",
      "Train accuracy: 0.595\t\tTest accuracy: 0.571\n",
      "Mean abs grad value: 0.011449739334838109\tMax abs grad value: 0.4073896025638352\n",
      "Loss = 0.9946928574292263\n",
      "Train accuracy: 0.664\t\tTest accuracy: 0.609\n",
      "Mean abs grad value: 0.00878255583228351\tMax abs grad value: 0.18608886330357155\n",
      "Loss = 0.8478530246615323\n",
      "Train accuracy: 0.727\t\tTest accuracy: 0.693\n",
      "Mean abs grad value: 0.011526709281071324\tMax abs grad value: 0.38322405162307677\n",
      "Loss = 0.7110268616503285\n",
      "Train accuracy: 0.773\t\tTest accuracy: 0.727\n",
      "Mean abs grad value: 0.007141235517361717\tMax abs grad value: 0.15386144649865569\n",
      "Loss = 0.5779117861163606\n",
      "Train accuracy: 0.821\t\tTest accuracy: 0.767\n",
      "Mean abs grad value: 0.006214849374351339\tMax abs grad value: 0.16381435491945195\n",
      "Loss = 0.4985646308551187\n",
      "Train accuracy: 0.827\t\tTest accuracy: 0.787\n",
      "Mean abs grad value: 0.006644210920919509\tMax abs grad value: 0.1458577857321085\n",
      "Loss = 0.45389421262782265\n",
      "Train accuracy: 0.846\t\tTest accuracy: 0.818\n",
      "Mean abs grad value: 0.005395096374535604\tMax abs grad value: 0.08312830134142786\n",
      "Loss = 0.41228626926591055\n",
      "Train accuracy: 0.857\t\tTest accuracy: 0.833\n",
      "Mean abs grad value: 0.0048153489706013125\tMax abs grad value: 0.10048961075892336\n",
      "Loss = 0.3439749081764796\n",
      "Train accuracy: 0.878\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.005677077132465943\tMax abs grad value: 0.09960758959926563\n",
      "Loss = 0.28423797031924075\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.882\n",
      "Mean abs grad value: 0.00942144911350514\tMax abs grad value: 0.28672503713439795\n",
      "Loss = 0.25511929408515666\n",
      "Train accuracy: 0.913\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.00389261449307065\tMax abs grad value: 0.07277433832393321\n",
      "Loss = 0.21385748583329853\n",
      "Train accuracy: 0.928\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.00347453992773052\tMax abs grad value: 0.07539686753017599\n",
      "Loss = 0.19674716180863627\n",
      "Train accuracy: 0.935\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.0037814683180245755\tMax abs grad value: 0.10215665196146868\n",
      "Loss = 0.17627597638810558\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.002987710820442224\tMax abs grad value: 0.04621224813832617\n",
      "Loss = 0.15129779229715948\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0030549643216394562\tMax abs grad value: 0.08681000034472916\n",
      "Loss = 0.11782143809004074\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0037483134340889498\tMax abs grad value: 0.11503133217513739\n",
      "Loss = 0.10438737063710218\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0022705221931107016\tMax abs grad value: 0.05641663894577759\n",
      "Loss = 0.09289017316977546\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0018097250441894853\tMax abs grad value: 0.053068719632952344\n",
      "Loss = 0.08274992481151704\n",
      "Train accuracy: 0.972\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0024384810177953934\tMax abs grad value: 0.0820277968135289\n",
      "Loss = 0.07204972671516309\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0022283944807779655\tMax abs grad value: 0.08337302093433607\n",
      "Loss = 0.06320392384034915\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0016393398171337928\tMax abs grad value: 0.033608101194953714\n",
      "Loss = 0.05654322188374043\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0014765161347714516\tMax abs grad value: 0.028275104279975274\n",
      "Loss = 0.0464180435540463\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0017476963778781172\tMax abs grad value: 0.061042964349323485\n",
      "Loss = 0.0358784732931629\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002403686572626451\tMax abs grad value: 0.07378888016456671\n",
      "Loss = 0.03174046794305032\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0011265197395928523\tMax abs grad value: 0.021635988856031362\n",
      "Loss = 0.024374944766339092\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.000779469137758322\tMax abs grad value: 0.02132572526232439\n",
      "Loss = 0.021035444098339323\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0007616086642788947\tMax abs grad value: 0.02404058321444742\n",
      "Loss = 0.01757199395980023\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0008760059728223388\tMax abs grad value: 0.025521573599193534\n",
      "Loss = 0.012518080541442463\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0009978901530713381\tMax abs grad value: 0.027333829424001827\n",
      "Loss = 0.009883968194512163\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.000564877345368653\tMax abs grad value: 0.011132160612302093\n",
      "Loss = 0.007945284708470257\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.000385160778163733\tMax abs grad value: 0.008753859058845419\n",
      "Loss = 0.006232707587551092\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0003281784780062686\tMax abs grad value: 0.009614607891899716\n",
      "Loss = 0.0046298519342905355\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0007931767906971758\tMax abs grad value: 0.03114554597706028\n",
      "Loss = 0.0037243666658551646\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00023596529463220696\tMax abs grad value: 0.006272477590433029\n",
      "Loss = 0.002396608610638731\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0002045253245588872\tMax abs grad value: 0.004371238860950166\n",
      "Loss = 0.0021628090612788847\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0001919558254853637\tMax abs grad value: 0.004434892869056591\n",
      "Loss = 0.0016037582708314422\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00013805132672461772\tMax abs grad value: 0.004243395686079162\n",
      "Loss = 0.00106623501480565\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.000149278392931756\tMax abs grad value: 0.003761494083830261\n",
      "Loss = 0.0007514852577682232\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 7.68549533252314e-05\tMax abs grad value: 0.0019310692990144305\n",
      "Loss = 0.0005395715703052172\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.9017258244500966e-05\tMax abs grad value: 0.0010715955834049492\n",
      "Loss = 0.0004429105249423617\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 4.452105064468406e-05\tMax abs grad value: 0.0011980564747682664\n",
      "Loss = 0.0002720009998167237\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 7.064599572596445e-05\tMax abs grad value: 0.0027348577313442107\n",
      "Loss = 0.00019296427457693682\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 3.023848051941622e-05\tMax abs grad value: 0.0006002271937870014\n",
      "Loss = 0.00012475698032376927\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 2.097445381678949e-05\tMax abs grad value: 0.0004222032721829756\n",
      "Loss = 9.83876687136879e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 1.3309668636238286e-05\tMax abs grad value: 0.0002774379929936353\n",
      "Loss = 6.35358147885003e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 1.0890903335529736e-05\tMax abs grad value: 0.00023737069765974723\n",
      "Loss = 4.0309609392821716e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 1.2430908141988607e-05\tMax abs grad value: 0.00031846412288616226\n",
      "Loss = 2.6024214159443434e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 5.21047955072067e-06\tMax abs grad value: 0.00014483565683479584\n",
      "Loss = 1.496783006587224e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 2.994876639311273e-06\tMax abs grad value: 6.994664981835777e-05\n",
      "Loss = 9.834342059136722e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 1.612073338442417e-06\tMax abs grad value: 3.41785069906847e-05\n",
      "Loss = 6.080454362814173e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 1.171123756949875e-06\tMax abs grad value: 3.087429753939025e-05\n",
      "Loss = 3.6214642630201027e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 1.314322333423569e-06\tMax abs grad value: 3.367549103448469e-05\n",
      "Loss = 2.189792827914187e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.021758325193707e-07\tMax abs grad value: 1.2208527953290222e-05\n",
      "Loss = 1.0848779987632298e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.7571168989596595e-07\tMax abs grad value: 5.579923968131113e-06\n",
      "Loss = 6.943186255226943e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.24649624799027822\tMax abs grad value: 5.979801731586445\n",
      "Loss = 9.389771404774281\n",
      "Mean abs grad value: 0.06383574524806614\tMax abs grad value: 1.2648972151916706\n",
      "Loss = 4.336231030403031\n",
      "Train accuracy: 0.090\t\tTest accuracy: 0.080\n",
      "Mean abs grad value: 0.032444432112806176\tMax abs grad value: 0.5953859594300193\n",
      "Loss = 2.948789103354786\n",
      "Train accuracy: 0.120\t\tTest accuracy: 0.124\n",
      "Mean abs grad value: 0.018309854156025485\tMax abs grad value: 0.264387980444558\n",
      "Loss = 2.247678151986055\n",
      "Train accuracy: 0.245\t\tTest accuracy: 0.218\n",
      "Mean abs grad value: 0.011550401799084505\tMax abs grad value: 0.16700268034896093\n",
      "Loss = 1.8380228269610004\n",
      "Train accuracy: 0.337\t\tTest accuracy: 0.311\n",
      "Mean abs grad value: 0.010225570844312753\tMax abs grad value: 0.18337064358765892\n",
      "Loss = 1.5422058919683932\n",
      "Train accuracy: 0.483\t\tTest accuracy: 0.467\n",
      "Mean abs grad value: 0.019459994424538114\tMax abs grad value: 0.4582557038835622\n",
      "Loss = 1.2820027198221793\n",
      "Train accuracy: 0.537\t\tTest accuracy: 0.504\n",
      "Mean abs grad value: 0.013236721377056972\tMax abs grad value: 0.26513026980562765\n",
      "Loss = 1.1070450640403628\n",
      "Train accuracy: 0.617\t\tTest accuracy: 0.573\n",
      "Mean abs grad value: 0.008262983708734252\tMax abs grad value: 0.15870777169526437\n",
      "Loss = 1.0418686297071695\n",
      "Train accuracy: 0.640\t\tTest accuracy: 0.598\n",
      "Mean abs grad value: 0.01041459368247905\tMax abs grad value: 0.2867379604494921\n",
      "Loss = 0.9384857797140177\n",
      "Train accuracy: 0.668\t\tTest accuracy: 0.620\n",
      "Mean abs grad value: 0.012054296587384801\tMax abs grad value: 0.31229033907935494\n",
      "Loss = 0.8223447999603222\n",
      "Train accuracy: 0.708\t\tTest accuracy: 0.647\n",
      "Mean abs grad value: 0.013352600616807668\tMax abs grad value: 0.43590238680222804\n",
      "Loss = 0.6756337085494855\n",
      "Train accuracy: 0.765\t\tTest accuracy: 0.733\n",
      "Mean abs grad value: 0.017407969438801057\tMax abs grad value: 0.7354765292950657\n",
      "Loss = 0.6482700431140591\n",
      "Train accuracy: 0.779\t\tTest accuracy: 0.784\n",
      "Mean abs grad value: 0.008502602281744388\tMax abs grad value: 0.2936804370066198\n",
      "Loss = 0.5829876426793439\n",
      "Train accuracy: 0.804\t\tTest accuracy: 0.800\n",
      "Mean abs grad value: 0.005275366939241541\tMax abs grad value: 0.16172623970028646\n",
      "Loss = 0.5627924556229265\n",
      "Train accuracy: 0.820\t\tTest accuracy: 0.796\n",
      "Mean abs grad value: 0.005023713217740363\tMax abs grad value: 0.1403130634799796\n",
      "Loss = 0.5402250340264549\n",
      "Train accuracy: 0.825\t\tTest accuracy: 0.800\n",
      "Mean abs grad value: 0.006858785995796435\tMax abs grad value: 0.2603673576970169\n",
      "Loss = 0.47270289229787893\n",
      "Train accuracy: 0.849\t\tTest accuracy: 0.811\n",
      "Mean abs grad value: 0.021614643797103563\tMax abs grad value: 1.6195110491629903\n",
      "Loss = 0.5173698784159853\n",
      "Mean abs grad value: 0.007663227719516111\tMax abs grad value: 0.3491534639252623\n",
      "Loss = 0.4371437921933755\n",
      "Train accuracy: 0.854\t\tTest accuracy: 0.820\n",
      "Mean abs grad value: 0.005654381697588096\tMax abs grad value: 0.10943569106315126\n",
      "Loss = 0.4047784289829527\n",
      "Train accuracy: 0.870\t\tTest accuracy: 0.840\n",
      "Mean abs grad value: 0.004976805039025759\tMax abs grad value: 0.1461697258158769\n",
      "Loss = 0.36143973824942605\n",
      "Train accuracy: 0.880\t\tTest accuracy: 0.838\n",
      "Mean abs grad value: 0.005684966917820796\tMax abs grad value: 0.15553689864609108\n",
      "Loss = 0.3242746911420653\n",
      "Train accuracy: 0.901\t\tTest accuracy: 0.858\n",
      "Mean abs grad value: 0.009479647450066747\tMax abs grad value: 0.29677743511571647\n",
      "Loss = 0.29560155990120157\n",
      "Train accuracy: 0.906\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.004429805411642695\tMax abs grad value: 0.12948374909035956\n",
      "Loss = 0.26499868418015643\n",
      "Train accuracy: 0.917\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.004017067252719102\tMax abs grad value: 0.0762272958281074\n",
      "Loss = 0.24928789708997282\n",
      "Train accuracy: 0.924\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.004681992651333958\tMax abs grad value: 0.18132507713348914\n",
      "Loss = 0.22866370917547352\n",
      "Train accuracy: 0.932\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.008123998621881684\tMax abs grad value: 0.4232662159444217\n",
      "Loss = 0.2170546237710262\n",
      "Train accuracy: 0.938\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.003968028098471062\tMax abs grad value: 0.11939689872681009\n",
      "Loss = 0.2006085124648512\n",
      "Train accuracy: 0.940\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.003000913644374268\tMax abs grad value: 0.09008283552313039\n",
      "Loss = 0.1894459481860348\n",
      "Train accuracy: 0.943\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0031036334791478227\tMax abs grad value: 0.09542647798267456\n",
      "Loss = 0.18106544156058993\n",
      "Train accuracy: 0.946\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.005158864976730726\tMax abs grad value: 0.18400374064184197\n",
      "Loss = 0.16903274365425128\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.00552103925844374\tMax abs grad value: 0.1999864212850885\n",
      "Loss = 0.1601347111544221\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.0032752771914522664\tMax abs grad value: 0.10912502306217294\n",
      "Loss = 0.14593159227009878\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.00223390732905014\tMax abs grad value: 0.05125168644458832\n",
      "Loss = 0.13089632143430777\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.002485113319880718\tMax abs grad value: 0.06401609673656933\n",
      "Loss = 0.12275770417706806\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.002840776370156299\tMax abs grad value: 0.07026417008078385\n",
      "Loss = 0.1141239730819072\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.002197009511935321\tMax abs grad value: 0.06872344739117384\n",
      "Loss = 0.10402957240161091\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0030907933484263204\tMax abs grad value: 0.0922631566499861\n",
      "Loss = 0.09347671954045038\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0024757308178086487\tMax abs grad value: 0.08312669497461513\n",
      "Loss = 0.08385218239434425\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0020524189145403847\tMax abs grad value: 0.07113435677530669\n",
      "Loss = 0.07715611314639813\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0018481591015701122\tMax abs grad value: 0.037860813055419024\n",
      "Loss = 0.07094222726612406\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0025869026037838305\tMax abs grad value: 0.11854593487043909\n",
      "Loss = 0.06369468103491556\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0021985295180649823\tMax abs grad value: 0.07275421031239215\n",
      "Loss = 0.055667902078599986\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0016538489995833064\tMax abs grad value: 0.04904116087981142\n",
      "Loss = 0.048159481537990094\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0015204782125636063\tMax abs grad value: 0.049283259992978994\n",
      "Loss = 0.043830054719031\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0014169560536985688\tMax abs grad value: 0.02802704240642846\n",
      "Loss = 0.039000527875829104\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0020807789579008417\tMax abs grad value: 0.062002332176342635\n",
      "Loss = 0.03534756035391804\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0013725126815313346\tMax abs grad value: 0.029707623775344263\n",
      "Loss = 0.03166884771884198\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0011706289764282\tMax abs grad value: 0.035694882967518105\n",
      "Loss = 0.026999814289796007\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0013839298711851348\tMax abs grad value: 0.05714099402735221\n",
      "Loss = 0.023669132669534153\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0011455049582295145\tMax abs grad value: 0.026598229615574197\n",
      "Loss = 0.020808536230923002\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0007761364762691081\tMax abs grad value: 0.015850461551874542\n",
      "Loss = 0.01893534483055453\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0006872828071110988\tMax abs grad value: 0.016801945431572575\n",
      "Loss = 0.017096739475457246\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0007270326966826552\tMax abs grad value: 0.02348074000722755\n",
      "Loss = 0.014638025311381118\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.001130941644750113\tMax abs grad value: 0.03793065014589829\n",
      "Loss = 0.012935277193514927\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0008096452783510843\tMax abs grad value: 0.018933093071377197\n",
      "Loss = 0.01087020421863499\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0008255383380139038\tMax abs grad value: 0.030937773073483853\n",
      "Loss = 0.009658580109452905\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0006745583489928286\tMax abs grad value: 0.026995378651003762\n",
      "Loss = 0.008276048245350248\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0006531835902910158\tMax abs grad value: 0.015394362270849086\n",
      "Loss = 0.007229451355486548\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0009860974603020836\tMax abs grad value: 0.02960476263746695\n",
      "Loss = 0.006330989157551082\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.00045722021007017907\tMax abs grad value: 0.018168340054632737\n",
      "Loss = 0.005520375720000322\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00035596295193928443\tMax abs grad value: 0.008684819611734836\n",
      "Loss = 0.004952130643815232\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00034979186203431195\tMax abs grad value: 0.01046384561927554\n",
      "Loss = 0.003578359622501373\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0005846801654853274\tMax abs grad value: 0.01791334873815633\n",
      "Loss = 0.00268008353586313\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0004552525420483802\tMax abs grad value: 0.019137500187853818\n",
      "Loss = 0.00217073010395175\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00022877721113951085\tMax abs grad value: 0.008203761875290136\n",
      "Loss = 0.001908735497310876\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0001664985512876822\tMax abs grad value: 0.0032670968190260923\n",
      "Loss = 0.0016821171744218872\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00019676989489935445\tMax abs grad value: 0.004191357839924047\n",
      "Loss = 0.0014732647874139576\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00019419475467931824\tMax abs grad value: 0.005867777295221866\n",
      "Loss = 0.0011466553097184682\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0004985378021539321\tMax abs grad value: 0.0125556341540087\n",
      "Loss = 0.0009551910561797092\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00013084924596610514\tMax abs grad value: 0.004026079973993014\n",
      "Loss = 0.0005816398559385692\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 9.111253519537966e-05\tMax abs grad value: 0.002421725528111446\n",
      "Loss = 0.0005221345885748304\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 7.665959993559555e-05\tMax abs grad value: 0.0013218634939805058\n",
      "Loss = 0.0004271849842400178\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 6.85872504427727e-05\tMax abs grad value: 0.0016530866846307499\n",
      "Loss = 0.00034693968294766494\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 4.116248939552697e-05\tMax abs grad value: 0.0015414727416277038\n",
      "Loss = 0.00022580265833893354\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 4.201034229126924e-05\tMax abs grad value: 0.0010005349361324283\n",
      "Loss = 0.00016948385045578815\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 3.7681888373504724e-05\tMax abs grad value: 0.0012162312479168044\n",
      "Loss = 0.00012952398597439822\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 2.563036144911394e-05\tMax abs grad value: 0.0006456601988195449\n",
      "Loss = 9.602754469563802e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.4966509748509649e-05\tMax abs grad value: 0.00038827839342824374\n",
      "Loss = 6.304989004219964e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 9.376038196608905e-06\tMax abs grad value: 0.00021992369834928645\n",
      "Loss = 3.523545605804178e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 8.288818415433469e-06\tMax abs grad value: 0.0002273833034712385\n",
      "Loss = 2.0934759717531692e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 3.435545169303864e-06\tMax abs grad value: 7.747866703378317e-05\n",
      "Loss = 1.1659450842313331e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 2.1428562368016264e-06\tMax abs grad value: 4.387170227369128e-05\n",
      "Loss = 8.008508640680014e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.5512174091599812e-06\tMax abs grad value: 3.739369198358227e-05\n",
      "Loss = 5.081619286270404e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 8.655726582726029e-07\tMax abs grad value: 1.89566288807809e-05\n",
      "Loss = 3.083463706379601e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 7.093893100087115e-07\tMax abs grad value: 1.8978607384489543e-05\n",
      "Loss = 2.1702465717529213e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 4.894866303133982e-07\tMax abs grad value: 9.683903493059402e-06\n",
      "Loss = 1.5421975029617793e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.3478638483104151\tMax abs grad value: 12.02713485380899\n",
      "Loss = 19.086939897913858\n",
      "Mean abs grad value: 0.07304909828622365\tMax abs grad value: 1.8897591567857055\n",
      "Loss = 3.7061018362050575\n",
      "Train accuracy: 0.117\t\tTest accuracy: 0.133\n",
      "Mean abs grad value: 0.030127656495822393\tMax abs grad value: 0.6243921938162541\n",
      "Loss = 2.6892376094917734\n",
      "Train accuracy: 0.133\t\tTest accuracy: 0.118\n",
      "Mean abs grad value: 0.021106014962809387\tMax abs grad value: 0.47045375709585996\n",
      "Loss = 2.413909089593869\n",
      "Train accuracy: 0.169\t\tTest accuracy: 0.138\n",
      "Mean abs grad value: 0.014408073704636447\tMax abs grad value: 0.3153097369626551\n",
      "Loss = 1.991923253534303\n",
      "Train accuracy: 0.255\t\tTest accuracy: 0.278\n",
      "Mean abs grad value: 0.016329201082790557\tMax abs grad value: 0.43922101419537046\n",
      "Loss = 1.7245065714907473\n",
      "Train accuracy: 0.419\t\tTest accuracy: 0.398\n",
      "Mean abs grad value: 0.015857139799855417\tMax abs grad value: 0.4554817908620774\n",
      "Loss = 1.531500313990993\n",
      "Train accuracy: 0.464\t\tTest accuracy: 0.436\n",
      "Mean abs grad value: 0.014262931683822658\tMax abs grad value: 0.29380135218597825\n",
      "Loss = 1.3769410671032976\n",
      "Train accuracy: 0.526\t\tTest accuracy: 0.491\n",
      "Mean abs grad value: 0.02183371303187405\tMax abs grad value: 0.4878805118396416\n",
      "Loss = 1.1428144494936718\n",
      "Train accuracy: 0.625\t\tTest accuracy: 0.607\n",
      "Mean abs grad value: 0.014118800526489445\tMax abs grad value: 0.3883962892780646\n",
      "Loss = 0.9475312159334092\n",
      "Train accuracy: 0.681\t\tTest accuracy: 0.664\n",
      "Mean abs grad value: 0.020467969147268353\tMax abs grad value: 0.6713917035091823\n",
      "Loss = 0.860483929959513\n",
      "Train accuracy: 0.709\t\tTest accuracy: 0.700\n",
      "Mean abs grad value: 0.012828152013147397\tMax abs grad value: 0.33726978500302585\n",
      "Loss = 0.747505886798631\n",
      "Train accuracy: 0.768\t\tTest accuracy: 0.716\n",
      "Mean abs grad value: 0.010807960477410934\tMax abs grad value: 0.27241977927842154\n",
      "Loss = 0.6602241149533156\n",
      "Train accuracy: 0.791\t\tTest accuracy: 0.727\n",
      "Mean abs grad value: 0.011044950267954252\tMax abs grad value: 0.2895937770650091\n",
      "Loss = 0.5736584972056779\n",
      "Train accuracy: 0.826\t\tTest accuracy: 0.771\n",
      "Mean abs grad value: 0.007402680868221468\tMax abs grad value: 0.18545113196634197\n",
      "Loss = 0.49690942401744836\n",
      "Train accuracy: 0.857\t\tTest accuracy: 0.804\n",
      "Mean abs grad value: 0.006285882159496491\tMax abs grad value: 0.1344537827560589\n",
      "Loss = 0.4470965546416052\n",
      "Train accuracy: 0.873\t\tTest accuracy: 0.822\n",
      "Mean abs grad value: 0.010823434533086583\tMax abs grad value: 0.3419510082423643\n",
      "Loss = 0.39102111987609095\n",
      "Train accuracy: 0.885\t\tTest accuracy: 0.838\n",
      "Mean abs grad value: 0.0059666886658174675\tMax abs grad value: 0.12905890445469737\n",
      "Loss = 0.3419143023241659\n",
      "Train accuracy: 0.892\t\tTest accuracy: 0.851\n",
      "Mean abs grad value: 0.005291847227730998\tMax abs grad value: 0.10585947146290689\n",
      "Loss = 0.31670080333505835\n",
      "Train accuracy: 0.903\t\tTest accuracy: 0.851\n",
      "Mean abs grad value: 0.007249441115209693\tMax abs grad value: 0.16747518684545767\n",
      "Loss = 0.27891398660743516\n",
      "Train accuracy: 0.915\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.009103459624338346\tMax abs grad value: 0.33041277152232357\n",
      "Loss = 0.25707665972832006\n",
      "Train accuracy: 0.927\t\tTest accuracy: 0.869\n",
      "Mean abs grad value: 0.0050785028918085475\tMax abs grad value: 0.10716711281667265\n",
      "Loss = 0.2375449240069722\n",
      "Train accuracy: 0.930\t\tTest accuracy: 0.873\n",
      "Mean abs grad value: 0.0035689140792401503\tMax abs grad value: 0.07474414208177833\n",
      "Loss = 0.21948346935089427\n",
      "Train accuracy: 0.936\t\tTest accuracy: 0.882\n",
      "Mean abs grad value: 0.00422067084735407\tMax abs grad value: 0.13474544801696023\n",
      "Loss = 0.20164702285793798\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.896\n",
      "Mean abs grad value: 0.006243649176853763\tMax abs grad value: 0.18328032750650974\n",
      "Loss = 0.18543986880328045\n",
      "Train accuracy: 0.943\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.003941124770869578\tMax abs grad value: 0.08300074367144297\n",
      "Loss = 0.16784142834301213\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.0029871046038754245\tMax abs grad value: 0.06972007372808109\n",
      "Loss = 0.15280024381367918\n",
      "Train accuracy: 0.949\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.003587997085136251\tMax abs grad value: 0.10243921815172553\n",
      "Loss = 0.14353257409735276\n",
      "Train accuracy: 0.953\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.003199781826838874\tMax abs grad value: 0.07526153424277121\n",
      "Loss = 0.1322504563691907\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.005737495292946863\tMax abs grad value: 0.18916456973734727\n",
      "Loss = 0.12569410377993054\n",
      "Train accuracy: 0.956\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.002933124285408085\tMax abs grad value: 0.05158382647740268\n",
      "Loss = 0.11384220546720317\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0027759268306085886\tMax abs grad value: 0.07322409804057692\n",
      "Loss = 0.10219633411687006\n",
      "Train accuracy: 0.965\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0028653196567389005\tMax abs grad value: 0.07827717711513849\n",
      "Loss = 0.09100778390235857\n",
      "Train accuracy: 0.971\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.003663635195075638\tMax abs grad value: 0.12723952649065082\n",
      "Loss = 0.07884530605761607\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.003183119331936804\tMax abs grad value: 0.07328456125857345\n",
      "Loss = 0.06847611344307779\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0021897034283692154\tMax abs grad value: 0.03851113371014421\n",
      "Loss = 0.06145772842179396\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0024748737172960167\tMax abs grad value: 0.05658335099940416\n",
      "Loss = 0.05551396579300462\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0023220444285243836\tMax abs grad value: 0.0708939991541613\n",
      "Loss = 0.04799602286267428\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0024948576599068315\tMax abs grad value: 0.05531161395581516\n",
      "Loss = 0.03766894097025394\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00431016677215974\tMax abs grad value: 0.13985281104050312\n",
      "Loss = 0.036873590428181294\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0016285044093888705\tMax abs grad value: 0.04294937514516038\n",
      "Loss = 0.03092374908755597\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0011821850605875958\tMax abs grad value: 0.02612894020508524\n",
      "Loss = 0.029109727405426784\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001657438359372198\tMax abs grad value: 0.03896003242764442\n",
      "Loss = 0.02592813770020301\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0013799296191885921\tMax abs grad value: 0.02652756140805136\n",
      "Loss = 0.023317271791884506\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0012750616266471492\tMax abs grad value: 0.032092401415708634\n",
      "Loss = 0.019552683345925886\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0020498919860160022\tMax abs grad value: 0.06708561360920297\n",
      "Loss = 0.01820507207120379\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0011303515871319701\tMax abs grad value: 0.02540969604094753\n",
      "Loss = 0.0166601342910669\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.001059578959869426\tMax abs grad value: 0.019954428229084897\n",
      "Loss = 0.015597897330962349\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0011547239103376046\tMax abs grad value: 0.02494548093799234\n",
      "Loss = 0.014480722903550711\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0011847393153013974\tMax abs grad value: 0.035756042432249585\n",
      "Loss = 0.011335052163269278\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0017283115795369065\tMax abs grad value: 0.053326873086672597\n",
      "Loss = 0.009561735658848472\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0007361361182490594\tMax abs grad value: 0.01851886307899734\n",
      "Loss = 0.007306929902822828\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0004740748819764944\tMax abs grad value: 0.008328854109557306\n",
      "Loss = 0.006241392972508518\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0004918136555250373\tMax abs grad value: 0.00915187712127317\n",
      "Loss = 0.00534991342372305\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.001233476542643607\tMax abs grad value: 0.030923026873810548\n",
      "Loss = 0.004758370690316265\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0005256610642736999\tMax abs grad value: 0.013109695017852521\n",
      "Loss = 0.0036669122940283082\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00035218905816890116\tMax abs grad value: 0.008257821014404877\n",
      "Loss = 0.003295039642102317\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00023210567166966778\tMax abs grad value: 0.005666868891294049\n",
      "Loss = 0.0027419934150454063\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00025693606074996125\tMax abs grad value: 0.006201696563601409\n",
      "Loss = 0.002251765649422527\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0003185308787368154\tMax abs grad value: 0.011261117250829783\n",
      "Loss = 0.00173797047165293\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0002568750427927623\tMax abs grad value: 0.00631096394756122\n",
      "Loss = 0.0012965787626390674\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00013644453301487027\tMax abs grad value: 0.0021412948047119795\n",
      "Loss = 0.0010805609894690394\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00011983820315567788\tMax abs grad value: 0.001971657030243899\n",
      "Loss = 0.0009274773058255382\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0001144026297265287\tMax abs grad value: 0.001804468812909369\n",
      "Loss = 0.0007724753094174164\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0001565052422454891\tMax abs grad value: 0.007951243718367031\n",
      "Loss = 0.00057972598605834\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00012587343198191902\tMax abs grad value: 0.005032805325574561\n",
      "Loss = 0.00045615436239581275\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 7.100660198817658e-05\tMax abs grad value: 0.0021956985120035054\n",
      "Loss = 0.0003794777806220722\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.392340163664245e-05\tMax abs grad value: 0.000931552384331113\n",
      "Loss = 0.0003165195971886116\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.917612100839606e-05\tMax abs grad value: 0.0008742789403311279\n",
      "Loss = 0.00026079940418939277\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 5.6009984529846875e-05\tMax abs grad value: 0.0015141942111703758\n",
      "Loss = 0.00017380902341823854\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00012117096643168313\tMax abs grad value: 0.003162646878219256\n",
      "Loss = 0.00016488775480912952\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.849629121435103e-05\tMax abs grad value: 0.000596358258971912\n",
      "Loss = 9.876318098502263e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.8706594836638137e-05\tMax abs grad value: 0.0003744669001765004\n",
      "Loss = 8.76210782497694e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.5382732343214252e-05\tMax abs grad value: 0.0002895638984911676\n",
      "Loss = 7.167492922987296e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.5073859272273568e-05\tMax abs grad value: 0.0004198043303686787\n",
      "Loss = 5.455982565807706e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.549340512654874e-05\tMax abs grad value: 0.0007392753714206781\n",
      "Loss = 3.509101990870024e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.1507982863013503e-05\tMax abs grad value: 0.0003144457256960562\n",
      "Loss = 2.0876984532286634e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.130941699464831e-06\tMax abs grad value: 0.00017837016768265952\n",
      "Loss = 1.6169437119362164e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.1996989054316196e-06\tMax abs grad value: 0.00010100461275289303\n",
      "Loss = 1.160739262709788e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.1530320182241465e-06\tMax abs grad value: 0.00010626203257329087\n",
      "Loss = 6.993509365274544e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.855284474993614e-06\tMax abs grad value: 0.00012701703901580645\n",
      "Loss = 5.037659421384146e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.6425343561722357e-06\tMax abs grad value: 4.138373182158096e-05\n",
      "Loss = 3.722446148127217e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.5538996363142257e-06\tMax abs grad value: 3.10410808481394e-05\n",
      "Loss = 3.105247028282294e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 7.988684628243968e-07\tMax abs grad value: 1.3789108084698707e-05\n",
      "Loss = 2.232128080702044e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.2554553321250126e-06\tMax abs grad value: 2.696741706661805e-05\n",
      "Loss = 1.7910507885714195e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 5.933092799089428e-07\tMax abs grad value: 1.5081651405674315e-05\n",
      "Loss = 1.2766220178121906e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.489316727551546e-07\tMax abs grad value: 1.3619514274799163e-05\n",
      "Loss = 9.946966346516968e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.576997764368514e-07\tMax abs grad value: 6.29165169732209e-06\n",
      "Loss = 6.114129023458896e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.1605092936402619\tMax abs grad value: 4.646264608663864\n",
      "Loss = 7.693730511914964\n",
      "Mean abs grad value: 0.05739759247006509\tMax abs grad value: 2.727006818554338\n",
      "Loss = 3.606949299718876\n",
      "Train accuracy: 0.083\t\tTest accuracy: 0.087\n",
      "Mean abs grad value: 0.015843190218313898\tMax abs grad value: 0.37202593811535867\n",
      "Loss = 2.4349403696941256\n",
      "Train accuracy: 0.151\t\tTest accuracy: 0.120\n",
      "Mean abs grad value: 0.011130574064197107\tMax abs grad value: 0.22638040768851422\n",
      "Loss = 2.258930709939238\n",
      "Train accuracy: 0.172\t\tTest accuracy: 0.140\n",
      "Mean abs grad value: 0.008455335397421193\tMax abs grad value: 0.15754910583169943\n",
      "Loss = 2.008924260369494\n",
      "Train accuracy: 0.268\t\tTest accuracy: 0.242\n",
      "Mean abs grad value: 0.008624808146928727\tMax abs grad value: 0.2004339035912615\n",
      "Loss = 1.734398610552531\n",
      "Train accuracy: 0.413\t\tTest accuracy: 0.407\n",
      "Mean abs grad value: 0.020029697380841673\tMax abs grad value: 0.6925506361987857\n",
      "Loss = 1.6391499938201237\n",
      "Train accuracy: 0.417\t\tTest accuracy: 0.409\n",
      "Mean abs grad value: 0.016738636913152593\tMax abs grad value: 0.6667774501869977\n",
      "Loss = 1.4341118491383233\n",
      "Train accuracy: 0.553\t\tTest accuracy: 0.533\n",
      "Mean abs grad value: 0.010173710015403603\tMax abs grad value: 0.33236645414151594\n",
      "Loss = 1.2900349103136843\n",
      "Train accuracy: 0.598\t\tTest accuracy: 0.573\n",
      "Mean abs grad value: 0.00881225317414928\tMax abs grad value: 0.29405152281054947\n",
      "Loss = 1.0911504240228365\n",
      "Train accuracy: 0.639\t\tTest accuracy: 0.604\n",
      "Mean abs grad value: 0.012957296799556787\tMax abs grad value: 0.43111969945639483\n",
      "Loss = 0.8388628737197311\n",
      "Train accuracy: 0.705\t\tTest accuracy: 0.660\n",
      "Mean abs grad value: 0.012081378263822764\tMax abs grad value: 0.4897195458271274\n",
      "Loss = 0.7018147996498043\n",
      "Train accuracy: 0.759\t\tTest accuracy: 0.698\n",
      "Mean abs grad value: 0.007420351224759829\tMax abs grad value: 0.1928106827039238\n",
      "Loss = 0.60014881084745\n",
      "Train accuracy: 0.813\t\tTest accuracy: 0.787\n",
      "Mean abs grad value: 0.007274276614806767\tMax abs grad value: 0.23055260702019334\n",
      "Loss = 0.5498215777225289\n",
      "Train accuracy: 0.821\t\tTest accuracy: 0.782\n",
      "Mean abs grad value: 0.005928412528099155\tMax abs grad value: 0.2103993637174665\n",
      "Loss = 0.4924163364702074\n",
      "Train accuracy: 0.837\t\tTest accuracy: 0.800\n",
      "Mean abs grad value: 0.006222523211235474\tMax abs grad value: 0.1486148796094239\n",
      "Loss = 0.4391299996844685\n",
      "Train accuracy: 0.852\t\tTest accuracy: 0.809\n",
      "Mean abs grad value: 0.01158642087887261\tMax abs grad value: 0.31700116722998545\n",
      "Loss = 0.41644977048492987\n",
      "Train accuracy: 0.869\t\tTest accuracy: 0.818\n",
      "Mean abs grad value: 0.005251210783355246\tMax abs grad value: 0.11647091580520189\n",
      "Loss = 0.36709764257658456\n",
      "Train accuracy: 0.875\t\tTest accuracy: 0.816\n",
      "Mean abs grad value: 0.004133618619995141\tMax abs grad value: 0.07824993574066406\n",
      "Loss = 0.3342860578788215\n",
      "Train accuracy: 0.894\t\tTest accuracy: 0.822\n",
      "Mean abs grad value: 0.004081266130008563\tMax abs grad value: 0.10877206735326514\n",
      "Loss = 0.29767193490074995\n",
      "Train accuracy: 0.903\t\tTest accuracy: 0.847\n",
      "Mean abs grad value: 0.007953324258265202\tMax abs grad value: 0.22199193424718505\n",
      "Loss = 0.2646366838972435\n",
      "Train accuracy: 0.915\t\tTest accuracy: 0.882\n",
      "Mean abs grad value: 0.004906864925480818\tMax abs grad value: 0.10636269882653494\n",
      "Loss = 0.2280801297638514\n",
      "Train accuracy: 0.932\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.00356395338409115\tMax abs grad value: 0.09547790757121646\n",
      "Loss = 0.20016763711820523\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.002955646874903072\tMax abs grad value: 0.063601484746264\n",
      "Loss = 0.1754675279097554\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.006908743595153259\tMax abs grad value: 0.17243200938856132\n",
      "Loss = 0.16380679010702273\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0036673293894394833\tMax abs grad value: 0.08284222035110092\n",
      "Loss = 0.14223878288439795\n",
      "Train accuracy: 0.950\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0028312398261273993\tMax abs grad value: 0.054570935385640174\n",
      "Loss = 0.13386545853245502\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.002926103814183767\tMax abs grad value: 0.06782162661867804\n",
      "Loss = 0.1126282580479109\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.003908712097820566\tMax abs grad value: 0.10939762611629134\n",
      "Loss = 0.09212970767011563\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0028491386117949647\tMax abs grad value: 0.06863310180459448\n",
      "Loss = 0.08021858557912674\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002163146462967177\tMax abs grad value: 0.041251336665175636\n",
      "Loss = 0.07328910472606193\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0023053309373276764\tMax abs grad value: 0.04234655246807088\n",
      "Loss = 0.06675547832137944\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0025255985418876823\tMax abs grad value: 0.04826049784583446\n",
      "Loss = 0.05478274924583783\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.003199408777360345\tMax abs grad value: 0.08077172938859503\n",
      "Loss = 0.0431538437365186\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.003847995149706184\tMax abs grad value: 0.09201317487817957\n",
      "Loss = 0.03753324218301909\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.001770141342078568\tMax abs grad value: 0.03752951567606197\n",
      "Loss = 0.02966564427341761\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0009879314912799454\tMax abs grad value: 0.017617487318187294\n",
      "Loss = 0.025345121378015624\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0011026985299491458\tMax abs grad value: 0.02116832233483852\n",
      "Loss = 0.021926761140281647\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0013531331619453706\tMax abs grad value: 0.03514878028478273\n",
      "Loss = 0.01761463272382372\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.001082636747528939\tMax abs grad value: 0.021962907371614614\n",
      "Loss = 0.013707934718914662\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0006990676547005786\tMax abs grad value: 0.009694182995487044\n",
      "Loss = 0.011483781067608629\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0008257640691570817\tMax abs grad value: 0.019371532513830995\n",
      "Loss = 0.009161625118030366\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0010738333032145214\tMax abs grad value: 0.0280170851357684\n",
      "Loss = 0.007353637716364478\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0006430331865245137\tMax abs grad value: 0.013300006983872405\n",
      "Loss = 0.0058930312868438655\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00045740373745364383\tMax abs grad value: 0.007876382961273316\n",
      "Loss = 0.004992007336771516\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0007869506809034813\tMax abs grad value: 0.020596866279924582\n",
      "Loss = 0.003655931237706978\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00029893399204940923\tMax abs grad value: 0.007430533113113855\n",
      "Loss = 0.0026619561999987663\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0004283428860205987\tMax abs grad value: 0.011610939251694668\n",
      "Loss = 0.00223252469370775\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0002643160472013891\tMax abs grad value: 0.00537366974366986\n",
      "Loss = 0.0015176222777531015\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00025992398423004134\tMax abs grad value: 0.004593168056881742\n",
      "Loss = 0.001175913105148555\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0001601855910953303\tMax abs grad value: 0.002720383077627041\n",
      "Loss = 0.0009219935198472699\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00018680440871901972\tMax abs grad value: 0.00565058058221349\n",
      "Loss = 0.000669637108421952\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00019194160843112834\tMax abs grad value: 0.004095684609292346\n",
      "Loss = 0.00048046129268819633\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00013839884386529733\tMax abs grad value: 0.0032806240940750223\n",
      "Loss = 0.00037247967112191243\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.6016293631734624e-05\tMax abs grad value: 0.0011594835073850992\n",
      "Loss = 0.00023401475101395456\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.763013685473086e-05\tMax abs grad value: 0.0009248559557073812\n",
      "Loss = 0.00018101254968785188\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 5.179580189408603e-05\tMax abs grad value: 0.001512815864199305\n",
      "Loss = 0.00013091611624647332\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.4203522286857523e-05\tMax abs grad value: 0.000532452510296749\n",
      "Loss = 9.402182735389094e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.94947470656242e-05\tMax abs grad value: 0.0005170219711978849\n",
      "Loss = 7.9206355384718e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.4932149867222667e-05\tMax abs grad value: 0.0003333132659625725\n",
      "Loss = 5.60039714537406e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.3108377775374499e-05\tMax abs grad value: 0.0002816077017313825\n",
      "Loss = 4.1141821109691834e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 8.69295778054827e-06\tMax abs grad value: 0.00015007270610620536\n",
      "Loss = 3.154287311241357e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.701909011259792e-06\tMax abs grad value: 0.00012003550392930283\n",
      "Loss = 2.3617646698323806e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.4047775345504075e-06\tMax abs grad value: 0.00010966027391528243\n",
      "Loss = 1.543638471713408e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.106958431969305e-06\tMax abs grad value: 0.0001264303138295116\n",
      "Loss = 8.939872670452874e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.1647526533726256e-06\tMax abs grad value: 4.051077720366697e-05\n",
      "Loss = 6.15369568079075e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.4846536247462577e-06\tMax abs grad value: 3.0364324564266643e-05\n",
      "Loss = 4.529209216394397e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 8.996988946511544e-07\tMax abs grad value: 1.8299355399227777e-05\n",
      "Loss = 2.778357123072669e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 7.147615360921988e-07\tMax abs grad value: 1.4397421294776623e-05\n",
      "Loss = 1.5401231943662303e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 5.718427462905699e-07\tMax abs grad value: 1.3883582048431333e-05\n",
      "Loss = 8.721061991132917e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.6039630632167216e-07\tMax abs grad value: 8.651273359047572e-06\n",
      "Loss = 5.389885349045785e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.12867196250473054\tMax abs grad value: 5.154274289811898\n",
      "Loss = 5.57028988734586\n",
      "Mean abs grad value: 0.03929867662994306\tMax abs grad value: 2.052757087304523\n",
      "Loss = 3.370879631939404\n",
      "Train accuracy: 0.166\t\tTest accuracy: 0.198\n",
      "Mean abs grad value: 0.015212167995199545\tMax abs grad value: 0.37804373116404544\n",
      "Loss = 2.3555256313875996\n",
      "Train accuracy: 0.133\t\tTest accuracy: 0.118\n",
      "Mean abs grad value: 0.011752239976091499\tMax abs grad value: 0.2874418250793203\n",
      "Loss = 2.1747082733421266\n",
      "Train accuracy: 0.174\t\tTest accuracy: 0.153\n",
      "Mean abs grad value: 0.011485686522899106\tMax abs grad value: 0.22239591215953577\n",
      "Loss = 1.9567978521417886\n",
      "Train accuracy: 0.264\t\tTest accuracy: 0.253\n",
      "Mean abs grad value: 0.01034672741555369\tMax abs grad value: 0.2923053421468939\n",
      "Loss = 1.7813740973732126\n",
      "Train accuracy: 0.368\t\tTest accuracy: 0.347\n",
      "Mean abs grad value: 0.016275084134080523\tMax abs grad value: 0.4680431061076746\n",
      "Loss = 1.5893651672883664\n",
      "Train accuracy: 0.462\t\tTest accuracy: 0.433\n",
      "Mean abs grad value: 0.011477102899664903\tMax abs grad value: 0.20287785238685735\n",
      "Loss = 1.3735050323948002\n",
      "Train accuracy: 0.537\t\tTest accuracy: 0.524\n",
      "Mean abs grad value: 0.01156148049549422\tMax abs grad value: 0.2823919274189841\n",
      "Loss = 1.18814380636687\n",
      "Train accuracy: 0.598\t\tTest accuracy: 0.573\n",
      "Mean abs grad value: 0.03037482104658981\tMax abs grad value: 1.6189943854371585\n",
      "Loss = 1.1034421577909919\n",
      "Mean abs grad value: 0.012221307711614138\tMax abs grad value: 0.3750168110086176\n",
      "Loss = 0.995702124783584\n",
      "Train accuracy: 0.675\t\tTest accuracy: 0.633\n",
      "Mean abs grad value: 0.012929274367951622\tMax abs grad value: 0.39066390305321297\n",
      "Loss = 0.7876535803938186\n",
      "Train accuracy: 0.720\t\tTest accuracy: 0.678\n",
      "Mean abs grad value: 0.02298388632877225\tMax abs grad value: 0.8603515606856013\n",
      "Loss = 0.8291405078195273\n",
      "Mean abs grad value: 0.011414635693040433\tMax abs grad value: 0.3270954656554908\n",
      "Loss = 0.6970799111796272\n",
      "Train accuracy: 0.766\t\tTest accuracy: 0.733\n",
      "Mean abs grad value: 0.007826009807834631\tMax abs grad value: 0.3027196571895058\n",
      "Loss = 0.6344041811037483\n",
      "Train accuracy: 0.794\t\tTest accuracy: 0.769\n",
      "Mean abs grad value: 0.0066336752555428\tMax abs grad value: 0.19250248106933848\n",
      "Loss = 0.5744121084256038\n",
      "Train accuracy: 0.818\t\tTest accuracy: 0.780\n",
      "Mean abs grad value: 0.008724309121559597\tMax abs grad value: 0.3242335830381286\n",
      "Loss = 0.4948892603301699\n",
      "Train accuracy: 0.842\t\tTest accuracy: 0.798\n",
      "Mean abs grad value: 0.008112925982409877\tMax abs grad value: 0.21156209869394343\n",
      "Loss = 0.43147997515174347\n",
      "Train accuracy: 0.866\t\tTest accuracy: 0.847\n",
      "Mean abs grad value: 0.005338973036555373\tMax abs grad value: 0.11816335321443497\n",
      "Loss = 0.39682299840743057\n",
      "Train accuracy: 0.882\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.005396656514441473\tMax abs grad value: 0.12734026181025854\n",
      "Loss = 0.3739380316449508\n",
      "Train accuracy: 0.892\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.006820795538232655\tMax abs grad value: 0.3032613596309244\n",
      "Loss = 0.32934802791718765\n",
      "Train accuracy: 0.912\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.007963598449816195\tMax abs grad value: 0.24012939524168564\n",
      "Loss = 0.30049423603898373\n",
      "Train accuracy: 0.903\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.005041682112461161\tMax abs grad value: 0.09749614406022901\n",
      "Loss = 0.2742488483167251\n",
      "Train accuracy: 0.922\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.004528726960268668\tMax abs grad value: 0.10184027177244034\n",
      "Loss = 0.2440336770232632\n",
      "Train accuracy: 0.931\t\tTest accuracy: 0.898\n",
      "Mean abs grad value: 0.004361803275312562\tMax abs grad value: 0.09886071781348933\n",
      "Loss = 0.22992369860887\n",
      "Train accuracy: 0.933\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.003704323314961434\tMax abs grad value: 0.09187703113166257\n",
      "Loss = 0.20843512489356705\n",
      "Train accuracy: 0.938\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.003935270994132357\tMax abs grad value: 0.10064480840386579\n",
      "Loss = 0.17907754426824823\n",
      "Train accuracy: 0.948\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0037651921006363223\tMax abs grad value: 0.10164992563840292\n",
      "Loss = 0.15393154808427417\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.005175676812908914\tMax abs grad value: 0.13284924128871428\n",
      "Loss = 0.13380044740401525\n",
      "Train accuracy: 0.962\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.003726766028462995\tMax abs grad value: 0.07092836403208826\n",
      "Loss = 0.11532988121320539\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.002740518389915648\tMax abs grad value: 0.07088868227654199\n",
      "Loss = 0.10235207489692567\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002527847051883651\tMax abs grad value: 0.05736420236238403\n",
      "Loss = 0.08848887348944702\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.004154055681765543\tMax abs grad value: 0.1965522179641676\n",
      "Loss = 0.07887636346199031\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.002761737308079323\tMax abs grad value: 0.06084258667275239\n",
      "Loss = 0.06688317179342544\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0020672427768571333\tMax abs grad value: 0.06559584377369511\n",
      "Loss = 0.058806914620641505\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0019466674279374598\tMax abs grad value: 0.077832310890325\n",
      "Loss = 0.05070242735918869\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002575210700932738\tMax abs grad value: 0.07218109206839673\n",
      "Loss = 0.04089099801402495\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0019265806181906055\tMax abs grad value: 0.03908231613049551\n",
      "Loss = 0.03356338515057979\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002955000149538515\tMax abs grad value: 0.05664974649736916\n",
      "Loss = 0.027384191122551815\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0014635722863964\tMax abs grad value: 0.03636784006145528\n",
      "Loss = 0.022973077662548906\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001086050171241713\tMax abs grad value: 0.01661418340911841\n",
      "Loss = 0.02001416356306039\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0010650821721576722\tMax abs grad value: 0.029703251435464647\n",
      "Loss = 0.01556034784637067\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.001209954741915968\tMax abs grad value: 0.024306622515265056\n",
      "Loss = 0.011693197002613658\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0019143367891476454\tMax abs grad value: 0.05253174190992302\n",
      "Loss = 0.010101622520212732\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.000730344061493088\tMax abs grad value: 0.015213766314488807\n",
      "Loss = 0.00819539636966922\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0005896395284665347\tMax abs grad value: 0.011385826722995486\n",
      "Loss = 0.0074782562801503855\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0005613272476482905\tMax abs grad value: 0.016715528609516327\n",
      "Loss = 0.006622194562467295\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0004218168639862311\tMax abs grad value: 0.01074141825614902\n",
      "Loss = 0.005159307665629478\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0010434222004124373\tMax abs grad value: 0.028381788868540078\n",
      "Loss = 0.004225149716882591\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.000389116253951306\tMax abs grad value: 0.008077533074142572\n",
      "Loss = 0.003042584131143121\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.000318297563448622\tMax abs grad value: 0.007165268603767061\n",
      "Loss = 0.0026963171315356493\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00021111071986553524\tMax abs grad value: 0.004285863149000948\n",
      "Loss = 0.0017533243034613187\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00037481729499188725\tMax abs grad value: 0.009901440688994513\n",
      "Loss = 0.001342622642810221\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00010953867467184189\tMax abs grad value: 0.0022654653153833027\n",
      "Loss = 0.0010175405478831563\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00010118876029309078\tMax abs grad value: 0.0019056314821184804\n",
      "Loss = 0.0008890697252139361\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00010741692265786785\tMax abs grad value: 0.001814476675401258\n",
      "Loss = 0.0007118424164507468\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00010299086916439513\tMax abs grad value: 0.0024133590903889406\n",
      "Loss = 0.0005137446501505726\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 6.611632186380955e-05\tMax abs grad value: 0.0016542121651394262\n",
      "Loss = 0.0003628131432427803\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.973211045712084e-05\tMax abs grad value: 0.0013262792088834065\n",
      "Loss = 0.00027951350056014813\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.714624088792469e-05\tMax abs grad value: 0.0007363596062004377\n",
      "Loss = 0.00020889579327654516\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.23425126448586e-05\tMax abs grad value: 0.0015677263779411694\n",
      "Loss = 0.00014587547335568872\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.7116378243671954e-05\tMax abs grad value: 0.0010736686541465308\n",
      "Loss = 0.00010305171352802747\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.0145697389907698e-05\tMax abs grad value: 0.0003385348080327677\n",
      "Loss = 7.677684954105332e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.585800514849767e-05\tMax abs grad value: 0.0002645812321546694\n",
      "Loss = 5.8101665041452204e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 7.613357733854078e-06\tMax abs grad value: 0.00015454483913024118\n",
      "Loss = 3.4971328132442266e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 9.163766833339185e-06\tMax abs grad value: 0.00015550983711720793\n",
      "Loss = 2.3718185751640383e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.67413775306923e-06\tMax abs grad value: 0.00011753636296087856\n",
      "Loss = 1.6378522788006954e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.659737244844927e-06\tMax abs grad value: 8.629387278695302e-05\n",
      "Loss = 1.2620846182059851e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.2829253132847365e-06\tMax abs grad value: 4.9244192349015274e-05\n",
      "Loss = 8.595784966354895e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.9938536935016712e-06\tMax abs grad value: 5.335758647330855e-05\n",
      "Loss = 5.695113577767567e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.825651254688781e-06\tMax abs grad value: 0.00010710543412680295\n",
      "Loss = 3.938193138671432e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 8.436342435576269e-07\tMax abs grad value: 1.766609289840605e-05\n",
      "Loss = 2.5889310686175467e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.345804488843354e-07\tMax abs grad value: 1.1368918725118929e-05\n",
      "Loss = 2.1406640011840466e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.815929657943099e-07\tMax abs grad value: 5.4206307272392805e-06\n",
      "Loss = 1.3462197153659857e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.09649853893169787\tMax abs grad value: 2.1684217022105594\n",
      "Loss = 5.02678895636794\n",
      "Mean abs grad value: 0.028350428357224372\tMax abs grad value: 1.0682832401784284\n",
      "Loss = 2.8999169175332784\n",
      "Train accuracy: 0.081\t\tTest accuracy: 0.071\n",
      "Mean abs grad value: 0.008786043131152459\tMax abs grad value: 0.548481989981602\n",
      "Loss = 2.263029528363823\n",
      "Train accuracy: 0.115\t\tTest accuracy: 0.107\n",
      "Mean abs grad value: 0.006536524279090782\tMax abs grad value: 0.21571140430148858\n",
      "Loss = 2.1320454628417522\n",
      "Train accuracy: 0.196\t\tTest accuracy: 0.171\n",
      "Mean abs grad value: 0.006627472887939299\tMax abs grad value: 0.1850503747488855\n",
      "Loss = 2.0274188903147454\n",
      "Train accuracy: 0.238\t\tTest accuracy: 0.229\n",
      "Mean abs grad value: 0.0070041531373307205\tMax abs grad value: 0.23699591750169816\n",
      "Loss = 1.8729097967298867\n",
      "Train accuracy: 0.317\t\tTest accuracy: 0.287\n",
      "Mean abs grad value: 0.05107981514705345\tMax abs grad value: 2.102238644863231\n",
      "Loss = 2.3425981403130707\n",
      "Mean abs grad value: 0.011123963853690723\tMax abs grad value: 0.41092211465482126\n",
      "Loss = 1.6781746687029027\n",
      "Train accuracy: 0.379\t\tTest accuracy: 0.351\n",
      "Mean abs grad value: 0.011324001224220887\tMax abs grad value: 0.34585519360656725\n",
      "Loss = 1.5165090823075402\n",
      "Train accuracy: 0.463\t\tTest accuracy: 0.413\n",
      "Mean abs grad value: 0.008363235250974804\tMax abs grad value: 0.2603208499934048\n",
      "Loss = 1.4033615952352727\n",
      "Train accuracy: 0.480\t\tTest accuracy: 0.433\n",
      "Mean abs grad value: 0.014175025851294362\tMax abs grad value: 0.4950789414944785\n",
      "Loss = 1.234411609066804\n",
      "Train accuracy: 0.563\t\tTest accuracy: 0.529\n",
      "Mean abs grad value: 0.009521508908419945\tMax abs grad value: 0.2167624365024389\n",
      "Loss = 1.086983367419869\n",
      "Train accuracy: 0.659\t\tTest accuracy: 0.607\n",
      "Mean abs grad value: 0.01898479030025951\tMax abs grad value: 0.8321127159113144\n",
      "Loss = 1.0366741751793354\n",
      "Mean abs grad value: 0.009386824708850426\tMax abs grad value: 0.2884970791694628\n",
      "Loss = 0.9536874501225698\n",
      "Train accuracy: 0.695\t\tTest accuracy: 0.609\n",
      "Mean abs grad value: 0.012627575609292037\tMax abs grad value: 0.39288585596231357\n",
      "Loss = 0.8179788051533561\n",
      "Train accuracy: 0.748\t\tTest accuracy: 0.691\n",
      "Mean abs grad value: 0.009881493864081372\tMax abs grad value: 0.3164722320799599\n",
      "Loss = 0.6770505569400413\n",
      "Train accuracy: 0.800\t\tTest accuracy: 0.771\n",
      "Mean abs grad value: 0.009647464535981606\tMax abs grad value: 0.28780086358928947\n",
      "Loss = 0.6106477621877874\n",
      "Train accuracy: 0.817\t\tTest accuracy: 0.780\n",
      "Mean abs grad value: 0.009028637110538711\tMax abs grad value: 0.2679607667609937\n",
      "Loss = 0.534124675407986\n",
      "Train accuracy: 0.824\t\tTest accuracy: 0.804\n",
      "Mean abs grad value: 0.008634548338569784\tMax abs grad value: 0.3113448557410015\n",
      "Loss = 0.43173860112204476\n",
      "Train accuracy: 0.864\t\tTest accuracy: 0.833\n",
      "Mean abs grad value: 0.0067225759970260856\tMax abs grad value: 0.19505879347978375\n",
      "Loss = 0.3894180291271628\n",
      "Train accuracy: 0.885\t\tTest accuracy: 0.856\n",
      "Mean abs grad value: 0.005310491071470377\tMax abs grad value: 0.1421012291792611\n",
      "Loss = 0.3674398145852695\n",
      "Train accuracy: 0.884\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.004512201153453488\tMax abs grad value: 0.10096561590936914\n",
      "Loss = 0.3467885979860235\n",
      "Train accuracy: 0.891\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.0043903964823702206\tMax abs grad value: 0.12143717342529602\n",
      "Loss = 0.31610048604775937\n",
      "Train accuracy: 0.902\t\tTest accuracy: 0.871\n",
      "Mean abs grad value: 0.00810996979939532\tMax abs grad value: 0.3324928838804922\n",
      "Loss = 0.2614297259527302\n",
      "Train accuracy: 0.915\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.008935263274953205\tMax abs grad value: 0.46730895164902847\n",
      "Loss = 0.23979401364082695\n",
      "Train accuracy: 0.923\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.00380852036314246\tMax abs grad value: 0.1766759115310606\n",
      "Loss = 0.2172590536974772\n",
      "Train accuracy: 0.935\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.00371465950586498\tMax abs grad value: 0.10435085962125525\n",
      "Loss = 0.2060810369475502\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.004249187996479955\tMax abs grad value: 0.14095935793167474\n",
      "Loss = 0.19495090578947402\n",
      "Train accuracy: 0.943\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0036476298935347496\tMax abs grad value: 0.22435061314627067\n",
      "Loss = 0.1774485992707084\n",
      "Train accuracy: 0.945\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.0033615331450343585\tMax abs grad value: 0.08113799854502837\n",
      "Loss = 0.15124871899555908\n",
      "Train accuracy: 0.950\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.0034795581809033463\tMax abs grad value: 0.13091045065875667\n",
      "Loss = 0.13467115533581617\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.003819463891549741\tMax abs grad value: 0.1768426339371971\n",
      "Loss = 0.1214942085841529\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.0035404805442366795\tMax abs grad value: 0.1607697032598517\n",
      "Loss = 0.11470511245743448\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.00224572252020357\tMax abs grad value: 0.0844255938514635\n",
      "Loss = 0.10956579810509151\n",
      "Train accuracy: 0.962\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0029751324438157187\tMax abs grad value: 0.11625248582143871\n",
      "Loss = 0.10375990392284837\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0035364996639035153\tMax abs grad value: 0.15838037585514353\n",
      "Loss = 0.09914562658770935\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0029529879468093317\tMax abs grad value: 0.1265951155487919\n",
      "Loss = 0.08699227926202384\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0028338598106770335\tMax abs grad value: 0.09638952214680149\n",
      "Loss = 0.07818055208787208\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0018198457332399608\tMax abs grad value: 0.06862633331739565\n",
      "Loss = 0.07159543461454487\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.002077691709082919\tMax abs grad value: 0.07987276465175941\n",
      "Loss = 0.06847678232970963\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.002014123116183541\tMax abs grad value: 0.0827863984995\n",
      "Loss = 0.06000943600417485\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.008189731563358473\tMax abs grad value: 0.3629264738655273\n",
      "Loss = 0.06747668177480626\n",
      "Mean abs grad value: 0.0025714575487069185\tMax abs grad value: 0.109791301969847\n",
      "Loss = 0.05560401453599537\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0016147066786300086\tMax abs grad value: 0.052975742209038904\n",
      "Loss = 0.05014335074146659\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0014817504526084045\tMax abs grad value: 0.048987520729831896\n",
      "Loss = 0.04500680573669812\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.002004348135703741\tMax abs grad value: 0.06620713356154631\n",
      "Loss = 0.040764869279357754\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0022188185988698907\tMax abs grad value: 0.11464648004801908\n",
      "Loss = 0.037301059131627436\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0013928977004965283\tMax abs grad value: 0.058344069570455806\n",
      "Loss = 0.033497242652020545\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0012812430395619182\tMax abs grad value: 0.03600006121979286\n",
      "Loss = 0.030227464426965472\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0013324284117183104\tMax abs grad value: 0.04339047115087275\n",
      "Loss = 0.027615292249482132\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0022212927296335547\tMax abs grad value: 0.09595181566024724\n",
      "Loss = 0.024616599888267015\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0010715388127431954\tMax abs grad value: 0.02713071042381728\n",
      "Loss = 0.02094496260070275\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0010471559749598543\tMax abs grad value: 0.03404864733272294\n",
      "Loss = 0.01918780139178442\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0011059438648729817\tMax abs grad value: 0.035666576404773456\n",
      "Loss = 0.01629733332770226\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0016063001948804052\tMax abs grad value: 0.05566480049530833\n",
      "Loss = 0.013752852271977443\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0008195442284848605\tMax abs grad value: 0.02458362403329505\n",
      "Loss = 0.011000520016600025\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0007126504727235507\tMax abs grad value: 0.028057944457857413\n",
      "Loss = 0.009216944947288164\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0016043044516823649\tMax abs grad value: 0.058279172991771\n",
      "Loss = 0.007771849438540546\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0006115500026199442\tMax abs grad value: 0.013459479990121015\n",
      "Loss = 0.006214601988083644\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00048408314839688853\tMax abs grad value: 0.012488553459387614\n",
      "Loss = 0.005709702041476167\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.000558147109846801\tMax abs grad value: 0.014477620887924451\n",
      "Loss = 0.0050284725928807245\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0005237101505536091\tMax abs grad value: 0.02177778165055354\n",
      "Loss = 0.004301870755455837\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0006497860443341054\tMax abs grad value: 0.027180200044770984\n",
      "Loss = 0.0030032414131729553\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0003917761039949389\tMax abs grad value: 0.013253597965808368\n",
      "Loss = 0.002362986717507141\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0002838115673554531\tMax abs grad value: 0.007549231863138173\n",
      "Loss = 0.0020549011424793088\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00021015031365635475\tMax abs grad value: 0.005464682676544085\n",
      "Loss = 0.0015330599532714984\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00013501150154760907\tMax abs grad value: 0.0063048794937664784\n",
      "Loss = 0.0011001557227753157\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0002106211235781708\tMax abs grad value: 0.006458458714479406\n",
      "Loss = 0.000791053277344801\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 9.361130375164816e-05\tMax abs grad value: 0.003200668292387619\n",
      "Loss = 0.000598595734089233\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 7.487495907385334e-05\tMax abs grad value: 0.001918983701472621\n",
      "Loss = 0.000507959444048943\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 8.528413497076793e-05\tMax abs grad value: 0.002396795961904592\n",
      "Loss = 0.0004278927825998568\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 8.434617549425375e-05\tMax abs grad value: 0.0019631345768420434\n",
      "Loss = 0.00032239476892086734\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 5.384487684326463e-05\tMax abs grad value: 0.001620520606165828\n",
      "Loss = 0.00024482883540943883\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 5.130531538923759e-05\tMax abs grad value: 0.0010352498121508004\n",
      "Loss = 0.00019534434648746683\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 2.8732530337718574e-05\tMax abs grad value: 0.0011203695623266622\n",
      "Loss = 0.00013248175553759827\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.2142163689518024e-05\tMax abs grad value: 0.0011275335483113297\n",
      "Loss = 0.00010480157259281164\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.8172554002579087e-05\tMax abs grad value: 0.0008940463138867243\n",
      "Loss = 7.979157278996124e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.5313008008507557e-05\tMax abs grad value: 0.0006035912972401024\n",
      "Loss = 5.927853587751899e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 8.73577043166167e-06\tMax abs grad value: 0.00025523936887002533\n",
      "Loss = 3.611612838815914e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 9.604513302832478e-06\tMax abs grad value: 0.0004877279615171877\n",
      "Loss = 2.6712368465846804e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 5.778905364681671e-06\tMax abs grad value: 0.00015905037537259796\n",
      "Loss = 1.8036678544281802e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.606508241104977e-06\tMax abs grad value: 7.378134921729476e-05\n",
      "Loss = 1.1617200082778585e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 3.3874045691291597e-06\tMax abs grad value: 0.00010067644336322409\n",
      "Loss = 7.891982971001792e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.2464393374430604e-06\tMax abs grad value: 3.1132832102555173e-05\n",
      "Loss = 4.500032976848463e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 9.413899726551745e-07\tMax abs grad value: 3.078790659604835e-05\n",
      "Loss = 3.241640199926961e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 5.9925125806352325e-06\tMax abs grad value: 0.000407373355180588\n",
      "Loss = 5.077801170252217e-06\n",
      "Mean abs grad value: 1.485975653970673e-06\tMax abs grad value: 7.91654215047048e-05\n",
      "Loss = 2.808603829141912e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 7.679023558453545e-07\tMax abs grad value: 2.848893878714134e-05\n",
      "Loss = 1.8076590572520655e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 4.489594147497925e-07\tMax abs grad value: 1.2122434168950792e-05\n",
      "Loss = 1.2222494181742826e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.886482088379344e-07\tMax abs grad value: 6.110875081625183e-06\n",
      "Loss = 7.67691730265874e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for i, layer_c in zip(range(5), range(1, 5+1)):\n",
    "    for j in range(5):\n",
    "        network = make_network(input_size, 32, output_size, layer_c, ReLU)\n",
    "        network, cb = train_network(network, history=True)\n",
    "        \n",
    "        accs_train[i, j] = cb.train_acc[-1]\n",
    "        accs_test[i, j] = cb.test_acc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Построим боксплоты полученного качества (горизонтальная линия в каждом столбце — среднее, прямоугольник показывает разброс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:36:07.402165200Z",
     "start_time": "2024-02-22T20:36:07.191813100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x800 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "axes[0].boxplot(accs_train.T, showfliers=False)\n",
    "axes[1].boxplot(accs_test.T, showfliers=False)\n",
    "\n",
    "axes[0].set_xlabel(\"Number of layers\")\n",
    "axes[1].set_xlabel(\"Number of layers\")\n",
    "\n",
    "axes[0].set_ylabel(\"Train accuracy\")\n",
    "axes[1].set_ylabel(\"Test accuracy\")\n",
    "\n",
    "axes[0].set_title(\"Train quality in 5 runs\")\n",
    "axes[1].set_title(\"Test quality in 5 runs\")\n",
    "\n",
    "axes[0].grid(True)\n",
    "axes[1].grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Дайте развёрнутый ответ на вопросы (в этой же ячейке):\n",
    "* Как изменяются качество на обучении и контроле и устойчивость процесса обучения при увеличении числа слоев?\n",
    "* Можно ли сказать, что логистическая регрессия (линейная модель) дает качество хуже, чем нелинейная модель?\n",
    "\n",
    "__Ответы:__\n",
    "\n",
    "Линейная модель показывает худший результат среди изученных моделей. \n",
    "На обучающей выборке модели стабильно получают точность, сравнимую с 1.\n",
    "На валидационной выборке модели получают качество на несколько процентов хуже, чем на тренировочной. \n",
    "\n",
    "Оптимальное число слоев --- 3 или 4 слоя. \n",
    "При числе слоёв > 4 начинает усиляться переобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Эксперименты c различными инициализациями весов (0.6 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Как уже было сказано, начальная инициализация весов нейронной сети может сильно влиять на процесс ее обучения и, как следствие, на ее качество.\n",
    "\n",
    "В этом пункте вам предлагается попробовать обучить несколько нейронных сетей с различными инициализациями слоев.\n",
    "\n",
    "Для этого необходимо реализовать функцию, инициализирующую веса линейных слоёв нашей нейронной сети. Добавьте в функционал данного метода возможность инициализировать его веса с помощью инициализации Kaiming (используется, если в нейронной сети в качестве функций активации используется ReLU) и инициализации Xavier (используется, если в нейронной сети в качестве функций активации используется Tanh или Sigmoid):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:36:07.408012400Z",
     "start_time": "2024-02-22T20:36:07.405498200Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_network(network, initialization):\n",
    "    for layer in network:\n",
    "        if isinstance(layer, Dense):\n",
    "            input_units, output_units = layer.weights.shape\n",
    "            if initialization == 'Kaiming':\n",
    "                # assert False, \"NOT IMPLEMENTED\"\n",
    "                sigma = 2 / layer.weights.shape[0]\n",
    "                layer.weights = np.random.normal(loc=0, scale=sigma, size=layer.weights.shape)\n",
    "            elif initialization == 'Xavier':\n",
    "                sigma = np.sqrt(2 / (layer.weights.shape[0] + layer.weights.shape[1]))\n",
    "                layer.weights = np.random.normal(loc=0, scale=sigma, size=layer.weights.shape)\n",
    "            else:\n",
    "                # Initialize weights with small random numbers from normal distribution.\n",
    "                # In this case `initialization` represents a standard deviation\n",
    "                # for normal distribution.\n",
    "                layer.weights = np.random.randn(input_units, output_units) * initialization\n",
    "            layer.biases = np.zeros_like(layer.biases)\n",
    "            \n",
    "            layer.params = [layer.weights, layer.biases]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь попробуйте для каждой из 3 инициализаций обучить нейронную сеть несколько раз. Попробуйте проделать данную операцию при зафиксированном числе слоев равным 3, 4 и 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `3 слоя`\n",
    "\n",
    "Зафиксируйте в сети число слоев равное трем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Заполните матрицы `accs_train` и `accs_test`. В позиции `[i, j]` должна стоять величина доли правильных ответов сети при $j$-м запуске (все запуски идентичны) с инициализацией Kaiming при $i = 3$, с инициализацией Xavier при $i = 4$ и с инициализацией из нормального распределения с фиксированными параметрами при $0 \\leqslant i \\leqslant 2$ (попробуйте здесь 3 разных параметра для стандартного отклонения для нормального распределения, например: `1e-3`, `1e-2`, `1e-1`). Заметьте, что при большом числе слоев слишком низкое стандартное отклонение может не давать нейронной сети нормально обучиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:36:07.420042200Z",
     "start_time": "2024-02-22T20:36:07.407011900Z"
    }
   },
   "outputs": [],
   "source": [
    "init_vars = [0.1, 0.1, 0.1, 'Kaiming', 'Xavier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:36:07.422043700Z",
     "start_time": "2024-02-22T20:36:07.411799900Z"
    }
   },
   "outputs": [],
   "source": [
    "accs_train = np.zeros((5, 5))\n",
    "accs_test = np.zeros((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:36:42.655873300Z",
     "start_time": "2024-02-22T20:36:07.415044200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean abs grad value: 0.023923768689335115\tMax abs grad value: 0.5397984325402326\n",
      "Loss = 2.4779531700741524\n",
      "Mean abs grad value: 0.035488186245531385\tMax abs grad value: 2.390627413824082\n",
      "Loss = 2.8451854848853926\n",
      "Mean abs grad value: 0.015596342272377972\tMax abs grad value: 0.335033009673193\n",
      "Loss = 2.2119403833879416\n",
      "Train accuracy: 0.145\t\tTest accuracy: 0.158\n",
      "Mean abs grad value: 0.011384368824348848\tMax abs grad value: 0.16998866494416282\n",
      "Loss = 2.051751330896222\n",
      "Train accuracy: 0.302\t\tTest accuracy: 0.307\n",
      "Mean abs grad value: 0.013350123675796147\tMax abs grad value: 0.2766089807625004\n",
      "Loss = 1.81918908115332\n",
      "Train accuracy: 0.511\t\tTest accuracy: 0.522\n",
      "Mean abs grad value: 0.017926759308805183\tMax abs grad value: 0.38309495066552596\n",
      "Loss = 1.5348455848459432\n",
      "Train accuracy: 0.570\t\tTest accuracy: 0.556\n",
      "Mean abs grad value: 0.053834276982821755\tMax abs grad value: 1.4770337108768092\n",
      "Loss = 1.4046945705353011\n",
      "Mean abs grad value: 0.021327574602466207\tMax abs grad value: 0.47082830592640407\n",
      "Loss = 1.21401614409607\n",
      "Train accuracy: 0.638\t\tTest accuracy: 0.618\n",
      "Mean abs grad value: 0.055930088565532686\tMax abs grad value: 1.443372875382144\n",
      "Loss = 1.1076825903865517\n",
      "Mean abs grad value: 0.022905530958242735\tMax abs grad value: 0.5643388641610676\n",
      "Loss = 0.9726977311678772\n",
      "Train accuracy: 0.694\t\tTest accuracy: 0.660\n",
      "Mean abs grad value: 0.050538349491639774\tMax abs grad value: 1.7680268013153375\n",
      "Loss = 0.9224052128924431\n",
      "Mean abs grad value: 0.020695294633085545\tMax abs grad value: 0.4496022315860427\n",
      "Loss = 0.7789322066255302\n",
      "Train accuracy: 0.751\t\tTest accuracy: 0.698\n",
      "Mean abs grad value: 0.037506531209501426\tMax abs grad value: 1.2686334258086918\n",
      "Loss = 0.7895836213743825\n",
      "Mean abs grad value: 0.016186553178316628\tMax abs grad value: 0.33579869408185475\n",
      "Loss = 0.6501345720830581\n",
      "Train accuracy: 0.799\t\tTest accuracy: 0.749\n",
      "Mean abs grad value: 0.010838094194877846\tMax abs grad value: 0.2599699239658377\n",
      "Loss = 0.5784528750083201\n",
      "Train accuracy: 0.814\t\tTest accuracy: 0.773\n",
      "Mean abs grad value: 0.010265123099106713\tMax abs grad value: 0.21351719120803236\n",
      "Loss = 0.5106827518623173\n",
      "Train accuracy: 0.827\t\tTest accuracy: 0.798\n",
      "Mean abs grad value: 0.010513491029214716\tMax abs grad value: 0.2029165590379473\n",
      "Loss = 0.43945030565482407\n",
      "Train accuracy: 0.853\t\tTest accuracy: 0.816\n",
      "Mean abs grad value: 0.011284742809620964\tMax abs grad value: 0.28010742553612483\n",
      "Loss = 0.35762696609247346\n",
      "Train accuracy: 0.879\t\tTest accuracy: 0.856\n",
      "Mean abs grad value: 0.008788112123429595\tMax abs grad value: 0.16616398683817082\n",
      "Loss = 0.290069057876047\n",
      "Train accuracy: 0.906\t\tTest accuracy: 0.882\n",
      "Mean abs grad value: 0.006825473321951722\tMax abs grad value: 0.12049069960588293\n",
      "Loss = 0.24003957770065515\n",
      "Train accuracy: 0.915\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.0061980719893166844\tMax abs grad value: 0.21989575423006727\n",
      "Loss = 0.19659137178884356\n",
      "Train accuracy: 0.939\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.007083129970138382\tMax abs grad value: 0.18251419950711095\n",
      "Loss = 0.17703995428179306\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0045600340051374704\tMax abs grad value: 0.09255820686129056\n",
      "Loss = 0.16554969016615176\n",
      "Train accuracy: 0.946\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.003811974373926096\tMax abs grad value: 0.06604422334602683\n",
      "Loss = 0.15018371097341165\n",
      "Train accuracy: 0.953\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.004057954584031933\tMax abs grad value: 0.10316527140749691\n",
      "Loss = 0.13842392452348357\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.00557159783463238\tMax abs grad value: 0.15139556863012377\n",
      "Loss = 0.12482443647758332\n",
      "Train accuracy: 0.966\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0029029955842767435\tMax abs grad value: 0.06786942680998838\n",
      "Loss = 0.11300203458130254\n",
      "Train accuracy: 0.965\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0026322577312208185\tMax abs grad value: 0.05399965689808009\n",
      "Loss = 0.1077378841755831\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.003599244467468698\tMax abs grad value: 0.08420462450831502\n",
      "Loss = 0.09590999909505606\n",
      "Train accuracy: 0.971\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0035092139019412415\tMax abs grad value: 0.0709428255903549\n",
      "Loss = 0.08687867738896203\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0043333755608064885\tMax abs grad value: 0.10691968259345301\n",
      "Loss = 0.0774872036946622\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.002776442296047342\tMax abs grad value: 0.04959379627874503\n",
      "Loss = 0.06917686917016254\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0025907631299167\tMax abs grad value: 0.06972806429541178\n",
      "Loss = 0.06558900756093107\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0037477336087425326\tMax abs grad value: 0.10392248765464099\n",
      "Loss = 0.05911368448529223\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0031819614706454316\tMax abs grad value: 0.07446365064133376\n",
      "Loss = 0.051561395170321225\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0028086752764779226\tMax abs grad value: 0.06505395657360996\n",
      "Loss = 0.04773973761508819\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0030652053062702406\tMax abs grad value: 0.05570177412178539\n",
      "Loss = 0.04224933628907307\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0028255385244536405\tMax abs grad value: 0.07095079468096463\n",
      "Loss = 0.03692270894789308\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0050133598187723895\tMax abs grad value: 0.1646282573020591\n",
      "Loss = 0.032590265378021746\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002803447635624135\tMax abs grad value: 0.07054978287216945\n",
      "Loss = 0.02847154598523278\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0015936268520250149\tMax abs grad value: 0.029620975685779007\n",
      "Loss = 0.027029705675977272\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0013401425926593928\tMax abs grad value: 0.025733615743358668\n",
      "Loss = 0.025835305119501124\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.001447479327728215\tMax abs grad value: 0.027743662068036894\n",
      "Loss = 0.023981245136373543\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002065374639176689\tMax abs grad value: 0.06807074705504901\n",
      "Loss = 0.020615520537085628\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0015181425749992046\tMax abs grad value: 0.05165588101503727\n",
      "Loss = 0.017260011865722822\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0008390028187048651\tMax abs grad value: 0.012158819202688947\n",
      "Loss = 0.016111798594301233\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0008965444898124925\tMax abs grad value: 0.01611348357480528\n",
      "Loss = 0.01537982326292301\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0010603593288115957\tMax abs grad value: 0.03159628239305286\n",
      "Loss = 0.01362401598583829\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.002406895549203925\tMax abs grad value: 0.06728665428703963\n",
      "Loss = 0.014562100326698097\n",
      "Mean abs grad value: 0.0012997539333494236\tMax abs grad value: 0.03888979263858059\n",
      "Loss = 0.011938885787293005\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0020755364374272136\tMax abs grad value: 0.04361857468047165\n",
      "Loss = 0.010049003639346918\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0011709350528119875\tMax abs grad value: 0.02437691140883499\n",
      "Loss = 0.008180874109383134\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0010662098031539186\tMax abs grad value: 0.031190927571662235\n",
      "Loss = 0.0072314167170347285\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0007808139897832261\tMax abs grad value: 0.014707761252406432\n",
      "Loss = 0.006685620211735867\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0006325917877953039\tMax abs grad value: 0.008779254249174716\n",
      "Loss = 0.006299398566846748\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.000619908566374846\tMax abs grad value: 0.00946125816088977\n",
      "Loss = 0.005760967797138073\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0007207247640199729\tMax abs grad value: 0.020010927178481352\n",
      "Loss = 0.004924145873470304\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0007314094577102378\tMax abs grad value: 0.014964906097968285\n",
      "Loss = 0.0041118766160667675\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00056970503385035\tMax abs grad value: 0.01282636929053273\n",
      "Loss = 0.003493298045684973\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0003259564983793856\tMax abs grad value: 0.005716717158102571\n",
      "Loss = 0.0026157494763408805\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0003126351142040539\tMax abs grad value: 0.009054169189662797\n",
      "Loss = 0.0020472424105041297\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0003965393591709542\tMax abs grad value: 0.011248999723796433\n",
      "Loss = 0.0016941052733931634\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0003067500252953261\tMax abs grad value: 0.008784972215583208\n",
      "Loss = 0.0014383220595856434\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00023845358812042705\tMax abs grad value: 0.005936276405407771\n",
      "Loss = 0.001079287109200303\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.00021218234949921838\tMax abs grad value: 0.004935008538785208\n",
      "Loss = 0.0008287434305084738\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00028270393503748405\tMax abs grad value: 0.00682244375042752\n",
      "Loss = 0.0007139476939351636\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.00015308423390878362\tMax abs grad value: 0.0034405560816046696\n",
      "Loss = 0.0006124965190574864\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0001115568710718006\tMax abs grad value: 0.002139042631279143\n",
      "Loss = 0.0005599351296992608\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00011228373842510413\tMax abs grad value: 0.0019867542185934427\n",
      "Loss = 0.0005000144358022754\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00010110835099867711\tMax abs grad value: 0.0025284367432643843\n",
      "Loss = 0.00043525450369889725\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 8.194520992838106e-05\tMax abs grad value: 0.0022002733004923077\n",
      "Loss = 0.00032655814083891276\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.752349173154165e-05\tMax abs grad value: 0.0016819948547090768\n",
      "Loss = 0.00021917723131394107\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00016307711621033752\tMax abs grad value: 0.004052641736529378\n",
      "Loss = 0.0002252265660124504\n",
      "Mean abs grad value: 6.0825981534229756e-05\tMax abs grad value: 0.0013658373911989699\n",
      "Loss = 0.0001739849597463042\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.491615663956461e-05\tMax abs grad value: 0.0005868624386239042\n",
      "Loss = 0.00014278768132034374\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.464895648224991e-05\tMax abs grad value: 0.0005902928196451054\n",
      "Loss = 0.00012088709143364522\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.422548571750524e-05\tMax abs grad value: 0.0008300819288991434\n",
      "Loss = 0.0001030879516008712\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.5450145735547567e-05\tMax abs grad value: 0.0004737251254556494\n",
      "Loss = 8.461539673466644e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.5381312011649352e-05\tMax abs grad value: 0.00045732031360242543\n",
      "Loss = 7.25089435229945e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 9.672509601611103e-05\tMax abs grad value: 0.002517421752755819\n",
      "Loss = 8.497667034615302e-05\n",
      "Mean abs grad value: 2.7822847011813585e-05\tMax abs grad value: 0.000563700098958099\n",
      "Loss = 5.089936915302192e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 9.853740650393584e-06\tMax abs grad value: 0.00029266054357944955\n",
      "Loss = 3.0779845166971176e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 7.139328627324822e-06\tMax abs grad value: 0.00017887781965472344\n",
      "Loss = 2.614352196813938e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.9509347966934765e-06\tMax abs grad value: 9.471955957954058e-05\n",
      "Loss = 2.1282281261405913e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 5.425566155974095e-06\tMax abs grad value: 8.894314361052201e-05\n",
      "Loss = 1.6670935323094645e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.6540616420782136e-06\tMax abs grad value: 7.283324924073855e-05\n",
      "Loss = 1.1772921906818941e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.319556922195726e-06\tMax abs grad value: 0.00015153453551865285\n",
      "Loss = 7.1512887063033275e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.874941141167817e-06\tMax abs grad value: 9.944217223184768e-05\n",
      "Loss = 5.18161216268405e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.1447708307360827e-06\tMax abs grad value: 4.568471303954989e-05\n",
      "Loss = 4.241863156956182e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.497672670285739e-06\tMax abs grad value: 2.2813817871253663e-05\n",
      "Loss = 3.356106045338904e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.3561113121304168e-06\tMax abs grad value: 3.071155833665745e-05\n",
      "Loss = 2.5104213048804775e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.2117060827159038e-06\tMax abs grad value: 3.437887001391719e-05\n",
      "Loss = 1.5778388819845276e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.593999837650017e-07\tMax abs grad value: 1.7185526302964042e-05\n",
      "Loss = 1.0585364362765746e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.918116001088676e-07\tMax abs grad value: 1.1664006509218573e-05\n",
      "Loss = 7.77292576110187e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.850059585492837e-07\tMax abs grad value: 7.582231462412439e-06\n",
      "Loss = 4.801863275890639e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.050596463872147085\tMax abs grad value: 1.4544924209747319\n",
      "Loss = 2.947493704117092\n",
      "Mean abs grad value: 0.011913209097980614\tMax abs grad value: 0.32614127187583286\n",
      "Loss = 2.329102453564599\n",
      "Train accuracy: 0.098\t\tTest accuracy: 0.122\n",
      "Mean abs grad value: 0.010165921867463696\tMax abs grad value: 0.27926058572627926\n",
      "Loss = 2.107636441475548\n",
      "Train accuracy: 0.324\t\tTest accuracy: 0.322\n",
      "Mean abs grad value: 0.011650190968756646\tMax abs grad value: 0.28037221475119284\n",
      "Loss = 1.8801236967262358\n",
      "Train accuracy: 0.427\t\tTest accuracy: 0.427\n",
      "Mean abs grad value: 0.016888454817139322\tMax abs grad value: 0.4361037112671903\n",
      "Loss = 1.5946682465272128\n",
      "Train accuracy: 0.498\t\tTest accuracy: 0.451\n",
      "Mean abs grad value: 0.020671791414834877\tMax abs grad value: 0.45007615655032157\n",
      "Loss = 1.3233385991481506\n",
      "Train accuracy: 0.599\t\tTest accuracy: 0.578\n",
      "Mean abs grad value: 0.02279343757916318\tMax abs grad value: 0.5317580837382737\n",
      "Loss = 1.1018623822437381\n",
      "Train accuracy: 0.662\t\tTest accuracy: 0.660\n",
      "Mean abs grad value: 0.015161328324604909\tMax abs grad value: 0.4203561055014446\n",
      "Loss = 0.9185637594374542\n",
      "Train accuracy: 0.706\t\tTest accuracy: 0.687\n",
      "Mean abs grad value: 0.010858468602565103\tMax abs grad value: 0.26947372095614525\n",
      "Loss = 0.7048415614621134\n",
      "Train accuracy: 0.732\t\tTest accuracy: 0.722\n",
      "Mean abs grad value: 0.019260696946257316\tMax abs grad value: 0.8868485559662079\n",
      "Loss = 0.6348298639720684\n",
      "Train accuracy: 0.764\t\tTest accuracy: 0.751\n",
      "Mean abs grad value: 0.008803998317058258\tMax abs grad value: 0.2326422908863498\n",
      "Loss = 0.52478856554839\n",
      "Train accuracy: 0.809\t\tTest accuracy: 0.802\n",
      "Mean abs grad value: 0.00609341187559388\tMax abs grad value: 0.13190297169327841\n",
      "Loss = 0.4842904015012006\n",
      "Train accuracy: 0.829\t\tTest accuracy: 0.827\n",
      "Mean abs grad value: 0.00655742658784248\tMax abs grad value: 0.11816262641526819\n",
      "Loss = 0.4243642177539577\n",
      "Train accuracy: 0.860\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.009220429181980922\tMax abs grad value: 0.5330388660335967\n",
      "Loss = 0.3545317890957969\n",
      "Train accuracy: 0.870\t\tTest accuracy: 0.878\n",
      "Mean abs grad value: 0.00888084923348591\tMax abs grad value: 0.41063650679717034\n",
      "Loss = 0.29762612935991206\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.004398230369266614\tMax abs grad value: 0.13837491079728345\n",
      "Loss = 0.26686574221826315\n",
      "Train accuracy: 0.915\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.004119746650963645\tMax abs grad value: 0.12733893720771788\n",
      "Loss = 0.2480293185322113\n",
      "Train accuracy: 0.922\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.004395519226651406\tMax abs grad value: 0.14931733931009233\n",
      "Loss = 0.2261219496512643\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.005701867909559204\tMax abs grad value: 0.168334055825087\n",
      "Loss = 0.19018617275206104\n",
      "Train accuracy: 0.935\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.009195575903636424\tMax abs grad value: 0.29097846170263886\n",
      "Loss = 0.17528113082085703\n",
      "Train accuracy: 0.942\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.003166222732637764\tMax abs grad value: 0.06564345384566797\n",
      "Loss = 0.14826769586381217\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002828323071065976\tMax abs grad value: 0.05049240151559511\n",
      "Loss = 0.13813387052731435\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002991551149766062\tMax abs grad value: 0.06222376077410745\n",
      "Loss = 0.11949451742132208\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0036470276271416083\tMax abs grad value: 0.10733913109898614\n",
      "Loss = 0.10588631031020684\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0031159407470558995\tMax abs grad value: 0.07633181624738304\n",
      "Loss = 0.09250761387032133\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0023165135047029427\tMax abs grad value: 0.050897703178647266\n",
      "Loss = 0.08413250267019197\n",
      "Train accuracy: 0.971\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.002757992878817447\tMax abs grad value: 0.05680840678580244\n",
      "Loss = 0.06990563965013964\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002938357190583383\tMax abs grad value: 0.06294374117059355\n",
      "Loss = 0.05978292682938692\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.003154352612956084\tMax abs grad value: 0.1326714555069585\n",
      "Loss = 0.04279542196765819\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.004716011463790684\tMax abs grad value: 0.12748161735131835\n",
      "Loss = 0.04050168547441485\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0016835150334604942\tMax abs grad value: 0.038385400101126524\n",
      "Loss = 0.03304520074476091\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0012003811094810247\tMax abs grad value: 0.02432194084364773\n",
      "Loss = 0.031065510090659262\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0013977994776558059\tMax abs grad value: 0.033245273426197805\n",
      "Loss = 0.027103251378752843\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0014293023283965599\tMax abs grad value: 0.03356263906179863\n",
      "Loss = 0.022677842345307026\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.002617951817013196\tMax abs grad value: 0.0703084040480554\n",
      "Loss = 0.020288164505664456\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001129284259976523\tMax abs grad value: 0.02541696045160423\n",
      "Loss = 0.015968078007035494\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0008033647084740769\tMax abs grad value: 0.014443759262698223\n",
      "Loss = 0.014109068346759316\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0009743209588907553\tMax abs grad value: 0.019062206106706094\n",
      "Loss = 0.012000918943164818\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0014689444093106668\tMax abs grad value: 0.05626600896542277\n",
      "Loss = 0.009785372694683813\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0008214014178402418\tMax abs grad value: 0.019968476531918543\n",
      "Loss = 0.007798614584204543\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0005638695136112719\tMax abs grad value: 0.011807393739019194\n",
      "Loss = 0.006321701682971622\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0004465815766547095\tMax abs grad value: 0.011542542349520166\n",
      "Loss = 0.004924892684211982\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0003730625685451707\tMax abs grad value: 0.007946898117500701\n",
      "Loss = 0.0038772617903680222\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0009896272587515253\tMax abs grad value: 0.031534594919038664\n",
      "Loss = 0.003424104824195065\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00030259940781346157\tMax abs grad value: 0.008887594082541599\n",
      "Loss = 0.0020281077441625145\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0001894652377523401\tMax abs grad value: 0.00544881943568414\n",
      "Loss = 0.0017285491175034987\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00015870839399665596\tMax abs grad value: 0.0031218406441604427\n",
      "Loss = 0.001323387094404749\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0001355570189442083\tMax abs grad value: 0.004055601363387086\n",
      "Loss = 0.0009418302119187038\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00041513516202799287\tMax abs grad value: 0.01785534939430608\n",
      "Loss = 0.0009350351646622256\n",
      "Mean abs grad value: 0.00018569927550375116\tMax abs grad value: 0.007322899747538302\n",
      "Loss = 0.0008003199794610467\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00010295489656793673\tMax abs grad value: 0.003160409759909749\n",
      "Loss = 0.0005984004771855167\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 7.334588355896676e-05\tMax abs grad value: 0.0015179605775324143\n",
      "Loss = 0.00042612153010825277\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00010481318889790822\tMax abs grad value: 0.0034819684342707567\n",
      "Loss = 0.0003081781099224102\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 4.6868175139699915e-05\tMax abs grad value: 0.0011489404878088554\n",
      "Loss = 0.00020530172346619886\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 3.673647795797501e-05\tMax abs grad value: 0.001040585009387581\n",
      "Loss = 0.00014402301058618212\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.9774835153607868e-05\tMax abs grad value: 0.00043180026535590086\n",
      "Loss = 7.696075611631815e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.1892959656732497e-05\tMax abs grad value: 0.00030178615349990854\n",
      "Loss = 4.539215569948081e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 7.717621522449608e-06\tMax abs grad value: 0.00011829640991332914\n",
      "Loss = 3.141186823344426e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 4.795474995027986e-06\tMax abs grad value: 8.82811048936307e-05\n",
      "Loss = 2.179729832925152e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 4.517106216276008e-06\tMax abs grad value: 9.448556820993791e-05\n",
      "Loss = 1.3830903637594144e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 2.0127715000054384e-06\tMax abs grad value: 6.134729349724546e-05\n",
      "Loss = 8.342192535516566e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 1.4918956971409476e-06\tMax abs grad value: 3.280391720085245e-05\n",
      "Loss = 6.427011447953299e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 1.5571700723920284e-06\tMax abs grad value: 4.2717046443807456e-05\n",
      "Loss = 4.043166747481424e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 5.728699320957371e-07\tMax abs grad value: 1.2600015689506685e-05\n",
      "Loss = 1.875152250606149e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 4.24043204085748e-07\tMax abs grad value: 8.125956287250946e-06\n",
      "Loss = 1.3149982203793363e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.03825841800946427\tMax abs grad value: 0.9360920715771042\n",
      "Loss = 2.850511989475178\n",
      "Mean abs grad value: 0.02769082935560456\tMax abs grad value: 0.6447923860254506\n",
      "Loss = 2.4440695270864214\n",
      "Train accuracy: 0.209\t\tTest accuracy: 0.187\n",
      "Mean abs grad value: 0.009391962363635122\tMax abs grad value: 0.35153639571850354\n",
      "Loss = 2.2208437481560357\n",
      "Train accuracy: 0.205\t\tTest accuracy: 0.171\n",
      "Mean abs grad value: 0.006713258086574796\tMax abs grad value: 0.30177614147591686\n",
      "Loss = 2.1677042028433258\n",
      "Train accuracy: 0.251\t\tTest accuracy: 0.216\n",
      "Mean abs grad value: 0.006009326880007239\tMax abs grad value: 0.26244751840842273\n",
      "Loss = 2.1166700993280343\n",
      "Train accuracy: 0.267\t\tTest accuracy: 0.236\n",
      "Mean abs grad value: 0.0382910094071161\tMax abs grad value: 1.9322934292680574\n",
      "Loss = 2.453690281328404\n",
      "Mean abs grad value: 0.007535502943552661\tMax abs grad value: 0.2277636286238843\n",
      "Loss = 2.0043946673148128\n",
      "Train accuracy: 0.273\t\tTest accuracy: 0.231\n",
      "Mean abs grad value: 0.008887269591671213\tMax abs grad value: 0.23152813426337923\n",
      "Loss = 1.8970608122621617\n",
      "Train accuracy: 0.291\t\tTest accuracy: 0.267\n",
      "Mean abs grad value: 0.07687213476512145\tMax abs grad value: 3.355621355309773\n",
      "Loss = 2.863281992603445\n",
      "Mean abs grad value: 0.020638032973290546\tMax abs grad value: 1.0900860865663096\n",
      "Loss = 1.6090059930528735\n",
      "Train accuracy: 0.418\t\tTest accuracy: 0.407\n",
      "Mean abs grad value: 0.018974819532888126\tMax abs grad value: 0.7714246492686542\n",
      "Loss = 1.3163907737547553\n",
      "Train accuracy: 0.566\t\tTest accuracy: 0.562\n",
      "Mean abs grad value: 0.026418488974630037\tMax abs grad value: 0.6866767285805369\n",
      "Loss = 1.1554776412321377\n",
      "Train accuracy: 0.585\t\tTest accuracy: 0.562\n",
      "Mean abs grad value: 0.013425283927668523\tMax abs grad value: 0.47001505487520606\n",
      "Loss = 0.9603593531724046\n",
      "Train accuracy: 0.713\t\tTest accuracy: 0.671\n",
      "Mean abs grad value: 0.01037807990224955\tMax abs grad value: 0.4968961419075438\n",
      "Loss = 0.7897740158415743\n",
      "Train accuracy: 0.764\t\tTest accuracy: 0.751\n",
      "Mean abs grad value: 0.016424878215169542\tMax abs grad value: 1.1382025638688043\n",
      "Loss = 0.7210619587850854\n",
      "Train accuracy: 0.774\t\tTest accuracy: 0.776\n",
      "Mean abs grad value: 0.00908768436728695\tMax abs grad value: 0.2468287164899015\n",
      "Loss = 0.6191805304460105\n",
      "Train accuracy: 0.806\t\tTest accuracy: 0.800\n",
      "Mean abs grad value: 0.009178464911225483\tMax abs grad value: 0.36347763373524156\n",
      "Loss = 0.5552888305776348\n",
      "Train accuracy: 0.840\t\tTest accuracy: 0.816\n",
      "Mean abs grad value: 0.008395454383162155\tMax abs grad value: 0.28314152006785837\n",
      "Loss = 0.49166143152354236\n",
      "Train accuracy: 0.854\t\tTest accuracy: 0.824\n",
      "Mean abs grad value: 0.008583567379253814\tMax abs grad value: 0.22748799578696013\n",
      "Loss = 0.40773871775023035\n",
      "Train accuracy: 0.863\t\tTest accuracy: 0.856\n",
      "Mean abs grad value: 0.008978234919444418\tMax abs grad value: 0.2889417284261946\n",
      "Loss = 0.3628679303997825\n",
      "Train accuracy: 0.883\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.005703121177361097\tMax abs grad value: 0.1354176843534414\n",
      "Loss = 0.3283418525293114\n",
      "Train accuracy: 0.897\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.007804885351802772\tMax abs grad value: 0.19956325100690517\n",
      "Loss = 0.29565307085544223\n",
      "Train accuracy: 0.906\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.006573631738101252\tMax abs grad value: 0.1736496804390682\n",
      "Loss = 0.26710479766026424\n",
      "Train accuracy: 0.915\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.008788023473297758\tMax abs grad value: 0.4344978177217408\n",
      "Loss = 0.2272006737992189\n",
      "Train accuracy: 0.930\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.005382876489764886\tMax abs grad value: 0.1379350246852956\n",
      "Loss = 0.20011549633761894\n",
      "Train accuracy: 0.939\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.0039763058855061964\tMax abs grad value: 0.06832090815067564\n",
      "Loss = 0.18720407629530017\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0031981824945857946\tMax abs grad value: 0.06221010819804595\n",
      "Loss = 0.16965545915050204\n",
      "Train accuracy: 0.950\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0038148902844127993\tMax abs grad value: 0.08041465611625241\n",
      "Loss = 0.14599492946466827\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.006324469384218664\tMax abs grad value: 0.15961984914522093\n",
      "Loss = 0.12181357620593271\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.004050512900687262\tMax abs grad value: 0.07471236197749531\n",
      "Loss = 0.1061770300695316\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.002469160314506967\tMax abs grad value: 0.06426164039607363\n",
      "Loss = 0.09821749290727869\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0022477427589957908\tMax abs grad value: 0.04926584604263289\n",
      "Loss = 0.08938318421511217\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0024070530379635873\tMax abs grad value: 0.054600724778210034\n",
      "Loss = 0.08206036782696413\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0036420529849344086\tMax abs grad value: 0.07353182081986527\n",
      "Loss = 0.06906802257276025\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.007024449273692771\tMax abs grad value: 0.25651674637765487\n",
      "Loss = 0.06911022368222479\n",
      "Mean abs grad value: 0.0035930882465206905\tMax abs grad value: 0.10620129628463987\n",
      "Loss = 0.06272439520328993\n",
      "Train accuracy: 0.980\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0023140154365297243\tMax abs grad value: 0.047818466881221176\n",
      "Loss = 0.053953504784785805\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0015180333251889303\tMax abs grad value: 0.02235489855673997\n",
      "Loss = 0.045518644038192946\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0022865247969939464\tMax abs grad value: 0.04428327487280723\n",
      "Loss = 0.04083786930775225\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.001474089564637348\tMax abs grad value: 0.026318316920445745\n",
      "Loss = 0.0356788143550517\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001555964939527659\tMax abs grad value: 0.02625209266723762\n",
      "Loss = 0.0275157568856515\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0015317364374164042\tMax abs grad value: 0.02563712038442265\n",
      "Loss = 0.022104833470263964\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0012518948935845238\tMax abs grad value: 0.02699597037914762\n",
      "Loss = 0.017698429849977146\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0010162000309993406\tMax abs grad value: 0.021116301493542818\n",
      "Loss = 0.015006628189225891\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0019435462902488176\tMax abs grad value: 0.06699295775511145\n",
      "Loss = 0.013123226686076218\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0010585380991860478\tMax abs grad value: 0.021558754548271237\n",
      "Loss = 0.011684724034186066\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0009829363583028219\tMax abs grad value: 0.01425901424463518\n",
      "Loss = 0.010722550115417112\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.000937570286643179\tMax abs grad value: 0.016176132217335586\n",
      "Loss = 0.008845398536599184\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0008171657667285843\tMax abs grad value: 0.016212699412150807\n",
      "Loss = 0.007047287595399154\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002691529946409884\tMax abs grad value: 0.08639921860967098\n",
      "Loss = 0.007877885292668455\n",
      "Mean abs grad value: 0.001004779763991036\tMax abs grad value: 0.0267878251800724\n",
      "Loss = 0.005875585945738776\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0005180495854789271\tMax abs grad value: 0.011501837842752884\n",
      "Loss = 0.004695213382554259\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00043176706147084166\tMax abs grad value: 0.009100325464173466\n",
      "Loss = 0.0038899307701734534\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0005313537793383957\tMax abs grad value: 0.01634600848968184\n",
      "Loss = 0.0030385654382888414\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00030915262331648744\tMax abs grad value: 0.005359791354923714\n",
      "Loss = 0.002453300643190352\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00023952301313798772\tMax abs grad value: 0.004694857341681953\n",
      "Loss = 0.0020388760405857325\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00027154976156444925\tMax abs grad value: 0.006353671379350011\n",
      "Loss = 0.001443405457411148\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00019085649724532403\tMax abs grad value: 0.005372859447104358\n",
      "Loss = 0.0010062046728049855\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0001399404351498192\tMax abs grad value: 0.002764422185443939\n",
      "Loss = 0.0007882618904439694\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00014886532220277242\tMax abs grad value: 0.0034108340117640704\n",
      "Loss = 0.000501826200485031\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 7.13361741833667e-05\tMax abs grad value: 0.0010544163069573743\n",
      "Loss = 0.00034898841898382555\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 5.13637471719131e-05\tMax abs grad value: 0.0008024684115704713\n",
      "Loss = 0.0002790454594651421\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 7.629852917443045e-05\tMax abs grad value: 0.0020679320880183055\n",
      "Loss = 0.00020319396817760886\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 3.6370019789600106e-05\tMax abs grad value: 0.0008318079431069855\n",
      "Loss = 0.0001341923203591069\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 3.146363190418164e-05\tMax abs grad value: 0.0005684982933388668\n",
      "Loss = 0.00010741781253297308\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 1.6017858549634594e-05\tMax abs grad value: 0.0003319656607727792\n",
      "Loss = 6.161575882770308e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 2.3443935215263273e-05\tMax abs grad value: 0.0005354182787659199\n",
      "Loss = 4.033150462232251e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 6.731188709330522e-06\tMax abs grad value: 0.00010645287130780096\n",
      "Loss = 2.0301745081211997e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 5.488455062652808e-06\tMax abs grad value: 8.709197077786292e-05\n",
      "Loss = 1.7013325315037818e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.1361091805718366e-06\tMax abs grad value: 3.6895525387997524e-05\n",
      "Loss = 8.587336903494227e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.575383771326671e-06\tMax abs grad value: 2.695515954099729e-05\n",
      "Loss = 5.143876580515338e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 3.196936490349479e-06\tMax abs grad value: 8.590457499919051e-05\n",
      "Loss = 3.857215390999847e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 8.912269592341847e-07\tMax abs grad value: 1.860822191199225e-05\n",
      "Loss = 2.046991050864364e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 6.267995934516287e-07\tMax abs grad value: 1.1005804213220251e-05\n",
      "Loss = 1.59892521354617e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 4.4807914240234196e-07\tMax abs grad value: 8.175642351352648e-06\n",
      "Loss = 1.0390946600441004e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.03655515746745551\tMax abs grad value: 0.880496526391451\n",
      "Loss = 2.526674748420958\n",
      "Mean abs grad value: 0.10173321361482038\tMax abs grad value: 6.235291010011134\n",
      "Loss = 4.834598417742811\n",
      "Mean abs grad value: 0.02929216479372683\tMax abs grad value: 1.004744107840712\n",
      "Loss = 2.2604592504918544\n",
      "Train accuracy: 0.160\t\tTest accuracy: 0.144\n",
      "Mean abs grad value: 0.017151822899670842\tMax abs grad value: 0.3277904008678568\n",
      "Loss = 2.0715668422775457\n",
      "Train accuracy: 0.314\t\tTest accuracy: 0.271\n",
      "Mean abs grad value: 0.01628739057434212\tMax abs grad value: 0.2929280524320191\n",
      "Loss = 1.9546833305968836\n",
      "Train accuracy: 0.365\t\tTest accuracy: 0.340\n",
      "Mean abs grad value: 0.017728143104209306\tMax abs grad value: 0.29330324169523425\n",
      "Loss = 1.6747028828045307\n",
      "Train accuracy: 0.523\t\tTest accuracy: 0.491\n",
      "Mean abs grad value: 0.01851374062373308\tMax abs grad value: 0.3684765850607551\n",
      "Loss = 1.3238699291552987\n",
      "Train accuracy: 0.602\t\tTest accuracy: 0.584\n",
      "Mean abs grad value: 0.018350926258996453\tMax abs grad value: 0.48331072590392654\n",
      "Loss = 0.9704078738419747\n",
      "Train accuracy: 0.698\t\tTest accuracy: 0.660\n",
      "Mean abs grad value: 0.015548442808411613\tMax abs grad value: 0.4675069206588278\n",
      "Loss = 0.7925334728540651\n",
      "Train accuracy: 0.773\t\tTest accuracy: 0.738\n",
      "Mean abs grad value: 0.013307584321620235\tMax abs grad value: 0.284124753084579\n",
      "Loss = 0.6560392710177793\n",
      "Train accuracy: 0.805\t\tTest accuracy: 0.762\n",
      "Mean abs grad value: 0.016162888655372427\tMax abs grad value: 1.3021638642361324\n",
      "Loss = 0.5860979631779528\n",
      "Train accuracy: 0.795\t\tTest accuracy: 0.778\n",
      "Mean abs grad value: 0.009484077615020152\tMax abs grad value: 0.15261292266316154\n",
      "Loss = 0.5113089862535398\n",
      "Train accuracy: 0.834\t\tTest accuracy: 0.824\n",
      "Mean abs grad value: 0.007392370888495565\tMax abs grad value: 0.1591455408087366\n",
      "Loss = 0.4753357938145295\n",
      "Train accuracy: 0.850\t\tTest accuracy: 0.838\n",
      "Mean abs grad value: 0.009401830750948616\tMax abs grad value: 0.2984634578928575\n",
      "Loss = 0.3939656429498108\n",
      "Train accuracy: 0.875\t\tTest accuracy: 0.851\n",
      "Mean abs grad value: 0.010130607364093776\tMax abs grad value: 0.29893789323131015\n",
      "Loss = 0.34928043731537783\n",
      "Train accuracy: 0.895\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.005233154466473783\tMax abs grad value: 0.10032477547063465\n",
      "Loss = 0.3169997012241365\n",
      "Train accuracy: 0.901\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.005657184284970714\tMax abs grad value: 0.08389729145164007\n",
      "Loss = 0.29477872956679146\n",
      "Train accuracy: 0.909\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.00690306182649509\tMax abs grad value: 0.1465096063107644\n",
      "Loss = 0.26944342462178167\n",
      "Train accuracy: 0.914\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.008919086675881158\tMax abs grad value: 0.215027461614882\n",
      "Loss = 0.24503618405871477\n",
      "Train accuracy: 0.924\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.004695313350865322\tMax abs grad value: 0.06063458451569833\n",
      "Loss = 0.2224870907912926\n",
      "Train accuracy: 0.932\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.005093341773728396\tMax abs grad value: 0.10268495119006282\n",
      "Loss = 0.20549711707033994\n",
      "Train accuracy: 0.935\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.005204534766507418\tMax abs grad value: 0.13275213091753973\n",
      "Loss = 0.1821241803154572\n",
      "Train accuracy: 0.945\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.00641548487415213\tMax abs grad value: 0.11358626227694431\n",
      "Loss = 0.15337155846999775\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.006649058019478286\tMax abs grad value: 0.11764812773601951\n",
      "Loss = 0.13691682149895343\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.004272193986451259\tMax abs grad value: 0.14025924676363516\n",
      "Loss = 0.12733237504516692\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0036252728474852973\tMax abs grad value: 0.07711130674076914\n",
      "Loss = 0.12170649768530493\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0039609639760086485\tMax abs grad value: 0.1429321509719209\n",
      "Loss = 0.11300093898104752\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.004342021154243435\tMax abs grad value: 0.1258360284563559\n",
      "Loss = 0.10121376510390794\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.006396121296342604\tMax abs grad value: 0.11742276514793286\n",
      "Loss = 0.09115362743206679\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.003607156639892745\tMax abs grad value: 0.08379125706479607\n",
      "Loss = 0.07718033836346329\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.002754001533436044\tMax abs grad value: 0.040524191355113794\n",
      "Loss = 0.06858227739354977\n",
      "Train accuracy: 0.980\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0032921803131537833\tMax abs grad value: 0.05255824884298561\n",
      "Loss = 0.06342339662960149\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0030381534667141647\tMax abs grad value: 0.06460344392708607\n",
      "Loss = 0.057396466776950594\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0024413465002436478\tMax abs grad value: 0.03323549637821086\n",
      "Loss = 0.04982472511195755\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0021620971897625975\tMax abs grad value: 0.03421610466769943\n",
      "Loss = 0.04384628416953346\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.003673142247433193\tMax abs grad value: 0.0717427849860577\n",
      "Loss = 0.037035059428317425\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002849254498012321\tMax abs grad value: 0.051325774335825185\n",
      "Loss = 0.031079010219218717\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0025479499647317635\tMax abs grad value: 0.04600600330815686\n",
      "Loss = 0.025342770512617633\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0032574225121150126\tMax abs grad value: 0.13304468980066933\n",
      "Loss = 0.019364715872934164\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.002430697951548708\tMax abs grad value: 0.05467985642945819\n",
      "Loss = 0.017332343036047835\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0012446704661595658\tMax abs grad value: 0.020142856877144504\n",
      "Loss = 0.016240263746570515\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0011534752121287683\tMax abs grad value: 0.01292668539306752\n",
      "Loss = 0.015542538846312053\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0015687111669557294\tMax abs grad value: 0.034210844218384495\n",
      "Loss = 0.01417944235487092\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.001546273688606341\tMax abs grad value: 0.037607459307013376\n",
      "Loss = 0.012065729445926987\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0037540599845114412\tMax abs grad value: 0.06403210411539664\n",
      "Loss = 0.010273448848110992\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0011402437051324485\tMax abs grad value: 0.014823296963753514\n",
      "Loss = 0.006887986075734691\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0008012232270128216\tMax abs grad value: 0.008520625389211002\n",
      "Loss = 0.005832716402808366\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0006947352794874535\tMax abs grad value: 0.010791911950362951\n",
      "Loss = 0.0044996464026013224\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0006792031888537615\tMax abs grad value: 0.016638171425791354\n",
      "Loss = 0.0031643592134588767\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0019383056826777637\tMax abs grad value: 0.03929649239845715\n",
      "Loss = 0.003557867025271698\n",
      "Mean abs grad value: 0.0006829743171554621\tMax abs grad value: 0.01797436106755211\n",
      "Loss = 0.00270751866647269\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0004686962680268781\tMax abs grad value: 0.010117138318738169\n",
      "Loss = 0.0023586144857808944\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0003630848208821869\tMax abs grad value: 0.0070037960275226826\n",
      "Loss = 0.002059769466988641\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00030292499875674245\tMax abs grad value: 0.004962984554293925\n",
      "Loss = 0.001779826647541131\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0002807301227900023\tMax abs grad value: 0.004819941125037078\n",
      "Loss = 0.0015721245573419881\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0002927938837773373\tMax abs grad value: 0.005304406819693061\n",
      "Loss = 0.0014020699855899622\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0003890510434678141\tMax abs grad value: 0.008429319776055192\n",
      "Loss = 0.0011249768099280619\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00019188322794738976\tMax abs grad value: 0.0036654936866050134\n",
      "Loss = 0.0009097736844550023\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0001489728681319384\tMax abs grad value: 0.0032911085331883997\n",
      "Loss = 0.0007848587499405099\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00012032096161240375\tMax abs grad value: 0.0027950604576229823\n",
      "Loss = 0.000653808361394264\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00042512143403149487\tMax abs grad value: 0.012154897472064812\n",
      "Loss = 0.0006118624090238589\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00015379194624843192\tMax abs grad value: 0.003243364099693665\n",
      "Loss = 0.0004145782743447579\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00010303131145536064\tMax abs grad value: 0.0018871028228419834\n",
      "Loss = 0.0003586539100782364\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 6.702222912751188e-05\tMax abs grad value: 0.0011487163488749278\n",
      "Loss = 0.0002999504645622786\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 6.312994586516456e-05\tMax abs grad value: 0.0011101609450254015\n",
      "Loss = 0.00025029227988951146\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 7.19953717927527e-05\tMax abs grad value: 0.0015414358861742436\n",
      "Loss = 0.00018181056993941667\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 9.836939417318952e-05\tMax abs grad value: 0.002416363469445493\n",
      "Loss = 0.0001330700282734165\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 4.663894675353127e-05\tMax abs grad value: 0.0008058928346635048\n",
      "Loss = 9.058780123138822e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.044879589439418e-05\tMax abs grad value: 0.0007284668971497473\n",
      "Loss = 7.368333913066882e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.8938999741982617e-05\tMax abs grad value: 0.00029863347837481\n",
      "Loss = 5.6766585417101024e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.2930908686885753e-05\tMax abs grad value: 0.00039149411065827637\n",
      "Loss = 4.186720631419375e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.3871089782664769e-05\tMax abs grad value: 0.00036205266842372866\n",
      "Loss = 2.867652132456042e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 8.351831023222862e-06\tMax abs grad value: 0.00012868146517512822\n",
      "Loss = 2.119581047029312e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 7.493821027353023e-06\tMax abs grad value: 0.00013311482799129257\n",
      "Loss = 1.5921072315749765e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 5.354880984628896e-06\tMax abs grad value: 0.00011947131219963703\n",
      "Loss = 1.0106766489451173e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 2.89029410181637e-06\tMax abs grad value: 7.081443476717211e-05\n",
      "Loss = 6.164552495737272e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.5760317189695966e-06\tMax abs grad value: 3.4928916734428286e-05\n",
      "Loss = 3.5612123336569914e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.6133993024937134e-06\tMax abs grad value: 3.929453808167006e-05\n",
      "Loss = 2.042061069476132e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 6.804800756164923e-07\tMax abs grad value: 1.4541664964631305e-05\n",
      "Loss = 1.078189201804868e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 4.2475178948026294e-07\tMax abs grad value: 9.341469434529127e-06\n",
      "Loss = 8.651998382314415e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.04235217489582984\tMax abs grad value: 1.1003571693418703\n",
      "Loss = 2.597048527444421\n",
      "Mean abs grad value: 0.03726981606699915\tMax abs grad value: 1.4129422952432829\n",
      "Loss = 2.8052232806571644\n",
      "Mean abs grad value: 0.023450372876647675\tMax abs grad value: 0.3889300980570021\n",
      "Loss = 2.275416424118469\n",
      "Train accuracy: 0.186\t\tTest accuracy: 0.176\n",
      "Mean abs grad value: 0.017278178248190345\tMax abs grad value: 0.22830028203926084\n",
      "Loss = 2.05366057277687\n",
      "Train accuracy: 0.291\t\tTest accuracy: 0.296\n",
      "Mean abs grad value: 0.02348846074865235\tMax abs grad value: 0.5069544858180282\n",
      "Loss = 1.7711514508200987\n",
      "Train accuracy: 0.364\t\tTest accuracy: 0.353\n",
      "Mean abs grad value: 0.01685722004334987\tMax abs grad value: 0.23660486958733778\n",
      "Loss = 1.4827018372785308\n",
      "Train accuracy: 0.544\t\tTest accuracy: 0.533\n",
      "Mean abs grad value: 0.0276336455688978\tMax abs grad value: 0.8449566771485388\n",
      "Loss = 1.23573885112811\n",
      "Train accuracy: 0.540\t\tTest accuracy: 0.498\n",
      "Mean abs grad value: 0.017159741590002137\tMax abs grad value: 0.28254683165086053\n",
      "Loss = 0.991207041213401\n",
      "Train accuracy: 0.674\t\tTest accuracy: 0.620\n",
      "Mean abs grad value: 0.014286562098108146\tMax abs grad value: 0.28820207155934413\n",
      "Loss = 0.7940183576520329\n",
      "Train accuracy: 0.777\t\tTest accuracy: 0.727\n",
      "Mean abs grad value: 0.01647692900598999\tMax abs grad value: 0.46834801397989895\n",
      "Loss = 0.5894836093683806\n",
      "Train accuracy: 0.831\t\tTest accuracy: 0.802\n",
      "Mean abs grad value: 0.01580964069954824\tMax abs grad value: 0.3423066743837562\n",
      "Loss = 0.4930795347024077\n",
      "Train accuracy: 0.856\t\tTest accuracy: 0.820\n",
      "Mean abs grad value: 0.008730522911862302\tMax abs grad value: 0.22798729472652987\n",
      "Loss = 0.42788817443899296\n",
      "Train accuracy: 0.881\t\tTest accuracy: 0.856\n",
      "Mean abs grad value: 0.006615445400082393\tMax abs grad value: 0.1146014758649352\n",
      "Loss = 0.38061619409425523\n",
      "Train accuracy: 0.892\t\tTest accuracy: 0.873\n",
      "Mean abs grad value: 0.007424370609682201\tMax abs grad value: 0.13337240237197745\n",
      "Loss = 0.34459593227538826\n",
      "Train accuracy: 0.903\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.012689777823223017\tMax abs grad value: 0.48768652216258057\n",
      "Loss = 0.29491014789004855\n",
      "Train accuracy: 0.913\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.005629843593017317\tMax abs grad value: 0.09944344037393493\n",
      "Loss = 0.23401149966008264\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.004261827954914176\tMax abs grad value: 0.08769045782328078\n",
      "Loss = 0.21576143085694835\n",
      "Train accuracy: 0.942\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0036214680151897593\tMax abs grad value: 0.08398155425843719\n",
      "Loss = 0.19589682085470667\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.003511196230297724\tMax abs grad value: 0.06229263357009178\n",
      "Loss = 0.177972740248308\n",
      "Train accuracy: 0.948\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.005684051307808996\tMax abs grad value: 0.09848174370492863\n",
      "Loss = 0.15434052771991813\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.004164005421646949\tMax abs grad value: 0.11920175802281176\n",
      "Loss = 0.1344743033793647\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0031933842553911085\tMax abs grad value: 0.057917954509949555\n",
      "Loss = 0.12174861899239255\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.003253230547013096\tMax abs grad value: 0.0646436389654623\n",
      "Loss = 0.10909556275667583\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.004547295037517967\tMax abs grad value: 0.09889292599400022\n",
      "Loss = 0.09208417877662456\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002938189274196101\tMax abs grad value: 0.046879226956066944\n",
      "Loss = 0.07547943253987364\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.002512910939579005\tMax abs grad value: 0.0424971174657449\n",
      "Loss = 0.06429908367995639\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0027240926378677274\tMax abs grad value: 0.04382411256681605\n",
      "Loss = 0.051022906353713704\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.004047661049366262\tMax abs grad value: 0.12069997130034693\n",
      "Loss = 0.04479570151192123\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.001813800445483396\tMax abs grad value: 0.031477832494806235\n",
      "Loss = 0.037366728014966905\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0014188003569727337\tMax abs grad value: 0.02183196177547568\n",
      "Loss = 0.0341092422862372\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0014909976323027642\tMax abs grad value: 0.029577034656743363\n",
      "Loss = 0.029557317012263003\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.003147263458584602\tMax abs grad value: 0.05663049728433494\n",
      "Loss = 0.02625543434642585\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0013654274374357786\tMax abs grad value: 0.025289149222715097\n",
      "Loss = 0.021454527049635227\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0010596103094762434\tMax abs grad value: 0.014348446253285229\n",
      "Loss = 0.017782104280303038\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0015440927627235017\tMax abs grad value: 0.028415412468832526\n",
      "Loss = 0.013716155053595138\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0037303541380775368\tMax abs grad value: 0.09600182336710485\n",
      "Loss = 0.013932843338073979\n",
      "Mean abs grad value: 0.0014744650338209216\tMax abs grad value: 0.029486445305940363\n",
      "Loss = 0.011596625533982281\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0009700209253706407\tMax abs grad value: 0.014993144683973893\n",
      "Loss = 0.009952190887351114\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0008366051284004907\tMax abs grad value: 0.013081432811960468\n",
      "Loss = 0.007988452025634415\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0009561508774481695\tMax abs grad value: 0.019292719217558048\n",
      "Loss = 0.005754606388233127\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0006015192024155495\tMax abs grad value: 0.009934125787305605\n",
      "Loss = 0.004417812464980955\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00039092215394197325\tMax abs grad value: 0.007209023195871551\n",
      "Loss = 0.00353595000399209\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0003248776368225943\tMax abs grad value: 0.0060224192001561636\n",
      "Loss = 0.0027322342327938264\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0004902539830222393\tMax abs grad value: 0.010875798917757811\n",
      "Loss = 0.0018600497611665659\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0003096665668530518\tMax abs grad value: 0.00499596534702923\n",
      "Loss = 0.001271028770915417\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.00019099186672605397\tMax abs grad value: 0.002584456568296514\n",
      "Loss = 0.0010737502700803386\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0001269160663393601\tMax abs grad value: 0.002068445965995971\n",
      "Loss = 0.0007415004398655118\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 8.35091636794843e-05\tMax abs grad value: 0.0012906114725022236\n",
      "Loss = 0.0005389072517103702\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00014349342746587573\tMax abs grad value: 0.003220079691124053\n",
      "Loss = 0.0003722537434270873\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 8.706646015437731e-05\tMax abs grad value: 0.0016080829370821806\n",
      "Loss = 0.0002472399322763608\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.342732032900421e-05\tMax abs grad value: 0.0007130613876682968\n",
      "Loss = 0.0001721482669156721\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.5574909426795734e-05\tMax abs grad value: 0.0003574144104167343\n",
      "Loss = 0.00011301819076604689\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.9550125082161125e-05\tMax abs grad value: 0.00032827858870502043\n",
      "Loss = 7.527912951911303e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.3208449150866255e-05\tMax abs grad value: 0.000508123879757073\n",
      "Loss = 4.612093382790194e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.4561864555403771e-05\tMax abs grad value: 0.0002810488583343682\n",
      "Loss = 2.9378124954570585e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 6.549482206526312e-06\tMax abs grad value: 0.0001063096561431535\n",
      "Loss = 2.125244980935608e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 4.7763468860731146e-06\tMax abs grad value: 9.085880976645876e-05\n",
      "Loss = 1.5228823555055647e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.3978354793315086e-06\tMax abs grad value: 6.604007820986813e-05\n",
      "Loss = 7.737085111228704e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.3036468709558685e-06\tMax abs grad value: 2.6537303930835096e-05\n",
      "Loss = 3.9097062127380386e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 9.219250838932672e-07\tMax abs grad value: 2.303912969300981e-05\n",
      "Loss = 2.233307129523006e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.3680465342913132e-06\tMax abs grad value: 4.7543700589240235e-05\n",
      "Loss = 1.7088288837635328e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.397022555372718e-07\tMax abs grad value: 1.0048692183129318e-05\n",
      "Loss = 6.482444930401661e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.6865825887888762e-07\tMax abs grad value: 3.359697995658892e-06\n",
      "Loss = 3.850259259603471e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.027310483498786363\tMax abs grad value: 0.5921736682104519\n",
      "Loss = 2.561668388857853\n",
      "Mean abs grad value: 0.04181445008277689\tMax abs grad value: 1.928968108803085\n",
      "Loss = 2.7191606702993605\n",
      "Mean abs grad value: 0.017686096780640054\tMax abs grad value: 0.4571696440123108\n",
      "Loss = 2.2881132780806954\n",
      "Train accuracy: 0.131\t\tTest accuracy: 0.142\n",
      "Mean abs grad value: 0.011840963120586667\tMax abs grad value: 0.1800401674026662\n",
      "Loss = 2.058191818871123\n",
      "Train accuracy: 0.318\t\tTest accuracy: 0.338\n",
      "Mean abs grad value: 0.014155684774651865\tMax abs grad value: 0.1981174384158639\n",
      "Loss = 1.8524659855081682\n",
      "Train accuracy: 0.382\t\tTest accuracy: 0.427\n",
      "Mean abs grad value: 0.0190545344827602\tMax abs grad value: 0.2628179145209129\n",
      "Loss = 1.5852722175003129\n",
      "Train accuracy: 0.421\t\tTest accuracy: 0.418\n",
      "Mean abs grad value: 0.034549741608200145\tMax abs grad value: 0.7510263561867567\n",
      "Loss = 1.2828323597494744\n",
      "Train accuracy: 0.549\t\tTest accuracy: 0.544\n",
      "Mean abs grad value: 0.025688734425065984\tMax abs grad value: 0.8161326516578425\n",
      "Loss = 0.9348111829366\n",
      "Train accuracy: 0.702\t\tTest accuracy: 0.640\n",
      "Mean abs grad value: 0.022437909644774625\tMax abs grad value: 0.6225127600915497\n",
      "Loss = 0.8159126541781179\n",
      "Train accuracy: 0.759\t\tTest accuracy: 0.729\n",
      "Mean abs grad value: 0.012861402750448545\tMax abs grad value: 0.22131177792257425\n",
      "Loss = 0.7467019087220044\n",
      "Train accuracy: 0.808\t\tTest accuracy: 0.760\n",
      "Mean abs grad value: 0.010717849129609703\tMax abs grad value: 0.3350558380130474\n",
      "Loss = 0.66115734030005\n",
      "Train accuracy: 0.819\t\tTest accuracy: 0.776\n",
      "Mean abs grad value: 0.022742610150226123\tMax abs grad value: 0.7908526668811577\n",
      "Loss = 0.5775698754731226\n",
      "Train accuracy: 0.817\t\tTest accuracy: 0.773\n",
      "Mean abs grad value: 0.009258749170682899\tMax abs grad value: 0.1913332682307991\n",
      "Loss = 0.4722181243711948\n",
      "Train accuracy: 0.870\t\tTest accuracy: 0.824\n",
      "Mean abs grad value: 0.007930107000627375\tMax abs grad value: 0.2366683574213382\n",
      "Loss = 0.4369323171544854\n",
      "Train accuracy: 0.891\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.007318342835138092\tMax abs grad value: 0.24002611601694537\n",
      "Loss = 0.3753918969467265\n",
      "Train accuracy: 0.906\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.01600040274449045\tMax abs grad value: 0.6891732697067854\n",
      "Loss = 0.3306477122793252\n",
      "Train accuracy: 0.893\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.007186819889865593\tMax abs grad value: 0.23110998598443985\n",
      "Loss = 0.27629720429697485\n",
      "Train accuracy: 0.918\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.004632393896492368\tMax abs grad value: 0.07703824648857255\n",
      "Loss = 0.2624586211757034\n",
      "Train accuracy: 0.921\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.004503725281237639\tMax abs grad value: 0.1301394487143026\n",
      "Loss = 0.2450187292354165\n",
      "Train accuracy: 0.930\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.004444065548910035\tMax abs grad value: 0.11939911435942135\n",
      "Loss = 0.22318463528514781\n",
      "Train accuracy: 0.935\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.004937975830877562\tMax abs grad value: 0.12349307335772161\n",
      "Loss = 0.17963583129023877\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.008699224227760847\tMax abs grad value: 0.22462132433115364\n",
      "Loss = 0.15980196373015979\n",
      "Train accuracy: 0.951\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0036984048160854936\tMax abs grad value: 0.06554775962550469\n",
      "Loss = 0.12997932980042026\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0027033175457653897\tMax abs grad value: 0.05705452493235891\n",
      "Loss = 0.11638360495685611\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.003841827243209645\tMax abs grad value: 0.0969156002138979\n",
      "Loss = 0.0984788561705688\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.005387182393722108\tMax abs grad value: 0.11862368299978651\n",
      "Loss = 0.090342675229125\n",
      "Train accuracy: 0.971\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.002501348398455832\tMax abs grad value: 0.04421548248182463\n",
      "Loss = 0.08052869056399645\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0018688401072310908\tMax abs grad value: 0.022196066684353494\n",
      "Loss = 0.07413815349235274\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0022278803772431003\tMax abs grad value: 0.041556973363500616\n",
      "Loss = 0.06541413644231511\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.006760277971210157\tMax abs grad value: 0.2390122899236953\n",
      "Loss = 0.0633237288261994\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0026707266395627795\tMax abs grad value: 0.07170867841099665\n",
      "Loss = 0.051662165999614644\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0020911607127249788\tMax abs grad value: 0.03677710157641193\n",
      "Loss = 0.04665007823389459\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.002561261282676974\tMax abs grad value: 0.04961971538479831\n",
      "Loss = 0.03919489636980838\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002378425969144785\tMax abs grad value: 0.06842746052857733\n",
      "Loss = 0.033668207021227\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0021066753695404474\tMax abs grad value: 0.04816120846046624\n",
      "Loss = 0.028905074250636542\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0015090140182241773\tMax abs grad value: 0.030879898922558106\n",
      "Loss = 0.023635434396210634\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001673113403020398\tMax abs grad value: 0.048174669009900896\n",
      "Loss = 0.019755287466726987\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.001210341127277154\tMax abs grad value: 0.03664476196602335\n",
      "Loss = 0.01701751030688476\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0009625288539772895\tMax abs grad value: 0.02344631319306303\n",
      "Loss = 0.014058715510839034\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0010485845534038815\tMax abs grad value: 0.02361887915187822\n",
      "Loss = 0.011382968269994572\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0010663236967326307\tMax abs grad value: 0.022657736276079962\n",
      "Loss = 0.00939113319111828\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0009563845605312777\tMax abs grad value: 0.024636900274620132\n",
      "Loss = 0.0071211358881863715\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.000736490392362684\tMax abs grad value: 0.01459028497033351\n",
      "Loss = 0.005334243457439518\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0005024065062573858\tMax abs grad value: 0.011141258693478059\n",
      "Loss = 0.004632119780314516\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00036645753994244686\tMax abs grad value: 0.006722980775893759\n",
      "Loss = 0.003566876987011331\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0007776291477037914\tMax abs grad value: 0.02284278821737485\n",
      "Loss = 0.0028163206464656065\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0003334942380726477\tMax abs grad value: 0.007905512502957455\n",
      "Loss = 0.0019274750450744412\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00020230944431352075\tMax abs grad value: 0.0051284721172146965\n",
      "Loss = 0.0013924658477115189\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.00015346297724820222\tMax abs grad value: 0.0032832702030630356\n",
      "Loss = 0.0009613152618495282\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0001473268914246433\tMax abs grad value: 0.0031150681305750936\n",
      "Loss = 0.0006445419188319803\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00011941632464438173\tMax abs grad value: 0.0028049508714844606\n",
      "Loss = 0.0004510402190827744\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.728241914661343e-05\tMax abs grad value: 0.0014141200998168564\n",
      "Loss = 0.000313145976079528\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.88247545139775e-05\tMax abs grad value: 0.0006978424965451876\n",
      "Loss = 0.00024895740812315046\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.759065622756008e-05\tMax abs grad value: 0.0008741729256860583\n",
      "Loss = 0.00019105686677480026\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.416919659601356e-05\tMax abs grad value: 0.0021419150818668513\n",
      "Loss = 0.00013948500509641275\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.458100020740132e-05\tMax abs grad value: 0.0006003522037317139\n",
      "Loss = 8.418577984810963e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.4424587416541416e-05\tMax abs grad value: 0.0005489764146757353\n",
      "Loss = 6.75471962413399e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.4487583061262986e-05\tMax abs grad value: 0.0003647764205856762\n",
      "Loss = 4.285112160779842e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 9.621270582632021e-06\tMax abs grad value: 0.00017892258783608954\n",
      "Loss = 3.024218080249461e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.682542890450892e-06\tMax abs grad value: 0.0001341112651640008\n",
      "Loss = 2.1407006242264494e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.02622766771014e-06\tMax abs grad value: 0.0001662781111074272\n",
      "Loss = 1.2325506240165219e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.71048926281104e-06\tMax abs grad value: 7.160225990946103e-05\n",
      "Loss = 7.659091879952915e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.448765561857788e-06\tMax abs grad value: 2.6339274891019103e-05\n",
      "Loss = 4.946745910371559e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.0625451313510241e-06\tMax abs grad value: 1.752390191332733e-05\n",
      "Loss = 2.9988728179350534e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.1822401460710805e-06\tMax abs grad value: 3.704333218812612e-05\n",
      "Loss = 1.781660189094317e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 5.20220944303143e-07\tMax abs grad value: 1.1996428044972492e-05\n",
      "Loss = 1.0684506485372634e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.3081311289990506e-07\tMax abs grad value: 6.186293939719943e-06\n",
      "Loss = 6.936667597964034e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0326488070931394\tMax abs grad value: 0.938348848633379\n",
      "Loss = 2.713842949206308\n",
      "Mean abs grad value: 0.012660858538674614\tMax abs grad value: 0.30623535403344115\n",
      "Loss = 2.2493124835992084\n",
      "Train accuracy: 0.124\t\tTest accuracy: 0.124\n",
      "Mean abs grad value: 0.010313064141587508\tMax abs grad value: 0.22566500258252134\n",
      "Loss = 2.02344364137719\n",
      "Train accuracy: 0.286\t\tTest accuracy: 0.273\n",
      "Mean abs grad value: 0.010929900740838286\tMax abs grad value: 0.15869505359022698\n",
      "Loss = 1.8417489290719502\n",
      "Mean abs grad value: 0.02701205875884831\tMax abs grad value: 0.7542659654351955\n",
      "Loss = 1.821329593573287\n",
      "Mean abs grad value: 0.01397528956976673\tMax abs grad value: 0.23167348009741914\n",
      "Loss = 1.6493282952598225\n",
      "Train accuracy: 0.442\t\tTest accuracy: 0.433\n",
      "Mean abs grad value: 0.02161510028591107\tMax abs grad value: 0.4878165825969106\n",
      "Loss = 1.3468532636982868\n",
      "Train accuracy: 0.575\t\tTest accuracy: 0.580\n",
      "Mean abs grad value: 0.023832917515165957\tMax abs grad value: 1.1615472542489944\n",
      "Loss = 0.985265555675047\n",
      "Train accuracy: 0.626\t\tTest accuracy: 0.622\n",
      "Mean abs grad value: 0.017721999145884158\tMax abs grad value: 0.5791766968233157\n",
      "Loss = 0.8170603979774994\n",
      "Train accuracy: 0.709\t\tTest accuracy: 0.698\n",
      "Mean abs grad value: 0.01190806527706748\tMax abs grad value: 0.37267842988438354\n",
      "Loss = 0.7503647111054972\n",
      "Train accuracy: 0.744\t\tTest accuracy: 0.709\n",
      "Mean abs grad value: 0.01116588833150132\tMax abs grad value: 0.33002375489548424\n",
      "Loss = 0.6908086406987023\n",
      "Train accuracy: 0.757\t\tTest accuracy: 0.740\n",
      "Mean abs grad value: 0.012955307739734204\tMax abs grad value: 0.29667764600687635\n",
      "Loss = 0.6126378909480954\n",
      "Train accuracy: 0.790\t\tTest accuracy: 0.758\n",
      "Mean abs grad value: 0.013995600658581284\tMax abs grad value: 0.8893059253107672\n",
      "Loss = 0.49805682949872765\n",
      "Train accuracy: 0.840\t\tTest accuracy: 0.824\n",
      "Mean abs grad value: 0.01763547868671674\tMax abs grad value: 1.0720070529268892\n",
      "Loss = 0.49787508897525523\n",
      "Mean abs grad value: 0.010374572348641998\tMax abs grad value: 0.2986536741743638\n",
      "Loss = 0.45175836529487784\n",
      "Train accuracy: 0.847\t\tTest accuracy: 0.838\n",
      "Mean abs grad value: 0.006910391253281164\tMax abs grad value: 0.23921242174935906\n",
      "Loss = 0.42995885439261644\n",
      "Train accuracy: 0.865\t\tTest accuracy: 0.849\n",
      "Mean abs grad value: 0.006331957821642276\tMax abs grad value: 0.1741142879614261\n",
      "Loss = 0.40367399532266884\n",
      "Train accuracy: 0.874\t\tTest accuracy: 0.856\n",
      "Mean abs grad value: 0.0066128522220738045\tMax abs grad value: 0.19653377864256885\n",
      "Loss = 0.36959038547325224\n",
      "Train accuracy: 0.884\t\tTest accuracy: 0.864\n",
      "Mean abs grad value: 0.007680964632585192\tMax abs grad value: 0.28991863164201875\n",
      "Loss = 0.3386164447840618\n",
      "Train accuracy: 0.895\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.006017749521213351\tMax abs grad value: 0.17385845671944164\n",
      "Loss = 0.2995563457759272\n",
      "Train accuracy: 0.905\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.005061057992597842\tMax abs grad value: 0.12353004694209688\n",
      "Loss = 0.26734392007430063\n",
      "Train accuracy: 0.916\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.004441121523052002\tMax abs grad value: 0.12120630513431635\n",
      "Loss = 0.2285183505715414\n",
      "Train accuracy: 0.927\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.007104118452629795\tMax abs grad value: 0.22725168542172602\n",
      "Loss = 0.21105071489494787\n",
      "Train accuracy: 0.928\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.0040303132303711\tMax abs grad value: 0.10172400751657719\n",
      "Loss = 0.19187674264502402\n",
      "Train accuracy: 0.938\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.002882435844486717\tMax abs grad value: 0.055956897295630234\n",
      "Loss = 0.17545907823429677\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0033938622132562136\tMax abs grad value: 0.0686080837751749\n",
      "Loss = 0.1647313293141871\n",
      "Train accuracy: 0.948\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.003770128377678214\tMax abs grad value: 0.1260622338137936\n",
      "Loss = 0.14720116919499615\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.011554443911050047\tMax abs grad value: 0.4505456847789127\n",
      "Loss = 0.1485150789935459\n",
      "Mean abs grad value: 0.005360881658195694\tMax abs grad value: 0.16593433668858934\n",
      "Loss = 0.13452225198078804\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0031257058898685303\tMax abs grad value: 0.06674687638172591\n",
      "Loss = 0.1211503073451976\n",
      "Train accuracy: 0.960\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.002530209467673237\tMax abs grad value: 0.046223866317567926\n",
      "Loss = 0.11130643802079591\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.003197864723498394\tMax abs grad value: 0.08179488517299899\n",
      "Loss = 0.10478862243562027\n",
      "Train accuracy: 0.962\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0031252765864108133\tMax abs grad value: 0.07222157812454531\n",
      "Loss = 0.09716544031508127\n",
      "Train accuracy: 0.962\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0028570888972041086\tMax abs grad value: 0.059561097138225404\n",
      "Loss = 0.08713459984975959\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.002865222962345877\tMax abs grad value: 0.0656353597532549\n",
      "Loss = 0.0740858877894656\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.006652509605781023\tMax abs grad value: 0.17334566240760402\n",
      "Loss = 0.06287018289032062\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002379195194542561\tMax abs grad value: 0.05895655215975732\n",
      "Loss = 0.05019655548517393\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0018241791342922013\tMax abs grad value: 0.03685340363877221\n",
      "Loss = 0.0478721114345878\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0020163561757068483\tMax abs grad value: 0.042272713984100825\n",
      "Loss = 0.0444489074487283\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0019829608626526283\tMax abs grad value: 0.042407167089817094\n",
      "Loss = 0.03995576666329117\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0016801297467211717\tMax abs grad value: 0.03504654385228229\n",
      "Loss = 0.0317386506143279\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.004242709269802025\tMax abs grad value: 0.09908851508304566\n",
      "Loss = 0.0286723323617934\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0014247515050345662\tMax abs grad value: 0.04589884842300692\n",
      "Loss = 0.02214127117242853\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0008323943544803834\tMax abs grad value: 0.011304326566482689\n",
      "Loss = 0.020612455274449933\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0007992337775420445\tMax abs grad value: 0.014919621587082878\n",
      "Loss = 0.019834322771989633\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0010272258745225317\tMax abs grad value: 0.02582348203396681\n",
      "Loss = 0.01820588508923601\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0015728096440352295\tMax abs grad value: 0.04854795222373045\n",
      "Loss = 0.01568401995181496\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0014538030463529053\tMax abs grad value: 0.04501471284224407\n",
      "Loss = 0.012853060587844045\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0009890038438919706\tMax abs grad value: 0.023027044524946153\n",
      "Loss = 0.010455457954567843\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0008749600095868696\tMax abs grad value: 0.015318639156919693\n",
      "Loss = 0.009424982851107749\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0007517162514546125\tMax abs grad value: 0.014289120334299268\n",
      "Loss = 0.00854773268192043\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0008660811449160572\tMax abs grad value: 0.01846834712540082\n",
      "Loss = 0.006829550909577076\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0007719929952813174\tMax abs grad value: 0.033465808144850576\n",
      "Loss = 0.005311812258819456\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.00041688697686463534\tMax abs grad value: 0.010710969826952308\n",
      "Loss = 0.004159718011818187\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0003765834667684131\tMax abs grad value: 0.00802184747045154\n",
      "Loss = 0.003508871200521569\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0003403068228788927\tMax abs grad value: 0.006678454741144539\n",
      "Loss = 0.0029595438229672176\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.000290582910540855\tMax abs grad value: 0.007057913451851962\n",
      "Loss = 0.0025285247561260106\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0002728855857579862\tMax abs grad value: 0.004883519195861214\n",
      "Loss = 0.0020067814166982198\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.00030140691513905307\tMax abs grad value: 0.007837325547714658\n",
      "Loss = 0.001511566530663375\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.00013164830072588308\tMax abs grad value: 0.002850446504630967\n",
      "Loss = 0.0011584987381763532\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0001333192562676198\tMax abs grad value: 0.002435187580359269\n",
      "Loss = 0.0010032286829010431\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.00016336101372877582\tMax abs grad value: 0.004720385237184602\n",
      "Loss = 0.0008688108337524621\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.00011228806394217659\tMax abs grad value: 0.0024779004651871096\n",
      "Loss = 0.0007617837042854292\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 8.514342488847371e-05\tMax abs grad value: 0.002091391307954078\n",
      "Loss = 0.0005865198341508667\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.00010057721635454197\tMax abs grad value: 0.003472666958010865\n",
      "Loss = 0.0004358864413249583\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.00017301307643897846\tMax abs grad value: 0.0056149198000388124\n",
      "Loss = 0.0004008359125609742\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 6.128968160067761e-05\tMax abs grad value: 0.0015074819578661948\n",
      "Loss = 0.0002924579973165479\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 4.472985340203945e-05\tMax abs grad value: 0.0009204741485301547\n",
      "Loss = 0.0002619917552151542\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 3.819238090304889e-05\tMax abs grad value: 0.0008140514753310301\n",
      "Loss = 0.00022792990484003719\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00010973311645954938\tMax abs grad value: 0.0033670729196855196\n",
      "Loss = 0.00021830972722348152\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.191708287749956e-05\tMax abs grad value: 0.0009010941487006591\n",
      "Loss = 0.00018248371201407462\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.6425625479145113e-05\tMax abs grad value: 0.0005871183654768506\n",
      "Loss = 0.0001660600053090338\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 3.226729960042468e-05\tMax abs grad value: 0.0006047913431705365\n",
      "Loss = 0.0001465124719188987\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.7494158810714736e-05\tMax abs grad value: 0.0005342898016079867\n",
      "Loss = 0.00012570805136522743\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 4.319022118868708e-05\tMax abs grad value: 0.00136512407908888\n",
      "Loss = 9.44599529667952e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 3.5013896983149044e-05\tMax abs grad value: 0.0008654898367691452\n",
      "Loss = 8.026746027866153e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.654770310422238e-05\tMax abs grad value: 0.00033654357224558\n",
      "Loss = 6.692168514662812e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.1266366084019503e-05\tMax abs grad value: 0.0002781905392910754\n",
      "Loss = 5.931851023564668e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 9.792020959655724e-06\tMax abs grad value: 0.00018950151829384476\n",
      "Loss = 4.808735614757754e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 9.583800130950355e-06\tMax abs grad value: 0.00024329984797296543\n",
      "Loss = 3.689949814623213e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.7202519679537187e-05\tMax abs grad value: 0.0006121935294709816\n",
      "Loss = 3.689127460080226e-05\n",
      "Mean abs grad value: 1.4246957436297532e-05\tMax abs grad value: 0.00035687737843574744\n",
      "Loss = 3.220530330465883e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 8.67401316275877e-06\tMax abs grad value: 0.0002627707603866535\n",
      "Loss = 2.404014455815706e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 6.21880787287467e-06\tMax abs grad value: 0.00014932460375247892\n",
      "Loss = 1.7685193829963447e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 4.432860800499325e-06\tMax abs grad value: 0.00011036164779128185\n",
      "Loss = 1.2431592582400862e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 7.286079451460923e-06\tMax abs grad value: 0.00023822708405739425\n",
      "Loss = 1.0081445898875673e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.3331506479673122e-06\tMax abs grad value: 7.043601037099738e-05\n",
      "Loss = 6.781743524585379e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.3598127523666968e-06\tMax abs grad value: 2.1462847089894162e-05\n",
      "Loss = 5.695177992050927e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.2577863853094752e-06\tMax abs grad value: 2.951258748838219e-05\n",
      "Loss = 4.850155143933981e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.1969051991309628e-06\tMax abs grad value: 2.5631110549335825e-05\n",
      "Loss = 3.5002853684415384e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.338615235211382e-06\tMax abs grad value: 6.863677569426701e-05\n",
      "Loss = 3.05413254297835e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 7.159300328790863e-07\tMax abs grad value: 1.5111819211030946e-05\n",
      "Loss = 1.634246721956697e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.648697163741696e-07\tMax abs grad value: 9.103910201701545e-06\n",
      "Loss = 1.2896147447764518e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.02707551433421266\tMax abs grad value: 0.6450777282528413\n",
      "Loss = 2.6195496916334244\n",
      "Mean abs grad value: 0.02743567255973253\tMax abs grad value: 1.2107397988500121\n",
      "Loss = 2.770396170419462\n",
      "Mean abs grad value: 0.017314555529220437\tMax abs grad value: 0.4048773941679463\n",
      "Loss = 2.2425437277653035\n",
      "Train accuracy: 0.159\t\tTest accuracy: 0.160\n",
      "Mean abs grad value: 0.011046309881276846\tMax abs grad value: 0.2247476823538538\n",
      "Loss = 2.0764978080699925\n",
      "Train accuracy: 0.267\t\tTest accuracy: 0.231\n",
      "Mean abs grad value: 0.011938620722697331\tMax abs grad value: 0.27014567915761795\n",
      "Loss = 1.9313273739612025\n",
      "Train accuracy: 0.422\t\tTest accuracy: 0.382\n",
      "Mean abs grad value: 0.02041969898735863\tMax abs grad value: 0.5981424169366639\n",
      "Loss = 1.3051213755236952\n",
      "Train accuracy: 0.567\t\tTest accuracy: 0.540\n",
      "Mean abs grad value: 0.06548026965181665\tMax abs grad value: 1.9700600225812306\n",
      "Loss = 2.1163962695577276\n",
      "Mean abs grad value: 0.01618498014823013\tMax abs grad value: 0.5159269756210662\n",
      "Loss = 1.126865809344032\n",
      "Train accuracy: 0.623\t\tTest accuracy: 0.647\n",
      "Mean abs grad value: 0.014290004988735214\tMax abs grad value: 0.291128674096069\n",
      "Loss = 1.0279535290816042\n",
      "Train accuracy: 0.699\t\tTest accuracy: 0.693\n",
      "Mean abs grad value: 0.014230595267869755\tMax abs grad value: 0.45327342993810177\n",
      "Loss = 0.8828517236675021\n",
      "Train accuracy: 0.742\t\tTest accuracy: 0.736\n",
      "Mean abs grad value: 0.016234270844612302\tMax abs grad value: 0.49729591726751377\n",
      "Loss = 0.6446886445358085\n",
      "Train accuracy: 0.803\t\tTest accuracy: 0.771\n",
      "Mean abs grad value: 0.017169936344827712\tMax abs grad value: 0.7583262323762652\n",
      "Loss = 0.5585960745038991\n",
      "Train accuracy: 0.838\t\tTest accuracy: 0.833\n",
      "Mean abs grad value: 0.006972558606460904\tMax abs grad value: 0.16645552086118998\n",
      "Loss = 0.48496984124511816\n",
      "Train accuracy: 0.855\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.005577971898591599\tMax abs grad value: 0.11572899144072638\n",
      "Loss = 0.46572155974142737\n",
      "Train accuracy: 0.862\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.006098592684149078\tMax abs grad value: 0.13970685421189805\n",
      "Loss = 0.43480993026662357\n",
      "Train accuracy: 0.871\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.011566851466324576\tMax abs grad value: 0.30144526659138426\n",
      "Loss = 0.3707491760413635\n",
      "Train accuracy: 0.878\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.009347530786112453\tMax abs grad value: 0.3157373059516978\n",
      "Loss = 0.3117499201654895\n",
      "Train accuracy: 0.904\t\tTest accuracy: 0.878\n",
      "Mean abs grad value: 0.0062297858263947814\tMax abs grad value: 0.15732606018415912\n",
      "Loss = 0.27559705764788706\n",
      "Train accuracy: 0.909\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.005106180713957087\tMax abs grad value: 0.10911860176907871\n",
      "Loss = 0.24734060589469925\n",
      "Train accuracy: 0.920\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.004153153654050709\tMax abs grad value: 0.0749973446179472\n",
      "Loss = 0.22108621296749525\n",
      "Train accuracy: 0.932\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.006589508848641163\tMax abs grad value: 0.16209201805186513\n",
      "Loss = 0.2076130479033872\n",
      "Train accuracy: 0.935\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.004540543243760355\tMax abs grad value: 0.09578329463081524\n",
      "Loss = 0.19096418971021184\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.005247185640967277\tMax abs grad value: 0.12211857319594205\n",
      "Loss = 0.1645897131990382\n",
      "Train accuracy: 0.949\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.004359681962096126\tMax abs grad value: 0.09127714532171931\n",
      "Loss = 0.14552052655130104\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.005827574850613451\tMax abs grad value: 0.12315435777999591\n",
      "Loss = 0.12493176910728356\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.004653443025292185\tMax abs grad value: 0.10404803815197122\n",
      "Loss = 0.1152628183664237\n",
      "Train accuracy: 0.959\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0029405813066265235\tMax abs grad value: 0.04849985790757235\n",
      "Loss = 0.10926544036538795\n",
      "Train accuracy: 0.959\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0032027116467071\tMax abs grad value: 0.07683017178590111\n",
      "Loss = 0.10220211405398623\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.003717807317733581\tMax abs grad value: 0.10495760381947629\n",
      "Loss = 0.09126468814675921\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.012815902424541342\tMax abs grad value: 0.4364686408794727\n",
      "Loss = 0.0974644095998627\n",
      "Mean abs grad value: 0.005336118629027875\tMax abs grad value: 0.17192035133507058\n",
      "Loss = 0.08554537964938022\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0029024875737892197\tMax abs grad value: 0.081574423805042\n",
      "Loss = 0.0768847226367394\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002166633616171115\tMax abs grad value: 0.03968630893050396\n",
      "Loss = 0.06968710573733931\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.002685484424026026\tMax abs grad value: 0.05685318536196619\n",
      "Loss = 0.06214441926747438\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002901049106701214\tMax abs grad value: 0.10870806672924577\n",
      "Loss = 0.055280721810485677\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002801291319982825\tMax abs grad value: 0.09480871228097618\n",
      "Loss = 0.0500850898620204\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.001525392306569609\tMax abs grad value: 0.028946171244281612\n",
      "Loss = 0.04615513708587154\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.001808046826158986\tMax abs grad value: 0.03978451205241767\n",
      "Loss = 0.04287322819564098\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0019507876625284553\tMax abs grad value: 0.05534267779162118\n",
      "Loss = 0.03954010505919502\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0026410169511189487\tMax abs grad value: 0.07576634631628121\n",
      "Loss = 0.03215271800224458\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.005139383684748919\tMax abs grad value: 0.14882103545495304\n",
      "Loss = 0.03357413685943117\n",
      "Mean abs grad value: 0.0021271213718124485\tMax abs grad value: 0.08277073326121755\n",
      "Loss = 0.027851805139570727\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0023486257337082283\tMax abs grad value: 0.09357437428834177\n",
      "Loss = 0.02493219540775641\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0012027844777783092\tMax abs grad value: 0.03159007458340845\n",
      "Loss = 0.022865228294276202\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0011396558646761354\tMax abs grad value: 0.024862671348001835\n",
      "Loss = 0.021621975245700947\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0011435208318653378\tMax abs grad value: 0.027079341456068308\n",
      "Loss = 0.02021989207658916\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0018467842849173286\tMax abs grad value: 0.05449364627149115\n",
      "Loss = 0.018553352779991972\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0012872540072859813\tMax abs grad value: 0.035964573305408136\n",
      "Loss = 0.01637237712564845\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.000934229037335867\tMax abs grad value: 0.016955559899850425\n",
      "Loss = 0.013228946555798982\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.001509329004299457\tMax abs grad value: 0.044887833893994686\n",
      "Loss = 0.011480668112373294\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0008205647674693081\tMax abs grad value: 0.017854453979440715\n",
      "Loss = 0.009896417858130106\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.000691146898134216\tMax abs grad value: 0.027827759013747497\n",
      "Loss = 0.008573285682211508\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0007160776525117485\tMax abs grad value: 0.02577425948350288\n",
      "Loss = 0.006876641887559817\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0023039685670251647\tMax abs grad value: 0.06217415844642997\n",
      "Loss = 0.006618692036057839\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0006098230664359992\tMax abs grad value: 0.01752912828781408\n",
      "Loss = 0.005270711548061385\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00042486668162474166\tMax abs grad value: 0.008982429190892902\n",
      "Loss = 0.00505749186245416\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00043253913602732413\tMax abs grad value: 0.011893328255602978\n",
      "Loss = 0.004561107928894818\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0005965526649388473\tMax abs grad value: 0.023330679224790946\n",
      "Loss = 0.003971076929074466\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0004667747994472292\tMax abs grad value: 0.016590267112478203\n",
      "Loss = 0.0034632754519860038\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0003686570049091075\tMax abs grad value: 0.00830900128991907\n",
      "Loss = 0.002787299929027284\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0004549287163879115\tMax abs grad value: 0.010579867277314829\n",
      "Loss = 0.002358777965584216\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00026440923436980564\tMax abs grad value: 0.008074807023140456\n",
      "Loss = 0.0020266691503773053\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00022873941043231972\tMax abs grad value: 0.0055877135336728796\n",
      "Loss = 0.0018648860244676701\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00023077260394252353\tMax abs grad value: 0.006957628603254052\n",
      "Loss = 0.0014991001506251612\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.000261669176423816\tMax abs grad value: 0.007668787790436577\n",
      "Loss = 0.0012426861251122708\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00018256825508830205\tMax abs grad value: 0.005770258234828124\n",
      "Loss = 0.0010551139960005534\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00010629193278669295\tMax abs grad value: 0.001886116445742113\n",
      "Loss = 0.0007449454010370053\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.00013142385829578704\tMax abs grad value: 0.00341540402095202\n",
      "Loss = 0.0005267948887919788\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0004955513288127281\tMax abs grad value: 0.017446375997403674\n",
      "Loss = 0.000565844412904522\n",
      "Mean abs grad value: 0.00016095738492498992\tMax abs grad value: 0.005166872773554453\n",
      "Loss = 0.00042666998673702446\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00010219009286410515\tMax abs grad value: 0.0027663755737508257\n",
      "Loss = 0.0003301390436863561\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 7.899390169180172e-05\tMax abs grad value: 0.0016988101169439446\n",
      "Loss = 0.0002475510085221046\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.282995029642679e-05\tMax abs grad value: 0.0017251335263856558\n",
      "Loss = 0.00017501748723175567\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 4.158222474208189e-05\tMax abs grad value: 0.0008158659377394136\n",
      "Loss = 0.00013082054476465187\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.0262173181492675e-05\tMax abs grad value: 0.0005175645901857355\n",
      "Loss = 9.690705728427164e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.767553060395042e-05\tMax abs grad value: 0.00041301133686594564\n",
      "Loss = 5.615801285561808e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.597691654304807e-05\tMax abs grad value: 0.00042019665801488543\n",
      "Loss = 3.521924002746916e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 7.896072489048274e-06\tMax abs grad value: 0.0001960707161089163\n",
      "Loss = 2.3928947831347272e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 7.087113193098329e-06\tMax abs grad value: 0.000164004301523056\n",
      "Loss = 1.940279538631287e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 9.153439385199e-06\tMax abs grad value: 0.00022603553982928801\n",
      "Loss = 1.2280536469346921e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.848623016850442e-06\tMax abs grad value: 8.367145332791247e-05\n",
      "Loss = 7.79076954635254e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.2376589706095887e-06\tMax abs grad value: 6.752955950717708e-05\n",
      "Loss = 6.188461961823551e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.9391843669139115e-06\tMax abs grad value: 6.303534941298269e-05\n",
      "Loss = 4.6787846457265375e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.3130936739916526e-06\tMax abs grad value: 3.430714242668537e-05\n",
      "Loss = 3.0891115892734593e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.4833587199517573e-06\tMax abs grad value: 5.1414176734905396e-05\n",
      "Loss = 1.9170745759774206e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 8.504362285315912e-07\tMax abs grad value: 2.2052133461173504e-05\n",
      "Loss = 1.4135535435968104e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.617011942909158e-07\tMax abs grad value: 1.507816900406025e-05\n",
      "Loss = 1.1450239233211438e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.56809653974381e-07\tMax abs grad value: 1.0984935393157134e-05\n",
      "Loss = 9.022172927842132e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.647684469876021e-07\tMax abs grad value: 1.1474701772112683e-05\n",
      "Loss = 6.712898886832689e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.536974662122997e-07\tMax abs grad value: 7.373713992428124e-06\n",
      "Loss = 4.0489094281016615e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.04145359072264738\tMax abs grad value: 0.8610422475246738\n",
      "Loss = 2.958850203250423\n",
      "Mean abs grad value: 0.012213872682040652\tMax abs grad value: 0.2966910313365779\n",
      "Loss = 2.3050400128378916\n",
      "Train accuracy: 0.177\t\tTest accuracy: 0.167\n",
      "Mean abs grad value: 0.008735035247623774\tMax abs grad value: 0.13147912150807348\n",
      "Loss = 2.047242232886887\n",
      "Train accuracy: 0.331\t\tTest accuracy: 0.307\n",
      "Mean abs grad value: 0.010820775426582097\tMax abs grad value: 0.18742021815845397\n",
      "Loss = 1.8699152601308564\n",
      "Train accuracy: 0.456\t\tTest accuracy: 0.438\n",
      "Mean abs grad value: 0.06726569033821153\tMax abs grad value: 2.57649109698462\n",
      "Loss = 2.2103963243707154\n",
      "Mean abs grad value: 0.02025774715912928\tMax abs grad value: 0.46363098880944154\n",
      "Loss = 1.6579290544478993\n",
      "Train accuracy: 0.385\t\tTest accuracy: 0.362\n",
      "Mean abs grad value: 0.02199287588235243\tMax abs grad value: 0.6174435908622784\n",
      "Loss = 1.3028386228234536\n",
      "Train accuracy: 0.567\t\tTest accuracy: 0.542\n",
      "Mean abs grad value: 0.1764987629780918\tMax abs grad value: 9.183405999598369\n",
      "Loss = 4.063198299366867\n",
      "Mean abs grad value: 0.026590074910158728\tMax abs grad value: 0.8057324986695836\n",
      "Loss = 1.1130857160956402\n",
      "Train accuracy: 0.613\t\tTest accuracy: 0.582\n",
      "Mean abs grad value: 0.02840483230947301\tMax abs grad value: 1.0995552584077575\n",
      "Loss = 0.8950383678860669\n",
      "Train accuracy: 0.699\t\tTest accuracy: 0.678\n",
      "Mean abs grad value: 0.01615043686609549\tMax abs grad value: 0.4040638468002841\n",
      "Loss = 0.8004000066582211\n",
      "Train accuracy: 0.775\t\tTest accuracy: 0.740\n",
      "Mean abs grad value: 0.010677266970254467\tMax abs grad value: 0.18469960944616856\n",
      "Loss = 0.7238967905428056\n",
      "Train accuracy: 0.786\t\tTest accuracy: 0.771\n",
      "Mean abs grad value: 0.013098503673558613\tMax abs grad value: 0.7126047760904201\n",
      "Loss = 0.6706640729184992\n",
      "Train accuracy: 0.788\t\tTest accuracy: 0.769\n",
      "Mean abs grad value: 0.010667852968942909\tMax abs grad value: 0.3092692522842416\n",
      "Loss = 0.6119272995298656\n",
      "Train accuracy: 0.808\t\tTest accuracy: 0.778\n",
      "Mean abs grad value: 0.014941884001418692\tMax abs grad value: 0.8052132498160814\n",
      "Loss = 0.5012478945977248\n",
      "Train accuracy: 0.826\t\tTest accuracy: 0.798\n",
      "Mean abs grad value: 0.018381609395458392\tMax abs grad value: 0.6673933089227623\n",
      "Loss = 0.4575950644172112\n",
      "Train accuracy: 0.858\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.008670481495823112\tMax abs grad value: 0.16439608962904387\n",
      "Loss = 0.4158826875771045\n",
      "Train accuracy: 0.877\t\tTest accuracy: 0.844\n",
      "Mean abs grad value: 0.008597279294466471\tMax abs grad value: 0.19980841028668567\n",
      "Loss = 0.39107388749829897\n",
      "Train accuracy: 0.878\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.009726468481896233\tMax abs grad value: 0.32448546170602227\n",
      "Loss = 0.3661180842109539\n",
      "Train accuracy: 0.887\t\tTest accuracy: 0.871\n",
      "Mean abs grad value: 0.010399636416020696\tMax abs grad value: 0.33888569996079104\n",
      "Loss = 0.30757851405301967\n",
      "Train accuracy: 0.909\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.012817890566620048\tMax abs grad value: 0.5290691871004526\n",
      "Loss = 0.2760300185244368\n",
      "Train accuracy: 0.913\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.0057504780733836375\tMax abs grad value: 0.14964664479129358\n",
      "Loss = 0.24798909661345342\n",
      "Train accuracy: 0.927\t\tTest accuracy: 0.898\n",
      "Mean abs grad value: 0.0047735208694823375\tMax abs grad value: 0.15966951841724308\n",
      "Loss = 0.24064662602256687\n",
      "Train accuracy: 0.928\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.005117034586883045\tMax abs grad value: 0.15963591448281467\n",
      "Loss = 0.22043379633817672\n",
      "Train accuracy: 0.933\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.006027558336554692\tMax abs grad value: 0.195896862902449\n",
      "Loss = 0.1974165959578408\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.007039439778774215\tMax abs grad value: 0.24040142982678228\n",
      "Loss = 0.17504042684155066\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0033282734325141227\tMax abs grad value: 0.089424281235104\n",
      "Loss = 0.15818164667445345\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.003371239706100198\tMax abs grad value: 0.09275977473245581\n",
      "Loss = 0.14926631939547055\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.003321476607373174\tMax abs grad value: 0.10534359946263062\n",
      "Loss = 0.13919337682030758\n",
      "Train accuracy: 0.959\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.004838023315014951\tMax abs grad value: 0.1662433243365058\n",
      "Loss = 0.1311268091138318\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.005454441759731322\tMax abs grad value: 0.19850265943945355\n",
      "Loss = 0.12527016095070978\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0033974096088615333\tMax abs grad value: 0.1159938527988105\n",
      "Loss = 0.11895710769205715\n",
      "Train accuracy: 0.966\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.003114822241695215\tMax abs grad value: 0.07408893622224402\n",
      "Loss = 0.11011192729612056\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0031704582036817977\tMax abs grad value: 0.09740167183942816\n",
      "Loss = 0.10122879685680886\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.009533028017975701\tMax abs grad value: 0.3780033429767627\n",
      "Loss = 0.10399747464827001\n",
      "Mean abs grad value: 0.003858162725395493\tMax abs grad value: 0.14335462786548123\n",
      "Loss = 0.09666378408258805\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.002849239218354163\tMax abs grad value: 0.10028997301460683\n",
      "Loss = 0.09027684320415033\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002475403418849966\tMax abs grad value: 0.079037787061471\n",
      "Loss = 0.08363149655314228\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0027419792399961916\tMax abs grad value: 0.08123537319328902\n",
      "Loss = 0.07418015915080038\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.012298767250317174\tMax abs grad value: 0.3359185420007441\n",
      "Loss = 0.09422792267776105\n",
      "Mean abs grad value: 0.004198939962434861\tMax abs grad value: 0.12477542937554621\n",
      "Loss = 0.06825617687625234\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002826865779744391\tMax abs grad value: 0.0808329486375023\n",
      "Loss = 0.06187210793199357\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0029457163998664556\tMax abs grad value: 0.09566060188555778\n",
      "Loss = 0.0545486693791239\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.003063803102917289\tMax abs grad value: 0.11275335231467157\n",
      "Loss = 0.0507789553741497\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0022980405518114627\tMax abs grad value: 0.07182296635949673\n",
      "Loss = 0.04822532499784931\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.001694095349361194\tMax abs grad value: 0.03819174519077416\n",
      "Loss = 0.04329419629468918\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0017587629336828646\tMax abs grad value: 0.03933470635515751\n",
      "Loss = 0.039949742352840066\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0037982232650055204\tMax abs grad value: 0.12883261368172777\n",
      "Loss = 0.038545040872793146\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0016452986890318046\tMax abs grad value: 0.047863491135562174\n",
      "Loss = 0.035625432978114296\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00134847757406284\tMax abs grad value: 0.03546710780347233\n",
      "Loss = 0.034636925637756596\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0018626612554838108\tMax abs grad value: 0.055444291822659746\n",
      "Loss = 0.0332091121520711\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0023588271693454634\tMax abs grad value: 0.07734805478667013\n",
      "Loss = 0.03126572461662002\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.002458562418567272\tMax abs grad value: 0.08725660480685857\n",
      "Loss = 0.027462165035350736\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0077969125507970334\tMax abs grad value: 0.2775957475358092\n",
      "Loss = 0.030885362382192933\n",
      "Mean abs grad value: 0.0030879769434382772\tMax abs grad value: 0.11550489877517289\n",
      "Loss = 0.02488154419971507\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.001355686553245689\tMax abs grad value: 0.03229621011875014\n",
      "Loss = 0.021336116688955624\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.001321120576849829\tMax abs grad value: 0.03888147347466607\n",
      "Loss = 0.019752478401148767\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0018024027784976154\tMax abs grad value: 0.055374937664329896\n",
      "Loss = 0.01791846188890142\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0013881719649650962\tMax abs grad value: 0.04218390311044334\n",
      "Loss = 0.01652701005737821\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0012292976216358342\tMax abs grad value: 0.030920407783448543\n",
      "Loss = 0.015238739818467023\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0013996344304887428\tMax abs grad value: 0.04533951066067709\n",
      "Loss = 0.013212770099292278\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0017881495322455171\tMax abs grad value: 0.06885931304096875\n",
      "Loss = 0.011595662494185673\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0010385603683042148\tMax abs grad value: 0.02991035409207449\n",
      "Loss = 0.010486867636129302\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.000843630215220964\tMax abs grad value: 0.017972070753682245\n",
      "Loss = 0.009560223408627945\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0009317081147465511\tMax abs grad value: 0.027304187635601735\n",
      "Loss = 0.008728410730275998\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0011318883274797095\tMax abs grad value: 0.03685135686773621\n",
      "Loss = 0.007722432783027147\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0007350933355208178\tMax abs grad value: 0.021257777583229106\n",
      "Loss = 0.006954040539617765\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0006452204147372199\tMax abs grad value: 0.0162183437600466\n",
      "Loss = 0.006331376614306119\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0007912650961579384\tMax abs grad value: 0.029816557369025703\n",
      "Loss = 0.005556275010681824\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0005935027380593134\tMax abs grad value: 0.023787137766579848\n",
      "Loss = 0.005170573941619439\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00042212747581288747\tMax abs grad value: 0.014659987532148958\n",
      "Loss = 0.004711956617902889\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0004451242417026558\tMax abs grad value: 0.009079328692899015\n",
      "Loss = 0.00427577474484737\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00046185264710462185\tMax abs grad value: 0.011251508344649134\n",
      "Loss = 0.0036618346421493464\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0036394146754976367\tMax abs grad value: 0.14248156130910586\n",
      "Loss = 0.005552591726576014\n",
      "Mean abs grad value: 0.0009484842447583433\tMax abs grad value: 0.03612428291626341\n",
      "Loss = 0.003302938635669471\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0005803733745663237\tMax abs grad value: 0.019693418605132157\n",
      "Loss = 0.0026657431285281724\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00030153853013065423\tMax abs grad value: 0.007533922619740303\n",
      "Loss = 0.002069000295956825\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00025288438936760374\tMax abs grad value: 0.00494906427673618\n",
      "Loss = 0.0017241190256236608\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0005974944549927733\tMax abs grad value: 0.018126354569220248\n",
      "Loss = 0.0016792350113896157\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0002261050407807148\tMax abs grad value: 0.006422232958146112\n",
      "Loss = 0.001501583431865671\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0002208465107550435\tMax abs grad value: 0.0059050634118542385\n",
      "Loss = 0.0014285724653582883\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0002968910435673396\tMax abs grad value: 0.009497128131368375\n",
      "Loss = 0.0012966599255953986\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00028305003339029473\tMax abs grad value: 0.009078078726629128\n",
      "Loss = 0.001153182226343494\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00024912483841080723\tMax abs grad value: 0.0065169768391330095\n",
      "Loss = 0.0008726856875657217\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00019004610772666394\tMax abs grad value: 0.005558247200745659\n",
      "Loss = 0.0006540931812873108\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0002686712823771275\tMax abs grad value: 0.009141370724917544\n",
      "Loss = 0.0006166867161426514\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00011888274297951102\tMax abs grad value: 0.0030774726798576896\n",
      "Loss = 0.0005213698632868038\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00010010894179245346\tMax abs grad value: 0.0027253591618251853\n",
      "Loss = 0.0004845649109874253\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00011261430898555999\tMax abs grad value: 0.0040433150891012485\n",
      "Loss = 0.00042977903168842834\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00010601444651822736\tMax abs grad value: 0.0035564307154690457\n",
      "Loss = 0.00034816200431625385\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00022369802722664706\tMax abs grad value: 0.007027615452237292\n",
      "Loss = 0.00033976975609832904\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 7.314198091259607e-05\tMax abs grad value: 0.0019271456709041993\n",
      "Loss = 0.00023748435506105707\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.623288055935429e-05\tMax abs grad value: 0.001357029852797693\n",
      "Loss = 0.00020772464585409406\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.1093242264828756e-05\tMax abs grad value: 0.0014708138191779408\n",
      "Loss = 0.0001691754229642627\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.221810558399116e-05\tMax abs grad value: 0.0019565889088286525\n",
      "Loss = 0.000129562508316293\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.655027564168205e-05\tMax abs grad value: 0.0015019089350896378\n",
      "Loss = 0.00011422903765777854\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.7843065285500317e-05\tMax abs grad value: 0.0014011266597891711\n",
      "Loss = 0.00010027374447068152\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.3568184202817257e-05\tMax abs grad value: 0.0007964405347110853\n",
      "Loss = 7.927414374777121e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.3465135614270065e-05\tMax abs grad value: 0.0006056356557473293\n",
      "Loss = 5.5616078862443076e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.7378530602491268e-05\tMax abs grad value: 0.0007101639490398879\n",
      "Loss = 3.728135787513985e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.0253617070236763e-05\tMax abs grad value: 0.0007525242150600132\n",
      "Loss = 2.812562175106635e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.1674871967259872e-05\tMax abs grad value: 0.0004944426491834386\n",
      "Loss = 2.3610933335856368e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 9.147849181184e-06\tMax abs grad value: 0.00030682264720924523\n",
      "Loss = 1.964463271111077e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 7.657004964513216e-06\tMax abs grad value: 0.0003078262920217319\n",
      "Loss = 1.4417090200723375e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.074972978452828e-06\tMax abs grad value: 0.00016740321757156658\n",
      "Loss = 1.0571576494457641e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.889460564132805e-06\tMax abs grad value: 7.456970994602097e-05\n",
      "Loss = 7.46337631759856e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.3329935446828494e-06\tMax abs grad value: 4.557714163049759e-05\n",
      "Loss = 5.804459299249626e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.0293491223097776e-06\tMax abs grad value: 7.763866225244271e-05\n",
      "Loss = 3.585347458381132e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.1001824981345364e-06\tMax abs grad value: 6.769437601362213e-05\n",
      "Loss = 2.328937137597015e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 8.263503270798972e-07\tMax abs grad value: 2.5108063516126665e-05\n",
      "Loss = 1.6634379763124507e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.312956293354882e-07\tMax abs grad value: 1.702600967073764e-05\n",
      "Loss = 1.3143892251224073e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.4809932007279186e-07\tMax abs grad value: 1.1114382699660167e-05\n",
      "Loss = 7.81832386513234e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.778367005085474e-07\tMax abs grad value: 8.16193605017252e-06\n",
      "Loss = 4.947858818699125e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.022543601937342447\tMax abs grad value: 0.5231825172485461\n",
      "Loss = 2.4686996637541307\n",
      "Mean abs grad value: 0.01766821456032083\tMax abs grad value: 0.7876669892863395\n",
      "Loss = 2.3425659150972837\n",
      "Train accuracy: 0.123\t\tTest accuracy: 0.144\n",
      "Mean abs grad value: 0.009145971725533702\tMax abs grad value: 0.2903331193598498\n",
      "Loss = 2.1245702645097366\n",
      "Train accuracy: 0.200\t\tTest accuracy: 0.213\n",
      "Mean abs grad value: 0.007377343788476656\tMax abs grad value: 0.1974168265827292\n",
      "Loss = 1.9685331683580225\n",
      "Train accuracy: 0.348\t\tTest accuracy: 0.347\n",
      "Mean abs grad value: 0.010535383667358239\tMax abs grad value: 0.22849905799435874\n",
      "Loss = 1.7874998337817407\n",
      "Train accuracy: 0.405\t\tTest accuracy: 0.413\n",
      "Mean abs grad value: 0.01225254202788459\tMax abs grad value: 0.26603796037411837\n",
      "Loss = 1.552103864874551\n",
      "Train accuracy: 0.462\t\tTest accuracy: 0.473\n",
      "Mean abs grad value: 0.019616080448024143\tMax abs grad value: 0.5819950189140647\n",
      "Loss = 1.2489385955419903\n",
      "Train accuracy: 0.583\t\tTest accuracy: 0.578\n",
      "Mean abs grad value: 0.05778752928207754\tMax abs grad value: 2.190026938785059\n",
      "Loss = 1.6233974727125513\n",
      "Mean abs grad value: 0.01815051812151072\tMax abs grad value: 0.49680729912409755\n",
      "Loss = 1.0427995754215873\n",
      "Train accuracy: 0.675\t\tTest accuracy: 0.631\n",
      "Mean abs grad value: 0.01923853782035232\tMax abs grad value: 0.7781801672367238\n",
      "Loss = 0.9309799951457142\n",
      "Train accuracy: 0.712\t\tTest accuracy: 0.720\n",
      "Mean abs grad value: 0.012262566882002826\tMax abs grad value: 0.39861210922642326\n",
      "Loss = 0.8531938702256016\n",
      "Train accuracy: 0.731\t\tTest accuracy: 0.711\n",
      "Mean abs grad value: 0.009969776537321078\tMax abs grad value: 0.26415142850131834\n",
      "Loss = 0.8026936236886856\n",
      "Train accuracy: 0.739\t\tTest accuracy: 0.711\n",
      "Mean abs grad value: 0.009644752467982066\tMax abs grad value: 0.4710374649291517\n",
      "Loss = 0.7398439014617207\n",
      "Train accuracy: 0.753\t\tTest accuracy: 0.724\n",
      "Mean abs grad value: 0.013205555652552745\tMax abs grad value: 0.4287750419575315\n",
      "Loss = 0.6331702847435846\n",
      "Train accuracy: 0.793\t\tTest accuracy: 0.784\n",
      "Mean abs grad value: 0.020865025841394522\tMax abs grad value: 0.6422245580388406\n",
      "Loss = 0.5949315670734104\n",
      "Train accuracy: 0.811\t\tTest accuracy: 0.782\n",
      "Mean abs grad value: 0.007739858825258623\tMax abs grad value: 0.20810733071957926\n",
      "Loss = 0.529172753263061\n",
      "Train accuracy: 0.829\t\tTest accuracy: 0.796\n",
      "Mean abs grad value: 0.006686531550911951\tMax abs grad value: 0.19467829612132684\n",
      "Loss = 0.5018827876205815\n",
      "Train accuracy: 0.840\t\tTest accuracy: 0.809\n",
      "Mean abs grad value: 0.007070893481634081\tMax abs grad value: 0.18930141702270792\n",
      "Loss = 0.4480980019880524\n",
      "Train accuracy: 0.860\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.045393819027380586\tMax abs grad value: 2.678853993101213\n",
      "Loss = 0.7670573154166768\n",
      "Mean abs grad value: 0.008948072735185655\tMax abs grad value: 0.3852981835633888\n",
      "Loss = 0.42742999716592184\n",
      "Train accuracy: 0.860\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.007102551888895159\tMax abs grad value: 0.32551262589415003\n",
      "Loss = 0.3911738936301395\n",
      "Train accuracy: 0.874\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.0061138870800382114\tMax abs grad value: 0.23719706740357616\n",
      "Loss = 0.3169433684525993\n",
      "Train accuracy: 0.900\t\tTest accuracy: 0.882\n",
      "Mean abs grad value: 0.014748407320846856\tMax abs grad value: 0.4098764554527688\n",
      "Loss = 0.29891890904523716\n",
      "Train accuracy: 0.889\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.005728168619021948\tMax abs grad value: 0.12916587086159448\n",
      "Loss = 0.2551979652397522\n",
      "Train accuracy: 0.910\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.00412423442719259\tMax abs grad value: 0.07793081966330331\n",
      "Loss = 0.2418144480569791\n",
      "Train accuracy: 0.917\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.004739610816663016\tMax abs grad value: 0.1147049958266888\n",
      "Loss = 0.22110024667953845\n",
      "Train accuracy: 0.927\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.007434265901890949\tMax abs grad value: 0.2524199921857809\n",
      "Loss = 0.1919728575689004\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.004602673455548233\tMax abs grad value: 0.14217622974797614\n",
      "Loss = 0.1730471673131847\n",
      "Train accuracy: 0.942\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.002741912853091031\tMax abs grad value: 0.05425563417815458\n",
      "Loss = 0.16136132843431275\n",
      "Train accuracy: 0.949\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.002616534434585307\tMax abs grad value: 0.07137850671098901\n",
      "Loss = 0.1500830824631025\n",
      "Train accuracy: 0.950\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.00563106872998366\tMax abs grad value: 0.13000251619047443\n",
      "Loss = 0.14007434429686563\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.0023789609187274937\tMax abs grad value: 0.04496543140787776\n",
      "Loss = 0.12842068016353939\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0024330114559640843\tMax abs grad value: 0.05875200881466739\n",
      "Loss = 0.12123569768431264\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.00346673052249036\tMax abs grad value: 0.0855256821280415\n",
      "Loss = 0.10961941663195414\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.003132056417569314\tMax abs grad value: 0.10061096885873268\n",
      "Loss = 0.09655101493290011\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.006753174558772481\tMax abs grad value: 0.20976584834880874\n",
      "Loss = 0.09635573355611432\n",
      "Mean abs grad value: 0.003729597221029913\tMax abs grad value: 0.11354382183336369\n",
      "Loss = 0.08819451697421408\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0022142891711462616\tMax abs grad value: 0.05064537167675644\n",
      "Loss = 0.07856453601252704\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0021652907391980975\tMax abs grad value: 0.0420247463743702\n",
      "Loss = 0.07196583636681973\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0022680241980004797\tMax abs grad value: 0.03938273317382612\n",
      "Loss = 0.06611124246952015\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.004342592203835931\tMax abs grad value: 0.11815838843310697\n",
      "Loss = 0.06020079990151311\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0016926243580098713\tMax abs grad value: 0.03767908930962056\n",
      "Loss = 0.051891339305990304\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0013277383682020686\tMax abs grad value: 0.039770471574733963\n",
      "Loss = 0.049091637653205684\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001826492630601337\tMax abs grad value: 0.03891076325276356\n",
      "Loss = 0.04409463940290465\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.002140049971457897\tMax abs grad value: 0.04572711153356704\n",
      "Loss = 0.03795066781596533\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0013789298636799618\tMax abs grad value: 0.02095505175462251\n",
      "Loss = 0.03221094171774639\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0013867350174747752\tMax abs grad value: 0.025860205460592325\n",
      "Loss = 0.02932037947346905\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0011558787370915078\tMax abs grad value: 0.02578412387803817\n",
      "Loss = 0.023952952014482724\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0019327584686351191\tMax abs grad value: 0.03892455163110064\n",
      "Loss = 0.019720112456956224\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.001804610906413047\tMax abs grad value: 0.064488727563976\n",
      "Loss = 0.017609857392794023\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0009934693939648172\tMax abs grad value: 0.01925178270322497\n",
      "Loss = 0.01571798654420305\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0008021594169533641\tMax abs grad value: 0.01656108967276748\n",
      "Loss = 0.013954776632277191\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0008784605562692198\tMax abs grad value: 0.01794008859231042\n",
      "Loss = 0.012203829246536254\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.001371043746887349\tMax abs grad value: 0.03203281172976906\n",
      "Loss = 0.010360015177965498\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0011223912283366082\tMax abs grad value: 0.03831242364201322\n",
      "Loss = 0.00879927756877556\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00044532115482014264\tMax abs grad value: 0.011058006401688797\n",
      "Loss = 0.007771124377484023\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0004191060238082175\tMax abs grad value: 0.016449019138844376\n",
      "Loss = 0.007229951555305368\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0004286069169872844\tMax abs grad value: 0.020568977178551322\n",
      "Loss = 0.006767107164636512\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0010389321865061547\tMax abs grad value: 0.028885491950502114\n",
      "Loss = 0.00617723346556966\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0003990342356247889\tMax abs grad value: 0.011400567278575016\n",
      "Loss = 0.005203215058580377\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00035202895027166826\tMax abs grad value: 0.008144777319303529\n",
      "Loss = 0.004516311828366864\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0004723058765457655\tMax abs grad value: 0.014951225796098004\n",
      "Loss = 0.0035715134511703525\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0010105090502634192\tMax abs grad value: 0.045770930182164785\n",
      "Loss = 0.0030497903094401416\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0004957727527260784\tMax abs grad value: 0.017310364208808268\n",
      "Loss = 0.0022197367292169806\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0003377534267528855\tMax abs grad value: 0.007947579941996252\n",
      "Loss = 0.0020050692581870524\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0002408712410335312\tMax abs grad value: 0.006885680258857495\n",
      "Loss = 0.001709414224133147\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0002486679068195346\tMax abs grad value: 0.007223779040055212\n",
      "Loss = 0.0014602296780476635\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0002812963187040592\tMax abs grad value: 0.006988086522153176\n",
      "Loss = 0.0010837979684490413\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0002092602327806483\tMax abs grad value: 0.0054026643350176574\n",
      "Loss = 0.0007416137699334433\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00010826179674863441\tMax abs grad value: 0.0024719483101085034\n",
      "Loss = 0.0004978771856898681\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 8.495443002281259e-05\tMax abs grad value: 0.003138923906889295\n",
      "Loss = 0.0003516708792614364\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 5.016319879952261e-05\tMax abs grad value: 0.0013445042011472031\n",
      "Loss = 0.0002002878466432318\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 2.545795181185856e-05\tMax abs grad value: 0.0004876755489553016\n",
      "Loss = 0.00012759793910061513\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.965843081737823e-05\tMax abs grad value: 0.0003118493123691098\n",
      "Loss = 8.69095063632277e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 4.585598113823831e-05\tMax abs grad value: 0.0011267602067560835\n",
      "Loss = 6.271720270402227e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.4519262587189186e-05\tMax abs grad value: 0.0002922704336493031\n",
      "Loss = 3.8122530122076647e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.1541042877728386e-05\tMax abs grad value: 0.00024390386485286498\n",
      "Loss = 3.194592643013575e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 6.274375802547619e-06\tMax abs grad value: 0.00013774887283160054\n",
      "Loss = 2.0056375439318176e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 7.533710636649847e-06\tMax abs grad value: 0.00018788829712858138\n",
      "Loss = 1.1744661907842193e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 3.5620201285595298e-06\tMax abs grad value: 8.684890236679684e-05\n",
      "Loss = 7.633444291949022e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 2.3579480634544724e-06\tMax abs grad value: 5.825606914680935e-05\n",
      "Loss = 4.936755859437082e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.0944733728597334e-06\tMax abs grad value: 3.1902917108944106e-05\n",
      "Loss = 2.779194762454925e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 7.851454683298382e-07\tMax abs grad value: 1.7480447628869056e-05\n",
      "Loss = 1.534727127781e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 9.516292921880554e-07\tMax abs grad value: 2.2064115595626943e-05\n",
      "Loss = 9.036816865792533e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 3.066005907620905e-07\tMax abs grad value: 6.446448660715073e-06\n",
      "Loss = 4.6622442326348935e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.07566136875672227\tMax abs grad value: 2.577688908495746\n",
      "Loss = 3.193147163610026\n",
      "Mean abs grad value: 0.011376749953163847\tMax abs grad value: 0.23611846982309334\n",
      "Loss = 2.2657913785028705\n",
      "Train accuracy: 0.218\t\tTest accuracy: 0.200\n",
      "Mean abs grad value: 0.01073350724882883\tMax abs grad value: 0.22592390654702066\n",
      "Loss = 2.1253642876372147\n",
      "Train accuracy: 0.359\t\tTest accuracy: 0.324\n",
      "Mean abs grad value: 0.014811858593443371\tMax abs grad value: 0.2658021034694253\n",
      "Loss = 1.8804073349949089\n",
      "Train accuracy: 0.405\t\tTest accuracy: 0.384\n",
      "Mean abs grad value: 0.018496055334516422\tMax abs grad value: 0.4838123010761355\n",
      "Loss = 1.364182265728751\n",
      "Train accuracy: 0.637\t\tTest accuracy: 0.587\n",
      "Mean abs grad value: 0.08077635562457461\tMax abs grad value: 2.253404352601435\n",
      "Loss = 1.6807717990842481\n",
      "Mean abs grad value: 0.019386449039858953\tMax abs grad value: 0.5856474676440265\n",
      "Loss = 1.1084668569703715\n",
      "Train accuracy: 0.627\t\tTest accuracy: 0.604\n",
      "Mean abs grad value: 0.02329583713673081\tMax abs grad value: 0.6143112186764481\n",
      "Loss = 0.9606782564656591\n",
      "Train accuracy: 0.656\t\tTest accuracy: 0.629\n",
      "Mean abs grad value: 0.011188976730651584\tMax abs grad value: 0.2506528715115168\n",
      "Loss = 0.8481264708132976\n",
      "Train accuracy: 0.702\t\tTest accuracy: 0.689\n",
      "Mean abs grad value: 0.012729392564910024\tMax abs grad value: 0.3135616777215318\n",
      "Loss = 0.759618821467369\n",
      "Train accuracy: 0.754\t\tTest accuracy: 0.744\n",
      "Mean abs grad value: 0.015479228291995654\tMax abs grad value: 0.38165938665237265\n",
      "Loss = 0.6377456094041216\n",
      "Train accuracy: 0.791\t\tTest accuracy: 0.787\n",
      "Mean abs grad value: 0.022853566042712672\tMax abs grad value: 0.7283477563412701\n",
      "Loss = 0.5298474399170658\n",
      "Train accuracy: 0.826\t\tTest accuracy: 0.820\n",
      "Mean abs grad value: 0.010553138060618994\tMax abs grad value: 0.3168430477396911\n",
      "Loss = 0.4259290981884194\n",
      "Train accuracy: 0.872\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.007354273018066355\tMax abs grad value: 0.17539499699993996\n",
      "Loss = 0.3992480274371074\n",
      "Train accuracy: 0.891\t\tTest accuracy: 0.856\n",
      "Mean abs grad value: 0.0064677274307889925\tMax abs grad value: 0.16039912052608085\n",
      "Loss = 0.37480399894956473\n",
      "Train accuracy: 0.893\t\tTest accuracy: 0.856\n",
      "Mean abs grad value: 0.007042081576932794\tMax abs grad value: 0.17106329513811983\n",
      "Loss = 0.33254764621664273\n",
      "Train accuracy: 0.905\t\tTest accuracy: 0.860\n",
      "Mean abs grad value: 0.018752867104951294\tMax abs grad value: 0.7035634097021118\n",
      "Loss = 0.333778827264804\n",
      "Mean abs grad value: 0.00874999218047674\tMax abs grad value: 0.3629506625170544\n",
      "Loss = 0.3091346293604129\n",
      "Train accuracy: 0.903\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.006069786483129866\tMax abs grad value: 0.14684482350056702\n",
      "Loss = 0.28453383158011025\n",
      "Train accuracy: 0.912\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.005138697007129628\tMax abs grad value: 0.11387626930057483\n",
      "Loss = 0.2631420087784197\n",
      "Train accuracy: 0.922\t\tTest accuracy: 0.882\n",
      "Mean abs grad value: 0.005848661059497325\tMax abs grad value: 0.17113233633072256\n",
      "Loss = 0.2359421216571307\n",
      "Train accuracy: 0.924\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.010768997996297828\tMax abs grad value: 0.2986699935249313\n",
      "Loss = 0.20096849574622638\n",
      "Train accuracy: 0.936\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.004587935540835986\tMax abs grad value: 0.08952982597789629\n",
      "Loss = 0.16766244878210756\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.002964912466395484\tMax abs grad value: 0.09528231524757269\n",
      "Loss = 0.1554092334223688\n",
      "Train accuracy: 0.948\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.0029998942494225914\tMax abs grad value: 0.05762373079164765\n",
      "Loss = 0.1439806792027201\n",
      "Train accuracy: 0.950\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.0039167171940634295\tMax abs grad value: 0.08172241279403879\n",
      "Loss = 0.13082108477523832\n",
      "Train accuracy: 0.962\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.003734883023877512\tMax abs grad value: 0.10959450159964618\n",
      "Loss = 0.11845402743982235\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.003011213296032882\tMax abs grad value: 0.05932119305831482\n",
      "Loss = 0.10730193778907175\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.00483752630084906\tMax abs grad value: 0.17970832592766148\n",
      "Loss = 0.09930814846973005\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0033832565825250138\tMax abs grad value: 0.09373686342422587\n",
      "Loss = 0.09238066306952614\n",
      "Train accuracy: 0.965\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.002995068036588307\tMax abs grad value: 0.06711247791171353\n",
      "Loss = 0.08804706688397822\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.004243729587287155\tMax abs grad value: 0.1409002190365593\n",
      "Loss = 0.07677842525287144\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.003971313635644585\tMax abs grad value: 0.08644486874172214\n",
      "Loss = 0.06941098063385188\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0017593488075243178\tMax abs grad value: 0.03187035387512528\n",
      "Loss = 0.0649387349844891\n",
      "Train accuracy: 0.980\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0014932308185876533\tMax abs grad value: 0.028810074721429376\n",
      "Loss = 0.06296261903155609\n",
      "Train accuracy: 0.980\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.001636108278828683\tMax abs grad value: 0.03328886066081898\n",
      "Loss = 0.06035257267186818\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.002591274850072334\tMax abs grad value: 0.0755308532798501\n",
      "Loss = 0.05272389667532689\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.00320167199114129\tMax abs grad value: 0.06883072573691751\n",
      "Loss = 0.04544389881875262\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0024390897291004165\tMax abs grad value: 0.10409325914293932\n",
      "Loss = 0.03925074157756122\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.001341010871033292\tMax abs grad value: 0.03167579449941466\n",
      "Loss = 0.035744378074681726\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0014174986852629721\tMax abs grad value: 0.03218160341166374\n",
      "Loss = 0.03404542198301894\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0013333926872896057\tMax abs grad value: 0.030994639470864237\n",
      "Loss = 0.031378105445087505\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0012026680261125091\tMax abs grad value: 0.025790561727313827\n",
      "Loss = 0.027552197154186463\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0013616050778445493\tMax abs grad value: 0.025014749156705682\n",
      "Loss = 0.022040591740567033\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.002519416753148304\tMax abs grad value: 0.07142341494553305\n",
      "Loss = 0.019637065352651393\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0013024016493948507\tMax abs grad value: 0.024169894407207626\n",
      "Loss = 0.016540870902024673\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0011640646338799316\tMax abs grad value: 0.02402848662772827\n",
      "Loss = 0.014880125442875982\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.00111913296162858\tMax abs grad value: 0.025542006123428038\n",
      "Loss = 0.012250676335665765\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0012519978067977173\tMax abs grad value: 0.03595633134782684\n",
      "Loss = 0.009913253086362551\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.001643979917098249\tMax abs grad value: 0.05236158132684836\n",
      "Loss = 0.008224834340462311\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0006803895497056078\tMax abs grad value: 0.01393600399579208\n",
      "Loss = 0.007126323267142561\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0006742198417958329\tMax abs grad value: 0.01517992405768305\n",
      "Loss = 0.006768363166427102\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0005621425370531923\tMax abs grad value: 0.01198732539616589\n",
      "Loss = 0.005774765047416722\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.001241987569241201\tMax abs grad value: 0.024889293148542106\n",
      "Loss = 0.004787370029216506\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0006878445058696106\tMax abs grad value: 0.01465698428156579\n",
      "Loss = 0.0035017624447797207\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00042542291575266197\tMax abs grad value: 0.008061943494631015\n",
      "Loss = 0.0028714492170055705\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00042542371145365247\tMax abs grad value: 0.01104713993139023\n",
      "Loss = 0.0022021985680036535\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00029351510830586303\tMax abs grad value: 0.006397777799287027\n",
      "Loss = 0.0016856162314923255\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0002608759804698757\tMax abs grad value: 0.0056293752761985005\n",
      "Loss = 0.0012083916104588103\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0004253817494524743\tMax abs grad value: 0.01738924171242363\n",
      "Loss = 0.0009767898382469253\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00021164003952070818\tMax abs grad value: 0.006482856570044316\n",
      "Loss = 0.0007880440783800442\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00017261402269364327\tMax abs grad value: 0.003063073041181655\n",
      "Loss = 0.0006819791392314642\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00016564532007955928\tMax abs grad value: 0.003113284838864623\n",
      "Loss = 0.0005340226206703464\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0002783297348566683\tMax abs grad value: 0.007880610298321905\n",
      "Loss = 0.00045060126990946096\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00014522085852921495\tMax abs grad value: 0.003521952749803264\n",
      "Loss = 0.0003379312126236593\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 8.418443820846689e-05\tMax abs grad value: 0.001683940373024512\n",
      "Loss = 0.0002454655261431762\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 4.3049520544737625e-05\tMax abs grad value: 0.0006365095392859222\n",
      "Loss = 0.00017272119161773462\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.367627833737526e-05\tMax abs grad value: 0.0005883639933542305\n",
      "Loss = 0.0001274794285588197\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0001340076758960778\tMax abs grad value: 0.0047089991203693275\n",
      "Loss = 0.00013275520269871914\n",
      "Mean abs grad value: 5.4812213675957634e-05\tMax abs grad value: 0.0017132478118275056\n",
      "Loss = 0.00010859799988333625\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.53883296527587e-05\tMax abs grad value: 0.0005314924451651573\n",
      "Loss = 7.800735062108673e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.8471180057100892e-05\tMax abs grad value: 0.0003110870081199285\n",
      "Loss = 6.235611659432179e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.1404031915078575e-05\tMax abs grad value: 0.00047869126670192427\n",
      "Loss = 4.207192483257293e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.1985556994089118e-05\tMax abs grad value: 0.0005370669287758049\n",
      "Loss = 2.5422595977760884e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 7.60860333006073e-06\tMax abs grad value: 0.00017103129490401363\n",
      "Loss = 1.8708663274726698e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 4.535180246866853e-06\tMax abs grad value: 7.504424957613402e-05\n",
      "Loss = 1.0974996671423629e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 3.4734524064008077e-06\tMax abs grad value: 7.333834834898192e-05\n",
      "Loss = 5.974683246175865e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.2495054260572544e-06\tMax abs grad value: 2.5517097556869446e-05\n",
      "Loss = 3.0365815596209463e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 8.018317447827313e-07\tMax abs grad value: 1.2355233889277372e-05\n",
      "Loss = 2.1141038355972394e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 6.108255206812608e-07\tMax abs grad value: 1.391490855707647e-05\n",
      "Loss = 1.3005351271259033e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.5493446679751484e-07\tMax abs grad value: 3.959361478596039e-06\n",
      "Loss = 7.914658559329215e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.033705398774142\tMax abs grad value: 1.067541867356528\n",
      "Loss = 2.698043807785197\n",
      "Mean abs grad value: 0.005866417106108223\tMax abs grad value: 0.38411211696338493\n",
      "Loss = 2.254940780603179\n",
      "Train accuracy: 0.204\t\tTest accuracy: 0.156\n",
      "Mean abs grad value: 0.009301620550594395\tMax abs grad value: 0.43997431541988613\n",
      "Loss = 2.147912882212177\n",
      "Train accuracy: 0.182\t\tTest accuracy: 0.189\n",
      "Mean abs grad value: 0.008922151317093679\tMax abs grad value: 0.31295417261613934\n",
      "Loss = 2.0320335998787535\n",
      "Train accuracy: 0.279\t\tTest accuracy: 0.262\n",
      "Mean abs grad value: 0.025480757244377004\tMax abs grad value: 0.859411367652136\n",
      "Loss = 1.934913427394301\n",
      "Train accuracy: 0.316\t\tTest accuracy: 0.296\n",
      "Mean abs grad value: 0.014071776097749148\tMax abs grad value: 0.22163684313000995\n",
      "Loss = 1.6944351986832658\n",
      "Train accuracy: 0.434\t\tTest accuracy: 0.413\n",
      "Mean abs grad value: 0.013437609770308384\tMax abs grad value: 0.37732762724861096\n",
      "Loss = 1.4271272842085336\n",
      "Train accuracy: 0.533\t\tTest accuracy: 0.524\n",
      "Mean abs grad value: 0.017673423344961463\tMax abs grad value: 0.6679278019705952\n",
      "Loss = 1.2600034850123543\n",
      "Train accuracy: 0.554\t\tTest accuracy: 0.549\n",
      "Mean abs grad value: 0.01578107353757549\tMax abs grad value: 0.7851461772784505\n",
      "Loss = 0.9873270766009308\n",
      "Train accuracy: 0.668\t\tTest accuracy: 0.642\n",
      "Mean abs grad value: 0.06168607064702138\tMax abs grad value: 2.986477071929795\n",
      "Loss = 1.2815043498193728\n",
      "Mean abs grad value: 0.01167057168394568\tMax abs grad value: 0.4543601689100995\n",
      "Loss = 0.7910595953697689\n",
      "Train accuracy: 0.748\t\tTest accuracy: 0.707\n",
      "Mean abs grad value: 0.011586896935262766\tMax abs grad value: 0.2395707340021497\n",
      "Loss = 0.717960058300276\n",
      "Train accuracy: 0.767\t\tTest accuracy: 0.758\n",
      "Mean abs grad value: 0.009924611663384613\tMax abs grad value: 0.19479483943115886\n",
      "Loss = 0.6472488607914707\n",
      "Train accuracy: 0.782\t\tTest accuracy: 0.751\n",
      "Mean abs grad value: 0.010054006442327838\tMax abs grad value: 0.25176390899294104\n",
      "Loss = 0.5382014482607371\n",
      "Train accuracy: 0.837\t\tTest accuracy: 0.807\n",
      "Mean abs grad value: 0.008720437351449629\tMax abs grad value: 0.28216794739333484\n",
      "Loss = 0.45966301454585323\n",
      "Train accuracy: 0.852\t\tTest accuracy: 0.838\n",
      "Mean abs grad value: 0.0065475209322874844\tMax abs grad value: 0.16801306477695516\n",
      "Loss = 0.3954456927368016\n",
      "Train accuracy: 0.875\t\tTest accuracy: 0.856\n",
      "Mean abs grad value: 0.0055573753175926464\tMax abs grad value: 0.11834911000217149\n",
      "Loss = 0.36053598108953655\n",
      "Train accuracy: 0.886\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.005411504823609782\tMax abs grad value: 0.16473564339397892\n",
      "Loss = 0.3219593362924777\n",
      "Train accuracy: 0.890\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.007229663184149126\tMax abs grad value: 0.24320475978608683\n",
      "Loss = 0.2993572062193514\n",
      "Train accuracy: 0.904\t\tTest accuracy: 0.898\n",
      "Mean abs grad value: 0.004387651534039986\tMax abs grad value: 0.13069127533786784\n",
      "Loss = 0.2730571900686194\n",
      "Train accuracy: 0.911\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.004329544730334178\tMax abs grad value: 0.10057602971053063\n",
      "Loss = 0.24520659137410936\n",
      "Train accuracy: 0.911\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.004589973550918191\tMax abs grad value: 0.13457340699410372\n",
      "Loss = 0.2252549627032498\n",
      "Train accuracy: 0.917\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.01193421357935183\tMax abs grad value: 0.4385437504291391\n",
      "Loss = 0.21890749805899587\n",
      "Train accuracy: 0.927\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.003912323686271981\tMax abs grad value: 0.1003727602143142\n",
      "Loss = 0.17642246945571277\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.002974064313601918\tMax abs grad value: 0.07244034962516722\n",
      "Loss = 0.16468775301417626\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0032574706740658003\tMax abs grad value: 0.11433473026199845\n",
      "Loss = 0.14661942076378773\n",
      "Train accuracy: 0.951\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.004055790657221669\tMax abs grad value: 0.1012979639602946\n",
      "Loss = 0.12272136075936162\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0035841836123427047\tMax abs grad value: 0.09632801893475149\n",
      "Loss = 0.10067173519953831\n",
      "Train accuracy: 0.962\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0025298211321883\tMax abs grad value: 0.05901565649811685\n",
      "Loss = 0.0905243015081199\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0027187399461195186\tMax abs grad value: 0.05578266820272619\n",
      "Loss = 0.08045572831004484\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.002776443860943324\tMax abs grad value: 0.08075780716274507\n",
      "Loss = 0.06714062872256552\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.011331635194822377\tMax abs grad value: 0.39629151299357984\n",
      "Loss = 0.08836127992570063\n",
      "Mean abs grad value: 0.004122968701896807\tMax abs grad value: 0.09457932326014781\n",
      "Loss = 0.06218608345278613\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0019982081561167393\tMax abs grad value: 0.06418359999191335\n",
      "Loss = 0.052583666154636825\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0014288055600729793\tMax abs grad value: 0.02251123335210309\n",
      "Loss = 0.04736354004601187\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0015746849755011471\tMax abs grad value: 0.030769594057503714\n",
      "Loss = 0.04157474564665557\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0022480567397684366\tMax abs grad value: 0.07556474368544475\n",
      "Loss = 0.034345358604150306\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0020747485768068934\tMax abs grad value: 0.07578120789753341\n",
      "Loss = 0.02907483105119028\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0015978905530375375\tMax abs grad value: 0.048819949607637365\n",
      "Loss = 0.02567897235099709\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0012161672405481467\tMax abs grad value: 0.027377304407028354\n",
      "Loss = 0.023573090102004503\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0009571093752239209\tMax abs grad value: 0.019393420979681997\n",
      "Loss = 0.020984258365904698\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0008930592906519432\tMax abs grad value: 0.016826634381552196\n",
      "Loss = 0.01814077559823912\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.002346117617857373\tMax abs grad value: 0.0805015032602721\n",
      "Loss = 0.017053464853209896\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0008924775610115718\tMax abs grad value: 0.028904906276958\n",
      "Loss = 0.013836086502011503\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0006689908093571377\tMax abs grad value: 0.01699176682696864\n",
      "Loss = 0.012468764891161272\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0008043551291180647\tMax abs grad value: 0.0228857687514577\n",
      "Loss = 0.010760440489247843\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0007984888804387741\tMax abs grad value: 0.021681235407125233\n",
      "Loss = 0.009303862858993869\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0007074599414816067\tMax abs grad value: 0.01731170788049061\n",
      "Loss = 0.007735710144542062\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0004913032333516996\tMax abs grad value: 0.012392246437936823\n",
      "Loss = 0.006682862316392943\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0005961978765804648\tMax abs grad value: 0.01841922755119039\n",
      "Loss = 0.005814915686325313\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.0006835851168365637\tMax abs grad value: 0.024617177856485945\n",
      "Loss = 0.004752330336806242\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.0015662125389590978\tMax abs grad value: 0.060250381506697426\n",
      "Loss = 0.004891904281265054\n",
      "Mean abs grad value: 0.0007078957025024016\tMax abs grad value: 0.03129407058687968\n",
      "Loss = 0.0041852271586065495\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.0004349180656844273\tMax abs grad value: 0.01601352453997085\n",
      "Loss = 0.003343730658638195\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.000252766580152862\tMax abs grad value: 0.007924020554287422\n",
      "Loss = 0.0027833048840901096\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 0.0002492990386355906\tMax abs grad value: 0.005157924515029672\n",
      "Loss = 0.0023101883725668874\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.973\n",
      "Mean abs grad value: 0.0002855283745112894\tMax abs grad value: 0.007842903723960045\n",
      "Loss = 0.001936670279070975\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.00031274295769997225\tMax abs grad value: 0.01092128698818995\n",
      "Loss = 0.0011865671343596787\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.971\n",
      "Mean abs grad value: 0.00023770820915452982\tMax abs grad value: 0.005386273910505791\n",
      "Loss = 0.0007966741168667037\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0001250209594511006\tMax abs grad value: 0.002873416115898298\n",
      "Loss = 0.0006534961239407904\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 8.806512547331306e-05\tMax abs grad value: 0.0015143066898764134\n",
      "Loss = 0.000561555467393971\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 7.399715886864074e-05\tMax abs grad value: 0.0012742847560294444\n",
      "Loss = 0.0004712778497517469\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 9.711860504208241e-05\tMax abs grad value: 0.001954249796838979\n",
      "Loss = 0.00035552532125754626\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 7.916203061462332e-05\tMax abs grad value: 0.002919184351836188\n",
      "Loss = 0.0002449422617864005\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.7573997961772174e-05\tMax abs grad value: 0.0013204321147154837\n",
      "Loss = 0.00016942199246289708\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 2.582322090591646e-05\tMax abs grad value: 0.0005769773379988889\n",
      "Loss = 0.00012611677529263333\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.2062523833822134e-05\tMax abs grad value: 0.0004759793427177129\n",
      "Loss = 8.741242082684956e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.383120676994991e-05\tMax abs grad value: 0.0005349489873239503\n",
      "Loss = 5.717211867115341e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.5259543026167575e-05\tMax abs grad value: 0.00028753318204651846\n",
      "Loss = 3.953428879872104e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.0019177681560437e-05\tMax abs grad value: 0.00018771008209667706\n",
      "Loss = 2.3674023452673737e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 6.297930945156274e-06\tMax abs grad value: 0.00013999158258262676\n",
      "Loss = 1.4424051707438847e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 2.8176678562112013e-06\tMax abs grad value: 5.092698554400175e-05\n",
      "Loss = 8.972558752068846e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.8012017792832374e-06\tMax abs grad value: 3.736599141788766e-05\n",
      "Loss = 5.444822184640834e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 4.032304456208595e-06\tMax abs grad value: 0.0001372351594134093\n",
      "Loss = 4.7021337816542346e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.0874175004561017e-06\tMax abs grad value: 3.093259462710885e-05\n",
      "Loss = 2.2525302986872085e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 7.545251856578322e-07\tMax abs grad value: 2.0707509181992797e-05\n",
      "Loss = 1.7071153092564639e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 4.977590659551608e-07\tMax abs grad value: 1.1621561972162073e-05\n",
      "Loss = 1.0763235297805077e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 3.3269774621057936e-07\tMax abs grad value: 7.776453804812374e-06\n",
      "Loss = 6.832521207321965e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.04028579610347639\tMax abs grad value: 1.242556715342192\n",
      "Loss = 2.8804039108778983\n",
      "Mean abs grad value: 0.015280138562069428\tMax abs grad value: 0.5518148877929144\n",
      "Loss = 2.4900055844760725\n",
      "Train accuracy: 0.159\t\tTest accuracy: 0.156\n",
      "Mean abs grad value: 0.007624786909977838\tMax abs grad value: 0.17454302011678524\n",
      "Loss = 2.1862684174597184\n",
      "Train accuracy: 0.215\t\tTest accuracy: 0.211\n",
      "Mean abs grad value: 0.00787679019061718\tMax abs grad value: 0.1639080258520106\n",
      "Loss = 2.0764566479153777\n",
      "Mean abs grad value: 0.01777475143594693\tMax abs grad value: 0.5498855877243083\n",
      "Loss = 1.970225128294306\n",
      "Train accuracy: 0.251\t\tTest accuracy: 0.253\n",
      "Mean abs grad value: 0.011146377536459895\tMax abs grad value: 0.21597203247756708\n",
      "Loss = 1.7401232361489045\n",
      "Train accuracy: 0.565\t\tTest accuracy: 0.582\n",
      "Mean abs grad value: 0.016290199731145576\tMax abs grad value: 0.31399897787215486\n",
      "Loss = 1.492195597844566\n",
      "Train accuracy: 0.607\t\tTest accuracy: 0.607\n",
      "Mean abs grad value: 0.05480165086065789\tMax abs grad value: 1.9846274127511685\n",
      "Loss = 2.031512695820275\n",
      "Mean abs grad value: 0.01600645533706556\tMax abs grad value: 0.3558479423022247\n",
      "Loss = 1.3010110730046631\n",
      "Train accuracy: 0.575\t\tTest accuracy: 0.536\n",
      "Mean abs grad value: 0.015437816474556509\tMax abs grad value: 0.3370230663452425\n",
      "Loss = 1.0514446636970536\n",
      "Train accuracy: 0.666\t\tTest accuracy: 0.631\n",
      "Mean abs grad value: 0.03290811876059578\tMax abs grad value: 1.0247615435376813\n",
      "Loss = 0.9534506499846862\n",
      "Mean abs grad value: 0.010304102725953739\tMax abs grad value: 0.3933556715830364\n",
      "Loss = 0.7354310241293087\n",
      "Train accuracy: 0.764\t\tTest accuracy: 0.720\n",
      "Mean abs grad value: 0.015851657333663817\tMax abs grad value: 0.5843792903415667\n",
      "Loss = 0.6581791084388\n",
      "Train accuracy: 0.773\t\tTest accuracy: 0.771\n",
      "Mean abs grad value: 0.006418991904908997\tMax abs grad value: 0.10821229843683922\n",
      "Loss = 0.5743278875629052\n",
      "Train accuracy: 0.815\t\tTest accuracy: 0.787\n",
      "Mean abs grad value: 0.006096867379557454\tMax abs grad value: 0.1264815170373071\n",
      "Loss = 0.5291160766196473\n",
      "Train accuracy: 0.838\t\tTest accuracy: 0.813\n",
      "Mean abs grad value: 0.007889000776116005\tMax abs grad value: 0.2388291874954905\n",
      "Loss = 0.4616518657365882\n",
      "Train accuracy: 0.846\t\tTest accuracy: 0.840\n",
      "Mean abs grad value: 0.012179108634177234\tMax abs grad value: 0.5478576211226315\n",
      "Loss = 0.421933550917653\n",
      "Train accuracy: 0.863\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.005559128989241799\tMax abs grad value: 0.15520945139900658\n",
      "Loss = 0.3798256955954517\n",
      "Train accuracy: 0.877\t\tTest accuracy: 0.869\n",
      "Mean abs grad value: 0.005238769242782055\tMax abs grad value: 0.14908390004230157\n",
      "Loss = 0.3529020754906334\n",
      "Train accuracy: 0.891\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.00602703006312237\tMax abs grad value: 0.16702253122669855\n",
      "Loss = 0.32523751946977614\n",
      "Train accuracy: 0.896\t\tTest accuracy: 0.873\n",
      "Mean abs grad value: 0.006796144418125623\tMax abs grad value: 0.19528567174663009\n",
      "Loss = 0.2964150509945055\n",
      "Train accuracy: 0.906\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.005133011135594336\tMax abs grad value: 0.19913173799346487\n",
      "Loss = 0.26648424426531453\n",
      "Train accuracy: 0.918\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.00455014938371083\tMax abs grad value: 0.14424984788001505\n",
      "Loss = 0.24033097913162055\n",
      "Train accuracy: 0.928\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.004463817784123282\tMax abs grad value: 0.09024151738865628\n",
      "Loss = 0.21852118715808067\n",
      "Train accuracy: 0.933\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.004954137300147057\tMax abs grad value: 0.1921048859331378\n",
      "Loss = 0.19358913456766297\n",
      "Train accuracy: 0.940\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.004164806120293656\tMax abs grad value: 0.0908515367772849\n",
      "Loss = 0.17299645263915597\n",
      "Train accuracy: 0.946\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.0027156656355480147\tMax abs grad value: 0.05368002493637148\n",
      "Loss = 0.15386812321391788\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0029294638282531755\tMax abs grad value: 0.07359291126838417\n",
      "Loss = 0.13656062514895875\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0039950866346013\tMax abs grad value: 0.07890218785908638\n",
      "Loss = 0.11570742032048818\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002246957329409466\tMax abs grad value: 0.05092620286771559\n",
      "Loss = 0.09656551937207773\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002493814213909475\tMax abs grad value: 0.05671739553639318\n",
      "Loss = 0.0848606993284066\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0039333369859045255\tMax abs grad value: 0.10476609178688485\n",
      "Loss = 0.07687636828502692\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.001969988014312391\tMax abs grad value: 0.03969535794118095\n",
      "Loss = 0.0687571830223953\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0018053740149332055\tMax abs grad value: 0.04638360765555944\n",
      "Loss = 0.06208355170515072\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0025675280926102575\tMax abs grad value: 0.07785374391075535\n",
      "Loss = 0.05475707219864821\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0021789837774987275\tMax abs grad value: 0.04810681914072652\n",
      "Loss = 0.04758318486996778\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0016655900980722196\tMax abs grad value: 0.03525140558119308\n",
      "Loss = 0.041713695863938145\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002843971589033876\tMax abs grad value: 0.11767320171469729\n",
      "Loss = 0.036217642724832695\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0013262214011175138\tMax abs grad value: 0.03247569877063667\n",
      "Loss = 0.03194027444872215\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0012678044517077294\tMax abs grad value: 0.023133193651025532\n",
      "Loss = 0.030440736082976\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.001356739909369058\tMax abs grad value: 0.033378318230617446\n",
      "Loss = 0.026908878816927582\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0014989713619054045\tMax abs grad value: 0.03574827153958053\n",
      "Loss = 0.023336373760394415\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.002902944117236279\tMax abs grad value: 0.10163863679091063\n",
      "Loss = 0.021223542947285914\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0008534714753970223\tMax abs grad value: 0.018418875206953556\n",
      "Loss = 0.01700457362859731\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0007266967281139196\tMax abs grad value: 0.016011057027677748\n",
      "Loss = 0.016027700046322674\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0007475773550844272\tMax abs grad value: 0.017092361434210807\n",
      "Loss = 0.01438704746822\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.001026528739850993\tMax abs grad value: 0.02908189673173369\n",
      "Loss = 0.011982895577189097\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0016347969634852905\tMax abs grad value: 0.04072569411400556\n",
      "Loss = 0.010116680869657004\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0006586959987764761\tMax abs grad value: 0.015488175732343696\n",
      "Loss = 0.008212902742308908\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.000547107440339937\tMax abs grad value: 0.009819739664921952\n",
      "Loss = 0.007154007178552835\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0005305566074957795\tMax abs grad value: 0.00944131245219758\n",
      "Loss = 0.006085198162624538\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001725291487763659\tMax abs grad value: 0.0775857479683268\n",
      "Loss = 0.005740326720427225\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0004568336398479292\tMax abs grad value: 0.011723034853604913\n",
      "Loss = 0.004248896799099924\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00032986425705972276\tMax abs grad value: 0.006285591336195825\n",
      "Loss = 0.003971462767212008\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00031436678335074213\tMax abs grad value: 0.007553443694156037\n",
      "Loss = 0.0034899059626851427\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0005306971160676445\tMax abs grad value: 0.01979597878976181\n",
      "Loss = 0.0027866082118529634\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.000285371023571975\tMax abs grad value: 0.007329821306265675\n",
      "Loss = 0.0022660511631262224\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0002307956382504115\tMax abs grad value: 0.005031479976323746\n",
      "Loss = 0.001962779792783139\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00020949752024787392\tMax abs grad value: 0.00503232009837359\n",
      "Loss = 0.0015011301002882634\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0001926511658623958\tMax abs grad value: 0.0073486430551803796\n",
      "Loss = 0.0012237851649500653\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00012834277194865724\tMax abs grad value: 0.00308023874737288\n",
      "Loss = 0.0010462622648438626\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00010422098064218494\tMax abs grad value: 0.0015164039608965448\n",
      "Loss = 0.0008585864386624981\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0001090320734582637\tMax abs grad value: 0.0026258758516875826\n",
      "Loss = 0.0006556849391378642\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00010179190570003094\tMax abs grad value: 0.0020614183015402843\n",
      "Loss = 0.0004635963368946307\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.71190680649818e-05\tMax abs grad value: 0.0012657881002057327\n",
      "Loss = 0.000342999149509251\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 5.717326440672759e-05\tMax abs grad value: 0.0014341705251359404\n",
      "Loss = 0.0002692703523317238\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.614801431197904e-05\tMax abs grad value: 0.0008944865631617439\n",
      "Loss = 0.0002150067050893353\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.6223672280026884e-05\tMax abs grad value: 0.0009581350393039857\n",
      "Loss = 0.00015817647802465358\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.8614038366497676e-05\tMax abs grad value: 0.000629976524631439\n",
      "Loss = 0.00012176355261147057\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.9434202704437834e-05\tMax abs grad value: 0.0005594643831238291\n",
      "Loss = 0.00010188901669795468\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.700217765593632e-05\tMax abs grad value: 0.00038953762073374746\n",
      "Loss = 6.918117777291866e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.4292814385536041e-05\tMax abs grad value: 0.0003494529995120329\n",
      "Loss = 4.874102217987252e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 7.70624071698829e-06\tMax abs grad value: 0.0001839092843876952\n",
      "Loss = 3.665406768040972e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.2008383010504156e-06\tMax abs grad value: 0.00011788545857305071\n",
      "Loss = 2.9272230492964613e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.652631363225189e-06\tMax abs grad value: 7.593451033968943e-05\n",
      "Loss = 1.9515506090760464e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 8.069058619185491e-06\tMax abs grad value: 0.0002669314171188487\n",
      "Loss = 1.4589517387128455e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.5653580066295707e-06\tMax abs grad value: 6.08526403139965e-05\n",
      "Loss = 6.916062342621589e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.5480072960923127e-06\tMax abs grad value: 3.635550464472513e-05\n",
      "Loss = 4.9173680339259215e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.310581100569231e-06\tMax abs grad value: 3.560959177632606e-05\n",
      "Loss = 2.9103586222200915e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.1889003163105877e-06\tMax abs grad value: 5.7717930996510593e-05\n",
      "Loss = 2.1609652289982705e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 6.919053650760675e-07\tMax abs grad value: 1.6095166013748973e-05\n",
      "Loss = 1.326939564165108e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 4.643276958319967e-07\tMax abs grad value: 9.350749415371214e-06\n",
      "Loss = 1.048644171531043e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.06995513533766401\tMax abs grad value: 2.61165759165232\n",
      "Loss = 3.285226376751719\n",
      "Mean abs grad value: 0.0318180005946895\tMax abs grad value: 1.016807448661759\n",
      "Loss = 2.9841331842204486\n",
      "Train accuracy: 0.206\t\tTest accuracy: 0.198\n",
      "Mean abs grad value: 0.013425318195100693\tMax abs grad value: 0.3288534359493436\n",
      "Loss = 2.303560318712102\n",
      "Train accuracy: 0.229\t\tTest accuracy: 0.173\n",
      "Mean abs grad value: 0.009653795672011144\tMax abs grad value: 0.1638059267015355\n",
      "Loss = 2.1317385697878772\n",
      "Train accuracy: 0.322\t\tTest accuracy: 0.280\n",
      "Mean abs grad value: 0.011269372956388593\tMax abs grad value: 0.12518769147833916\n",
      "Loss = 1.8791195028228322\n",
      "Train accuracy: 0.408\t\tTest accuracy: 0.409\n",
      "Mean abs grad value: 0.019662214748870123\tMax abs grad value: 0.419009862342935\n",
      "Loss = 1.3274149454393311\n",
      "Train accuracy: 0.517\t\tTest accuracy: 0.504\n",
      "Mean abs grad value: 0.05935868558580363\tMax abs grad value: 1.8389018703622388\n",
      "Loss = 1.5201449167412373\n",
      "Mean abs grad value: 0.019542689735956766\tMax abs grad value: 0.7341731236840315\n",
      "Loss = 1.100142055821711\n",
      "Train accuracy: 0.647\t\tTest accuracy: 0.656\n",
      "Mean abs grad value: 0.021249714742988264\tMax abs grad value: 0.5884842835559184\n",
      "Loss = 0.9804864721901684\n",
      "Train accuracy: 0.659\t\tTest accuracy: 0.653\n",
      "Mean abs grad value: 0.011744961245743698\tMax abs grad value: 0.22605637625029207\n",
      "Loss = 0.852156010440437\n",
      "Train accuracy: 0.738\t\tTest accuracy: 0.731\n",
      "Mean abs grad value: 0.010343880753988888\tMax abs grad value: 0.2393059414283154\n",
      "Loss = 0.7667436371936985\n",
      "Train accuracy: 0.779\t\tTest accuracy: 0.796\n",
      "Mean abs grad value: 0.012701952229979567\tMax abs grad value: 0.46688784714441706\n",
      "Loss = 0.6493057545951851\n",
      "Train accuracy: 0.816\t\tTest accuracy: 0.811\n",
      "Mean abs grad value: 0.01628072006760314\tMax abs grad value: 0.3678769267879151\n",
      "Loss = 0.4693693554265635\n",
      "Train accuracy: 0.870\t\tTest accuracy: 0.869\n",
      "Mean abs grad value: 0.008183628585233131\tMax abs grad value: 0.1704748622156195\n",
      "Loss = 0.3826598295443359\n",
      "Train accuracy: 0.888\t\tTest accuracy: 0.878\n",
      "Mean abs grad value: 0.005249557843102182\tMax abs grad value: 0.0856673162038369\n",
      "Loss = 0.3590688237543591\n",
      "Train accuracy: 0.901\t\tTest accuracy: 0.882\n",
      "Mean abs grad value: 0.00482909975424122\tMax abs grad value: 0.13186368299807505\n",
      "Loss = 0.322435675745531\n",
      "Train accuracy: 0.913\t\tTest accuracy: 0.896\n",
      "Mean abs grad value: 0.004906234410349882\tMax abs grad value: 0.11068233543838804\n",
      "Loss = 0.27748683925741185\n",
      "Train accuracy: 0.921\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.015911441562672306\tMax abs grad value: 0.32487651582545385\n",
      "Loss = 0.27262516141374704\n",
      "Mean abs grad value: 0.007999690852834689\tMax abs grad value: 0.13090946684392404\n",
      "Loss = 0.24794189781224413\n",
      "Train accuracy: 0.932\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.004724442979699705\tMax abs grad value: 0.09762816561421112\n",
      "Loss = 0.21898052272286672\n",
      "Train accuracy: 0.933\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.003828375787684292\tMax abs grad value: 0.0743620853756996\n",
      "Loss = 0.19676439709629298\n",
      "Train accuracy: 0.940\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.004419880469546952\tMax abs grad value: 0.08392498837285664\n",
      "Loss = 0.1752916172219183\n",
      "Train accuracy: 0.940\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.006626494662498374\tMax abs grad value: 0.0985855946101446\n",
      "Loss = 0.15793236587399606\n",
      "Train accuracy: 0.950\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.003571970029564678\tMax abs grad value: 0.06215406521383286\n",
      "Loss = 0.1401015076338226\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0027117563255877656\tMax abs grad value: 0.036690251844227466\n",
      "Loss = 0.12494790977497326\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.004178456618239374\tMax abs grad value: 0.06728944605184106\n",
      "Loss = 0.11223437487539926\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0033824861864131766\tMax abs grad value: 0.06705690686279595\n",
      "Loss = 0.09840201928483366\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002576579510917426\tMax abs grad value: 0.037609609963635694\n",
      "Loss = 0.08918311359120937\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0029752737490581498\tMax abs grad value: 0.06567033943084588\n",
      "Loss = 0.07305906884894521\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.003662065443840468\tMax abs grad value: 0.12343998165153901\n",
      "Loss = 0.06543690519963852\n",
      "Train accuracy: 0.980\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002206229992480033\tMax abs grad value: 0.03449606604054692\n",
      "Loss = 0.0588558010243337\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0018410348990618862\tMax abs grad value: 0.054369618968952975\n",
      "Loss = 0.051782972644338905\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001984030262640677\tMax abs grad value: 0.06623581460839133\n",
      "Loss = 0.04621392164654825\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.002842214077956242\tMax abs grad value: 0.06413989585229544\n",
      "Loss = 0.03922915626873969\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.003524118380597005\tMax abs grad value: 0.09027250289139778\n",
      "Loss = 0.035168700754072524\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0016594855641869726\tMax abs grad value: 0.04811440169401646\n",
      "Loss = 0.0300595717682307\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0013682842252947316\tMax abs grad value: 0.029434636019460378\n",
      "Loss = 0.027060120085026663\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0010680640033651325\tMax abs grad value: 0.025094156536446772\n",
      "Loss = 0.0237948834883477\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0012959407858621512\tMax abs grad value: 0.022135804916511813\n",
      "Loss = 0.02055465186531644\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.002600803304414519\tMax abs grad value: 0.041001522825572435\n",
      "Loss = 0.01828356494137793\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0013147719104895294\tMax abs grad value: 0.022083522012533986\n",
      "Loss = 0.014336616782191456\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0007817843424184899\tMax abs grad value: 0.01287588547559962\n",
      "Loss = 0.010900052356265452\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0013212410889869024\tMax abs grad value: 0.026622907182895318\n",
      "Loss = 0.008948335931048155\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0006221670033711965\tMax abs grad value: 0.012759336090670849\n",
      "Loss = 0.007324614509002752\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0006884896008349468\tMax abs grad value: 0.012265456477214335\n",
      "Loss = 0.006556307034573486\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0006375266894187\tMax abs grad value: 0.01284159918525426\n",
      "Loss = 0.005324265027333095\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0016323396911418586\tMax abs grad value: 0.04087144225624113\n",
      "Loss = 0.004405370198550359\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0007967158793879794\tMax abs grad value: 0.014538999987431042\n",
      "Loss = 0.003330833274423511\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.000436271186696359\tMax abs grad value: 0.007866867209218866\n",
      "Loss = 0.0028532813761202587\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0003349520681526651\tMax abs grad value: 0.006741071741971381\n",
      "Loss = 0.0025781222924939344\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00032059949496378114\tMax abs grad value: 0.007771866320345743\n",
      "Loss = 0.0022070544585104206\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00029058813200202145\tMax abs grad value: 0.007198606074288722\n",
      "Loss = 0.0018407338592198801\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0004989131211650783\tMax abs grad value: 0.014011453715897054\n",
      "Loss = 0.0014741524719252583\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0001794758423139546\tMax abs grad value: 0.0032563033901641353\n",
      "Loss = 0.0011495200117757672\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0001475917198514073\tMax abs grad value: 0.0020523416975994457\n",
      "Loss = 0.001033973147806279\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00012787632537713042\tMax abs grad value: 0.002194232542729585\n",
      "Loss = 0.0008734907180053315\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00013972911195577213\tMax abs grad value: 0.003825832050299406\n",
      "Loss = 0.000701906350691758\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00010013379338950915\tMax abs grad value: 0.0034648098265893466\n",
      "Loss = 0.0005118545381618174\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00010361648494213389\tMax abs grad value: 0.0019894584864632685\n",
      "Loss = 0.00041275158545967726\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 6.520908843056898e-05\tMax abs grad value: 0.0011569365255588958\n",
      "Loss = 0.00033219417623572145\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.918085873512123e-05\tMax abs grad value: 0.0007560728497454231\n",
      "Loss = 0.00023336541575419436\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 5.59177420945798e-05\tMax abs grad value: 0.0010213856807721126\n",
      "Loss = 0.00017182033603102223\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 3.4732695880275053e-05\tMax abs grad value: 0.0006921643873216219\n",
      "Loss = 0.00011574407199136358\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 2.8573981503924877e-05\tMax abs grad value: 0.0005607350342144941\n",
      "Loss = 9.629637647877758e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.99790098041551e-05\tMax abs grad value: 0.0004780297965985742\n",
      "Loss = 6.094186819103626e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 2.1192719053228773e-05\tMax abs grad value: 0.00039197184793643316\n",
      "Loss = 4.2558401442633253e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 9.301864572211354e-06\tMax abs grad value: 0.00015680654548990206\n",
      "Loss = 2.7193484603548793e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 6.075539851461394e-06\tMax abs grad value: 9.580481653170292e-05\n",
      "Loss = 1.992461976732152e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.0437659077623335e-06\tMax abs grad value: 4.132601146254922e-05\n",
      "Loss = 1.1597906367463261e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.927850572561463e-06\tMax abs grad value: 0.00010466541186686333\n",
      "Loss = 6.688422661624058e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.4442373403688551e-06\tMax abs grad value: 2.353615898703021e-05\n",
      "Loss = 3.4942322867392463e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.1828503147073444e-06\tMax abs grad value: 1.905504588743262e-05\n",
      "Loss = 2.6420672861249007e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.4377892312139597e-06\tMax abs grad value: 3.18986924189101e-05\n",
      "Loss = 1.5644783070591508e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.3543535230172094e-07\tMax abs grad value: 4.953536888829523e-06\n",
      "Loss = 4.6459263151318123e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.03758725622225012\tMax abs grad value: 0.6337015980831504\n",
      "Loss = 2.805468381254394\n",
      "Mean abs grad value: 0.02878943454652318\tMax abs grad value: 0.5639611586254435\n",
      "Loss = 2.477341000424789\n",
      "Train accuracy: 0.249\t\tTest accuracy: 0.211\n",
      "Mean abs grad value: 0.010882979427275142\tMax abs grad value: 0.19766470149806803\n",
      "Loss = 2.077886208104109\n",
      "Train accuracy: 0.383\t\tTest accuracy: 0.351\n",
      "Mean abs grad value: 0.009452901499140286\tMax abs grad value: 0.15878433001733513\n",
      "Loss = 1.9400151625387363\n",
      "Train accuracy: 0.414\t\tTest accuracy: 0.380\n",
      "Mean abs grad value: 0.04610056012858849\tMax abs grad value: 1.596224654125523\n",
      "Loss = 2.189751460110815\n",
      "Mean abs grad value: 0.013375428531587262\tMax abs grad value: 0.24666907764735813\n",
      "Loss = 1.7556327842853785\n",
      "Train accuracy: 0.430\t\tTest accuracy: 0.373\n",
      "Mean abs grad value: 0.014486295723478738\tMax abs grad value: 0.23927323154068497\n",
      "Loss = 1.5474715829120458\n",
      "Train accuracy: 0.496\t\tTest accuracy: 0.496\n",
      "Mean abs grad value: 0.439623425505181\tMax abs grad value: 25.95112596679175\n",
      "Loss = 16.034456846602772\n",
      "Mean abs grad value: 0.016778876280684744\tMax abs grad value: 0.3305030493539564\n",
      "Loss = 1.186192998036348\n",
      "Train accuracy: 0.608\t\tTest accuracy: 0.602\n",
      "Mean abs grad value: 0.10607120546010633\tMax abs grad value: 4.873698176181346\n",
      "Loss = 2.2016927963646147\n",
      "Mean abs grad value: 0.018212928320466386\tMax abs grad value: 0.509498749630766\n",
      "Loss = 0.9352183658186825\n",
      "Train accuracy: 0.664\t\tTest accuracy: 0.653\n",
      "Mean abs grad value: 0.1101833177232104\tMax abs grad value: 5.9167794066929575\n",
      "Loss = 1.8643045003602638\n",
      "Mean abs grad value: 0.01418206171910134\tMax abs grad value: 0.3593252571619575\n",
      "Loss = 0.8361418997178774\n",
      "Train accuracy: 0.727\t\tTest accuracy: 0.724\n",
      "Mean abs grad value: 0.015111772766615057\tMax abs grad value: 0.36696208044652223\n",
      "Loss = 0.7481331179588158\n",
      "Train accuracy: 0.751\t\tTest accuracy: 0.736\n",
      "Mean abs grad value: 0.012396672476466163\tMax abs grad value: 0.28235065100509077\n",
      "Loss = 0.6765697617033707\n",
      "Train accuracy: 0.790\t\tTest accuracy: 0.776\n",
      "Mean abs grad value: 0.011287602098601284\tMax abs grad value: 0.22205599652025906\n",
      "Loss = 0.5530009151264023\n",
      "Train accuracy: 0.831\t\tTest accuracy: 0.811\n",
      "Mean abs grad value: 0.01054428361295246\tMax abs grad value: 0.41152077183658414\n",
      "Loss = 0.48143058350094675\n",
      "Train accuracy: 0.856\t\tTest accuracy: 0.849\n",
      "Mean abs grad value: 0.008429280188570478\tMax abs grad value: 0.3892702182885742\n",
      "Loss = 0.4281183153415238\n",
      "Train accuracy: 0.871\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.007896871681941992\tMax abs grad value: 0.2424575085150905\n",
      "Loss = 0.3958933395535661\n",
      "Train accuracy: 0.882\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.005869431058603019\tMax abs grad value: 0.2237471289193855\n",
      "Loss = 0.3477401953193529\n",
      "Train accuracy: 0.896\t\tTest accuracy: 0.898\n",
      "Mean abs grad value: 0.006715422492837033\tMax abs grad value: 0.18339124761672232\n",
      "Loss = 0.3105740417617641\n",
      "Train accuracy: 0.902\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.010935133808321586\tMax abs grad value: 0.3545244792172572\n",
      "Loss = 0.29130863985150485\n",
      "Train accuracy: 0.905\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.0046333764278728325\tMax abs grad value: 0.09296440897037575\n",
      "Loss = 0.2706151991314957\n",
      "Train accuracy: 0.914\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.0039127498340188836\tMax abs grad value: 0.06954097479098331\n",
      "Loss = 0.26346870535359085\n",
      "Train accuracy: 0.916\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.0034893411575232167\tMax abs grad value: 0.08829007994171711\n",
      "Loss = 0.24476281670214164\n",
      "Train accuracy: 0.924\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.004449475974775209\tMax abs grad value: 0.08503316485981333\n",
      "Loss = 0.21616639759156897\n",
      "Train accuracy: 0.938\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.007578014967940874\tMax abs grad value: 0.2567513434712309\n",
      "Loss = 0.18168636199567564\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0036406787809070305\tMax abs grad value: 0.08037218382914002\n",
      "Loss = 0.1541948819233128\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0037316822962981124\tMax abs grad value: 0.12061662204331625\n",
      "Loss = 0.1361391253539115\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.006599413346332252\tMax abs grad value: 0.3266586329897108\n",
      "Loss = 0.12774359558678833\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.003117578171849651\tMax abs grad value: 0.06040126150761407\n",
      "Loss = 0.11987649997358706\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.002809314373649415\tMax abs grad value: 0.05224348586203958\n",
      "Loss = 0.11557766010009174\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.002927200909746434\tMax abs grad value: 0.0824676554774445\n",
      "Loss = 0.10964181472405726\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0033129979625260105\tMax abs grad value: 0.07797802237123916\n",
      "Loss = 0.1018337803663255\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.004904528356757734\tMax abs grad value: 0.14548211930720018\n",
      "Loss = 0.0885653379225238\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.004056267789586708\tMax abs grad value: 0.1943596650807483\n",
      "Loss = 0.07843061475308546\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.002249861371983152\tMax abs grad value: 0.08096601490873971\n",
      "Loss = 0.07117457589510807\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0016622398280255392\tMax abs grad value: 0.022588528188074535\n",
      "Loss = 0.0671444798354242\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0018549414473028197\tMax abs grad value: 0.04587637711755145\n",
      "Loss = 0.06455303972253511\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0042072317587155805\tMax abs grad value: 0.25972382596791954\n",
      "Loss = 0.060754151772023764\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0026397400841215494\tMax abs grad value: 0.1553420081198079\n",
      "Loss = 0.05396550981346818\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.002091848364799019\tMax abs grad value: 0.0329713849509358\n",
      "Loss = 0.04601629214654415\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0019062995978654542\tMax abs grad value: 0.03689015792943692\n",
      "Loss = 0.0424854788109132\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.004042509238544085\tMax abs grad value: 0.14127704173751499\n",
      "Loss = 0.040310836843832513\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0018713535731470147\tMax abs grad value: 0.0411680892868528\n",
      "Loss = 0.03716195576179685\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0019461164370839627\tMax abs grad value: 0.057304866941774085\n",
      "Loss = 0.03492633476392621\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.002195686114538881\tMax abs grad value: 0.07332080608614025\n",
      "Loss = 0.032247969082652185\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0019280224641940464\tMax abs grad value: 0.0806467934717561\n",
      "Loss = 0.028759622799292957\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0014040369998425297\tMax abs grad value: 0.0428521159652663\n",
      "Loss = 0.025553433411574355\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0013762073430470749\tMax abs grad value: 0.06897429566121714\n",
      "Loss = 0.02350369593583898\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0016396455502123302\tMax abs grad value: 0.0708169587194212\n",
      "Loss = 0.02153446709509514\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0031468865435447563\tMax abs grad value: 0.1014803444579134\n",
      "Loss = 0.021872698467860007\n",
      "Mean abs grad value: 0.0013904893960819133\tMax abs grad value: 0.0472513840782601\n",
      "Loss = 0.020478973223242818\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0010648430349426681\tMax abs grad value: 0.018782279044373042\n",
      "Loss = 0.01939312275216414\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0012426130048227835\tMax abs grad value: 0.0438606762217558\n",
      "Loss = 0.017334951362951507\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.001516445247450475\tMax abs grad value: 0.04206271398487696\n",
      "Loss = 0.015364140621053637\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0016176953237829232\tMax abs grad value: 0.04538222117211261\n",
      "Loss = 0.013505458354217915\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0008659048200275689\tMax abs grad value: 0.02346680694767825\n",
      "Loss = 0.011089786345944676\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0012525335326304184\tMax abs grad value: 0.02373493949209567\n",
      "Loss = 0.009300863378990663\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0014199797245692015\tMax abs grad value: 0.05530415621065369\n",
      "Loss = 0.007903207582890542\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0006982219533156025\tMax abs grad value: 0.013341173643183891\n",
      "Loss = 0.006770257088654723\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.000624763907041342\tMax abs grad value: 0.009984556755434412\n",
      "Loss = 0.006270009734107445\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.000658283331469129\tMax abs grad value: 0.012477369980244214\n",
      "Loss = 0.0051837681629542\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0015426861296796237\tMax abs grad value: 0.051426431949844045\n",
      "Loss = 0.00463950983220024\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0007201667407787565\tMax abs grad value: 0.02053850263183957\n",
      "Loss = 0.0036145068382578997\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0004908680378970938\tMax abs grad value: 0.008387153060069206\n",
      "Loss = 0.0032483625988531323\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00046397442640134866\tMax abs grad value: 0.010462132579190134\n",
      "Loss = 0.002776769582979593\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00040985591715595165\tMax abs grad value: 0.013356720752097505\n",
      "Loss = 0.0022736883695534563\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0004775404812231716\tMax abs grad value: 0.014902548187276916\n",
      "Loss = 0.001526059756866681\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0007026166493201438\tMax abs grad value: 0.01897818448856888\n",
      "Loss = 0.001358379919427633\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00018600836273494268\tMax abs grad value: 0.004711683950466518\n",
      "Loss = 0.0008403833753790599\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00013595293271761707\tMax abs grad value: 0.0031971294820688076\n",
      "Loss = 0.0007167935327777151\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00023204297160205918\tMax abs grad value: 0.006774837791517253\n",
      "Loss = 0.0005102541201199933\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0001139608609369948\tMax abs grad value: 0.0016975761111825832\n",
      "Loss = 0.00035908260367716196\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 7.924558128870093e-05\tMax abs grad value: 0.0015822695881643285\n",
      "Loss = 0.00027618457454307903\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 6.999392746569346e-05\tMax abs grad value: 0.0015380108510294093\n",
      "Loss = 0.00019586185026407494\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 8.162826720235245e-05\tMax abs grad value: 0.0021182135794485875\n",
      "Loss = 0.00014945649834684202\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 4.335629510139899e-05\tMax abs grad value: 0.0008513522164649073\n",
      "Loss = 0.00011478682001747533\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.758233559472837e-05\tMax abs grad value: 0.000608067397585946\n",
      "Loss = 9.854656466076244e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 5.263439350329465e-05\tMax abs grad value: 0.0008508739393727313\n",
      "Loss = 5.9718153106179996e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.912402853014467e-05\tMax abs grad value: 0.0006857159476907243\n",
      "Loss = 3.219717960378425e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.2699892676809616e-05\tMax abs grad value: 0.0004321358479422227\n",
      "Loss = 2.3778283603146364e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.833919959236552e-06\tMax abs grad value: 0.00023607024327087126\n",
      "Loss = 1.3567476952755383e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.806973739770276e-06\tMax abs grad value: 8.381762682274768e-05\n",
      "Loss = 7.566837722978023e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.4268450071707497e-06\tMax abs grad value: 8.806056352803376e-05\n",
      "Loss = 3.9123645232867115e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.1579158921406932e-06\tMax abs grad value: 2.2436562577062392e-05\n",
      "Loss = 2.30550894848595e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.314012120558844e-07\tMax abs grad value: 1.3243597896814505e-05\n",
      "Loss = 1.3539604848906514e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 8.122441004395145e-07\tMax abs grad value: 1.7680666883733735e-05\n",
      "Loss = 8.202498176368719e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.78726337783408e-06\tMax abs grad value: 0.00010429172718340339\n",
      "Loss = 1.4946778728561435e-06\n",
      "Mean abs grad value: 5.253781582093716e-07\tMax abs grad value: 1.125601522432224e-05\n",
      "Loss = 5.902321403430525e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.1288881740812736e-07\tMax abs grad value: 7.63214425301478e-06\n",
      "Loss = 4.4762987480769034e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.005376034093189219\tMax abs grad value: 0.06827799547436574\n",
      "Loss = 2.3147742238725058\n",
      "Mean abs grad value: 0.0064244801845041305\tMax abs grad value: 0.1921322595442659\n",
      "Loss = 2.275041349563361\n",
      "Train accuracy: 0.105\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 0.007820241295927574\tMax abs grad value: 0.295475718114314\n",
      "Loss = 2.2325989706529015\n",
      "Train accuracy: 0.246\t\tTest accuracy: 0.253\n",
      "Mean abs grad value: 0.006116617645619205\tMax abs grad value: 0.34995619266245503\n",
      "Loss = 2.1220160472769476\n",
      "Train accuracy: 0.254\t\tTest accuracy: 0.260\n",
      "Mean abs grad value: 0.012433196942954708\tMax abs grad value: 0.7039229574186892\n",
      "Loss = 1.9632061981200581\n",
      "Train accuracy: 0.242\t\tTest accuracy: 0.258\n",
      "Mean abs grad value: 0.009800086845094334\tMax abs grad value: 0.3972889309974268\n",
      "Loss = 1.7419515702366912\n",
      "Train accuracy: 0.360\t\tTest accuracy: 0.331\n",
      "Mean abs grad value: 0.11395216850660085\tMax abs grad value: 8.417763317942715\n",
      "Loss = 4.139834420818822\n",
      "Mean abs grad value: 0.011225928712358163\tMax abs grad value: 0.5516018471975547\n",
      "Loss = 1.557971757833404\n",
      "Train accuracy: 0.373\t\tTest accuracy: 0.331\n",
      "Mean abs grad value: 0.019375964683411837\tMax abs grad value: 0.6072601390900256\n",
      "Loss = 1.3196579069272074\n",
      "Train accuracy: 0.551\t\tTest accuracy: 0.544\n",
      "Mean abs grad value: 0.011669384855905024\tMax abs grad value: 0.4174483117332118\n",
      "Loss = 1.1253245930802958\n",
      "Train accuracy: 0.705\t\tTest accuracy: 0.676\n",
      "Mean abs grad value: 0.011980039623345826\tMax abs grad value: 0.7398227695401542\n",
      "Loss = 1.0309787271020536\n",
      "Train accuracy: 0.729\t\tTest accuracy: 0.713\n",
      "Mean abs grad value: 0.012462714027023874\tMax abs grad value: 0.6480326424953932\n",
      "Loss = 0.9030796928840898\n",
      "Train accuracy: 0.765\t\tTest accuracy: 0.758\n",
      "Mean abs grad value: 0.012864951294370186\tMax abs grad value: 0.46239513290089057\n",
      "Loss = 0.765921645410058\n",
      "Train accuracy: 0.801\t\tTest accuracy: 0.800\n",
      "Mean abs grad value: 0.015516600740695467\tMax abs grad value: 0.5991327260082566\n",
      "Loss = 0.6362807261451687\n",
      "Train accuracy: 0.830\t\tTest accuracy: 0.818\n",
      "Mean abs grad value: 0.008132613569346345\tMax abs grad value: 0.3208501590105422\n",
      "Loss = 0.5450519675815217\n",
      "Train accuracy: 0.846\t\tTest accuracy: 0.829\n",
      "Mean abs grad value: 0.005867348060758712\tMax abs grad value: 0.2131452373494166\n",
      "Loss = 0.5036421242906433\n",
      "Train accuracy: 0.849\t\tTest accuracy: 0.847\n",
      "Mean abs grad value: 0.005153608900435228\tMax abs grad value: 0.17455604399371027\n",
      "Loss = 0.4484875913246742\n",
      "Train accuracy: 0.860\t\tTest accuracy: 0.849\n",
      "Mean abs grad value: 0.009694998931575301\tMax abs grad value: 0.36197734895664646\n",
      "Loss = 0.41367067035307514\n",
      "Train accuracy: 0.877\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.004926736907122572\tMax abs grad value: 0.17896914885037413\n",
      "Loss = 0.37632984895566124\n",
      "Train accuracy: 0.883\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.0039226046713413424\tMax abs grad value: 0.1405026393661688\n",
      "Loss = 0.3442202945628265\n",
      "Train accuracy: 0.884\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.0035023890711685522\tMax abs grad value: 0.09936281791222011\n",
      "Loss = 0.3079609762017719\n",
      "Train accuracy: 0.901\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.008027262421601648\tMax abs grad value: 0.44634597274218807\n",
      "Loss = 0.278619670354296\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.003392643067311344\tMax abs grad value: 0.13161607237358766\n",
      "Loss = 0.24296633374052873\n",
      "Train accuracy: 0.921\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.0031943543550356584\tMax abs grad value: 0.14095419298539227\n",
      "Loss = 0.22740943976795266\n",
      "Train accuracy: 0.932\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.003947921801601167\tMax abs grad value: 0.12377344698685624\n",
      "Loss = 0.21042086784469474\n",
      "Train accuracy: 0.932\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.002980393015022919\tMax abs grad value: 0.09721950549879213\n",
      "Loss = 0.19708913291065616\n",
      "Train accuracy: 0.938\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0030910713217206275\tMax abs grad value: 0.11777822595415807\n",
      "Loss = 0.18275735044713212\n",
      "Train accuracy: 0.946\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0032505177610010795\tMax abs grad value: 0.1442093552765028\n",
      "Loss = 0.16135807088181317\n",
      "Train accuracy: 0.953\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.007770985983719977\tMax abs grad value: 0.2594265707524267\n",
      "Loss = 0.15777207421565206\n",
      "Train accuracy: 0.951\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.002356151737468161\tMax abs grad value: 0.07472717214870085\n",
      "Loss = 0.13875971262551734\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0017561825326928972\tMax abs grad value: 0.049375956008943685\n",
      "Loss = 0.13301904046326077\n",
      "Train accuracy: 0.956\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.002276072892746959\tMax abs grad value: 0.07514124543937646\n",
      "Loss = 0.12352826214085481\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0032051595575575244\tMax abs grad value: 0.13103124677998682\n",
      "Loss = 0.11199672414736028\n",
      "Train accuracy: 0.960\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.002095408985267593\tMax abs grad value: 0.08890832185234082\n",
      "Loss = 0.0977081277761081\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0019623991875183278\tMax abs grad value: 0.064333392653468\n",
      "Loss = 0.08557330436374974\n",
      "Train accuracy: 0.972\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0036736368974454015\tMax abs grad value: 0.12930401034395825\n",
      "Loss = 0.07840345562030783\n",
      "Train accuracy: 0.971\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001910608770716347\tMax abs grad value: 0.04845403299436526\n",
      "Loss = 0.07205192386225927\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0017313682929618955\tMax abs grad value: 0.051727777622432254\n",
      "Loss = 0.0689675746283084\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0018518084465408648\tMax abs grad value: 0.06080527013777295\n",
      "Loss = 0.0596117391696016\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0021095493290117476\tMax abs grad value: 0.07024589625550508\n",
      "Loss = 0.051339274856087636\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0014639987100626892\tMax abs grad value: 0.03552280596776863\n",
      "Loss = 0.04525449176382691\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0012419425433865278\tMax abs grad value: 0.02628683409380012\n",
      "Loss = 0.04139127458017471\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0014166692290599105\tMax abs grad value: 0.034601109670648375\n",
      "Loss = 0.035119673135101344\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.007037273266604587\tMax abs grad value: 0.2267457970468515\n",
      "Loss = 0.046730939510419456\n",
      "Mean abs grad value: 0.0018779864850965954\tMax abs grad value: 0.05711407486229613\n",
      "Loss = 0.031296739449320266\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001562649841354483\tMax abs grad value: 0.049176893425564895\n",
      "Loss = 0.02731042442659069\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0018385139463222926\tMax abs grad value: 0.04648827601739431\n",
      "Loss = 0.02312359422172344\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0009419652742905598\tMax abs grad value: 0.020843365733748776\n",
      "Loss = 0.02086172594465049\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0007471514325944406\tMax abs grad value: 0.014769099800663621\n",
      "Loss = 0.020101179187171192\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0007913429022684889\tMax abs grad value: 0.031468451999633204\n",
      "Loss = 0.017207305218227314\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0010919959632936453\tMax abs grad value: 0.030160147808616547\n",
      "Loss = 0.014575710364307624\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0019077518794209148\tMax abs grad value: 0.0967665489461371\n",
      "Loss = 0.013457243493371757\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0006588892966542181\tMax abs grad value: 0.03011299479922514\n",
      "Loss = 0.01115017241573861\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0004601806258159689\tMax abs grad value: 0.01413060276931345\n",
      "Loss = 0.01023414651679029\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0005514847462124929\tMax abs grad value: 0.01500570124206902\n",
      "Loss = 0.0093524380267997\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0005968361297266312\tMax abs grad value: 0.02522606565279032\n",
      "Loss = 0.008016736012482503\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0014863151024203697\tMax abs grad value: 0.04498782872772637\n",
      "Loss = 0.0077228985678127245\n",
      "Mean abs grad value: 0.0008069855563873251\tMax abs grad value: 0.02876241083637612\n",
      "Loss = 0.006738388796266897\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0004961064200159496\tMax abs grad value: 0.014235943842801968\n",
      "Loss = 0.004989513707845024\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0005822061920655873\tMax abs grad value: 0.011614809178995846\n",
      "Loss = 0.0043365092343091325\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0003776676856935886\tMax abs grad value: 0.012065687856280906\n",
      "Loss = 0.003738954813920084\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0003067083150714814\tMax abs grad value: 0.011675883973317782\n",
      "Loss = 0.003236755469101594\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0005892491012709635\tMax abs grad value: 0.028771497214228964\n",
      "Loss = 0.0029804958011725546\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0003116835389822503\tMax abs grad value: 0.008194908863644965\n",
      "Loss = 0.002596178628542611\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00019894210184987252\tMax abs grad value: 0.0057502125717401025\n",
      "Loss = 0.0023277392528181827\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00023203832290607016\tMax abs grad value: 0.007526165516828829\n",
      "Loss = 0.0020737580415837176\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00022481401136314512\tMax abs grad value: 0.007909952525413705\n",
      "Loss = 0.0017606922275498688\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00019002536010199266\tMax abs grad value: 0.0060473702485118646\n",
      "Loss = 0.0013094085692083564\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00022142000764319354\tMax abs grad value: 0.007188372356756789\n",
      "Loss = 0.0010380657500116382\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00010422375547220513\tMax abs grad value: 0.0041595141803406855\n",
      "Loss = 0.0008535647523629464\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 8.684060430604887e-05\tMax abs grad value: 0.002847308948084951\n",
      "Loss = 0.0007052761482553274\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 9.312619958678013e-05\tMax abs grad value: 0.003314733108546632\n",
      "Loss = 0.0005117671779900262\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 9.772864922500145e-05\tMax abs grad value: 0.0030733411049101928\n",
      "Loss = 0.0003596240409265766\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.701665738640087e-05\tMax abs grad value: 0.0020032797466601293\n",
      "Loss = 0.0002687163243991049\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 3.629106335826677e-05\tMax abs grad value: 0.001027756477551447\n",
      "Loss = 0.0001992394320234798\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.1031544584699996e-05\tMax abs grad value: 0.0009674338021265414\n",
      "Loss = 0.00013663286942027826\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.9959653739563595e-05\tMax abs grad value: 0.0030693797836336104\n",
      "Loss = 0.00011547293196885418\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.922260124966399e-05\tMax abs grad value: 0.0006431916914734396\n",
      "Loss = 5.99407526153467e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.1219765061012207e-05\tMax abs grad value: 0.0003539540306667238\n",
      "Loss = 4.7158914784659886e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.679161173303718e-06\tMax abs grad value: 0.00016882845368696543\n",
      "Loss = 3.327713640459631e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.256491496025234e-06\tMax abs grad value: 0.00011993511439463795\n",
      "Loss = 2.3366917266859968e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.560230598744084e-06\tMax abs grad value: 9.5125809689344e-05\n",
      "Loss = 1.4752435955147262e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.0067669053005354e-05\tMax abs grad value: 0.00029537959708461614\n",
      "Loss = 1.1669998386673974e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.7663811871326494e-06\tMax abs grad value: 4.391598344814341e-05\n",
      "Loss = 5.677626106058961e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.4688077552101898e-06\tMax abs grad value: 3.656788120128107e-05\n",
      "Loss = 4.720997305899131e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 8.735963715140633e-07\tMax abs grad value: 1.8086145508102735e-05\n",
      "Loss = 2.747137855609802e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 7.87672664883827e-07\tMax abs grad value: 2.5998240860143453e-05\n",
      "Loss = 1.5919629384660299e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.294735386434689e-07\tMax abs grad value: 6.852755877615741e-06\n",
      "Loss = 1.0099781370495928e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0042759985146853955\tMax abs grad value: 0.06048129375627293\n",
      "Loss = 2.2990651325751457\n",
      "Mean abs grad value: 0.007833085764987273\tMax abs grad value: 0.3140178130377077\n",
      "Loss = 2.1522011534643997\n",
      "Train accuracy: 0.113\t\tTest accuracy: 0.089\n",
      "Mean abs grad value: 0.014636448365295323\tMax abs grad value: 0.47025282439937205\n",
      "Loss = 1.880704262260916\n",
      "Train accuracy: 0.350\t\tTest accuracy: 0.333\n",
      "Mean abs grad value: 0.023280149418938193\tMax abs grad value: 1.1413766124644926\n",
      "Loss = 1.7377189324163778\n",
      "Train accuracy: 0.363\t\tTest accuracy: 0.360\n",
      "Mean abs grad value: 0.015133379801307363\tMax abs grad value: 0.7815612997593194\n",
      "Loss = 1.5075045834066645\n",
      "Train accuracy: 0.445\t\tTest accuracy: 0.429\n",
      "Mean abs grad value: 0.01379530861947929\tMax abs grad value: 0.7029278436254618\n",
      "Loss = 1.3006392603274053\n",
      "Train accuracy: 0.547\t\tTest accuracy: 0.502\n",
      "Mean abs grad value: 0.09383013548322465\tMax abs grad value: 4.527274673856184\n",
      "Loss = 2.0732114796336787\n",
      "Mean abs grad value: 0.018820771797260234\tMax abs grad value: 0.5894642543391841\n",
      "Loss = 1.088824923834386\n",
      "Train accuracy: 0.631\t\tTest accuracy: 0.587\n",
      "Mean abs grad value: 0.016112395668134803\tMax abs grad value: 0.9539551216396621\n",
      "Loss = 0.9214213739985628\n",
      "Train accuracy: 0.687\t\tTest accuracy: 0.640\n",
      "Mean abs grad value: 0.01761081665051483\tMax abs grad value: 0.5145708556389055\n",
      "Loss = 0.8183992472898673\n",
      "Train accuracy: 0.733\t\tTest accuracy: 0.700\n",
      "Mean abs grad value: 0.011307625877301622\tMax abs grad value: 0.3454140720195852\n",
      "Loss = 0.7581773871846424\n",
      "Train accuracy: 0.785\t\tTest accuracy: 0.744\n",
      "Mean abs grad value: 0.010277498294611597\tMax abs grad value: 0.24225380944474498\n",
      "Loss = 0.713760251164474\n",
      "Train accuracy: 0.807\t\tTest accuracy: 0.756\n",
      "Mean abs grad value: 0.009634701593445582\tMax abs grad value: 0.23113818988133697\n",
      "Loss = 0.6288181809213285\n",
      "Train accuracy: 0.829\t\tTest accuracy: 0.796\n",
      "Mean abs grad value: 0.015284554024830803\tMax abs grad value: 0.42570668387827093\n",
      "Loss = 0.5434787257187519\n",
      "Train accuracy: 0.844\t\tTest accuracy: 0.802\n",
      "Mean abs grad value: 0.0068923152226823435\tMax abs grad value: 0.22983436628936066\n",
      "Loss = 0.45743736492049647\n",
      "Train accuracy: 0.870\t\tTest accuracy: 0.844\n",
      "Mean abs grad value: 0.0070942918284661975\tMax abs grad value: 0.2463910717971233\n",
      "Loss = 0.4172501642393753\n",
      "Train accuracy: 0.872\t\tTest accuracy: 0.847\n",
      "Mean abs grad value: 0.008628815665999478\tMax abs grad value: 0.15724551177275356\n",
      "Loss = 0.366493252542239\n",
      "Train accuracy: 0.879\t\tTest accuracy: 0.871\n",
      "Mean abs grad value: 0.009827254793197585\tMax abs grad value: 0.24857627270040292\n",
      "Loss = 0.32851302081302375\n",
      "Train accuracy: 0.882\t\tTest accuracy: 0.871\n",
      "Mean abs grad value: 0.006819654936066489\tMax abs grad value: 0.2210855164817125\n",
      "Loss = 0.303608144308344\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.898\n",
      "Mean abs grad value: 0.0054255345377840734\tMax abs grad value: 0.18533412816976003\n",
      "Loss = 0.28651821589433313\n",
      "Train accuracy: 0.903\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.00595347267447701\tMax abs grad value: 0.12499447106731634\n",
      "Loss = 0.2678436574849697\n",
      "Train accuracy: 0.915\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.0070236123375100445\tMax abs grad value: 0.2613351668202103\n",
      "Loss = 0.23221426340362333\n",
      "Train accuracy: 0.926\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.006897818434599769\tMax abs grad value: 0.22870648190061482\n",
      "Loss = 0.2147862767075638\n",
      "Train accuracy: 0.928\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0040232168453804345\tMax abs grad value: 0.08672934070192952\n",
      "Loss = 0.2003931440601185\n",
      "Train accuracy: 0.936\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.004021901269916989\tMax abs grad value: 0.08285954422169424\n",
      "Loss = 0.19013881537121238\n",
      "Train accuracy: 0.940\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0034947577742384353\tMax abs grad value: 0.09154414623368844\n",
      "Loss = 0.17858812798771462\n",
      "Train accuracy: 0.943\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.004562373318352826\tMax abs grad value: 0.0971347105854151\n",
      "Loss = 0.16107754161255222\n",
      "Train accuracy: 0.951\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0065812352400932824\tMax abs grad value: 0.18877938327236315\n",
      "Loss = 0.15222482153452993\n",
      "Train accuracy: 0.950\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.003373786625567033\tMax abs grad value: 0.07199831574935785\n",
      "Loss = 0.13899782259331023\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0025283477658433855\tMax abs grad value: 0.06730088284219186\n",
      "Loss = 0.13226570884830316\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.003036858498394786\tMax abs grad value: 0.06689049296559793\n",
      "Loss = 0.125494643997758\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.004704916582565806\tMax abs grad value: 0.1423557138512925\n",
      "Loss = 0.12121412026137636\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0032256583474739395\tMax abs grad value: 0.0933831961650466\n",
      "Loss = 0.11643288153753148\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.003173211621063518\tMax abs grad value: 0.09252818627288267\n",
      "Loss = 0.10236735091633561\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.003925029957301915\tMax abs grad value: 0.13048920108975348\n",
      "Loss = 0.09134389919437486\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.006351031516543963\tMax abs grad value: 0.21011796250234907\n",
      "Loss = 0.08757229676206985\n",
      "Train accuracy: 0.972\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0021427333145927854\tMax abs grad value: 0.05077901475414827\n",
      "Loss = 0.07615049468309326\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0018574411183179397\tMax abs grad value: 0.043958781136144875\n",
      "Loss = 0.07361889374399198\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0023282425839939347\tMax abs grad value: 0.0650733805301122\n",
      "Loss = 0.0680462165577181\n",
      "Train accuracy: 0.980\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0026397809524919946\tMax abs grad value: 0.09269843699065042\n",
      "Loss = 0.06063304250688502\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.005260232378363484\tMax abs grad value: 0.16995684669395394\n",
      "Loss = 0.0578046750873512\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0021783598508465936\tMax abs grad value: 0.05357859413689383\n",
      "Loss = 0.04896598980981717\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.001554639498319851\tMax abs grad value: 0.03617950818948624\n",
      "Loss = 0.04465205704677072\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0022785688634920785\tMax abs grad value: 0.064918688572359\n",
      "Loss = 0.03838087381844216\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0021305561851165953\tMax abs grad value: 0.06405973788966501\n",
      "Loss = 0.03473504486895866\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0025057397744138728\tMax abs grad value: 0.07461074338422577\n",
      "Loss = 0.03191097802022555\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0012196370023229472\tMax abs grad value: 0.02640035446977805\n",
      "Loss = 0.028564192384306113\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0012571250197522667\tMax abs grad value: 0.03402001976734014\n",
      "Loss = 0.026217979647324478\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0013304710777858359\tMax abs grad value: 0.031392809729296894\n",
      "Loss = 0.02414646777888142\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0020408569979168036\tMax abs grad value: 0.058184685785672825\n",
      "Loss = 0.020366180490607514\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001499438379513337\tMax abs grad value: 0.06386543879692841\n",
      "Loss = 0.015262288073224078\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0009812397881903397\tMax abs grad value: 0.03071564732841615\n",
      "Loss = 0.01346869374538342\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0006437991207819612\tMax abs grad value: 0.014942735298002536\n",
      "Loss = 0.011847794248911388\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0006123565895124974\tMax abs grad value: 0.01912209459049245\n",
      "Loss = 0.010631269777156198\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0013139591174028576\tMax abs grad value: 0.03868793586330452\n",
      "Loss = 0.009257701658689695\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0006674439323587228\tMax abs grad value: 0.018414018940055243\n",
      "Loss = 0.007671958901613885\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0006251698753301289\tMax abs grad value: 0.011230656352844585\n",
      "Loss = 0.006707204492778489\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0005026536185444193\tMax abs grad value: 0.013110699544635616\n",
      "Loss = 0.0055374257128367795\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0005548504612406287\tMax abs grad value: 0.010679675363566392\n",
      "Loss = 0.004509114537382634\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0005829115022998071\tMax abs grad value: 0.01809222023155464\n",
      "Loss = 0.0036523585522536192\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.00034076492910684037\tMax abs grad value: 0.010644411836570774\n",
      "Loss = 0.0030759001642854463\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0002332117601695938\tMax abs grad value: 0.007400337594799319\n",
      "Loss = 0.002475386468489706\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00028184525526221905\tMax abs grad value: 0.005372956921023991\n",
      "Loss = 0.0020164443808049605\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00041080793935990747\tMax abs grad value: 0.011823938654124953\n",
      "Loss = 0.0017510581567934437\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00022448432058163264\tMax abs grad value: 0.006957975282939202\n",
      "Loss = 0.0014855167392074584\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00016754187534508862\tMax abs grad value: 0.00412860718358078\n",
      "Loss = 0.0011271152750584722\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.000156300875964446\tMax abs grad value: 0.004405304359232734\n",
      "Loss = 0.0009238048197536184\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00011324442556858821\tMax abs grad value: 0.002416307926262417\n",
      "Loss = 0.0006775340021664413\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0003768793967359171\tMax abs grad value: 0.016917996379342385\n",
      "Loss = 0.0006189035962369426\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 9.893055126312146e-05\tMax abs grad value: 0.0031196422930039698\n",
      "Loss = 0.0004044292074565232\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 6.835441456545743e-05\tMax abs grad value: 0.0016321380861128321\n",
      "Loss = 0.00034597470477459153\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 5.325186193000011e-05\tMax abs grad value: 0.0012593878061633328\n",
      "Loss = 0.00024161174503183766\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.601345632390995e-05\tMax abs grad value: 0.0012681351494120512\n",
      "Loss = 0.00017177523871442533\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 4.920725188746661e-05\tMax abs grad value: 0.0015933592056889146\n",
      "Loss = 0.00010727480956739079\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.482921335970985e-05\tMax abs grad value: 0.000861075005149253\n",
      "Loss = 6.616554125192375e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.5586772732382e-05\tMax abs grad value: 0.00058656375154548\n",
      "Loss = 5.0709585553474034e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.0104957181424636e-05\tMax abs grad value: 0.0002514434813689856\n",
      "Loss = 4.017195317912567e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 8.158187972335304e-06\tMax abs grad value: 0.0002187728560176889\n",
      "Loss = 2.903730761586626e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.1802746976721598e-05\tMax abs grad value: 0.00029981509022922913\n",
      "Loss = 1.8861316630876653e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 4.170145185518e-06\tMax abs grad value: 0.00011873178573035037\n",
      "Loss = 1.0609968184967976e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 2.3477688055553313e-06\tMax abs grad value: 5.509806813159334e-05\n",
      "Loss = 7.654511723139831e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.839638868070872e-06\tMax abs grad value: 4.665897953386125e-05\n",
      "Loss = 5.3997636326893024e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 4.61017216685784e-06\tMax abs grad value: 0.00016669059260583272\n",
      "Loss = 4.71292115328634e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.352129192341075e-06\tMax abs grad value: 3.831779004333938e-05\n",
      "Loss = 2.840807483629201e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 9.194021346917575e-07\tMax abs grad value: 2.1662659300799258e-05\n",
      "Loss = 2.3562292570343177e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 7.423063109504132e-07\tMax abs grad value: 1.3831961450233857e-05\n",
      "Loss = 1.780413006140523e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 4.4538595768704763e-07\tMax abs grad value: 1.1579351673757993e-05\n",
      "Loss = 1.1790823110036386e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.570365755219143e-07\tMax abs grad value: 9.809894297962446e-06\n",
      "Loss = 6.953121189039633e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.005109246496564029\tMax abs grad value: 0.04466052133345868\n",
      "Loss = 2.3100998952042606\n",
      "Mean abs grad value: 0.010566071283025807\tMax abs grad value: 0.22880664124041958\n",
      "Loss = 2.159777064470375\n",
      "Train accuracy: 0.307\t\tTest accuracy: 0.273\n",
      "Mean abs grad value: 0.025151340483627542\tMax abs grad value: 1.4004502331169497\n",
      "Loss = 2.0840448741600635\n",
      "Mean abs grad value: 0.009114880666151202\tMax abs grad value: 0.28853478354781414\n",
      "Loss = 2.012571474121246\n",
      "Train accuracy: 0.336\t\tTest accuracy: 0.304\n",
      "Mean abs grad value: 0.03599456252778649\tMax abs grad value: 1.4232762075612648\n",
      "Loss = 2.1114834147192827\n",
      "Mean abs grad value: 0.015778783537945144\tMax abs grad value: 0.6876948169888\n",
      "Loss = 1.930354926806597\n",
      "Train accuracy: 0.336\t\tTest accuracy: 0.324\n",
      "Mean abs grad value: 0.017491618867174923\tMax abs grad value: 0.7033256017104528\n",
      "Loss = 1.8096260789553582\n",
      "Train accuracy: 0.276\t\tTest accuracy: 0.300\n",
      "Mean abs grad value: 0.021847385612187332\tMax abs grad value: 0.7442503284451052\n",
      "Loss = 1.6158934055640821\n",
      "Train accuracy: 0.414\t\tTest accuracy: 0.411\n",
      "Mean abs grad value: 0.04595130692878238\tMax abs grad value: 2.689774907935292\n",
      "Loss = 1.690655048878572\n",
      "Mean abs grad value: 0.020139651529862777\tMax abs grad value: 0.772633003135752\n",
      "Loss = 1.540245562696686\n",
      "Train accuracy: 0.485\t\tTest accuracy: 0.473\n",
      "Mean abs grad value: 0.013293377695053751\tMax abs grad value: 0.4212103236486029\n",
      "Loss = 1.4406660185113844\n",
      "Train accuracy: 0.529\t\tTest accuracy: 0.498\n",
      "Mean abs grad value: 0.014008874470453955\tMax abs grad value: 0.5433595221274434\n",
      "Loss = 1.3777529015159384\n",
      "Train accuracy: 0.547\t\tTest accuracy: 0.491\n",
      "Mean abs grad value: 0.013261375830424535\tMax abs grad value: 0.45699642066166485\n",
      "Loss = 1.2880475559318765\n",
      "Train accuracy: 0.611\t\tTest accuracy: 0.556\n",
      "Mean abs grad value: 0.022222370167764873\tMax abs grad value: 1.4661634280431517\n",
      "Loss = 1.2571164666838637\n",
      "Train accuracy: 0.638\t\tTest accuracy: 0.609\n",
      "Mean abs grad value: 0.014081689607863709\tMax abs grad value: 0.8317652214133492\n",
      "Loss = 1.1639379114204755\n",
      "Train accuracy: 0.682\t\tTest accuracy: 0.664\n",
      "Mean abs grad value: 0.011718903253242605\tMax abs grad value: 0.4611828430567584\n",
      "Loss = 1.0528792068199972\n",
      "Train accuracy: 0.711\t\tTest accuracy: 0.687\n",
      "Mean abs grad value: 0.0166346715507503\tMax abs grad value: 0.5901882061321777\n",
      "Loss = 0.9475446741514273\n",
      "Train accuracy: 0.702\t\tTest accuracy: 0.689\n",
      "Mean abs grad value: 0.01394318595892895\tMax abs grad value: 0.6093945180578283\n",
      "Loss = 0.8828916579612333\n",
      "Train accuracy: 0.731\t\tTest accuracy: 0.709\n",
      "Mean abs grad value: 0.009745368868032457\tMax abs grad value: 0.43960176121376704\n",
      "Loss = 0.8322401844442598\n",
      "Train accuracy: 0.743\t\tTest accuracy: 0.740\n",
      "Mean abs grad value: 0.011076156797557865\tMax abs grad value: 0.9261788173367131\n",
      "Loss = 0.7650258874190622\n",
      "Train accuracy: 0.762\t\tTest accuracy: 0.769\n",
      "Mean abs grad value: 0.010653536003911127\tMax abs grad value: 0.4734935266686477\n",
      "Loss = 0.7150026561961582\n",
      "Train accuracy: 0.773\t\tTest accuracy: 0.769\n",
      "Mean abs grad value: 0.00970149808818055\tMax abs grad value: 0.2492835887634489\n",
      "Loss = 0.6376060879094195\n",
      "Train accuracy: 0.801\t\tTest accuracy: 0.787\n",
      "Mean abs grad value: 0.04012541164147253\tMax abs grad value: 2.508828858904733\n",
      "Loss = 0.6309310783671672\n",
      "Mean abs grad value: 0.01578632022949762\tMax abs grad value: 0.9014841272213645\n",
      "Loss = 0.5650264705135429\n",
      "Train accuracy: 0.831\t\tTest accuracy: 0.818\n",
      "Mean abs grad value: 0.0074393247036096\tMax abs grad value: 0.25769567212555844\n",
      "Loss = 0.47686522745077564\n",
      "Train accuracy: 0.855\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.006374377092809497\tMax abs grad value: 0.18996674078249087\n",
      "Loss = 0.4413212422747795\n",
      "Train accuracy: 0.873\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.01961192884718343\tMax abs grad value: 0.8013588460314678\n",
      "Loss = 0.41455226168657133\n",
      "Train accuracy: 0.869\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.0067442365767422865\tMax abs grad value: 0.16702734938818484\n",
      "Loss = 0.3665942333170088\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.873\n",
      "Mean abs grad value: 0.005377146891020334\tMax abs grad value: 0.1355474916309717\n",
      "Loss = 0.35510912455865057\n",
      "Train accuracy: 0.901\t\tTest accuracy: 0.878\n",
      "Mean abs grad value: 0.0057522709934255045\tMax abs grad value: 0.18365027695205471\n",
      "Loss = 0.31439456047581865\n",
      "Train accuracy: 0.914\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.008328932501645308\tMax abs grad value: 0.22527274906077266\n",
      "Loss = 0.27119209774594266\n",
      "Train accuracy: 0.921\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.005753083001221453\tMax abs grad value: 0.15151000712842264\n",
      "Loss = 0.23113139961818494\n",
      "Train accuracy: 0.925\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.005842655214391783\tMax abs grad value: 0.1721017515784101\n",
      "Loss = 0.2166059883778295\n",
      "Train accuracy: 0.927\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.003815387781593005\tMax abs grad value: 0.15007179523627737\n",
      "Loss = 0.2015253184135043\n",
      "Train accuracy: 0.930\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.003724562780707739\tMax abs grad value: 0.1144078592563018\n",
      "Loss = 0.19031738400007134\n",
      "Train accuracy: 0.933\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.003639907933933585\tMax abs grad value: 0.14242649684758166\n",
      "Loss = 0.1728986507928302\n",
      "Train accuracy: 0.943\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.009213184255024438\tMax abs grad value: 0.2700672037275762\n",
      "Loss = 0.16209891623623612\n",
      "Train accuracy: 0.940\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.003090563771762951\tMax abs grad value: 0.07671786184735999\n",
      "Loss = 0.14486582698432515\n",
      "Train accuracy: 0.948\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.002386246169594286\tMax abs grad value: 0.07142312572687023\n",
      "Loss = 0.13931490247231185\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0029658235060458214\tMax abs grad value: 0.07298954955033586\n",
      "Loss = 0.13143956130355072\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0027489996520933683\tMax abs grad value: 0.1116913375597476\n",
      "Loss = 0.12021496350450893\n",
      "Train accuracy: 0.960\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.006679287424222383\tMax abs grad value: 0.2047439881831401\n",
      "Loss = 0.11235406660781462\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.002184785700774481\tMax abs grad value: 0.045411449271908724\n",
      "Loss = 0.09747744689127301\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0019785229435346943\tMax abs grad value: 0.04520784700149506\n",
      "Loss = 0.09416945070227922\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0029302243783740143\tMax abs grad value: 0.10851344814794052\n",
      "Loss = 0.08872913191781873\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.004165214543687086\tMax abs grad value: 0.08955504761910474\n",
      "Loss = 0.0809861669661571\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0031193027243215797\tMax abs grad value: 0.06341352667477519\n",
      "Loss = 0.07326576959525158\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0024822267315582356\tMax abs grad value: 0.061545150900127264\n",
      "Loss = 0.06568664937133403\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0018799231307634148\tMax abs grad value: 0.06908420444729982\n",
      "Loss = 0.05841247298823764\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0035184009747895157\tMax abs grad value: 0.09355816533498976\n",
      "Loss = 0.052620162870491156\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.002198774376782482\tMax abs grad value: 0.0723205935019684\n",
      "Loss = 0.04663061511172344\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001603929632284125\tMax abs grad value: 0.05279852961461483\n",
      "Loss = 0.0431307178734137\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0012720720816577734\tMax abs grad value: 0.034574122562649585\n",
      "Loss = 0.03763634322846585\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0016936889849687576\tMax abs grad value: 0.06664402989442676\n",
      "Loss = 0.03523958855138939\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0012231051754587573\tMax abs grad value: 0.04953243446648484\n",
      "Loss = 0.0327307068310365\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0010575461646873748\tMax abs grad value: 0.03132448184016176\n",
      "Loss = 0.028159054118779607\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.002842288471965285\tMax abs grad value: 0.09631700190447412\n",
      "Loss = 0.026697104372772864\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0019166978168945747\tMax abs grad value: 0.059667087492551465\n",
      "Loss = 0.02424054615788638\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0009736681288183642\tMax abs grad value: 0.026068797461649997\n",
      "Loss = 0.022983075845480767\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0006784393047991258\tMax abs grad value: 0.015097557378282432\n",
      "Loss = 0.02177145659936796\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0007365040234447805\tMax abs grad value: 0.021923825012214664\n",
      "Loss = 0.02021164322340537\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0018299528628943924\tMax abs grad value: 0.05085375180272851\n",
      "Loss = 0.01826588771845362\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.000778990041955247\tMax abs grad value: 0.019328800317242247\n",
      "Loss = 0.015475242495025942\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0006320275094626435\tMax abs grad value: 0.023018737423032395\n",
      "Loss = 0.013684265739230882\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0006527581402245695\tMax abs grad value: 0.023723335173574847\n",
      "Loss = 0.011876352038366811\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0009033587126849516\tMax abs grad value: 0.01990826257169177\n",
      "Loss = 0.009849472823063369\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0010778413115502684\tMax abs grad value: 0.027444289943252244\n",
      "Loss = 0.008532186617911827\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0005765218908230684\tMax abs grad value: 0.011202601658558778\n",
      "Loss = 0.007310789509755616\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0004328141113960243\tMax abs grad value: 0.012461110439035316\n",
      "Loss = 0.0067417341893055305\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0007197978001556303\tMax abs grad value: 0.03279551058120606\n",
      "Loss = 0.005679413796820976\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0008255261114266598\tMax abs grad value: 0.029693707926634564\n",
      "Loss = 0.00480322168036773\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0004686718283876093\tMax abs grad value: 0.009357132669851232\n",
      "Loss = 0.004204303559262572\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0004013273343512741\tMax abs grad value: 0.009119561634361043\n",
      "Loss = 0.0038395795806955464\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.000401831639832321\tMax abs grad value: 0.014801692755944994\n",
      "Loss = 0.003268394075607317\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.00032945948828119005\tMax abs grad value: 0.010612979740452057\n",
      "Loss = 0.0027309804557685818\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0006417360503511502\tMax abs grad value: 0.014961405675924026\n",
      "Loss = 0.002285986836936947\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.00021595779314788712\tMax abs grad value: 0.003674528829698542\n",
      "Loss = 0.0016256756763423756\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00014997259067695348\tMax abs grad value: 0.0028512436298499854\n",
      "Loss = 0.0014153510816053117\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0001614942192411021\tMax abs grad value: 0.004400380350188387\n",
      "Loss = 0.00112090694397338\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00013900142804503633\tMax abs grad value: 0.004502714999263693\n",
      "Loss = 0.0008854752117908366\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00045740472346024214\tMax abs grad value: 0.018007353993375327\n",
      "Loss = 0.0008677144075988902\n",
      "Mean abs grad value: 0.00024402148382713485\tMax abs grad value: 0.00901167238491008\n",
      "Loss = 0.000739372537699176\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 7.198459078197817e-05\tMax abs grad value: 0.0019943126373592078\n",
      "Loss = 0.0005101018627326397\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 6.173990667549739e-05\tMax abs grad value: 0.0016111378399180497\n",
      "Loss = 0.0004439905870493762\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 8.416169865251468e-05\tMax abs grad value: 0.002418038711627201\n",
      "Loss = 0.00032237670444540406\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00010409171533612884\tMax abs grad value: 0.00215127145802008\n",
      "Loss = 0.00027798573097436027\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.821911659263608e-05\tMax abs grad value: 0.000653865140103315\n",
      "Loss = 0.00022617530721625112\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.7970411518506732e-05\tMax abs grad value: 0.0006247197869633929\n",
      "Loss = 0.00020364674685819785\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.8249185485795323e-05\tMax abs grad value: 0.0007196939333552637\n",
      "Loss = 0.00015906006465765457\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.2445989033089398e-05\tMax abs grad value: 0.0005595789747444447\n",
      "Loss = 0.00010708350598734014\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 9.132863264835667e-05\tMax abs grad value: 0.0019379919242719116\n",
      "Loss = 0.00011533250749137577\n",
      "Mean abs grad value: 3.163189293815384e-05\tMax abs grad value: 0.0007197658937989744\n",
      "Loss = 8.545751658345835e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.3704947181067845e-05\tMax abs grad value: 0.00033327790403889516\n",
      "Loss = 5.180137026384079e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 9.303418398881444e-06\tMax abs grad value: 0.00016744284094484315\n",
      "Loss = 3.810707658604931e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 6.428108839687219e-06\tMax abs grad value: 0.00017127664522668777\n",
      "Loss = 2.507522030914904e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 1.1285115676218195e-05\tMax abs grad value: 0.0002388699368017874\n",
      "Loss = 1.6260016282617812e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 3.307303426784852e-06\tMax abs grad value: 6.678421074712272e-05\n",
      "Loss = 7.934406762333464e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 2.1438137718177356e-06\tMax abs grad value: 4.5529824826474216e-05\n",
      "Loss = 5.769823157078155e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 9.713614941883465e-07\tMax abs grad value: 1.883431995025842e-05\n",
      "Loss = 3.123556641610551e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 8.55192702222077e-07\tMax abs grad value: 1.7009646940881328e-05\n",
      "Loss = 1.901107561787345e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 4.38967701947266e-07\tMax abs grad value: 9.638344805548339e-06\n",
      "Loss = 9.319781874603627e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.004915077076723468\tMax abs grad value: 0.07612690775933746\n",
      "Loss = 2.3073487495073306\n",
      "Mean abs grad value: 0.007437692659361737\tMax abs grad value: 0.25560083592705823\n",
      "Loss = 2.224293300215244\n",
      "Train accuracy: 0.128\t\tTest accuracy: 0.116\n",
      "Mean abs grad value: 0.016588509686371402\tMax abs grad value: 0.706284061425516\n",
      "Loss = 2.1142444043062416\n",
      "Train accuracy: 0.262\t\tTest accuracy: 0.242\n",
      "Mean abs grad value: 0.008308889843771053\tMax abs grad value: 0.16978582636818468\n",
      "Loss = 1.9643846541102519\n",
      "Train accuracy: 0.517\t\tTest accuracy: 0.504\n",
      "Mean abs grad value: 0.012875812007823187\tMax abs grad value: 0.3945218993785193\n",
      "Loss = 1.813238384593386\n",
      "Train accuracy: 0.358\t\tTest accuracy: 0.318\n",
      "Mean abs grad value: 0.04785382553372491\tMax abs grad value: 1.9618979604903355\n",
      "Loss = 1.8262098880094229\n",
      "Mean abs grad value: 0.022364042787226035\tMax abs grad value: 0.7559374495712826\n",
      "Loss = 1.6384908300199599\n",
      "Train accuracy: 0.362\t\tTest accuracy: 0.349\n",
      "Mean abs grad value: 0.045147178203493524\tMax abs grad value: 2.331987450661883\n",
      "Loss = 1.494220594158686\n",
      "Mean abs grad value: 0.025246122827584108\tMax abs grad value: 0.9462952603259676\n",
      "Loss = 1.4473488746487155\n",
      "Train accuracy: 0.439\t\tTest accuracy: 0.440\n",
      "Mean abs grad value: 0.1000741773836322\tMax abs grad value: 3.9496114828259663\n",
      "Loss = 2.2619204615874198\n",
      "Mean abs grad value: 0.023711477832743195\tMax abs grad value: 0.9465339756055721\n",
      "Loss = 1.2708544114014793\n",
      "Train accuracy: 0.585\t\tTest accuracy: 0.598\n",
      "Mean abs grad value: 0.024421201481938694\tMax abs grad value: 0.8755507333632631\n",
      "Loss = 1.1428028727167103\n",
      "Train accuracy: 0.638\t\tTest accuracy: 0.633\n",
      "Mean abs grad value: 0.015560374617009282\tMax abs grad value: 0.5978828031193911\n",
      "Loss = 1.038086568857435\n",
      "Train accuracy: 0.699\t\tTest accuracy: 0.684\n",
      "Mean abs grad value: 0.00988998369580029\tMax abs grad value: 0.35183640824130363\n",
      "Loss = 0.9867844124595083\n",
      "Train accuracy: 0.751\t\tTest accuracy: 0.722\n",
      "Mean abs grad value: 0.01065156492860208\tMax abs grad value: 0.37605371035498336\n",
      "Loss = 0.9511000278434268\n",
      "Train accuracy: 0.753\t\tTest accuracy: 0.709\n",
      "Mean abs grad value: 0.012000912449364099\tMax abs grad value: 0.40271776585530644\n",
      "Loss = 0.8827520109808684\n",
      "Train accuracy: 0.771\t\tTest accuracy: 0.736\n",
      "Mean abs grad value: 0.016101573571738123\tMax abs grad value: 0.6765613770703863\n",
      "Loss = 0.706666693230002\n",
      "Train accuracy: 0.806\t\tTest accuracy: 0.771\n",
      "Mean abs grad value: 0.031521076600098195\tMax abs grad value: 1.4207575578538882\n",
      "Loss = 0.6835044741718079\n",
      "Mean abs grad value: 0.015622974672163352\tMax abs grad value: 0.8043242880712972\n",
      "Loss = 0.6310977649482293\n",
      "Train accuracy: 0.827\t\tTest accuracy: 0.811\n",
      "Mean abs grad value: 0.010074305000881328\tMax abs grad value: 0.34743164237901686\n",
      "Loss = 0.5422177783494017\n",
      "Train accuracy: 0.848\t\tTest accuracy: 0.820\n",
      "Mean abs grad value: 0.009081228669610274\tMax abs grad value: 0.42512347587534394\n",
      "Loss = 0.4877141588574484\n",
      "Train accuracy: 0.863\t\tTest accuracy: 0.838\n",
      "Mean abs grad value: 0.008645100468396684\tMax abs grad value: 0.3019757304125186\n",
      "Loss = 0.4550504690918585\n",
      "Train accuracy: 0.875\t\tTest accuracy: 0.849\n",
      "Mean abs grad value: 0.008111811085177095\tMax abs grad value: 0.22908919045298048\n",
      "Loss = 0.4331173790077528\n",
      "Train accuracy: 0.881\t\tTest accuracy: 0.847\n",
      "Mean abs grad value: 0.006664516131781024\tMax abs grad value: 0.21425727811593206\n",
      "Loss = 0.3985622058924067\n",
      "Train accuracy: 0.883\t\tTest accuracy: 0.864\n",
      "Mean abs grad value: 0.011611287345369559\tMax abs grad value: 0.4168331708571659\n",
      "Loss = 0.33900413699949905\n",
      "Train accuracy: 0.889\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.028022765818491977\tMax abs grad value: 1.00215571479689\n",
      "Loss = 0.403340712254235\n",
      "Mean abs grad value: 0.0084677904778874\tMax abs grad value: 0.3061844612960705\n",
      "Loss = 0.31892779656151216\n",
      "Train accuracy: 0.896\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.005474972966182012\tMax abs grad value: 0.1737379443079372\n",
      "Loss = 0.30553222686925924\n",
      "Train accuracy: 0.902\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.004484617031554714\tMax abs grad value: 0.10778797702267716\n",
      "Loss = 0.2902969656404979\n",
      "Train accuracy: 0.909\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.0045660910423796905\tMax abs grad value: 0.13522286741223868\n",
      "Loss = 0.2773532824287933\n",
      "Train accuracy: 0.910\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.005949962539628614\tMax abs grad value: 0.20388526752844938\n",
      "Loss = 0.2532982273998311\n",
      "Train accuracy: 0.914\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.00872071223371749\tMax abs grad value: 0.3825437085853931\n",
      "Loss = 0.23700940068837573\n",
      "Train accuracy: 0.921\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.005115975338797501\tMax abs grad value: 0.11449988915058248\n",
      "Loss = 0.2217461881808548\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.004666884309953134\tMax abs grad value: 0.1471595154268658\n",
      "Loss = 0.209894370015148\n",
      "Train accuracy: 0.935\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.005113732279192735\tMax abs grad value: 0.20750474297889987\n",
      "Loss = 0.19541300272511192\n",
      "Train accuracy: 0.937\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.005359260688132878\tMax abs grad value: 0.35300858039624977\n",
      "Loss = 0.17744878751523327\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.00731319101446215\tMax abs grad value: 0.28961935919294224\n",
      "Loss = 0.17093347821172447\n",
      "Train accuracy: 0.945\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0030375260627477215\tMax abs grad value: 0.07992942730187709\n",
      "Loss = 0.16043488758098534\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0025324598775513167\tMax abs grad value: 0.07382176009537089\n",
      "Loss = 0.15543318186078364\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0027274576131286346\tMax abs grad value: 0.067992631852293\n",
      "Loss = 0.1475663640809774\n",
      "Train accuracy: 0.959\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.004520621173064492\tMax abs grad value: 0.13899259853176932\n",
      "Loss = 0.13493093014321672\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.007262837480478589\tMax abs grad value: 0.37225489485863306\n",
      "Loss = 0.1334637967216728\n",
      "Mean abs grad value: 0.003686465492981419\tMax abs grad value: 0.12473785544097457\n",
      "Loss = 0.12834139354928842\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0030902758147380856\tMax abs grad value: 0.11538761837920977\n",
      "Loss = 0.11996485358599439\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.005957187136342443\tMax abs grad value: 0.32091866418642556\n",
      "Loss = 0.10637423084394103\n",
      "Train accuracy: 0.962\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.006674865820157538\tMax abs grad value: 0.34076373560052636\n",
      "Loss = 0.10244817079015761\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0030678778179108854\tMax abs grad value: 0.08268223161062022\n",
      "Loss = 0.09631514998621658\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.002160759936001065\tMax abs grad value: 0.06969892592547684\n",
      "Loss = 0.09334460809257837\n",
      "Train accuracy: 0.966\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0025028237651094636\tMax abs grad value: 0.0671355377709251\n",
      "Loss = 0.0886819442477534\n",
      "Train accuracy: 0.965\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.003164728660580991\tMax abs grad value: 0.09196786727562214\n",
      "Loss = 0.08348930536936512\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.008137297000263647\tMax abs grad value: 0.4204284012385396\n",
      "Loss = 0.08333264880265998\n",
      "Mean abs grad value: 0.004496081847590082\tMax abs grad value: 0.1807163308279147\n",
      "Loss = 0.07839681591820843\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002611040675576584\tMax abs grad value: 0.06967699044391226\n",
      "Loss = 0.07159855933228022\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002267755130531353\tMax abs grad value: 0.04505020895665597\n",
      "Loss = 0.06714376316931535\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0024489928683371696\tMax abs grad value: 0.06593473862233042\n",
      "Loss = 0.06147738069777192\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.004269882597055281\tMax abs grad value: 0.11285057768426203\n",
      "Loss = 0.05540321848761043\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0029110990102820277\tMax abs grad value: 0.07569477208177824\n",
      "Loss = 0.04849798529672878\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0016873834920281675\tMax abs grad value: 0.04910316934771206\n",
      "Loss = 0.042808831954341584\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0020905332014207645\tMax abs grad value: 0.09583409569866558\n",
      "Loss = 0.03970692397623055\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00230245454276067\tMax abs grad value: 0.1116941717565467\n",
      "Loss = 0.0382665760112513\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0014978563458766156\tMax abs grad value: 0.03372710599249976\n",
      "Loss = 0.03675159615781854\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.001657515753089383\tMax abs grad value: 0.06615375445131849\n",
      "Loss = 0.035105206747002765\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.002014135234563996\tMax abs grad value: 0.10357621730672022\n",
      "Loss = 0.032428410355293195\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0020834703540099403\tMax abs grad value: 0.09701481825090216\n",
      "Loss = 0.028619893360584178\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.005367892817754107\tMax abs grad value: 0.28930122725097684\n",
      "Loss = 0.02900859613974347\n",
      "Mean abs grad value: 0.002667564500102374\tMax abs grad value: 0.09447357342273813\n",
      "Loss = 0.025509064879323303\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0013365562293083117\tMax abs grad value: 0.03186720788775545\n",
      "Loss = 0.022211570828504997\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0011684532340445334\tMax abs grad value: 0.03360217046852761\n",
      "Loss = 0.02031033497293469\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0016356783924349235\tMax abs grad value: 0.052341815699112795\n",
      "Loss = 0.018008893108933867\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0011987201521868696\tMax abs grad value: 0.03302730945817804\n",
      "Loss = 0.01611081197278844\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0010696434140413282\tMax abs grad value: 0.03185849418394311\n",
      "Loss = 0.014674701255748617\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0008126036575757431\tMax abs grad value: 0.018766479244687696\n",
      "Loss = 0.013263846934282949\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0008741089314854225\tMax abs grad value: 0.035061283926196646\n",
      "Loss = 0.011476174274730331\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0019316636434149952\tMax abs grad value: 0.09414586057665987\n",
      "Loss = 0.010923354115076637\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0007255152414232692\tMax abs grad value: 0.022337326707202804\n",
      "Loss = 0.009892826030465486\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0006122468840328375\tMax abs grad value: 0.019076736004801198\n",
      "Loss = 0.009532549990609799\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.000773790701795516\tMax abs grad value: 0.02629645872013493\n",
      "Loss = 0.008766566547405303\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0007647780289778793\tMax abs grad value: 0.025938081672302014\n",
      "Loss = 0.007630613298294946\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0026590784901043578\tMax abs grad value: 0.10732577355059486\n",
      "Loss = 0.008402336994456607\n",
      "Mean abs grad value: 0.0011471898305426653\tMax abs grad value: 0.04949285485166004\n",
      "Loss = 0.007113156497504373\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0006291852258683149\tMax abs grad value: 0.0190439391237971\n",
      "Loss = 0.006078030490792691\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00044219383505189787\tMax abs grad value: 0.008525328719526264\n",
      "Loss = 0.005333847146679562\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0005115139334331872\tMax abs grad value: 0.013069975560489795\n",
      "Loss = 0.004964166956676301\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00047747871681239946\tMax abs grad value: 0.012578936972120624\n",
      "Loss = 0.0044498784306587396\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00041665346331910065\tMax abs grad value: 0.013966572877691466\n",
      "Loss = 0.003883947894744348\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00032633422997795975\tMax abs grad value: 0.00818008632796638\n",
      "Loss = 0.003419145134087737\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0002694748356657937\tMax abs grad value: 0.005604402871250324\n",
      "Loss = 0.00286064534764792\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0009252362702624136\tMax abs grad value: 0.040457870501026755\n",
      "Loss = 0.0028091255292923105\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00037275501444825656\tMax abs grad value: 0.01107716825305671\n",
      "Loss = 0.0019708399172649834\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00019910015286335898\tMax abs grad value: 0.005360739798357884\n",
      "Loss = 0.0018323257658253787\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00015789759006192835\tMax abs grad value: 0.003574446818516471\n",
      "Loss = 0.0017074914411770068\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00018861894024051938\tMax abs grad value: 0.0042466702676491695\n",
      "Loss = 0.0016172054428095336\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00018469882381947028\tMax abs grad value: 0.004705124039252851\n",
      "Loss = 0.001405952318545201\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001215564781634347\tMax abs grad value: 0.03614447512014939\n",
      "Loss = 0.0021671426780583373\n",
      "Mean abs grad value: 0.00027211973082831185\tMax abs grad value: 0.008967599023523612\n",
      "Loss = 0.0013325014206874372\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00015077650851880699\tMax abs grad value: 0.004383022567233802\n",
      "Loss = 0.001105240555254203\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00011101898446387342\tMax abs grad value: 0.0021826354305336383\n",
      "Loss = 0.0009501884607639895\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00013586065084631902\tMax abs grad value: 0.004040039219874599\n",
      "Loss = 0.0008301481048012696\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00014344382306604136\tMax abs grad value: 0.0043096178529486604\n",
      "Loss = 0.0006830968340880978\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00010508901407331515\tMax abs grad value: 0.0032548941555763673\n",
      "Loss = 0.0005803940707502237\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 8.982807867994473e-05\tMax abs grad value: 0.002645025709800247\n",
      "Loss = 0.0004445056694385786\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00010085558019374017\tMax abs grad value: 0.0030534347479959484\n",
      "Loss = 0.0003646837680602099\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 4.787750204561412e-05\tMax abs grad value: 0.0014943010059065547\n",
      "Loss = 0.0003223907905351251\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 3.8159799343832795e-05\tMax abs grad value: 0.001015707953699014\n",
      "Loss = 0.0002881170453024333\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.557090876462413e-05\tMax abs grad value: 0.0011908537496667594\n",
      "Loss = 0.0002536296630085451\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.908031120792631e-05\tMax abs grad value: 0.0016494800442176886\n",
      "Loss = 0.00021218966282192682\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 3.074277745596939e-05\tMax abs grad value: 0.0006309841223974325\n",
      "Loss = 0.00016960594120753078\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.4874395608507636e-05\tMax abs grad value: 0.0004701744525525197\n",
      "Loss = 0.00014397272213671774\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.7214750296584672e-05\tMax abs grad value: 0.0008613227499997389\n",
      "Loss = 0.00011468869174688423\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 4.559921897505922e-05\tMax abs grad value: 0.0016944821684377876\n",
      "Loss = 9.46399548914725e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 2.313560341038076e-05\tMax abs grad value: 0.0006392836537342918\n",
      "Loss = 7.502130439663397e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 1.4847886108042905e-05\tMax abs grad value: 0.00034501270970720035\n",
      "Loss = 6.122150668804455e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 1.2329302419387152e-05\tMax abs grad value: 0.00026700560073302545\n",
      "Loss = 5.030769489214617e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 8.766282314434138e-06\tMax abs grad value: 0.0002157973380643511\n",
      "Loss = 4.0776546025587006e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 8.988854581809524e-06\tMax abs grad value: 0.00019358719307248975\n",
      "Loss = 3.014675206467867e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 6.76177048884441e-05\tMax abs grad value: 0.0015595063517782333\n",
      "Loss = 7.071952050554594e-05\n",
      "Mean abs grad value: 9.662673280260169e-06\tMax abs grad value: 0.00018439558808258533\n",
      "Loss = 2.4536794060645352e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 4.903419257964371e-06\tMax abs grad value: 9.735307811385096e-05\n",
      "Loss = 1.629876255577861e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.8522327851427824e-06\tMax abs grad value: 4.477424999121471e-05\n",
      "Loss = 1.0524936281138861e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.522347289023266e-06\tMax abs grad value: 7.747363097034034e-05\n",
      "Loss = 6.306656577542285e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.080669233941373e-06\tMax abs grad value: 5.004983158753401e-05\n",
      "Loss = 3.0929368429466267e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 8.286642476856181e-07\tMax abs grad value: 1.5428866275994706e-05\n",
      "Loss = 1.8381124134560756e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 3.875586058844574e-07\tMax abs grad value: 5.883910519860947e-06\n",
      "Loss = 1.2322704546800408e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.005977306293116903\tMax abs grad value: 0.09738634925733142\n",
      "Loss = 2.32152799055381\n",
      "Mean abs grad value: 0.004257553075713152\tMax abs grad value: 0.11723969810882967\n",
      "Loss = 2.232072711906851\n",
      "Train accuracy: 0.102\t\tTest accuracy: 0.118\n",
      "Mean abs grad value: 0.013686262081232357\tMax abs grad value: 0.23135591915476506\n",
      "Loss = 2.0677557504048125\n",
      "Train accuracy: 0.266\t\tTest accuracy: 0.280\n",
      "Mean abs grad value: 0.012345716718799212\tMax abs grad value: 0.24142377851253596\n",
      "Loss = 1.8053014990068033\n",
      "Train accuracy: 0.356\t\tTest accuracy: 0.329\n",
      "Mean abs grad value: 0.8826357041754914\tMax abs grad value: 28.802640088586877\n",
      "Loss = 45.920358187602645\n",
      "Mean abs grad value: 0.012527805551439548\tMax abs grad value: 0.4331881035634172\n",
      "Loss = 1.6928127103545814\n",
      "Train accuracy: 0.350\t\tTest accuracy: 0.320\n",
      "Mean abs grad value: 0.015910193492280292\tMax abs grad value: 0.35881352838460207\n",
      "Loss = 1.5646392320791684\n",
      "Train accuracy: 0.463\t\tTest accuracy: 0.456\n",
      "Mean abs grad value: 0.022970978090711643\tMax abs grad value: 1.0580291769818975\n",
      "Loss = 1.521289071041148\n",
      "Mean abs grad value: 0.014662988942441854\tMax abs grad value: 0.49781311271979833\n",
      "Loss = 1.4762267976898338\n",
      "Train accuracy: 0.512\t\tTest accuracy: 0.498\n",
      "Mean abs grad value: 0.016270462691956204\tMax abs grad value: 0.6363377206273542\n",
      "Loss = 1.2833261979956399\n",
      "Train accuracy: 0.540\t\tTest accuracy: 0.531\n",
      "Mean abs grad value: 0.0262430559387418\tMax abs grad value: 0.9472392483363008\n",
      "Loss = 1.1441766415646495\n",
      "Train accuracy: 0.566\t\tTest accuracy: 0.531\n",
      "Mean abs grad value: 0.011224049267945832\tMax abs grad value: 0.4274702060210649\n",
      "Loss = 0.9773847523726822\n",
      "Train accuracy: 0.650\t\tTest accuracy: 0.624\n",
      "Mean abs grad value: 0.011483269246869491\tMax abs grad value: 0.6320599827994932\n",
      "Loss = 0.854429572883562\n",
      "Train accuracy: 0.729\t\tTest accuracy: 0.716\n",
      "Mean abs grad value: 0.011513068352127634\tMax abs grad value: 0.5213908941579302\n",
      "Loss = 0.7769340851656876\n",
      "Train accuracy: 0.785\t\tTest accuracy: 0.762\n",
      "Mean abs grad value: 0.01038283629952521\tMax abs grad value: 0.40831608717425705\n",
      "Loss = 0.6978749597983676\n",
      "Train accuracy: 0.795\t\tTest accuracy: 0.756\n",
      "Mean abs grad value: 0.009824404431041286\tMax abs grad value: 0.35962366062294526\n",
      "Loss = 0.6688721565521827\n",
      "Train accuracy: 0.822\t\tTest accuracy: 0.802\n",
      "Mean abs grad value: 0.005936223914549665\tMax abs grad value: 0.12251541409957484\n",
      "Loss = 0.6306649073088564\n",
      "Train accuracy: 0.831\t\tTest accuracy: 0.809\n",
      "Mean abs grad value: 0.007207865429411939\tMax abs grad value: 0.3052760591246131\n",
      "Loss = 0.5833282500110011\n",
      "Train accuracy: 0.834\t\tTest accuracy: 0.824\n",
      "Mean abs grad value: 0.008409342850465837\tMax abs grad value: 0.3312497020112879\n",
      "Loss = 0.5184248548193584\n",
      "Train accuracy: 0.843\t\tTest accuracy: 0.829\n",
      "Mean abs grad value: 0.008624724819712732\tMax abs grad value: 0.3239370462256849\n",
      "Loss = 0.4922181152254612\n",
      "Train accuracy: 0.860\t\tTest accuracy: 0.827\n",
      "Mean abs grad value: 0.005128691201960698\tMax abs grad value: 0.16270375955713823\n",
      "Loss = 0.4694793800546389\n",
      "Train accuracy: 0.863\t\tTest accuracy: 0.840\n",
      "Mean abs grad value: 0.004806747774565431\tMax abs grad value: 0.19634037435153592\n",
      "Loss = 0.44320329518601453\n",
      "Train accuracy: 0.867\t\tTest accuracy: 0.847\n",
      "Mean abs grad value: 0.006670453677657201\tMax abs grad value: 0.2966999729057259\n",
      "Loss = 0.4072550984020456\n",
      "Train accuracy: 0.875\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.010378631785879581\tMax abs grad value: 0.7019749395437994\n",
      "Loss = 0.37187914152572693\n",
      "Train accuracy: 0.878\t\tTest accuracy: 0.864\n",
      "Mean abs grad value: 0.005157430719921058\tMax abs grad value: 0.1702472130379956\n",
      "Loss = 0.3173349442591237\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.004582015985248657\tMax abs grad value: 0.1207177088701403\n",
      "Loss = 0.293907825031699\n",
      "Train accuracy: 0.907\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.003586645974792118\tMax abs grad value: 0.10913023279933287\n",
      "Loss = 0.2751571473029553\n",
      "Train accuracy: 0.911\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.004300379986568718\tMax abs grad value: 0.13972187801340244\n",
      "Loss = 0.25263140284451335\n",
      "Train accuracy: 0.916\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.006001685905615168\tMax abs grad value: 0.1652806409090563\n",
      "Loss = 0.22784367554179807\n",
      "Train accuracy: 0.919\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.003590645674111744\tMax abs grad value: 0.11323176039863021\n",
      "Loss = 0.20764605185724713\n",
      "Train accuracy: 0.934\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.0031467242982617934\tMax abs grad value: 0.11064675331061537\n",
      "Loss = 0.1938955198949741\n",
      "Train accuracy: 0.935\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.003583903693087722\tMax abs grad value: 0.09577665544149201\n",
      "Loss = 0.18040603251780815\n",
      "Train accuracy: 0.939\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0034290349236106143\tMax abs grad value: 0.08430615468196846\n",
      "Loss = 0.1698106913095677\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.002862992099909556\tMax abs grad value: 0.10375108187735092\n",
      "Loss = 0.15790679539810518\n",
      "Train accuracy: 0.942\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.003375409809902775\tMax abs grad value: 0.08560688123722081\n",
      "Loss = 0.14208477211779783\n",
      "Train accuracy: 0.951\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.004785291763687843\tMax abs grad value: 0.21859847575423258\n",
      "Loss = 0.12660937850147205\n",
      "Train accuracy: 0.953\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0035411845151860437\tMax abs grad value: 0.07629934341492624\n",
      "Loss = 0.1128486178033406\n",
      "Train accuracy: 0.960\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.002463945917300566\tMax abs grad value: 0.060431651403758335\n",
      "Loss = 0.10666108176381883\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0026500719230661187\tMax abs grad value: 0.07684689706764149\n",
      "Loss = 0.09995014922154807\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.003047015641182039\tMax abs grad value: 0.06613203423479666\n",
      "Loss = 0.09219435240846031\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.003420582102906924\tMax abs grad value: 0.10887732285700838\n",
      "Loss = 0.07893327309991362\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.004718207665842859\tMax abs grad value: 0.14725327953443568\n",
      "Loss = 0.07163998605852062\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0017613737529048013\tMax abs grad value: 0.03356908773549282\n",
      "Loss = 0.06401820163069838\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0016154298979001028\tMax abs grad value: 0.0333560631010242\n",
      "Loss = 0.06151676020035439\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.001973156643122864\tMax abs grad value: 0.040238321489405524\n",
      "Loss = 0.05734084979669317\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0024478303547225953\tMax abs grad value: 0.05713642864764554\n",
      "Loss = 0.050491397163375425\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.005175218458654113\tMax abs grad value: 0.1808427257844548\n",
      "Loss = 0.04974828824737956\n",
      "Mean abs grad value: 0.002643025567716877\tMax abs grad value: 0.08083222550847316\n",
      "Loss = 0.04507251209259204\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.002263237460448913\tMax abs grad value: 0.06779711247693446\n",
      "Loss = 0.039624997570685\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.002767268262985714\tMax abs grad value: 0.13409543717980538\n",
      "Loss = 0.037283123437234215\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0011059396822359025\tMax abs grad value: 0.024895438698229747\n",
      "Loss = 0.03438994391382396\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0010643355073093816\tMax abs grad value: 0.026569850114627667\n",
      "Loss = 0.033416377640434564\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0014306140190693455\tMax abs grad value: 0.03469116713385487\n",
      "Loss = 0.030967487473363454\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0018739439604246362\tMax abs grad value: 0.06013913108059121\n",
      "Loss = 0.027414840698949554\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00184245650145893\tMax abs grad value: 0.05945577234799368\n",
      "Loss = 0.02234018122481601\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0019734377926160897\tMax abs grad value: 0.07687730540390177\n",
      "Loss = 0.01945711630986555\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0011569446388409528\tMax abs grad value: 0.031127159297624003\n",
      "Loss = 0.016630832538586438\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0009191247801812599\tMax abs grad value: 0.020955478214442318\n",
      "Loss = 0.014198360970995525\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0009831175855160319\tMax abs grad value: 0.02809467031915161\n",
      "Loss = 0.011859880627352049\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0018997127413647947\tMax abs grad value: 0.07260482611368721\n",
      "Loss = 0.011240968381652136\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0007601626151188285\tMax abs grad value: 0.023018789219095833\n",
      "Loss = 0.00915908888745502\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0005534827928839221\tMax abs grad value: 0.0143982409040519\n",
      "Loss = 0.008388851621986793\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0006587072280224046\tMax abs grad value: 0.02332331694646712\n",
      "Loss = 0.007611416912998667\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00100245350252555\tMax abs grad value: 0.03533048127123751\n",
      "Loss = 0.006636597798756522\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0006569607614769549\tMax abs grad value: 0.020627907654174472\n",
      "Loss = 0.005581849547038959\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00038381031539875995\tMax abs grad value: 0.010407852000432734\n",
      "Loss = 0.004747751757027255\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0002899389425415995\tMax abs grad value: 0.008983340939199684\n",
      "Loss = 0.0039767820568240506\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0005865304046102455\tMax abs grad value: 0.023689746991186103\n",
      "Loss = 0.0033757065205706643\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.000319856789461631\tMax abs grad value: 0.010435433105942107\n",
      "Loss = 0.0027310808729943507\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0002775314148221885\tMax abs grad value: 0.0093408942650443\n",
      "Loss = 0.002405285047140457\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00023510605016364544\tMax abs grad value: 0.0055465734174079155\n",
      "Loss = 0.0019897938458229686\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00044866174759010223\tMax abs grad value: 0.020834097606391048\n",
      "Loss = 0.0016546794722627153\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00020856912615038883\tMax abs grad value: 0.00649094440516974\n",
      "Loss = 0.0012893655521064307\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00018311011339829238\tMax abs grad value: 0.004917993363586434\n",
      "Loss = 0.0011735286202815788\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0001512284114151403\tMax abs grad value: 0.0045692048720504\n",
      "Loss = 0.0008743926934171199\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00011819927323471316\tMax abs grad value: 0.003043104243004194\n",
      "Loss = 0.0006619524624206567\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 9.065013891310274e-05\tMax abs grad value: 0.003128827313256945\n",
      "Loss = 0.0004339506926326499\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 8.550492715232253e-05\tMax abs grad value: 0.0024734910330032243\n",
      "Loss = 0.00029434989262026217\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.705133282191191e-05\tMax abs grad value: 0.0011427108061854846\n",
      "Loss = 0.00021360333706540365\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.477012835440187e-05\tMax abs grad value: 0.0008913028392731182\n",
      "Loss = 0.00018094093389302057\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.336055810788335e-05\tMax abs grad value: 0.0005042946895885237\n",
      "Loss = 0.00013482442201240047\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.7449453550863247e-05\tMax abs grad value: 0.0003733706785523887\n",
      "Loss = 9.998926440047296e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.2773611820317582e-05\tMax abs grad value: 0.00027054442571196005\n",
      "Loss = 6.052160463768597e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.912967789112526e-05\tMax abs grad value: 0.001624388942291953\n",
      "Loss = 5.903829538677369e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 8.916814957577285e-06\tMax abs grad value: 0.0003452817487057757\n",
      "Loss = 2.5493448264781063e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.41777895720934e-06\tMax abs grad value: 0.00022284553282239235\n",
      "Loss = 2.0844468488743204e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 3.6050197393808886e-06\tMax abs grad value: 0.00011771245719513177\n",
      "Loss = 1.3065585735233775e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.985559151360374e-06\tMax abs grad value: 6.792114647890606e-05\n",
      "Loss = 8.323018527208564e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.3498557718626367e-06\tMax abs grad value: 4.054521628656842e-05\n",
      "Loss = 5.203067952393179e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.493112164283152e-06\tMax abs grad value: 5.239928322302942e-05\n",
      "Loss = 3.602204989211921e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 7.859761410704957e-07\tMax abs grad value: 3.412167978798385e-05\n",
      "Loss = 2.1964787145564957e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.1017088447969096e-07\tMax abs grad value: 1.1563552320044981e-05\n",
      "Loss = 1.3357635758440028e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.424745542218396e-07\tMax abs grad value: 9.842004424560746e-06\n",
      "Loss = 7.865531270155267e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.26924558323576697\tMax abs grad value: 4.7503764043215435\n",
      "Loss = 10.440594724604889\n",
      "Mean abs grad value: 0.1404482875883481\tMax abs grad value: 4.203420895778035\n",
      "Loss = 6.662795119346867\n",
      "Train accuracy: 0.082\t\tTest accuracy: 0.051\n",
      "Mean abs grad value: 0.0674716367353682\tMax abs grad value: 2.970951193624233\n",
      "Loss = 4.050754716203933\n",
      "Train accuracy: 0.113\t\tTest accuracy: 0.111\n",
      "Mean abs grad value: 0.03906585545359281\tMax abs grad value: 1.1663214686728383\n",
      "Loss = 2.9242633865508507\n",
      "Train accuracy: 0.111\t\tTest accuracy: 0.129\n",
      "Mean abs grad value: 0.017328285267883985\tMax abs grad value: 0.4732839519711492\n",
      "Loss = 2.3560717915336857\n",
      "Train accuracy: 0.139\t\tTest accuracy: 0.149\n",
      "Mean abs grad value: 0.013354572187519429\tMax abs grad value: 0.35089761876545905\n",
      "Loss = 2.2304011931049548\n",
      "Train accuracy: 0.183\t\tTest accuracy: 0.196\n",
      "Mean abs grad value: 0.011813099984353875\tMax abs grad value: 0.25537206855074374\n",
      "Loss = 2.007283403276062\n",
      "Train accuracy: 0.304\t\tTest accuracy: 0.322\n",
      "Mean abs grad value: 0.013925546396513368\tMax abs grad value: 0.5331136421982509\n",
      "Loss = 1.687742819333119\n",
      "Train accuracy: 0.445\t\tTest accuracy: 0.449\n",
      "Mean abs grad value: 0.045059829721176066\tMax abs grad value: 1.388864290751052\n",
      "Loss = 1.7467421299808872\n",
      "Mean abs grad value: 0.020782729756793565\tMax abs grad value: 0.7233430138424015\n",
      "Loss = 1.3888324732729345\n",
      "Train accuracy: 0.523\t\tTest accuracy: 0.478\n",
      "Mean abs grad value: 0.01999092898501898\tMax abs grad value: 0.6930721206920492\n",
      "Loss = 1.177313497165946\n",
      "Train accuracy: 0.615\t\tTest accuracy: 0.547\n",
      "Mean abs grad value: 0.013685385694087351\tMax abs grad value: 0.41244471925313403\n",
      "Loss = 1.0090000746979662\n",
      "Train accuracy: 0.682\t\tTest accuracy: 0.627\n",
      "Mean abs grad value: 0.011280176868905726\tMax abs grad value: 0.38858225810756974\n",
      "Loss = 0.8648445544451729\n",
      "Train accuracy: 0.719\t\tTest accuracy: 0.662\n",
      "Mean abs grad value: 0.013706614535204147\tMax abs grad value: 0.5531572323593146\n",
      "Loss = 0.7700576993588739\n",
      "Train accuracy: 0.746\t\tTest accuracy: 0.722\n",
      "Mean abs grad value: 0.012043246923060818\tMax abs grad value: 0.3768654926640064\n",
      "Loss = 0.6610290790124993\n",
      "Train accuracy: 0.780\t\tTest accuracy: 0.753\n",
      "Mean abs grad value: 0.007759470162446687\tMax abs grad value: 0.25105810045246735\n",
      "Loss = 0.4685002069476815\n",
      "Train accuracy: 0.848\t\tTest accuracy: 0.824\n",
      "Mean abs grad value: 0.017545223106609678\tMax abs grad value: 0.6272325818801663\n",
      "Loss = 0.4443252000004319\n",
      "Train accuracy: 0.846\t\tTest accuracy: 0.796\n",
      "Mean abs grad value: 0.005824754118142306\tMax abs grad value: 0.16120319265671376\n",
      "Loss = 0.3599550961979787\n",
      "Train accuracy: 0.879\t\tTest accuracy: 0.847\n",
      "Mean abs grad value: 0.004260975472129294\tMax abs grad value: 0.0848751360097729\n",
      "Loss = 0.3371533772446326\n",
      "Train accuracy: 0.889\t\tTest accuracy: 0.860\n",
      "Mean abs grad value: 0.005192868327242404\tMax abs grad value: 0.12815466040811613\n",
      "Loss = 0.3098369176655448\n",
      "Train accuracy: 0.895\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.005357693997137221\tMax abs grad value: 0.16132448111334938\n",
      "Loss = 0.2692515044533507\n",
      "Train accuracy: 0.908\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.01444908365155016\tMax abs grad value: 0.6903904320095103\n",
      "Loss = 0.2772176984758022\n",
      "Mean abs grad value: 0.0064600060237091535\tMax abs grad value: 0.20258762953097859\n",
      "Loss = 0.2381108203269637\n",
      "Train accuracy: 0.913\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.0037243712412322934\tMax abs grad value: 0.08948748090874462\n",
      "Loss = 0.20387380372406874\n",
      "Train accuracy: 0.932\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0028082142011517782\tMax abs grad value: 0.08042922574283705\n",
      "Loss = 0.17835119494396237\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0030184056524907776\tMax abs grad value: 0.06293540865363816\n",
      "Loss = 0.1536553647968509\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.005891888812762478\tMax abs grad value: 0.2192839634230111\n",
      "Loss = 0.14504111685891585\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0026618656798278813\tMax abs grad value: 0.08464379203896057\n",
      "Loss = 0.12494229946089463\n",
      "Train accuracy: 0.962\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0023231165617888356\tMax abs grad value: 0.04789817993636553\n",
      "Loss = 0.11280129108791065\n",
      "Train accuracy: 0.965\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.00275099453240526\tMax abs grad value: 0.0754828557814493\n",
      "Loss = 0.09933564352739642\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.002362188645367156\tMax abs grad value: 0.07138068044214768\n",
      "Loss = 0.08182400188598309\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0049267111965974825\tMax abs grad value: 0.11561469441260397\n",
      "Loss = 0.08122847019792752\n",
      "Train accuracy: 0.971\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0016806354795756483\tMax abs grad value: 0.03727616500469976\n",
      "Loss = 0.06436342261059148\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0012163654863793973\tMax abs grad value: 0.02489157288643171\n",
      "Loss = 0.06030193090580872\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0014655194257588836\tMax abs grad value: 0.040448092574453094\n",
      "Loss = 0.051501922239044304\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.003859328471067574\tMax abs grad value: 0.11055411071593907\n",
      "Loss = 0.04845606684683961\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0015223646693032402\tMax abs grad value: 0.04330223770897843\n",
      "Loss = 0.040621138725112624\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0010746569645767535\tMax abs grad value: 0.029599510833308137\n",
      "Loss = 0.03651744583095087\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0012982362932819971\tMax abs grad value: 0.04510426942516569\n",
      "Loss = 0.03133707458515829\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0014325390200396525\tMax abs grad value: 0.04582160720881482\n",
      "Loss = 0.024928977632730102\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0028609591011473086\tMax abs grad value: 0.08861502940354192\n",
      "Loss = 0.024548838557815818\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0012081697213202564\tMax abs grad value: 0.02486001093897445\n",
      "Loss = 0.020852132448352677\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.0007774382564548545\tMax abs grad value: 0.014044019496634343\n",
      "Loss = 0.019020146414416714\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 0.000985213971792411\tMax abs grad value: 0.03018489507681439\n",
      "Loss = 0.016786139745206898\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0008644045113553788\tMax abs grad value: 0.02599656804707636\n",
      "Loss = 0.013754431602956663\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.001956539728098043\tMax abs grad value: 0.07870702327026051\n",
      "Loss = 0.013256936643514171\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0006838758940150799\tMax abs grad value: 0.012199481647879457\n",
      "Loss = 0.009215170223583698\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0005216266388677333\tMax abs grad value: 0.008145934510132362\n",
      "Loss = 0.008108117101363048\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0005690060243067452\tMax abs grad value: 0.01646761953462445\n",
      "Loss = 0.0061744386688152905\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0013937888549228879\tMax abs grad value: 0.06658029742433363\n",
      "Loss = 0.006997230955697365\n",
      "Mean abs grad value: 0.0004789707846732044\tMax abs grad value: 0.02217840599067926\n",
      "Loss = 0.005558218058274384\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0003546577208360918\tMax abs grad value: 0.012369402614518831\n",
      "Loss = 0.004961249710588261\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0002813405098674095\tMax abs grad value: 0.0052255436567642905\n",
      "Loss = 0.004254565399366955\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0002770029649486112\tMax abs grad value: 0.007511062040114823\n",
      "Loss = 0.0036457110380645617\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0002098454081773579\tMax abs grad value: 0.00663216773014777\n",
      "Loss = 0.0024117444918051495\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0003370506304413018\tMax abs grad value: 0.013962812461774148\n",
      "Loss = 0.0016404098673475313\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0004682473092705188\tMax abs grad value: 0.011879259519306034\n",
      "Loss = 0.0012908115394071793\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00010418886784676236\tMax abs grad value: 0.0024741405983571864\n",
      "Loss = 0.0008104204424407079\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 8.025644397160632e-05\tMax abs grad value: 0.002443387499545668\n",
      "Loss = 0.0007130641545012706\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 6.696809634090761e-05\tMax abs grad value: 0.0018414470154653388\n",
      "Loss = 0.0005214062259992602\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 5.116649697455363e-05\tMax abs grad value: 0.0011600234606550326\n",
      "Loss = 0.0003702871036542501\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00015764348935690348\tMax abs grad value: 0.006560244903319055\n",
      "Loss = 0.00031425657965992185\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 3.501832900228472e-05\tMax abs grad value: 0.0010538076156239153\n",
      "Loss = 0.00019507809454475698\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.0123238591347823e-05\tMax abs grad value: 0.0009031094906094478\n",
      "Loss = 0.00017899073988416256\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.2105071799561975e-05\tMax abs grad value: 0.0009184962706058501\n",
      "Loss = 0.00012339415865283946\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.4108553644754954e-05\tMax abs grad value: 0.00047405150887348644\n",
      "Loss = 8.299588557201389e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.1345232188479515e-05\tMax abs grad value: 0.0003804968884445391\n",
      "Loss = 5.864471039042022e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.820018656962896e-05\tMax abs grad value: 0.0007027532473002609\n",
      "Loss = 4.343159494644733e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 7.73950375560614e-06\tMax abs grad value: 0.0002085525318937176\n",
      "Loss = 3.0578113329700805e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 6.096317343148386e-06\tMax abs grad value: 0.00018454959996517002\n",
      "Loss = 2.308843617121276e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 4.042232626522495e-06\tMax abs grad value: 0.00011403431636077555\n",
      "Loss = 1.49367304512477e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 3.324560401684375e-06\tMax abs grad value: 0.00011109883923307991\n",
      "Loss = 8.452241061098456e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.6922097206765546e-06\tMax abs grad value: 5.10447186653068e-05\n",
      "Loss = 4.211623353801705e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.1037057097372198e-06\tMax abs grad value: 2.4956284173117454e-05\n",
      "Loss = 2.9463902964411286e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.572034726294928e-07\tMax abs grad value: 1.70282871290394e-05\n",
      "Loss = 1.7225481290252674e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.1592547794118e-07\tMax abs grad value: 7.007765455897325e-06\n",
      "Loss = 9.163465481623779e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.22453964037041152\tMax abs grad value: 4.7263580005251\n",
      "Loss = 7.990676474628197\n",
      "Mean abs grad value: 0.09989070187138079\tMax abs grad value: 3.729987447487395\n",
      "Loss = 4.74904756642627\n",
      "Train accuracy: 0.111\t\tTest accuracy: 0.120\n",
      "Mean abs grad value: 0.08219208724905581\tMax abs grad value: 2.3164725335010905\n",
      "Loss = 3.5635581751586014\n",
      "Train accuracy: 0.170\t\tTest accuracy: 0.162\n",
      "Mean abs grad value: 0.03741929376672981\tMax abs grad value: 1.1738633507826965\n",
      "Loss = 2.512914218297067\n",
      "Train accuracy: 0.200\t\tTest accuracy: 0.209\n",
      "Mean abs grad value: 0.021146439146576827\tMax abs grad value: 0.4454175534660916\n",
      "Loss = 2.090987698176739\n",
      "Train accuracy: 0.269\t\tTest accuracy: 0.282\n",
      "Mean abs grad value: 0.017059316179561836\tMax abs grad value: 0.47120933497845713\n",
      "Loss = 1.8451064586568617\n",
      "Train accuracy: 0.367\t\tTest accuracy: 0.322\n",
      "Mean abs grad value: 0.01483794211928594\tMax abs grad value: 0.5296427984107258\n",
      "Loss = 1.6542283307238985\n",
      "Train accuracy: 0.425\t\tTest accuracy: 0.387\n",
      "Mean abs grad value: 0.018389784589258322\tMax abs grad value: 0.5879301629367747\n",
      "Loss = 1.2691597632109606\n",
      "Train accuracy: 0.556\t\tTest accuracy: 0.527\n",
      "Mean abs grad value: 0.01971254683344203\tMax abs grad value: 0.736926088939462\n",
      "Loss = 1.0838547405044199\n",
      "Train accuracy: 0.608\t\tTest accuracy: 0.578\n",
      "Mean abs grad value: 0.011337477875446055\tMax abs grad value: 0.3465427422033535\n",
      "Loss = 0.9273684932456624\n",
      "Train accuracy: 0.706\t\tTest accuracy: 0.640\n",
      "Mean abs grad value: 0.008937664955518709\tMax abs grad value: 0.19083854136480635\n",
      "Loss = 0.7923767237155593\n",
      "Train accuracy: 0.736\t\tTest accuracy: 0.693\n",
      "Mean abs grad value: 0.008479887548332534\tMax abs grad value: 0.4336570323394594\n",
      "Loss = 0.6932355493743457\n",
      "Train accuracy: 0.768\t\tTest accuracy: 0.727\n",
      "Mean abs grad value: 0.009452562301593104\tMax abs grad value: 0.35058321635486894\n",
      "Loss = 0.59282929293924\n",
      "Train accuracy: 0.805\t\tTest accuracy: 0.769\n",
      "Mean abs grad value: 0.009253561855270933\tMax abs grad value: 0.2288651401151762\n",
      "Loss = 0.5295107042637384\n",
      "Train accuracy: 0.829\t\tTest accuracy: 0.796\n",
      "Mean abs grad value: 0.007757004604911648\tMax abs grad value: 0.1766572549360571\n",
      "Loss = 0.46363619420009955\n",
      "Train accuracy: 0.850\t\tTest accuracy: 0.831\n",
      "Mean abs grad value: 0.007830493251582004\tMax abs grad value: 0.2811419757662904\n",
      "Loss = 0.36499330052063117\n",
      "Train accuracy: 0.871\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.010953118160666036\tMax abs grad value: 0.7352076178213781\n",
      "Loss = 0.3313240617752649\n",
      "Train accuracy: 0.890\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.0054446300314963305\tMax abs grad value: 0.15475583817031344\n",
      "Loss = 0.29211691722296357\n",
      "Train accuracy: 0.907\t\tTest accuracy: 0.898\n",
      "Mean abs grad value: 0.0040934188485917\tMax abs grad value: 0.08598390517950696\n",
      "Loss = 0.2721448982571708\n",
      "Train accuracy: 0.909\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.0047395108153803584\tMax abs grad value: 0.11987394513889081\n",
      "Loss = 0.2412015921537231\n",
      "Train accuracy: 0.922\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.005941064361206889\tMax abs grad value: 0.2995026692924426\n",
      "Loss = 0.21344049606495152\n",
      "Train accuracy: 0.933\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.0035869868154025093\tMax abs grad value: 0.09422491848282025\n",
      "Loss = 0.1854207895098165\n",
      "Train accuracy: 0.935\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0034267760289618115\tMax abs grad value: 0.08467440780374652\n",
      "Loss = 0.16983273658034292\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0035070432527270355\tMax abs grad value: 0.10549949877479574\n",
      "Loss = 0.1420822787390355\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.006398490708374324\tMax abs grad value: 0.34697876331291416\n",
      "Loss = 0.1238367578506452\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0032942364944095986\tMax abs grad value: 0.11204823023534356\n",
      "Loss = 0.10628245442143866\n",
      "Train accuracy: 0.962\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0024915531841692355\tMax abs grad value: 0.06630902512320733\n",
      "Loss = 0.09827572276044244\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0025248656929190076\tMax abs grad value: 0.09020277590731847\n",
      "Loss = 0.08944819207353329\n",
      "Train accuracy: 0.971\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002648283136150719\tMax abs grad value: 0.07027278861097219\n",
      "Loss = 0.07997119669848236\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0033361849823613367\tMax abs grad value: 0.14616060246473783\n",
      "Loss = 0.07200953209474927\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.001987563519857728\tMax abs grad value: 0.06373142340081131\n",
      "Loss = 0.06365548499506025\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.001652262270606147\tMax abs grad value: 0.07091356546985052\n",
      "Loss = 0.058243919817057434\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0016550981742493507\tMax abs grad value: 0.07275502009976204\n",
      "Loss = 0.050375751210935536\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0034556666170864735\tMax abs grad value: 0.19276562595655697\n",
      "Loss = 0.04570715187590397\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0015152997139001988\tMax abs grad value: 0.03124772725942107\n",
      "Loss = 0.03649195893951606\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0011323259656276228\tMax abs grad value: 0.026569953237887772\n",
      "Loss = 0.03351243406433591\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0013136273913666257\tMax abs grad value: 0.049540536888818446\n",
      "Loss = 0.02791375281850938\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0016483110032815243\tMax abs grad value: 0.05631948805919657\n",
      "Loss = 0.022704800643335965\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0016994667547697937\tMax abs grad value: 0.09138623920115214\n",
      "Loss = 0.020042283139333015\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0010350837776289302\tMax abs grad value: 0.042155728122197714\n",
      "Loss = 0.018185342737554084\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0007794742784569685\tMax abs grad value: 0.026427684742757106\n",
      "Loss = 0.015965044542455856\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0007259147165080528\tMax abs grad value: 0.028135802146213813\n",
      "Loss = 0.014806419298155132\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0009241850048013094\tMax abs grad value: 0.0334737839291165\n",
      "Loss = 0.011605177900306364\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.002404952061107576\tMax abs grad value: 0.09228463262871184\n",
      "Loss = 0.012005770504962569\n",
      "Mean abs grad value: 0.0008603685206413133\tMax abs grad value: 0.024982437447481833\n",
      "Loss = 0.009924630532256963\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0006367987527403608\tMax abs grad value: 0.014449024511022411\n",
      "Loss = 0.008496560413742435\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0005392503046073256\tMax abs grad value: 0.013171342624184958\n",
      "Loss = 0.006667116478944475\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0004918078511627129\tMax abs grad value: 0.01453271013692887\n",
      "Loss = 0.005412817030582767\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00032357410488674965\tMax abs grad value: 0.006746033013909987\n",
      "Loss = 0.004570449403800797\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0002657949980798888\tMax abs grad value: 0.007672486185244974\n",
      "Loss = 0.0034926188874691132\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00038119964032743786\tMax abs grad value: 0.014027897920656472\n",
      "Loss = 0.002682592337556384\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00036076410624493756\tMax abs grad value: 0.013609146317440998\n",
      "Loss = 0.002204443158127317\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00026511619091306934\tMax abs grad value: 0.009158730958905261\n",
      "Loss = 0.001913788040055686\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0001936360802470277\tMax abs grad value: 0.005881103825294833\n",
      "Loss = 0.001693801594867489\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00016725371144689678\tMax abs grad value: 0.0031366876779068313\n",
      "Loss = 0.0013916376344132626\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00014355252281502708\tMax abs grad value: 0.0034771647280527397\n",
      "Loss = 0.0011047225336974639\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00011677458293895534\tMax abs grad value: 0.003187125729973042\n",
      "Loss = 0.0007277454594865979\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 9.5947813236301e-05\tMax abs grad value: 0.0026492531158803733\n",
      "Loss = 0.00046058000557327636\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 7.947861005469613e-05\tMax abs grad value: 0.0021347266670736476\n",
      "Loss = 0.0003404098237892042\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 9.116943994018244e-05\tMax abs grad value: 0.0036494855253861097\n",
      "Loss = 0.00024418018846514213\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 3.4801966019895994e-05\tMax abs grad value: 0.0007696279822382844\n",
      "Loss = 0.0001708896503018214\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 2.4495748021227785e-05\tMax abs grad value: 0.0004165189973832827\n",
      "Loss = 0.00015050014393646537\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 2.1580159884212305e-05\tMax abs grad value: 0.0007185211423616092\n",
      "Loss = 0.00011933905699696493\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 2.967965344325119e-05\tMax abs grad value: 0.0014481288388854872\n",
      "Loss = 0.00010024833875059407\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 1.5169950745280589e-05\tMax abs grad value: 0.0003613930723418801\n",
      "Loss = 8.022364387977028e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 1.3253574251958077e-05\tMax abs grad value: 0.00027706520981920975\n",
      "Loss = 6.699739719626389e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 9.444779106431605e-06\tMax abs grad value: 0.00025699907896944426\n",
      "Loss = 4.985571613804237e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.1294447315235639e-05\tMax abs grad value: 0.00036677692120425906\n",
      "Loss = 3.945646667343399e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 5.675291645959667e-06\tMax abs grad value: 0.00018114857903425453\n",
      "Loss = 2.9581517026464004e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.860100662538353e-06\tMax abs grad value: 0.00010238458051332867\n",
      "Loss = 2.1950430778684213e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.782627591356666e-06\tMax abs grad value: 7.295855343819156e-05\n",
      "Loss = 1.4456197134779367e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.2033068925395047e-06\tMax abs grad value: 6.993103070840086e-05\n",
      "Loss = 8.92816834329367e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.2998739107287141e-06\tMax abs grad value: 4.1549115620780045e-05\n",
      "Loss = 6.25801639576606e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.2297433664355228e-06\tMax abs grad value: 3.7216651386789665e-05\n",
      "Loss = 4.1153423556807085e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 7.520970395120399e-07\tMax abs grad value: 2.109161572913053e-05\n",
      "Loss = 2.849007810933143e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.4929435585910686e-07\tMax abs grad value: 9.517815527523868e-06\n",
      "Loss = 2.1389128618056947e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.3087074323028746\tMax abs grad value: 8.039883808647156\n",
      "Loss = 10.622657804691654\n",
      "Mean abs grad value: 0.15622768031504125\tMax abs grad value: 5.355248098636714\n",
      "Loss = 7.149127456002145\n",
      "Train accuracy: 0.096\t\tTest accuracy: 0.111\n",
      "Mean abs grad value: 0.07292340003538718\tMax abs grad value: 1.968391997456576\n",
      "Loss = 3.8405055261525485\n",
      "Train accuracy: 0.154\t\tTest accuracy: 0.136\n",
      "Mean abs grad value: 0.04985313983577234\tMax abs grad value: 1.5486259705096765\n",
      "Loss = 2.9159472307173955\n",
      "Train accuracy: 0.177\t\tTest accuracy: 0.151\n",
      "Mean abs grad value: 0.0274420587912468\tMax abs grad value: 0.4924748025651108\n",
      "Loss = 2.415724371904443\n",
      "Train accuracy: 0.211\t\tTest accuracy: 0.176\n",
      "Mean abs grad value: 0.018380280985745793\tMax abs grad value: 0.31343320222666976\n",
      "Loss = 2.046161012446691\n",
      "Train accuracy: 0.253\t\tTest accuracy: 0.236\n",
      "Mean abs grad value: 0.014498172529242835\tMax abs grad value: 0.3245582662062037\n",
      "Loss = 1.6788536786702695\n",
      "Train accuracy: 0.382\t\tTest accuracy: 0.402\n",
      "Mean abs grad value: 0.025967012523708734\tMax abs grad value: 0.6038398512742282\n",
      "Loss = 1.4249768852141278\n",
      "Train accuracy: 0.492\t\tTest accuracy: 0.487\n",
      "Mean abs grad value: 0.01439758079484895\tMax abs grad value: 0.3778404925742946\n",
      "Loss = 1.1757561188039405\n",
      "Train accuracy: 0.629\t\tTest accuracy: 0.600\n",
      "Mean abs grad value: 0.012795985801129837\tMax abs grad value: 0.40422547482397836\n",
      "Loss = 0.9860263368474065\n",
      "Train accuracy: 0.692\t\tTest accuracy: 0.682\n",
      "Mean abs grad value: 0.01294475641576475\tMax abs grad value: 0.2965237683264335\n",
      "Loss = 0.825419319841288\n",
      "Train accuracy: 0.756\t\tTest accuracy: 0.744\n",
      "Mean abs grad value: 0.010263887639196324\tMax abs grad value: 0.23998020279762644\n",
      "Loss = 0.6368436409581658\n",
      "Train accuracy: 0.788\t\tTest accuracy: 0.778\n",
      "Mean abs grad value: 0.010454751813047981\tMax abs grad value: 0.21556821823626995\n",
      "Loss = 0.5042133546634994\n",
      "Train accuracy: 0.829\t\tTest accuracy: 0.831\n",
      "Mean abs grad value: 0.007564594477498091\tMax abs grad value: 0.2223480884568449\n",
      "Loss = 0.4367213630979626\n",
      "Train accuracy: 0.863\t\tTest accuracy: 0.860\n",
      "Mean abs grad value: 0.005610485429787404\tMax abs grad value: 0.12533858337820483\n",
      "Loss = 0.39185704312042946\n",
      "Train accuracy: 0.878\t\tTest accuracy: 0.878\n",
      "Mean abs grad value: 0.006091705110638969\tMax abs grad value: 0.13140303332221162\n",
      "Loss = 0.33464943458739294\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.008128326871972319\tMax abs grad value: 0.1811376749849945\n",
      "Loss = 0.27682298114627\n",
      "Train accuracy: 0.904\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.005584261914817523\tMax abs grad value: 0.11983050841009847\n",
      "Loss = 0.23615956109229358\n",
      "Train accuracy: 0.923\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.00398307107688726\tMax abs grad value: 0.0729577630412955\n",
      "Loss = 0.21914701940760956\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.005357266404784533\tMax abs grad value: 0.0900893277882535\n",
      "Loss = 0.18905705375304033\n",
      "Train accuracy: 0.946\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.003938492488921394\tMax abs grad value: 0.058280133455413656\n",
      "Loss = 0.16906925383486202\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0029879981063642438\tMax abs grad value: 0.0705223555519467\n",
      "Loss = 0.14008837631633916\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0029182350538065095\tMax abs grad value: 0.08004578884566206\n",
      "Loss = 0.12401106843678263\n",
      "Train accuracy: 0.960\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.005395875827650845\tMax abs grad value: 0.1015755692889968\n",
      "Loss = 0.10654936633938472\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.005069921692443434\tMax abs grad value: 0.09471759303516801\n",
      "Loss = 0.09616915126611425\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0022244348589698544\tMax abs grad value: 0.04739089986913834\n",
      "Loss = 0.08730647685295441\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0016753783459014329\tMax abs grad value: 0.030423301659723002\n",
      "Loss = 0.08253656772828546\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0023968435429231145\tMax abs grad value: 0.04424292484456353\n",
      "Loss = 0.0721624381062079\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002374431776391804\tMax abs grad value: 0.05069154376193516\n",
      "Loss = 0.06156815759851846\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.006502744168967837\tMax abs grad value: 0.16244147134116818\n",
      "Loss = 0.057064076896838796\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0017805247763689215\tMax abs grad value: 0.026163108187634766\n",
      "Loss = 0.04354814155001497\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0013728612196829922\tMax abs grad value: 0.021353062878810718\n",
      "Loss = 0.04077366528198127\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0013414668393718241\tMax abs grad value: 0.031198276780174814\n",
      "Loss = 0.03589721825868896\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0013306428748940493\tMax abs grad value: 0.03447908794389543\n",
      "Loss = 0.030712758005437348\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002811519729891755\tMax abs grad value: 0.07087277972715579\n",
      "Loss = 0.026244415122570752\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0011238966446489604\tMax abs grad value: 0.024102262832894968\n",
      "Loss = 0.019631388118946498\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0008326266607460238\tMax abs grad value: 0.015522802238905736\n",
      "Loss = 0.01707880810673308\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0007158672082020305\tMax abs grad value: 0.014146171117197277\n",
      "Loss = 0.012316862179857752\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0011667511900576115\tMax abs grad value: 0.027354851503708918\n",
      "Loss = 0.009398401657722577\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0006690559905550855\tMax abs grad value: 0.016308586152383422\n",
      "Loss = 0.006615472897747474\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0005069214878390365\tMax abs grad value: 0.009085559960363946\n",
      "Loss = 0.005154512300202629\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0005520213503658945\tMax abs grad value: 0.011314225935965224\n",
      "Loss = 0.003849981705208309\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0005295981299784539\tMax abs grad value: 0.009351600368099528\n",
      "Loss = 0.0030935833786927473\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00033159745311784586\tMax abs grad value: 0.004448020509763563\n",
      "Loss = 0.0026619624051766305\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0002429697356601871\tMax abs grad value: 0.004600094311329731\n",
      "Loss = 0.0020406099115091733\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0002071783618999149\tMax abs grad value: 0.004492759355510783\n",
      "Loss = 0.0014914327032150212\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00032518212658651376\tMax abs grad value: 0.006823597785966182\n",
      "Loss = 0.001072464562078127\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0001632323731053673\tMax abs grad value: 0.003969818062990829\n",
      "Loss = 0.0007592637179937074\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.00011632075630427313\tMax abs grad value: 0.001865758575161612\n",
      "Loss = 0.0006146387188508828\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 6.505824506613838e-05\tMax abs grad value: 0.0010793666830394707\n",
      "Loss = 0.000435410223103471\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 6.397948317482444e-05\tMax abs grad value: 0.0013073783650595723\n",
      "Loss = 0.0003201707081931599\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 6.642801387737686e-05\tMax abs grad value: 0.0014788574303781618\n",
      "Loss = 0.0002308316128292792\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.180883728820157e-05\tMax abs grad value: 0.000723545053592814\n",
      "Loss = 0.00016791745939659004\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.4997809042056288e-05\tMax abs grad value: 0.0004286886098445475\n",
      "Loss = 0.00013847973580740302\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.119259092652559e-05\tMax abs grad value: 0.0003883005131760784\n",
      "Loss = 8.988489024358596e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00011111296775661062\tMax abs grad value: 0.0026555918759536908\n",
      "Loss = 0.0001517595745650504\n",
      "Mean abs grad value: 2.2052211151815645e-05\tMax abs grad value: 0.0005362536775436942\n",
      "Loss = 7.176612351181329e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 9.99825005456273e-06\tMax abs grad value: 0.00022795907064472682\n",
      "Loss = 4.775203391246635e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 7.141517354427402e-06\tMax abs grad value: 0.00013651399206067325\n",
      "Loss = 3.3510028276217525e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.622286572202256e-06\tMax abs grad value: 9.566712108119735e-05\n",
      "Loss = 2.034588809745854e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 7.662730258535485e-06\tMax abs grad value: 0.0001665291791357549\n",
      "Loss = 1.4555401664913886e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.0158677513161115e-06\tMax abs grad value: 4.225402192721066e-05\n",
      "Loss = 8.204600976672972e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.5047432253548703e-06\tMax abs grad value: 2.7361778605558676e-05\n",
      "Loss = 6.54747035646687e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.0462012684531264e-06\tMax abs grad value: 1.7158497486803303e-05\n",
      "Loss = 3.9757224234816674e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.7730276463740073e-06\tMax abs grad value: 4.070449312439595e-05\n",
      "Loss = 2.7322159346175538e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.838466311045227e-07\tMax abs grad value: 1.0100798270985851e-05\n",
      "Loss = 1.5305049460748681e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.8835535648047855e-07\tMax abs grad value: 7.466610457994154e-06\n",
      "Loss = 1.1745379540581204e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.23268648765864489\tMax abs grad value: 10.796187491526856\n",
      "Loss = 7.7219530543030475\n",
      "Mean abs grad value: 0.17313220475906926\tMax abs grad value: 4.218712676361963\n",
      "Loss = 8.402069768752007\n",
      "Mean abs grad value: 0.1419763830023144\tMax abs grad value: 3.0301236730963925\n",
      "Loss = 5.336312590682532\n",
      "Train accuracy: 0.057\t\tTest accuracy: 0.060\n",
      "Mean abs grad value: 0.07946476702950186\tMax abs grad value: 1.3027535163080946\n",
      "Loss = 3.9408449178119342\n",
      "Train accuracy: 0.094\t\tTest accuracy: 0.122\n",
      "Mean abs grad value: 0.05289204999497679\tMax abs grad value: 0.7788412716015738\n",
      "Loss = 3.051293310560303\n",
      "Train accuracy: 0.175\t\tTest accuracy: 0.198\n",
      "Mean abs grad value: 0.03780980775802241\tMax abs grad value: 0.3954909027467938\n",
      "Loss = 2.209246030321799\n",
      "Train accuracy: 0.235\t\tTest accuracy: 0.276\n",
      "Mean abs grad value: 0.02332513474024045\tMax abs grad value: 0.2835655806565429\n",
      "Loss = 1.6475081608037982\n",
      "Train accuracy: 0.451\t\tTest accuracy: 0.429\n",
      "Mean abs grad value: 0.02576536376958536\tMax abs grad value: 0.6025563514640598\n",
      "Loss = 1.3368347825021911\n",
      "Train accuracy: 0.534\t\tTest accuracy: 0.544\n",
      "Mean abs grad value: 0.01906880469969359\tMax abs grad value: 0.47839799368346597\n",
      "Loss = 1.0772171612242738\n",
      "Train accuracy: 0.679\t\tTest accuracy: 0.649\n",
      "Mean abs grad value: 0.013968047198435283\tMax abs grad value: 0.31634836281785034\n",
      "Loss = 0.9238305963498508\n",
      "Train accuracy: 0.709\t\tTest accuracy: 0.698\n",
      "Mean abs grad value: 0.010438459177514167\tMax abs grad value: 0.20889449692405995\n",
      "Loss = 0.6925763004513408\n",
      "Train accuracy: 0.765\t\tTest accuracy: 0.751\n",
      "Mean abs grad value: 0.012167794309588153\tMax abs grad value: 0.36234197250185435\n",
      "Loss = 0.5540540510553936\n",
      "Train accuracy: 0.817\t\tTest accuracy: 0.756\n",
      "Mean abs grad value: 0.007546006664611832\tMax abs grad value: 0.20068556687982173\n",
      "Loss = 0.4525361889905907\n",
      "Train accuracy: 0.846\t\tTest accuracy: 0.813\n",
      "Mean abs grad value: 0.0063334901937940604\tMax abs grad value: 0.16715370839211247\n",
      "Loss = 0.3839429389125273\n",
      "Train accuracy: 0.883\t\tTest accuracy: 0.844\n",
      "Mean abs grad value: 0.008378074379557806\tMax abs grad value: 0.21154359120968683\n",
      "Loss = 0.31279814848740906\n",
      "Train accuracy: 0.907\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.005722435554107312\tMax abs grad value: 0.14388866317970167\n",
      "Loss = 0.24980136231456126\n",
      "Train accuracy: 0.926\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.004108817378493101\tMax abs grad value: 0.08698769069756494\n",
      "Loss = 0.21617147664705216\n",
      "Train accuracy: 0.932\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.0037720345101267382\tMax abs grad value: 0.07986742877709861\n",
      "Loss = 0.18434012976959\n",
      "Train accuracy: 0.945\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.005251157374208803\tMax abs grad value: 0.11697570529391185\n",
      "Loss = 0.15984327816919014\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.0027178141056168397\tMax abs grad value: 0.04972297689432471\n",
      "Loss = 0.13454913964095794\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0028913735158131353\tMax abs grad value: 0.04683890025052072\n",
      "Loss = 0.111766274088068\n",
      "Train accuracy: 0.971\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.004760487570987779\tMax abs grad value: 0.11169808285297401\n",
      "Loss = 0.09933849693601271\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.002780460822265154\tMax abs grad value: 0.04713810382956407\n",
      "Loss = 0.08477370327773735\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002549987364577191\tMax abs grad value: 0.05788803929904871\n",
      "Loss = 0.07302633471065555\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0026045594170753567\tMax abs grad value: 0.04679110633504145\n",
      "Loss = 0.06133331488758394\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0023827798096558305\tMax abs grad value: 0.040121479688746645\n",
      "Loss = 0.04975581812306444\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0026302564398275117\tMax abs grad value: 0.06305584200779514\n",
      "Loss = 0.03682670441517072\n",
      "Train accuracy: 0.988\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.00429899540952898\tMax abs grad value: 0.08671537145167006\n",
      "Loss = 0.034267389627106744\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0013461509781730794\tMax abs grad value: 0.02532369986801459\n",
      "Loss = 0.026888153071831965\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0010516105039374809\tMax abs grad value: 0.01706312878494082\n",
      "Loss = 0.024721606447207816\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0012370190539110542\tMax abs grad value: 0.033168537733750746\n",
      "Loss = 0.02039725159215203\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0010245539958400082\tMax abs grad value: 0.04018114281371876\n",
      "Loss = 0.016568117712171065\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0009298369976113888\tMax abs grad value: 0.027923011745692738\n",
      "Loss = 0.011720488123162412\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0007676931430843644\tMax abs grad value: 0.01877483588880857\n",
      "Loss = 0.009821954799754624\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0009239268772256348\tMax abs grad value: 0.01919917097220111\n",
      "Loss = 0.008293748072120914\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0006052776663413783\tMax abs grad value: 0.010846051085580555\n",
      "Loss = 0.007033000920156565\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00045764210125227346\tMax abs grad value: 0.007936846158588789\n",
      "Loss = 0.0057487774323650214\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00034894635017568157\tMax abs grad value: 0.005942183418894986\n",
      "Loss = 0.003914507494756157\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0007622213763616387\tMax abs grad value: 0.017995984884944423\n",
      "Loss = 0.003021034908441228\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00023011211631475528\tMax abs grad value: 0.005010521094531423\n",
      "Loss = 0.0019522403168003104\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00015460053287497558\tMax abs grad value: 0.0033603520574650913\n",
      "Loss = 0.00165251982579807\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00014142663584321385\tMax abs grad value: 0.0025856657927811285\n",
      "Loss = 0.00129063372181974\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0004776366925977166\tMax abs grad value: 0.013877168324974517\n",
      "Loss = 0.0011772437213284027\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00014566081576549832\tMax abs grad value: 0.002502209873043419\n",
      "Loss = 0.0007635295980249798\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0001026939517870177\tMax abs grad value: 0.0014634183625516419\n",
      "Loss = 0.0006444327325748878\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.872562990933414e-05\tMax abs grad value: 0.001216851263046296\n",
      "Loss = 0.0004534731791254525\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.6399815343688e-05\tMax abs grad value: 0.0011486919964503097\n",
      "Loss = 0.00028241043671659304\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0001654173489718079\tMax abs grad value: 0.004543076750308567\n",
      "Loss = 0.00029381506384009505\n",
      "Mean abs grad value: 6.909310727166364e-05\tMax abs grad value: 0.0016987246934694721\n",
      "Loss = 0.00022251429779124513\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.93306171765272e-05\tMax abs grad value: 0.0007131722398443343\n",
      "Loss = 0.00013407499650125175\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.914432670383506e-05\tMax abs grad value: 0.0003780105509631096\n",
      "Loss = 9.600558963333532e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.4925856015827238e-05\tMax abs grad value: 0.00035689853754927953\n",
      "Loss = 6.009106266505195e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 9.909068089115288e-06\tMax abs grad value: 0.00027801947911704845\n",
      "Loss = 4.1272169984848944e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 8.117971376995811e-06\tMax abs grad value: 0.00023520660962303989\n",
      "Loss = 2.7921945575132465e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.432116061847829e-06\tMax abs grad value: 9.63391923857289e-05\n",
      "Loss = 1.6685849386341424e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 4.440899362180091e-06\tMax abs grad value: 9.99674263724094e-05\n",
      "Loss = 1.0311833371119248e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.979948666049534e-06\tMax abs grad value: 0.00016419712018822552\n",
      "Loss = 6.231339110229286e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.6743788238014784e-06\tMax abs grad value: 4.327064984651168e-05\n",
      "Loss = 3.848489205568262e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.221040273104485e-06\tMax abs grad value: 3.555667736402437e-05\n",
      "Loss = 3.1455941101831328e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.792272869688562e-07\tMax abs grad value: 1.6407277804745724e-05\n",
      "Loss = 2.2194487419425537e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.871571299024205e-07\tMax abs grad value: 1.3414684647803903e-05\n",
      "Loss = 1.4439269974819586e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.87069240856902e-07\tMax abs grad value: 2.39155539222258e-05\n",
      "Loss = 8.955905006018247e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.8694840507892087e-07\tMax abs grad value: 3.410910803790788e-06\n",
      "Loss = 3.986420603857067e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.1985253418408327\tMax abs grad value: 4.936230722503098\n",
      "Loss = 8.864496779824446\n",
      "Mean abs grad value: 0.08553802191253727\tMax abs grad value: 2.035047690692622\n",
      "Loss = 4.75234567742646\n",
      "Train accuracy: 0.062\t\tTest accuracy: 0.064\n",
      "Mean abs grad value: 0.03152659681510647\tMax abs grad value: 0.5252353701514456\n",
      "Loss = 2.431722010714042\n",
      "Train accuracy: 0.147\t\tTest accuracy: 0.133\n",
      "Mean abs grad value: 0.021265167545617945\tMax abs grad value: 0.3639675083068293\n",
      "Loss = 2.041842665415951\n",
      "Train accuracy: 0.265\t\tTest accuracy: 0.238\n",
      "Mean abs grad value: 0.016424341520624303\tMax abs grad value: 0.3180538765414921\n",
      "Loss = 1.7785200703277246\n",
      "Train accuracy: 0.370\t\tTest accuracy: 0.338\n",
      "Mean abs grad value: 0.01246937486616854\tMax abs grad value: 0.2560151772512013\n",
      "Loss = 1.4286880288579973\n",
      "Train accuracy: 0.547\t\tTest accuracy: 0.540\n",
      "Mean abs grad value: 0.020703545138020623\tMax abs grad value: 0.7050674445674102\n",
      "Loss = 1.2593671644277582\n",
      "Train accuracy: 0.542\t\tTest accuracy: 0.522\n",
      "Mean abs grad value: 0.010813866538649578\tMax abs grad value: 0.43345566483591086\n",
      "Loss = 1.0283784909631595\n",
      "Train accuracy: 0.665\t\tTest accuracy: 0.629\n",
      "Mean abs grad value: 0.009850066342332129\tMax abs grad value: 0.2943863557317208\n",
      "Loss = 0.8338594328145864\n",
      "Train accuracy: 0.736\t\tTest accuracy: 0.682\n",
      "Mean abs grad value: 0.011579131283971872\tMax abs grad value: 0.35929826684828875\n",
      "Loss = 0.6479990411662601\n",
      "Train accuracy: 0.797\t\tTest accuracy: 0.762\n",
      "Mean abs grad value: 0.013876120842313239\tMax abs grad value: 0.512837995700706\n",
      "Loss = 0.587109338889736\n",
      "Train accuracy: 0.810\t\tTest accuracy: 0.771\n",
      "Mean abs grad value: 0.0071600325312342694\tMax abs grad value: 0.14541535557323604\n",
      "Loss = 0.5243795895091349\n",
      "Train accuracy: 0.843\t\tTest accuracy: 0.802\n",
      "Mean abs grad value: 0.006244067908964248\tMax abs grad value: 0.17067226587306772\n",
      "Loss = 0.4778163637321169\n",
      "Train accuracy: 0.860\t\tTest accuracy: 0.820\n",
      "Mean abs grad value: 0.007079658473158773\tMax abs grad value: 0.19413315915684284\n",
      "Loss = 0.43752020840484473\n",
      "Train accuracy: 0.869\t\tTest accuracy: 0.822\n",
      "Mean abs grad value: 0.009751061045788538\tMax abs grad value: 0.19544385633029546\n",
      "Loss = 0.3539662376235553\n",
      "Train accuracy: 0.894\t\tTest accuracy: 0.856\n",
      "Mean abs grad value: 0.015499953036235654\tMax abs grad value: 0.5685333646362005\n",
      "Loss = 0.35350373919233286\n",
      "Mean abs grad value: 0.007713141569143493\tMax abs grad value: 0.24666192092917222\n",
      "Loss = 0.31146010586207723\n",
      "Train accuracy: 0.896\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.004625252196708782\tMax abs grad value: 0.12631253116491392\n",
      "Loss = 0.27243098303495666\n",
      "Train accuracy: 0.918\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.0036585652812115344\tMax abs grad value: 0.1023146054352127\n",
      "Loss = 0.23612286916288927\n",
      "Train accuracy: 0.928\t\tTest accuracy: 0.898\n",
      "Mean abs grad value: 0.0037651518296203225\tMax abs grad value: 0.13982566437225977\n",
      "Loss = 0.21217554498221114\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.005469011346773896\tMax abs grad value: 0.1618730239431259\n",
      "Loss = 0.19033109571337697\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.902\n",
      "Mean abs grad value: 0.003133867289110938\tMax abs grad value: 0.0621276187974054\n",
      "Loss = 0.16653412105977228\n",
      "Train accuracy: 0.953\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.002737836494378192\tMax abs grad value: 0.07108965638791694\n",
      "Loss = 0.14122728417896163\n",
      "Train accuracy: 0.960\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0028678041026323547\tMax abs grad value: 0.0951600235032305\n",
      "Loss = 0.12233234867282146\n",
      "Train accuracy: 0.966\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.006933449742219071\tMax abs grad value: 0.20131089151975998\n",
      "Loss = 0.11237575119221063\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0024353457646008993\tMax abs grad value: 0.06374455482802739\n",
      "Loss = 0.08601328768529988\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0020420375373271615\tMax abs grad value: 0.03890534256988874\n",
      "Loss = 0.07930574673462037\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0021359303912563046\tMax abs grad value: 0.045659432323998765\n",
      "Loss = 0.06923428550830171\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.00254588217814227\tMax abs grad value: 0.07074004244083172\n",
      "Loss = 0.05899245481015639\n",
      "Train accuracy: 0.980\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.002562647598887433\tMax abs grad value: 0.07660814252432228\n",
      "Loss = 0.051208105389459066\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0019888109428719955\tMax abs grad value: 0.05885760505511988\n",
      "Loss = 0.045484377455646326\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0012598539831320456\tMax abs grad value: 0.0260114239099778\n",
      "Loss = 0.04263963247365613\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0011590223478022388\tMax abs grad value: 0.03068904951275756\n",
      "Loss = 0.03887851799333806\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0012224911992730356\tMax abs grad value: 0.03974122167741887\n",
      "Loss = 0.03472281608480522\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0012166796615234415\tMax abs grad value: 0.03872117714257481\n",
      "Loss = 0.02971585024296738\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.004104073502113464\tMax abs grad value: 0.16000285832997255\n",
      "Loss = 0.0331430072524141\n",
      "Mean abs grad value: 0.0013227898865754459\tMax abs grad value: 0.03146236821914568\n",
      "Loss = 0.027196607232657162\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0008776194186238926\tMax abs grad value: 0.015929658247690808\n",
      "Loss = 0.024373557542940395\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0008053934704550762\tMax abs grad value: 0.016663783538441366\n",
      "Loss = 0.02205165908892244\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0006898979538846044\tMax abs grad value: 0.014105437239540582\n",
      "Loss = 0.02004899308305719\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0008626303788096545\tMax abs grad value: 0.03203127302586025\n",
      "Loss = 0.01608311816402227\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0009504849645651522\tMax abs grad value: 0.01877207298000368\n",
      "Loss = 0.012674332615006102\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0012125882175253913\tMax abs grad value: 0.03550338459829682\n",
      "Loss = 0.011195424906913637\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0005709522211807667\tMax abs grad value: 0.011553732076870544\n",
      "Loss = 0.009405206130577414\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0005136190081520038\tMax abs grad value: 0.014202834027099069\n",
      "Loss = 0.00816493973066036\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0004980914371479348\tMax abs grad value: 0.015845578737186825\n",
      "Loss = 0.006354575305536849\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0004956167588073134\tMax abs grad value: 0.016806520768888746\n",
      "Loss = 0.004294774588396845\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0004128819407845911\tMax abs grad value: 0.008907885489846067\n",
      "Loss = 0.0029631133251339144\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00020198943777170733\tMax abs grad value: 0.004589943530558279\n",
      "Loss = 0.0023958685896070158\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00016813791986399325\tMax abs grad value: 0.0034377749890682594\n",
      "Loss = 0.002019086617641749\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0003164119443268927\tMax abs grad value: 0.009221323167415954\n",
      "Loss = 0.0017201159794230556\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.00015758116983455845\tMax abs grad value: 0.0035396300126704933\n",
      "Loss = 0.0014927153758486603\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00013077265173726707\tMax abs grad value: 0.0032171081808901195\n",
      "Loss = 0.0013285869692938879\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00013821238120001456\tMax abs grad value: 0.003815379330333915\n",
      "Loss = 0.0011295649190738149\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0001442971425089876\tMax abs grad value: 0.005348395741098524\n",
      "Loss = 0.0008693927725401859\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00040129266364743424\tMax abs grad value: 0.013273802393007534\n",
      "Loss = 0.0009502578878691195\n",
      "Mean abs grad value: 0.0001563827814603316\tMax abs grad value: 0.005332625345151589\n",
      "Loss = 0.0007517630025999585\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00010122153903986794\tMax abs grad value: 0.0030529478704592757\n",
      "Loss = 0.0006300545732619394\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 5.522306562059126e-05\tMax abs grad value: 0.0014097278285043952\n",
      "Loss = 0.0005087221233756031\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 6.0247893293841886e-05\tMax abs grad value: 0.0011721464718034871\n",
      "Loss = 0.00042600096532043025\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 8.064871393112744e-05\tMax abs grad value: 0.0023429394283479995\n",
      "Loss = 0.0003093473796632972\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 4.9908147197742e-05\tMax abs grad value: 0.0011870512894775092\n",
      "Loss = 0.00021472959206370268\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 3.814587128349917e-05\tMax abs grad value: 0.0010245032695576656\n",
      "Loss = 0.0001605927836773814\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.9904312329895762e-05\tMax abs grad value: 0.0007477676162135105\n",
      "Loss = 0.00011328354331509252\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 1.4621264326984498e-05\tMax abs grad value: 0.0002959913280547305\n",
      "Loss = 8.53285890436364e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 1.1812499784102665e-05\tMax abs grad value: 0.0002872988575378496\n",
      "Loss = 6.3627318629246e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 1.252283759926219e-05\tMax abs grad value: 0.0003209950629239312\n",
      "Loss = 4.517370232683937e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 6.8640112139775325e-06\tMax abs grad value: 0.0002058882596153913\n",
      "Loss = 3.3360549424361746e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 4.27065634531387e-06\tMax abs grad value: 6.985684787097966e-05\n",
      "Loss = 2.541560331628109e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.969\n",
      "Mean abs grad value: 6.258071277960514e-06\tMax abs grad value: 0.00013114484499896997\n",
      "Loss = 1.6629572103303485e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 4.02444863302363e-06\tMax abs grad value: 0.0001237632877817045\n",
      "Loss = 1.0011406374667096e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 2.5991332271705685e-06\tMax abs grad value: 5.707782756888467e-05\n",
      "Loss = 7.77502720278986e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 1.8115129749320075e-06\tMax abs grad value: 3.9398784973538926e-05\n",
      "Loss = 5.76148197007977e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 1.064462674255851e-06\tMax abs grad value: 2.2546248420080944e-05\n",
      "Loss = 3.699623020344257e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 9.77508595387728e-07\tMax abs grad value: 2.602602280536085e-05\n",
      "Loss = 2.554189262663148e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 5.173849309857861e-07\tMax abs grad value: 1.3157853538523578e-05\n",
      "Loss = 1.8353836354065592e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.456423798722378e-07\tMax abs grad value: 1.3585712470833471e-05\n",
      "Loss = 1.5506443293699478e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.2090237810234875e-07\tMax abs grad value: 1.1149442624775775e-05\n",
      "Loss = 9.375364012667563e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 2.2270329289662821e-07\tMax abs grad value: 5.9311980891840884e-06\n",
      "Loss = 6.225930742667025e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "layer_c = 3\n",
    "\n",
    "for i, initialization in enumerate(init_vars):\n",
    "    for j in range(5):\n",
    "        network = make_network(input_size, 32, output_size, layer_c, ReLU)\n",
    "        initialize_network(network, initialization)\n",
    "        network, cb = train_network(network, history=True)\n",
    "        \n",
    "        accs_train[i, j] = cb.train_acc[-1]\n",
    "        accs_test[i, j] = cb.test_acc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Построим боксплоты полученного качества (горизонтальная линия в каждом столбце — среднее, прямоугольник показывает разброс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true,
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:36:42.841670100Z",
     "start_time": "2024-02-22T20:36:42.654873700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABu2ElEQVR4nO3deVyU5f7/8Tcgq6i4oAghWyqaCy6BlqnlgqIeNUszS+IYpWmWfM3UyLWkOke0xZNauaSWVi6nlURKPeYaSmWoueSxVHApRURwgPn94c85TYCCzu00+Ho+Hjxqrvu6r/szV5eTb+5lnMxms1kAAAAAAMDmnO1dAAAAAAAAlRWhGwAAAAAAgxC6AQAAAAAwCKEbAAAAAACDELoBAAAAADAIoRsAAAAAAIMQugEAAAAAMAihGwAAAAAAgxC6AQAAAAAwCKEbAABIkg4fPiwnJyctWrTI0jZlyhQ5OTkZfuz169fLyclJ69evN/xYAADcSIRuAMBNx8nJqVw/tgiAeXl5mjJlSqUKkzNmzNCaNWvsXcZVde7cudT/rj169LB3aQCAm0gVexcAAMCNtmTJEqvX7777rlJTU0u0N2nS5LqPlZeXp6lTp0q6FAIdTWJiosaPH2/VNmPGDN13333q16+fzY7TsWNHXbhwQW5ubjYbU5JuueUWJSUlWbX5+/vb9BgAAFwJoRsAcNN56KGHrF5v3bpVqampJdohValSRVWqGP/XBWdnZ3l4eNh83Bo1atjsv2t+fr7c3Nzk7MyFggCA8uP/GgAAlKK4uFizZ8/WbbfdJg8PD9WrV0+PP/64fv/9d6t+3377raKjo1WnTh15enoqJCREf//73yVdukfa19dXkjR16lTL5c1Tpky54rF//PFH3XPPPfL09NQtt9yiF154QQsWLJCTk5MOHz5s6VfWWMHBwXrkkUcsr3/77TeNHTtWzZs3l7e3t6pXr66ePXvqu+++u+o8/PmebicnJ50/f16LFy+2vJ9HHnlEX3/9tZycnLR69eoSY7z33ntycnLSli1byjxOafd0d+7cWc2aNVNmZqbuvvtueXl5KSAgQK+88spV6/6jwsJC5ebmVmify/UsX75ciYmJCggIkJeXl3Jycsq8z33RokUl/hsFBwerd+/e2rRpkyIjI+Xh4aHQ0FC9++67VvuaTCZNnTpVDRs2lIeHh2rXrq0OHTooNTW1QnUDAP56ONMNAEApHn/8cS1atEhxcXEaPXq0fv75Z73xxhvatWuXvvnmG7m6uurEiRPq3r27fH19NX78ePn4+Ojw4cNatWqVJMnX11dvvvmmRowYof79++vee++VJLVo0aLM42ZlZenuu+9WYWGhxo8fr6pVq2r+/Pny9PS85vdy6NAhrVmzRvfff79CQkKUnZ2tefPmqVOnTsrMzKzQ5dZLlizRo48+qsjISD322GOSpLCwMLVr106BgYFatmyZ+vfvb7XPsmXLFBYWpvbt21e49t9//109evTQvffeq4EDB+qjjz7Ss88+q+bNm6tnz55X3f+nn35S1apVdfHiRdWrV0/x8fGaNGmSXF1dy3X86dOny83NTWPHjlVBQcE1Xf5+4MAB3XfffRo2bJhiY2O1YMECPfLII2rTpo1uu+02SZd+uZGUlGSZ25ycHH377bfauXOnunXrVuFjAgD+OgjdAAD8yaZNm/T2229r2bJlevDBBy3td999t3r06KEPP/xQDz74oDZv3qzff/9da9euVdu2bS39XnjhBUlS1apVdd9992nEiBFq0aJFuS5zfvnll3Xy5Elt27ZNkZGRkqTY2Fg1bNjwmt9P8+bN9dNPP1ldFv3www8rPDxc77zzjp5//vlyj/XQQw9p+PDhCg0NLfF+HnroISUnJ+vs2bOqUaOGJOnkyZNau3atnnvuuWuq/dixY3r33Xf18MMPS5KGDRumoKAgvfPOO1cN3WFhYbr77rvVvHlznT9/Xh999JFeeOEF/fTTT1qxYkW5jp+fn69vv/32un7psW/fPm3cuFF33XWXJGngwIEKDAzUwoUL9c9//lOS9NlnnykmJkbz58+/5uMAAP6auLwcAIA/+fDDD1WjRg1169ZNp06dsvy0adNG3t7e+vrrryVJPj4+kqRPP/1UJpPJJsf+/PPP1a5dO0vgli6dMR8yZMg1j+nu7m4J3EVFRTp9+rS8vb3VuHFj7dy587prvmzo0KEqKCjQRx99ZGlbsWKFCgsLr/m+am9vb6t93dzcFBkZqUOHDl1133feeUeTJ0/Wvffeq4cfflj//ve/FR8frw8++EBbt24t1/FjY2OvK3BLUtOmTS2BW7r037Nx48ZW78HHx0c//vij9u/ff13HAgD89RC6AQD4k/379+vs2bOqW7eufH19rX5yc3N14sQJSVKnTp00YMAATZ06VXXq1FHfvn21cOFCFRQUXPOx//vf/5Z6Vrtx48bXPGZxcbFmzZqlhg0byt3dXXXq1JGvr6++//57nT179prH/bPw8HDdfvvtWrZsmaVt2bJlateunW699dZrGvOWW24pcf90zZo1S9xbX17/93//J0lat25dufqHhIRc03H+qEGDBiXa/vwepk2bpjNnzqhRo0Zq3ry5nnnmGX3//ffXfWwAgP1xeTkAAH9SXFysunXrWoXHP7r8cDQnJyd99NFH2rp1qz755BN9+eWX+vvf/66ZM2dq69at8vb2vpFlWxQVFVm9njFjhp5//nn9/e9/1/Tp01WrVi05Ozvr6aefVnFxsU2PPXToUD311FP69ddfVVBQoK1bt+qNN9645vFcXFxKbTebzdc0XmBgoKRLD5crj9LOcpf2EDWp5LxfVp730LFjRx08eFD//ve/tXbtWr399tuaNWuW5s6dq0cffbRctQIA/poI3QAA/ElYWJjWrVunO++8s1yXFrdr107t2rXTiy++qPfee09DhgzR8uXL9eijj5YZ0MoSFBRU6iXG+/btK9FWs2ZNnTlzxqrt4sWLOn78uFXbRx99pLvvvlvvvPOOVfuZM2dUp06dCtUnlR06JemBBx5QQkKC3n//fV24cEGurq4aNGhQhY9hlMuXdF/+xcm1qFmzpqRL83f5FgPp0lUK16NWrVqKi4tTXFyccnNz1bFjR02ZMoXQDQAOjsvLAQD4k4EDB6qoqEjTp08vsa2wsNASdH///fcSZ1wjIiIkyXKJuZeXlySVCMdliYmJ0datW7V9+3ZL28mTJ0s96x4WFqaNGzdatc2fP7/EGVcXF5cSdX744Yc6evRouWr6s6pVq5b5furUqaOePXtq6dKlWrZsmXr06HFNwf565eTklLjM32w2Wx5yFx0dfc1jh4WFSZLV3F/+GrVrdfr0aavX3t7euvXWW6/rVgUAwF8DZ7oBAPiTTp066fHHH1dSUpIyMjLUvXt3ubq6av/+/frwww/16quv6r777tPixYv1r3/9S/3791dYWJjOnTunt956S9WrV1dMTIykS5cnN23aVCtWrFCjRo1Uq1YtNWvWTM2aNSv12OPGjdOSJUvUo0cPPfXUU5avDAsKCipxj++jjz6q4cOHa8CAAerWrZu+++47ffnllyVCbu/evTVt2jTFxcXpjjvu0A8//KBly5YpNDT0muanTZs2WrdunZKTk+Xv76+QkBBFRUVZtg8dOlT33XefJJX6i4sbYefOnRo8eLAGDx6sW2+9VRcuXNDq1av1zTff6LHHHlPr1q2veezu3burQYMGGjZsmJ555hm5uLhowYIF8vX11ZEjR65pzKZNm6pz585q06aNatWqpW+//VYfffSRRo0adc11AgD+GgjdAACUYu7cuWrTpo3mzZuniRMnqkqVKgoODtZDDz2kO++8U9KlcL59+3YtX75c2dnZqlGjhiIjI7Vs2TKrB3C9/fbbevLJJzVmzBhdvHhRkydPLjN0169fX19//bWefPJJvfTSS6pdu7aGDx8uf39/DRs2zKpvfHy8fv75Z73zzjtKSUnRXXfdpdTUVHXp0sWq38SJE3X+/Hm99957WrFihVq3bq3PPvtM48ePv6a5SU5O1mOPPabExERduHBBsbGxVqG7T58+qlmzpoqLi/W3v/3tmo5xvYKCgnTXXXdp9erVysrKkrOzs5o0aaK5c+davl/8Wrm6umr16tV64okn9Pzzz8vPz09PP/20atasqbi4uGsac/To0fr444+1du1aFRQUKCgoSC+88IKeeeaZ66oVAGB/TuZrfRIJAAC4YRYtWqS4uDj9/PPPCg4Otnc5V1RYWCh/f3/16dOnxH3kAADcbLinGwAA2NSaNWt08uRJDR061N6lAABgd1xeDgAAbGLbtm36/vvvNX36dLVq1UqdOnWyd0kAANgdZ7oBAIBNvPnmmxoxYoTq1q2rd999197lAADwl8A93QAAAAAAGIQz3QAAAAAAGITQDQAAAACAQXiQmoGKi4t17NgxVatWTU5OTvYuBwAAAABgI2azWefOnZO/v7+cncs+n03oNtCxY8cUGBho7zIAAAAAAAb55ZdfdMstt5S5ndBtoGrVqkm69B+hevXqdq6mcjKZTFq7dq26d+8uV1dXe5cDXBPWMSoL1jIqA9YxKgvWsvFycnIUGBhoyX1lIXQb6PIl5dWrVyd0G8RkMsnLy0vVq1fnwwQOi3WMyoK1jMqAdYzKgrV841ztVmIepAYAAAAAgEHsHrrnzJmj4OBgeXh4KCoqStu3by+zr8lk0rRp0xQWFiYPDw+1bNlSKSkpJfodPXpUDz30kGrXri1PT081b95c3377rWX7I488IicnJ6ufHj16WI3x22+/aciQIapevbp8fHw0bNgw5ebm2u6NAwAAAAAqPbuG7hUrVighIUGTJ0/Wzp071bJlS0VHR+vEiROl9k9MTNS8efP0+uuvKzMzU8OHD1f//v21a9cuS5/ff/9dd955p1xdXfXFF18oMzNTM2fOVM2aNa3G6tGjh44fP275ef/99622DxkyRD/++KNSU1P16aefauPGjXrsscdsPwkAAAAAgErLrvd0JycnKz4+XnFxcZKkuXPn6rPPPtOCBQs0fvz4Ev2XLFmi5557TjExMZKkESNGaN26dZo5c6aWLl0qSXr55ZcVGBiohQsXWvYLCQkpMZa7u7v8/PxKrWvPnj1KSUnRjh071LZtW0nS66+/rpiYGP3zn/+Uv7//9b1xAAAAAMBNwW5nui9evKj09HR17dr1f8U4O6tr167asmVLqfsUFBTIw8PDqs3T01ObNm2yvP7444/Vtm1b3X///apbt65atWqlt956q8RY69evV926ddW4cWONGDFCp0+ftmzbsmWLfHx8LIFbkrp27SpnZ2dt27btmt8zAAAAAODmYrcz3adOnVJRUZHq1atn1V6vXj3t3bu31H2io6OVnJysjh07KiwsTGlpaVq1apWKioosfQ4dOqQ333xTCQkJmjhxonbs2KHRo0fLzc1NsbGxki5dWn7vvfcqJCREBw8e1MSJE9WzZ09t2bJFLi4uysrKUt26da2OXaVKFdWqVUtZWVllvqeCggIVFBRYXufk5Ei6dC+6yWSq2AShXC7PK/MLR8Y6RmXBWkZlwDpGZcFaNl5559ahvjLs1VdfVXx8vMLDw+Xk5KSwsDDFxcVpwYIFlj7FxcVq27atZsyYIUlq1aqVdu/erblz51pC9wMPPGDp37x5c7Vo0UJhYWFav369unTpcs31JSUlaerUqSXa165dKy8vr2seF1eXmppq7xKA68Y6RmXBWkZlwDpGZcFaNk5eXl65+tktdNepU0cuLi7Kzs62as/Ozi7zXmtfX1+tWbNG+fn5On36tPz9/TV+/HiFhoZa+tSvX19Nmza12q9JkyZauXJlmbWEhoaqTp06OnDggLp06SI/P78SD3MrLCzUb7/9VmZtkjRhwgQlJCRYXl/+svTu3bvzPd0GMZlMSk1NVbdu3fj+QTgs1jEqC9YyKgPWMSoL1rLxLl/ZfDV2C91ubm5q06aN0tLS1K9fP0mXzlKnpaVp1KhRV9zXw8NDAQEBMplMWrlypQYOHGjZduedd2rfvn1W/X/66ScFBQWVOd6vv/6q06dPq379+pKk9u3b68yZM0pPT1ebNm0kSV999ZWKi4sVFRVV5jju7u5yd3cv0e7q6spCNxhzjMqAdYzKgrWMyoB1jMqCtWyc8s6rXb8yLCEhQW+99ZYWL16sPXv2aMSIETp//rzlaeZDhw7VhAkTLP23bdumVatW6dChQ/rPf/6jHj16qLi4WOPGjbP0GTNmjLZu3aoZM2bowIEDeu+99zR//nyNHDlSkpSbm6tnnnlGW7du1eHDh5WWlqa+ffvq1ltvVXR0tKRLZ8Z79Oih+Ph4bd++Xd98841GjRqlBx54gCeXAwAAAADKza73dA8aNEgnT57UpEmTlJWVpYiICKWkpFgernbkyBE5O//v9wL5+flKTEzUoUOH5O3trZiYGC1ZskQ+Pj6WPrfffrtWr16tCRMmaNq0aQoJCdHs2bM1ZMgQSZKLi4u+//57LV68WGfOnJG/v7+6d++u6dOnW52lXrZsmUaNGqUuXbrI2dlZAwYM0GuvvXZjJgYAAAAAUCnY/UFqo0aNKvNy8vXr11u97tSpkzIzM686Zu/evdW7d+9St3l6eurLL7+86hi1atXSe++9d9V+AAAAAACUxa6XlwMAAAAAUJkRugEAAAAAMAihGwAAAAAAg9j9nm4AAHBj5eXlae/evTYf99y5c9qwYYN8fHxUrVo1m48fHh4uLy8vm48L4+3fv1/nzp2z6ZgXLlzQ4cOHbTqmJBUVFSkjI0Nnz56Vi4uLzceXpODgYHl6etp0zGrVqqlhw4Y2HROAbRC6AQC4yezdu1dt2rQxbPxZs2YZMm56erpat25tyNgwzv79+9WoUSN7l3FT+OmnnwjewF8QoRsAgJtMeHi40tPTbT7u7t27FRsbq8WLF6tZs2Y2Hz88PNzmY8J4l89wL126VE2aNLHZuEaf6Y6IiHCYM9179uzRQw89ZPOrCQDYBqEbAICbjJeXlyFnjAsLCyVdCseckcafNWnSxObr4s4777TpeJJkMplUo0YNxcTEyNXV1ebjA7j58CA1AAAAAAAMQugGAAAAAMAghG4AAAAAAAxC6AYAAAAAwCCEbgAAAAAADELoBgAAAADAIIRuAAAAAAAMQugGAAAAAMAghG4AAAAAAAxC6AYAAAAAwCCEbgAAAAAADELoBgAAAADAIIRuAAAAAAAMQugGAAAAAMAghG4AAAAAAAxC6AYAAAAAwCCEbgAAAAAADELoBgAAAADAIIRuAAAAAAAMQugGAAAAAMAghG4AAAAAAAxC6AYAAAAAwCCEbgAAAAAADELoBgAAAADAIIRuAAAAAAAMQugGAAAAAMAghG4AAAAAAAxC6AYAAAAAwCB2D91z5sxRcHCwPDw8FBUVpe3bt5fZ12Qyadq0aQoLC5OHh4datmyplJSUEv2OHj2qhx56SLVr15anp6eaN2+ub7/91jLGs88+q+bNm6tq1ary9/fX0KFDdezYMasxgoOD5eTkZPXz0ksv2fbNAwAAAAAqNbuG7hUrVighIUGTJ0/Wzp071bJlS0VHR+vEiROl9k9MTNS8efP0+uuvKzMzU8OHD1f//v21a9cuS5/ff/9dd955p1xdXfXFF18oMzNTM2fOVM2aNSVJeXl52rlzp55//nnt3LlTq1at0r59+/S3v/2txPGmTZum48ePW36efPJJYyYCAAAAAFApVbHnwZOTkxUfH6+4uDhJ0ty5c/XZZ59pwYIFGj9+fIn+S5Ys0XPPPaeYmBhJ0ogRI7Ru3TrNnDlTS5culSS9/PLLCgwM1MKFCy37hYSEWP69Ro0aSk1NtRr3jTfeUGRkpI4cOaIGDRpY2qtVqyY/Pz/bvWEAAAAAwE3FbqH74sWLSk9P14QJEyxtzs7O6tq1q7Zs2VLqPgUFBfLw8LBq8/T01KZNmyyvP/74Y0VHR+v+++/Xhg0bFBAQoCeeeELx8fFl1nL27Fk5OTnJx8fHqv2ll17S9OnT1aBBAz344IMaM2aMqlQpe8oKCgpUUFBgeZ2TkyPp0iXtJpOpzP1w7S7PK/MLR8Y6RmXxx7XMesZlhYWFln86wrpwxM9kR5tj3BiOuJYdTXnn1m6h+9SpUyoqKlK9evWs2uvVq6e9e/eWuk90dLSSk5PVsWNHhYWFKS0tTatWrVJRUZGlz6FDh/Tmm28qISFBEydO1I4dOzR69Gi5ubkpNja2xJj5+fl69tlnNXjwYFWvXt3SPnr0aLVu3Vq1atXS5s2bNWHCBB0/flzJycllvqekpCRNnTq1RPvatWvl5eV11TnBtfvz1QuAI2Idw9EdPHhQkrRt2zadOnXKztXgr+Lyuti0aZOOHz9u52rKz5E+kx11jnFjONJadjR5eXnl6udkNpvNBtdSqmPHjikgIECbN29W+/btLe3jxo3Thg0btG3bthL7nDx5UvHx8frkk0/k5OSksLAwde3aVQsWLNCFCxckSW5ubmrbtq02b95s2W/06NHasWNHiTPoJpNJAwYM0K+//qr169dbhe4/W7BggR5//HHl5ubK3d291D6lnekODAzUqVOnrjg2rp3JZFJqaqq6desmV1dXe5cDXBPWMSqL7du3q0OHDtq0aZMiIyPtXQ7+Inbt2qWoqCht27ZNrVq1snc5V+WIn8mONse4MRxxLTuanJwc1alTR2fPnr1i3rPbme46derIxcVF2dnZVu3Z2dll3kft6+urNWvWKD8/X6dPn5a/v7/Gjx+v0NBQS5/69euradOmVvs1adJEK1eutGozmUwaOHCg/vvf/+qrr766aiiOiopSYWGhDh8+rMaNG5fax93dvdRA7urqykI3GHOMyoB1DEd3ef2ylvFHl2/Nq1KlikOtC0dax446x7gxHGktO5ryzqvdnl7u5uamNm3aKC0tzdJWXFystLQ0qzPfpfHw8FBAQIAKCwu1cuVK9e3b17Ltzjvv1L59+6z6//TTTwoKCrK8vhy49+/fr3Xr1ql27dpXrTcjI0POzs6qW7dued8iAAAAAOAmZ9enlyckJCg2NlZt27ZVZGSkZs+erfPnz1ueZj506FAFBAQoKSlJ0qV7xI4ePaqIiAgdPXpUU6ZMUXFxscaNG2cZc8yYMbrjjjs0Y8YMDRw4UNu3b9f8+fM1f/58SZcC93333aedO3fq008/VVFRkbKysiRJtWrVkpubm7Zs2aJt27bp7rvvVrVq1bRlyxaNGTNGDz30kOWrxwAAAAAAuBq7hu5Bgwbp5MmTmjRpkrKyshQREaGUlBTLw9WOHDkiZ+f/nYzPz89XYmKiDh06JG9vb8XExGjJkiVWTx2//fbbtXr1ak2YMEHTpk1TSEiIZs+erSFDhkiSjh49qo8//liSFBERYVXP119/rc6dO8vd3V3Lly/XlClTVFBQoJCQEI0ZM0YJCQnGTggAAAAAoFKxa+iWpFGjRmnUqFGlblu/fr3V606dOikzM/OqY/bu3Vu9e/cudVtwcLCu9uy41q1ba+vWrVc9DgAAAAAAV2K3e7oBAAAAAKjsCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQeweuufMmaPg4GB5eHgoKipK27dvL7OvyWTStGnTFBYWJg8PD7Vs2VIpKSkl+h09elQPPfSQateuLU9PTzVv3lzffvutZbvZbNakSZNUv359eXp6qmvXrtq/f7/VGL/99puGDBmi6tWry8fHR8OGDVNubq7t3jgAAAAAoNKza+hesWKFEhISNHnyZO3cuVMtW7ZUdHS0Tpw4UWr/xMREzZs3T6+//royMzM1fPhw9e/fX7t27bL0+f3333XnnXfK1dVVX3zxhTIzMzVz5kzVrFnT0ueVV17Ra6+9prlz52rbtm2qWrWqoqOjlZ+fb+kzZMgQ/fjjj0pNTdWnn36qjRs36rHHHjNuMgAAAAAAlY5dQ3dycrLi4+MVFxenpk2bau7cufLy8tKCBQtK7b9kyRJNnDhRMTExCg0N1YgRIxQTE6OZM2da+rz88ssKDAzUwoULFRkZqZCQEHXv3l1hYWGSLp3lnj17thITE9W3b1+1aNFC7777ro4dO6Y1a9ZIkvbs2aOUlBS9/fbbioqKUocOHfT6669r+fLlOnbsmOHzAgAAAACoHKrY68AXL15Uenq6JkyYYGlzdnZW165dtWXLllL3KSgokIeHh1Wbp6enNm3aZHn98ccfKzo6Wvfff782bNiggIAAPfHEE4qPj5ck/fzzz8rKylLXrl0t+9SoUUNRUVHasmWLHnjgAW3ZskU+Pj5q27atpU/Xrl3l7Oysbdu2qX///mXWV1BQYHmdk5Mj6dJl8SaTqbxTUynl5eVp3759Nh/33Llz2rBhg7y9vVWtWjWbj9+4cWN5eXnZfFzgjy5/PtzsnxMoaf/+/Q51a9Pu3but/ukIvL291bBhQ3uXUakVFhZa/ukIn3OO+JnsaHPskEx5+mXXV8rLy7PpsBcvFujYseM2HfOyoqJCHThwUJ8fz5CLi+1jn79/fbm5udt0TC8vLwW2ukdydYy/f5f3z5vdQvepU6dUVFSkevXqWbXXq1dPe/fuLXWf6OhoJScnq2PHjgoLC1NaWppWrVqloqIiS59Dhw7pzTffVEJCgiZOnKgdO3Zo9OjRcnNzU2xsrLKysizH+fNxL2/LyspS3bp1rbZXqVJFtWrVsvQpTVJSkqZOnVqife3atTd9cDt48KD+7//+z7DxZ82aZci4M2fOtFwlARgtNTXV3iXgL+TYsWN64okn7F3GNRk2bJi9S6iQf/3rX/L397d3GZXWwYMHJUmbNm3S8ePGhAsjONJnsqPOsSO5+N8duv+31w0Zu7Uho/5/3pLKji/X56gxw36Y/qTcgm43ZnAbK+8vYewWuq/Fq6++qvj4eIWHh8vJyUlhYWGKi4uzuhy9uLhYbdu21YwZMyRJrVq10u7duzV37lzFxsYaWt+ECROUkJBgeZ2Tk6PAwEB1795d1atXN/TYf3V5eXnq0KGDzcfdvXu3hg0bpnfeeUfNmjWz+fic6caNYDKZlJqaqm7dusnV1dXe5eAv4vLzShYtWqQmTZrYuZryOXfunD777DP16tXLkKuPbG3Pnj165JFH1KZNG7Vq1cre5VRal9dyhw4dHGKeHfEz2dHm2BF9921Ntb730gm2kJAQm417I85033prmEOc6f755581efJkzV/VXS3btrfZuEa6fGXz1dgtdNepU0cuLi7Kzs62as/Ozpafn1+p+/j6+mrNmjXKz8/X6dOn5e/vr/Hjxys0NNTSp379+mratKnVfk2aNNHKlSslyTJ2dna26tevb3XciIgIS58/P8ytsLBQv/32W5m1SZK7u7vc3UsuPFdXV4f50DZKjRo1FBkZadj4zZo1M3R84EbgswJ/VKXKpf9FN2/eXK1bG3oexGZMJpNyc3PVsWNHh1jLl+e4SpUqDlGvo3LUeXakz2RHnWNH4uzurV1ZxQpoG6NmNv5MNuoT3mQy6fPPP1dMTIxDrIuLO3dqV9bzcnb3doh6JZW7Trs9SM3NzU1t2rRRWlqapa24uFhpaWlq3/7Kv9nw8PBQQECACgsLtXLlSvXt29ey7c477yxx7/BPP/2koKAgSVJISIj8/PysjpuTk6Nt27ZZjtu+fXudOXNG6enplj5fffWViouLFRUVde1vGgAAAABwU7Hr5eUJCQmKjY1V27ZtFRkZqdmzZ+v8+fOKi4uTJA0dOlQBAQFKSkqSJG3btk1Hjx5VRESEjh49qilTpqi4uFjjxo2zjDlmzBjdcccdmjFjhgYOHKjt27dr/vz5mj9/viTJyclJTz/9tF544QU1bNhQISEhev755+Xv769+/fpJunRmvEePHoqPj9fcuXNlMpk0atQoPfDAA9zzBQAAAAAoN7uG7kGDBunkyZOaNGmSsrKyFBERoZSUFMtDzo4cOSJn5/+djM/Pz1diYqIOHTokb29vxcTEaMmSJfLx8bH0uf3227V69WpNmDBB06ZNU0hIiGbPnq0hQ4ZY+owbN07nz5/XY489pjNnzqhDhw5KSUmxejL6smXLNGrUKHXp0kXOzs4aMGCAXnvtNeMnBQAAAABQadj9QWqjRo3SqFGjSt22fv16q9edOnVSZmbmVcfs3bu3evfuXeZ2JycnTZs2TdOmTSuzT61atfTee+9d9VgAAAAAAJTFbvd0AwAAAABQ2RG6AQAAAAAwCKEbAAAAAACDELoBAAAAADAIoRsAAAAAAIMQugEAAAAAMAihGwAAAAAAgxC6AQAAAAAwCKEbAAAAAACDELoBAAAAADAIoRsAAAAAAIMQugEAAAAAMAihGwAAAAAAgxC6AQAAAAAwCKEbAAAAAACDELoBAAAAADAIoRsAAAAAAIMQugEAAAAAMAihGwAAAAAAgxC6AQAAAAAwCKEbAAAAAACDELoBAAAAADAIoRsAAAAAAIMQugEAAAAAMAihGwAAAAAAgxC6AQAAAAAwCKEbAAAAAACDELoBAAAAADAIoRsAAAAAAIMQugEAAAAAMAihGwAAAAAAgxC6AQAAAAAwCKEbAAAAAACDVLF3AQBghP379+vcuXM2HfPChQs6fPiwTceUpKKiImVkZOjs2bNycXGx+fiSFBwcLE9PT5uOWa1aNTVs2NCmYwIA8FeUl5cnSdq5c6edKym/3NxcbdiwQTVr1pS3t7e9y7mqPXv22LsEwxC6AVQ6+/fvV6NGjexdxk3hp59+IngDACq9vXv3SpLi4+PtXEnFzZo1y94lVEi1atXsXYLN/SVC95w5c/SPf/xDWVlZatmypV5//XVFRkaW2tdkMikpKUmLFy/W0aNH1bhxY7388svq0aOHpc+UKVM0depUq/0aN25s+cNy+PBhhYSElDr+Bx98oPvvv1+S5OTkVGL7+++/rwceeOCa3ieAG+PyGe6lS5eqSZMmNhvX6DPdERERDnOme8+ePXrooYdsfjUBAAB/Rf369ZMkhYeHy8vLy77FlNPu3bsVGxurxYsXq1mzZvYup1wq61V0dg/dK1asUEJCgubOnauoqCjNnj1b0dHR2rdvn+rWrVuif2JiopYuXaq33npL4eHh+vLLL9W/f39t3rxZrVq1svS77bbbtG7dOsvrKlX+91YDAwN1/Phxq3Hnz5+vf/zjH+rZs6dV+8KFC60CvY+Pz/W+ZQA3SJMmTdS6dWubjnnnnXfadDzp0i8Ta9SooZiYGLm6utp8fAAAcH3q1KmjRx991N5lVEhhYaGkS78osPXfh1Axdn+QWnJysuLj4xUXF6emTZtq7ty58vLy0oIFC0rtv2TJEk2cOFExMTEKDQ3ViBEjFBMTo5kzZ1r1q1Klivz8/Cw/derUsWxzcXGx2ubn56fVq1dr4MCBJe538PHxsern4eFh+0kAAAAAAFRKdj3TffHiRaWnp2vChAmWNmdnZ3Xt2lVbtmwpdZ+CgoISwdfT01ObNm2yatu/f7/8/f3l4eGh9u3bKykpSQ0aNCh1zPT0dGVkZGjOnDklto0cOVKPPvqoQkNDNXz4cMXFxZV62fnl2goKCiyvc3JyJF06i2UymUrdB9fn8rwyx/ijy7/ZLSwsdIh18cd17CgcbY4dkSPOsaOtZUecY0fkaPPsaOtYcrw5xo3B35ONV955tWvoPnXqlIqKilSvXj2r9nr16lnuv/6z6OhoJScnq2PHjgoLC1NaWppWrVqloqIiS5+oqCgtWrRIjRs31vHjxzV16lTddddd2r17d6k35r/zzjtq0qSJ7rjjDqv2adOm6Z577pGXl5fWrl2rJ554Qrm5uRo9enSptSUlJZW4l1yS1q5d6zD3fjiagwcPSpK2bdumU6dO2bka/FVcXhebNm0qcSvJX1lqaqq9Syg3R51jR+LIc+woa9mR59iROOo8O8o6lhx3jmEs/p5svMtPtb8au9/TXVGvvvqq4uPjFR4eLicnJ4WFhSkuLs7qcvQ/3pfdokULRUVFKSgoSB988IGGDRtmNd6FCxf03nvv6fnnny9xrD+2tWrVSufPn9c//vGPMkP3hAkTlJCQYHmdk5OjwMBAde/eXdWrV7/m94yybd++XdKlX7SU9fA93Hx27dolSerQoYPVsx7+qkwmk1JTU9WtWzeHuafb0ebYETniHDvaWnbEOXZEjjbPjraOJcebY9wY/D3ZeJevbL4au4buOnXqyMXFRdnZ2Vbt2dnZ8vPzK3UfX19frVmzRvn5+Tp9+rT8/f01fvx4hYaGlnkcHx8fNWrUSAcOHCix7aOPPlJeXp6GDh161XqjoqI0ffp0FRQUyN3dvcR2d3f3UttdXV0d5kPb0VyeV+YYf3T5wYlVqlRxqHXhSOvYUefYkTjyHDvKWnbkOXYkjjrPjrKOJcedYxiLvycbr7zzatcHqbm5ualNmzZKS0uztBUXFystLU3t27e/4r4eHh4KCAhQYWGhVq5cqb59+5bZNzc3VwcPHlT9+vVLbHvnnXf0t7/9Tb6+vletNyMjQzVr1iw1WAMAAAAA8Gd2v7w8ISFBsbGxatu2rSIjIzV79mydP39ecXFxkqShQ4cqICBASUlJki7dk3D06FFFRETo6NGjmjJlioqLizVu3DjLmGPHjlWfPn0UFBSkY8eOafLkyXJxcdHgwYOtjn3gwAFt3LhRn3/+eYm6PvnkE2VnZ6tdu3by8PBQamqqZsyYobFjxxo4GwAAAACAysTuoXvQoEE6efKkJk2apKysLEVERCglJcXycLUjR47I2fl/J+Tz8/OVmJioQ4cOydvbWzExMVqyZInV92f/+uuvGjx4sE6fPi1fX1916NBBW7duLXE2e8GCBbrlllvUvXv3EnW5urpqzpw5GjNmjMxms2699VbL15sBAAAAAFAedg/dkjRq1CiNGjWq1G3r16+3et2pUydlZmZecbzly5eX67gzZszQjBkzSt3Wo0cP9ejRo1zjAAAAAABQGrve0w0AAAAAQGVG6AYAAAAAwCCEbgAAAAAADELoBgAAAADAIBUO3cHBwZo2bZqOHDliRD0AAAAAAFQaFQ7dTz/9tFatWqXQ0FB169ZNy5cvV0FBgRG1AQAAAADg0K4pdGdkZGj79u1q0qSJnnzySdWvX1+jRo3Szp07jagRAAAAAACHdM33dLdu3Vqvvfaajh07psmTJ+vtt9/W7bffroiICC1YsEBms9mWdQIAAAAA4HCqXOuOJpNJq1ev1sKFC5Wamqp27dpp2LBh+vXXXzVx4kStW7dO7733ni1rBQAAAADAoVQ4dO/cuVMLFy7U+++/L2dnZw0dOlSzZs1SeHi4pU///v11++2327RQAAAAAAAcTYVD9+23365u3brpzTffVL9+/eTq6lqiT0hIiB544AGbFAgAAAAAgKOqcOg+dOiQgoKCrtinatWqWrhw4TUXBQAAAABAZVDhB6mdOHFC27ZtK9G+bds2ffvttzYpCgAAAACAyqDCoXvkyJH65ZdfSrQfPXpUI0eOtElRAAAAAABUBhUO3ZmZmWrdunWJ9latWikzM9MmRQEAAAAAUBlUOHS7u7srOzu7RPvx48dVpco1fwMZAAAAAACVToVDd/fu3TVhwgSdPXvW0nbmzBlNnDhR3bp1s2lxAAAAAAA4sgqfmv7nP/+pjh07KigoSK1atZIkZWRkqF69elqyZInNCwQAAAAAwFFVOHQHBATo+++/17Jly/Tdd9/J09NTcXFxGjx4cKnf2Q0AAAAAwM3qmm7Crlq1qh577DFb1wIAAAAAQKVyzU8+y8zM1JEjR3Tx4kWr9r/97W/XXRQAAAAAAJVBhUP3oUOH1L9/f/3www9ycnKS2WyWJDk5OUmSioqKbFshAAAAAAAOqsJPL3/qqacUEhKiEydOyMvLSz/++KM2btyotm3bav369QaUCAAAAACAY6rwme4tW7boq6++Up06deTs7CxnZ2d16NBBSUlJGj16tHbt2mVEnQAAAAAAOJwKn+kuKipStWrVJEl16tTRsWPHJElBQUHat2+fbasDAAAAAMCBVfhMd7NmzfTdd98pJCREUVFReuWVV+Tm5qb58+crNDTUiBoBAAAAAHBIFQ7diYmJOn/+vCRp2rRp6t27t+666y7Vrl1bK1assHmBAAAAAAA4qgqH7ujoaMu/33rrrdq7d69+++031axZ0/IEcwAAAAAAUMHQbTKZ5OnpqYyMDDVr1szSXqtWLZsXBvvYv3+/zp07Z+8yym3v3r2Wf1apcs1fO3/DVatWTQ0bNrR3GZVW/rnf1MrPWf/d+rE8z/xks3ELCgosz7GwpeLiYh3Yt09fntgtZ+cKP2qjXPz9/eXu7m6z8bJ+/lmt/JzlVJhvszFhzakwX638nC+t4WPGrAubKyxUjbzD0vHvJAf4TPY88xPrGIBd5eXlWf4+a2tG/z05PDxcXl5eNh+3MqrQ7Lu6uqpBgwZ8F3cltX//fjVq1MjeZVyT2NhYe5dQYT/99BPB2yDZP27Szse9pROzpBO2HTvCtsNZ9PaWdNSgwSXpF9sO10RSzOPeOmI+bduBYeGRe+TSOt74uLTR3tWUj6ukzpLkIM9VbSJp5+Pe2pN7RNId9i4HwE1o7969atOmjaHHMOrvyenp6WrdurUhY1c2Ff6Vx3PPPaeJEydqyZIlnOGuZC6f4V66dKmaNGli52rKJzc3V2vWrFG/fv3k7e1t73LKZc+ePXrooYcc6ooCR3NX/2FavVoKDg6Wh4eHzcY18kz3vn371LhxY4c50y1JVatWVYNWXWw6Jv4n37uBWs/L1bJly9QkPNze5ZSLqbBQ33zzje688065OsCZ7j1792rIkCF6J6aBvUsBcJMKDw9Xenq6IWOfO3dO//73v9W3b1/Lt0/ZUriD/L/pr6DC/0d84403dODAAfn7+ysoKEhVq1a12r5z506bFQf7aNKkicP81spkMun3339X+/bt5erqau9y8BdRp36g+j8xxZCxIwwY02QyqejzzxUdE8M6hoW5iod2ZRXrgk8jyT/C3uWUj8mks15HpfotJQdYyxeyirUrq1jmKrb75RwAVISXl5dhf+82mUw6c+aM7rjjDv5+YWcVDt39+vUzoAwAAAAAACqfCofuyZMnG1EHAAAAAACVjoM8DhUAAAAAAMdT4dDt7OwsFxeXMn+uxZw5cywPPIqKitL27dvL7GsymTRt2jSFhYXJw8NDLVu2VEpKilWfKVOmyMnJyernzzf6d+7cuUSf4cOHW/U5cuSIevXqJS8vL9WtW1fPPPOMCgsLr+k9AgAAAABuPhW+vHz16tVWr00mk3bt2qXFixdr6tSpFS5gxYoVSkhI0Ny5cxUVFaXZs2crOjpa+/btU926dUv0T0xM1NKlS/XWW28pPDxcX375pfr376/NmzerVatWln633Xab1q1bZ3ld2nfTxcfHa9q0aZbXf/yeuaKiIvXq1Ut+fn7avHmzjh8/rqFDh8rV1VUzZsyo8PsEAAAAANx8Khy6+/btW6Ltvvvu02233aYVK1Zo2LBhFRovOTlZ8fHxiouLkyTNnTtXn332mRYsWKDx48eX6L9kyRI999xziomJkSSNGDFC69at08yZM7V06VJLvypVqsjPz++Kx/by8iqzz9q1a5WZmal169apXr16ioiI0PTp0/Xss89qypQpcnNzq9D7BAAAAADcfGz2JZrt2rXTY489VqF9Ll68qPT0dE2YMMHS5uzsrK5du2rLli2l7lNQUFDie3c9PT21adMmq7b9+/fL399fHh4eat++vZKSktSggfX3cC5btkxLly6Vn5+f+vTpo+eff95ytnvLli1q3ry56tWrZ+kfHR2tESNG6Mcff7Q6q/7H2goKCiyvc3JyJF26GsBkMpVnSuzq8qXzhYWFDlGvJEudjlKv5JjzDGM54jqG8Rzxs8LR1rIjzrEjcrR5drR1LDneHOPGcMS17GjKO7c2Cd0XLlzQa6+9poCAgArtd+rUKRUVFVkFW0mqV6+e9u7dW+o+0dHRSk5OVseOHRUWFqa0tDStWrVKRUVFlj5RUVFatGiRGjdurOPHj2vq1Km66667tHv3bssXwz/44IMKCgqSv7+/vv/+ez377LPat2+fVq1aJUnKysoqta7L20qTlJRU6iX2a9eutbp0/a/q4MGDkqRNmzbp+PHjdq6mYlJTU+1dQrk58jzDWI60jmE8R/6scJS17Mhz7EgcdZ4dZR1LjjvHuDEcaS07mry8vHL1q3DorlmzppycnCyvzWazzp07Jy8vL6vLu43y6quvKj4+XuHh4XJyclJYWJji4uK0YMECS5+ePXta/r1FixaKiopSUFCQPvjgA8vl7388K9+8eXPVr19fXbp00cGDBxUWFnZNtU2YMEEJCQmW1zk5OQoMDFT37t1VvXr1axrzRtq1a5ckqUOHDqWeyf8rMplMSk1NVbdu3eTq6mrvcsrFEecZxnLEdQzjOeJnhaOtZUecY0fkaPPsaOtYcrw5xo3hiGvZ0Vy+svlqKhy6Z82aZRW6nZ2d5evrq6ioKNWsWbNCY9WpU0cuLi7Kzs62as/Ozi7zXmtfX1+tWbNG+fn5On36tPz9/TV+/HiFhoaWeRwfHx81atRIBw4cKLNPVFSUJOnAgQMKCwuTn59fiaeoX66zrNrc3d3l7u5eot3V1dUhFvrlh81VqVLFIer9I0eZY8mx5xnGcqR1DOM58meFo6xlR55jR+Ko8+wo61hy3DnGjeFIa9nRlHdeKxy6H3nkkYruUiY3Nze1adNGaWlp6tevnySpuLhYaWlpGjVq1BX39fDwUEBAgEwmk1auXKmBAweW2Tc3N1cHDx7Uww8/XGafjIwMSVL9+vUlSe3bt9eLL76oEydOWJ6inpqaqurVq6tp06YVeJcAAAAAgJtVhb+ne+HChfrwww9LtH/44YdavHhxhQtISEjQW2+9pcWLF2vPnj0aMWKEzp8/b3ma+dChQ60etLZt2zatWrVKhw4d0n/+8x/16NFDxcXFGjdunKXP2LFjtWHDBh0+fFibN29W//795eLiosGDB0u6dN/L9OnTlZ6ersOHD+vjjz/W0KFD1bFjR7Vo0UKS1L17dzVt2lQPP/ywvvvuO3355ZdKTEzUyJEjSz2bDQAAAADAn1X4THdSUpLmzZtXor1u3bp67LHHFBsbW6HxBg0apJMnT2rSpEnKyspSRESEUlJSLA8tO3LkiJyd//e7gfz8fCUmJurQoUPy9vZWTEyMlixZIh8fH0ufX3/9VYMHD9bp06fl6+urDh06aOvWrfL19ZV06Qz7unXrNHv2bJ0/f16BgYEaMGCAEhMTLWO4uLjo008/1YgRI9S+fXtVrVpVsbGxVt/rDQAAAADAlVQ4dB85ckQhISEl2oOCgnTkyJFrKmLUqFFlXk6+fv16q9edOnVSZmbmFcdbvnz5FbcHBgZqw4YNV60rKChIn3/++VX7AQAAAABQmgpfXl63bl19//33Jdq/++471a5d2yZFAQAAAABQGVQ4dA8ePFijR4/W119/raKiIhUVFemrr77SU089pQceeMCIGgEAAAAAcEgVvrx8+vTpOnz4sLp06WL5eoLi4mINHTpUM2bMsHmBAAAAAAA4qgqHbjc3N61YsUIvvPCCMjIy5OnpqebNmysoKMiI+gAAAAAAcFgVDt2XNWzYUA0bNrRlLQAAAAAAVCoVvqd7wIABevnll0u0v/LKK7r//vttUhQAAAAAAJVBhUP3xo0bFRMTU6K9Z8+e2rhxo02KAgAAAACgMqhw6M7NzZWbm1uJdldXV+Xk5NikKAAAAAAAKoMKh+7mzZtrxYoVJdqXL1+upk2b2qQoAAAAAAAqgwo/SO3555/Xvffeq4MHD+qee+6RJKWlpen999/Xhx9+aPMCAQAAAABwVBUO3X369NGaNWs0Y8YMffTRR/L09FSLFi20bt06derUyYgaAQAAAABwSNf0lWG9evVSr169bF0LAAAAAACVSoXv6QYAAAAAAOVT4TPdRUVFmjVrlj744AMdOXJEFy9etNr+22+/2aw4AAAAAAAcWYXPdE+dOlXJyckaNGiQzp49q4SEBN17771ydnbWlClTDCgRAAAAAADHVOHQvWzZMr311lv6v//7P1WpUkWDBw/W22+/rUmTJmnr1q1G1AgAAAAAgEOqcOjOyspS8+bNJUne3t46e/asJKl379767LPPbFsdAAAAAAAOrMKh+5ZbbtHx48clSWFhYVq7dq0kaceOHXJ3d7dtdQAAAAAAOLAKh+7+/fsrLS1NkvTkk0/q+eefV8OGDTV06FD9/e9/t3mBAAAAAAA4qgo/vfyll16y/PugQYMUFBSkzZs3q2HDhurTp49NiwMAAAAAwJFVOHT/Wbt27dSuXTtb1AIAAAAAQKVS4cvLAQAAAABA+RC6AQAAAAAwyHVfXg4AAACUxakwX638nOV55ifpmAOc7yksVI28w9Lx76QqjvFXZc8zP6mVn7OcCvPtXQqAUjjGJwkAAAAckkfuEe183Fva+Li00d7VXJ2rpM6StM++dVREE0k7H/fWntwjku6wdzkA/qTCoTs0NFQ7duxQ7dq1rdrPnDmj1q1b69ChQzYrDgAAAI4t37uBWs/L1bJly9QkPNze5VyVqbBQ33zzje688065OsiZ7j1792rIkCF6J6aBvUsBUIoKf5IcPnxYRUVFJdoLCgp09OhRmxQFAACAysFcxUO7sop1waeR5B9h73KuzmTSWa+jUv2WkqurvasplwtZxdqVVSxzFQ97lwKgFOUO3R9//LHl37/88kvVqFHD8rqoqEhpaWkKDg62aXEAAAAAADiycofufv36SZKcnJwUGxtrtc3V1VXBwcGaOXOmTYsDAAAAAMCRlTt0FxcXS5JCQkK0Y8cO1alTx7CiAAAAAACoDCp8T/fPP/9cou3MmTPy8fGxRT0AAAAAAFQaFf6yxJdfflkrVqywvL7//vtVq1YtBQQE6LvvvrNpcQAAAAAAOLIKh+65c+cqMDBQkpSamqp169YpJSVFPXv21DPPPGPzAgEAAAAAcFQVvrw8KyvLEro//fRTDRw4UN27d1dwcLCioqJsXiAAAAAAAI6qwme6a9asqV9++UWSlJKSoq5du0qSzGZzqd/fDQAAAADAzarCofvee+/Vgw8+qG7duun06dPq2bOnJGnXrl269dZbr6mIOXPmKDg4WB4eHoqKitL27dvL7GsymTRt2jSFhYXJw8NDLVu2VEpKilWfKVOmyMnJyeonPDzcsv23337Tk08+qcaNG8vT01MNGjTQ6NGjdfbsWatx/jyGk5OTli9ffk3vEQAAAABw86nw5eWzZs1ScHCwfvnlF73yyivy9vaWJB0/flxPPPFEhQtYsWKFEhISNHfuXEVFRWn27NmKjo7Wvn37VLdu3RL9ExMTtXTpUr311lsKDw/Xl19+qf79+2vz5s1q1aqVpd9tt92mdevW/e+NVvnfWz127JiOHTumf/7zn2ratKn++9//avjw4Tp27Jg++ugjq+MtXLhQPXr0sLzmKe0AAAAAgPKqcOh2dXXV2LFjS7SPGTPmmgpITk5WfHy84uLiJF16UNtnn32mBQsWaPz48SX6L1myRM8995xiYmIkSSNGjNC6des0c+ZMLV261NKvSpUq8vPzK/WYzZo108qVKy2vw8LC9OKLL+qhhx5SYWGhVUD38fEpcxwAAAAAAK6kwqFbuhR8582bp0OHDmnLli0KCgrS7NmzFRISor59+5Z7nIsXLyo9PV0TJkywtDk7O6tr167asmVLqfsUFBTIw8PDqs3T01ObNm2yatu/f7/8/f3l4eGh9u3bKykpSQ0aNCizlrNnz6p69epWgVuSRo4cqUcffVShoaEaPny44uLi5OTkVGZtBQUFltc5OTmSLl0SbzKZyjz2X0VhYaHln45QryRLnY5Sr+SY8wxjOeI6hvEc8bPC0dayI86xI3K0eXa0dSw53hzjxnDEtexoyju3FQ7db775piZNmqSnn35aL774ouXhaT4+Ppo9e3aFQvepU6dUVFSkevXqWbXXq1dPe/fuLXWf6OhoJScnq2PHjgoLC1NaWppWrVpl9RC3qKgoLVq0SI0bN9bx48c1depU3XXXXdq9e7eqVatWah3Tp0/XY489ZtU+bdo03XPPPfLy8tLatWv1xBNPKDc3V6NHjy61tqSkJE2dOrVE+9q1a+Xl5XXV+bC3gwcPSpI2bdqk48eP27maiklNTbV3CeXmyPMMYznSOobxHPmzwlHWsiPPsSNx1Hl2lHUsOe4c48ZwpLXsaPLy8srVz8lsNpsrMnDTpk01Y8YM9evXT9WqVdN3332n0NBQ7d69W507d9apU6fKPdaxY8cUEBCgzZs3q3379pb2cePGacOGDdq2bVuJfU6ePKn4+Hh98skncnJyUlhYmLp27aoFCxbowoULpR7nzJkzCgoKUnJysoYNG2a1LScnR926dVOtWrX08ccfy9XVtcx6J02apIULF1qe3v5npZ3pDgwM1KlTp1S9evUrzsVfwa5duxQVFaVt27ZZ3R//V2YymZSamqpu3bpd8b/dX4kjzjOM5YjrGMZzxM8KR1vLjjjHjsjR5tnR1rHkeHOMG8MR17KjycnJUZ06dSxXTZelwme6f/7551L/MLu7u+v8+fMVGqtOnTpycXFRdna2VXt2dnaZ91H7+vpqzZo1ys/P1+nTp+Xv76/x48crNDS0zOP4+PioUaNGOnDggFX7uXPn1KNHD1WrVk2rV6++6mKMiorS9OnTVVBQIHd39xLb3d3dS213dXV1iIV++dL6KlWqOES9f+Qocyw59jzDWI60jmE8R/6scJS17Mhz7EgcdZ4dZR1LjjvHuDEcaS07mvLOa4W/MiwkJEQZGRkl2lNSUtSkSZMKjeXm5qY2bdooLS3N0lZcXKy0tDSrM9+l8fDwUEBAgAoLC7Vy5corXtaem5urgwcPqn79+pa2nJwcde/eXW5ubvr4449L3CdemoyMDNWsWbPUYA0AAAAAwJ+V+0z3tGnTNHbsWCUkJGjkyJHKz8+X2WzW9u3b9f777yspKUlvv/12hQtISEhQbGys2rZtq8jISM2ePVvnz5+3PM186NChCggIUFJSkiRp27ZtOnr0qCIiInT06FFNmTJFxcXFGjdunGXMsWPHqk+fPgoKCtKxY8c0efJkubi4aPDgwZL+F7jz8vK0dOlS5eTkWB565uvrKxcXF33yySfKzs5Wu3bt5OHhodTUVM2YMaPUJ7cDAAAAAFCacofuqVOnavjw4Xr00Ufl6empxMRE5eXl6cEHH5S/v79effVVPfDAAxUuYNCgQTp58qQmTZqkrKwsRUREKCUlxfJwtSNHjsjZ+X8n5PPz85WYmKhDhw7J29tbMTExWrJkidX3Z//6668aPHiwTp8+LV9fX3Xo0EFbt26Vr6+vJGnnzp2W+8VvvfVWq3p+/vlnBQcHy9XVVXPmzNGYMWNkNpt16623Wr7eDAAAAACA8ih36P7j89aGDBmiIUOGKC8vT7m5uapbt+51FTFq1CiNGjWq1G3r16+3et2pUydlZmZecbzly5dfcXvnzp11tefH9ejRQz169LhiHwAAAAAArqRCD1L78/dTe3l5OcRXYQEAAAAAYA8VCt2NGjUqEbz/7LfffruuggAAAAAAqCwqFLqnTp2qGjVqGFULAAAAAACVSoVC9wMPPHDd928DAAAAAHCzKPf3dF/tsnIAAAAAAGCt3KH7ak/7BgAAAAAA1sp9eXlxcbGRdQAAAAAAUOmU+0w3AAAAAACoGEI3AAAAAAAGIXQDAAAAAGAQQjcAAAAAAAYhdAMAAAAAYBBCNwAAAAAABiF0AwAAAABgEEI3AAAAAAAGIXQDAAAAAGAQQjcAAAAAAAYhdAMAAAAAYJAq9i4AAAAAlVdeXp4kaefOnXaupHxyc3O1YcMG1axZU97e3vYup1z27Nlj7xIAXAGhGwAAAIbZu3evJCk+Pt7OlVTMrFmz7F1ChVWrVs3eJQAoBaEbAAAAhunXr58kKTw8XF5eXvYtphx2796t2NhYLV68WM2aNbN3OeVWrVo1NWzY0N5lACgFoRsAAACGqVOnjh599FF7l1FuhYWFki79kqB169Z2rgZAZcCD1AAAAAAAMAihGwAAAAAAgxC6AQAAAAAwCKEbAAAAAACDELoBAAAAADAIoRsAAAAAAIMQugEAAAAAMAihGwAAAAAAgxC6AQAAAAAwCKEbAAAAAACDELoBAAAAADAIoRsAAAAAAIMQugEAAAAAMMhfInTPmTNHwcHB8vDwUFRUlLZv315mX5PJpGnTpiksLEweHh5q2bKlUlJSrPpMmTJFTk5OVj/h4eFWffLz8zVy5EjVrl1b3t7eGjBggLKzs636HDlyRL169ZKXl5fq1q2rZ555RoWFhbZ74wAAAACASs3uoXvFihVKSEjQ5MmTtXPnTrVs2VLR0dE6ceJEqf0TExM1b948vf7668rMzNTw4cPVv39/7dq1y6rfbbfdpuPHj1t+Nm3aZLV9zJgx+uSTT/Thhx9qw4YNOnbsmO69917L9qKiIvXq1UsXL17U5s2btXjxYi1atEiTJk2y/SQAAAAAAColu4fu5ORkxcfHKy4uTk2bNtXcuXPl5eWlBQsWlNp/yZIlmjhxomJiYhQaGqoRI0YoJiZGM2fOtOpXpUoV+fn5WX7q1Klj2Xb27Fm98847Sk5O1j333KM2bdpo4cKF2rx5s7Zu3SpJWrt2rTIzM7V06VJFRESoZ8+emj59uubMmaOLFy8aNyEAAAAAgEqjij0PfvHiRaWnp2vChAmWNmdnZ3Xt2lVbtmwpdZ+CggJ5eHhYtXl6epY4k71//375+/vLw8ND7du3V1JSkho0aCBJSk9Pl8lkUteuXS39w8PD1aBBA23ZskXt2rXTli1b1Lx5c9WrV8/SJzo6WiNGjNCPP/6oVq1alVpbQUGB5XVOTo6kS5fEm0ym8k6L3Vy+dL6wsNAh6pVkqdNR6pUcc55hLEdcxzCeI35WONpadsQ5hvH+uI5ZF3BkjvaZ7IjKO7d2Dd2nTp1SUVGRVbCVpHr16mnv3r2l7hMdHa3k5GR17NhRYWFhSktL06pVq1RUVGTpExUVpUWLFqlx48Y6fvy4pk6dqrvuuku7d+9WtWrVlJWVJTc3N/n4+JQ4blZWliQpKyur1LoubytNUlKSpk6dWqJ97dq18vLyuvJk/AUcPHhQkrRp0yYdP37cztVUTGpqqr1LKDdHnmcYy5HWMYznyJ8VjrKWHXmOYZzL62Lbtm06deqUnasBrp+jfCY7ory8vHL1s2vovhavvvqq4uPjFR4eLicnJ4WFhSkuLs7qcvSePXta/r1FixaKiopSUFCQPvjgAw0bNsyw2iZMmKCEhATL65ycHAUGBqp79+6qXr26Yce1lcv3xXfo0KHUM/l/RSaTSampqerWrZtcXV3tXU65OOI8w1iOuI5hPEf8rHC0teyIcwzjXX6gb1RUlCIjI+1cDXDtHO0z2RFdvrL5auwauuvUqSMXF5cSTw3Pzs6Wn59fqfv4+vpqzZo1ys/P1+nTp+Xv76/x48crNDS0zOP4+PioUaNGOnDggCTJz89PFy9e1JkzZ6zOdv/xuH5+fiWeon65zrJqc3d3l7u7e4l2V1dXh1joVapUsfzTEer9I0eZY8mx5xnGcqR1DOM58meFo6xlR55jGOfyWnCUdQxcDWvZOOWdV7s+SM3NzU1t2rRRWlqapa24uFhpaWlq3779Fff18PBQQECACgsLtXLlSvXt27fMvrm5uTp48KDq168vSWrTpo1cXV2tjrtv3z4dOXLEctz27dvrhx9+sHqKempqqqpXr66mTZte0/sFAAAAANxc7H55eUJCgmJjY9W2bVtFRkZq9uzZOn/+vOLi4iRJQ4cOVUBAgJKSkiRdur/m6NGjioiI0NGjRzVlyhQVFxdr3LhxljHHjh2rPn36KCgoSMeOHdPkyZPl4uKiwYMHS5Jq1KihYcOGKSEhQbVq1VL16tX15JNPqn379mrXrp0kqXv37mratKkefvhhvfLKK8rKylJiYqJGjhxZ6tlsAAAAAAD+zO6he9CgQTp58qQmTZqkrKwsRUREKCUlxfLQsiNHjsjZ+X8n5PPz85WYmKhDhw7J29tbMTExWrJkidVl4r/++qsGDx6s06dPy9fXVx06dNDWrVvl6+tr6TNr1iw5OztrwIABKigoUHR0tP71r39Ztru4uOjTTz/ViBEj1L59e1WtWlWxsbGaNm2a8ZMCAAAAAKgU7B66JWnUqFEaNWpUqdvWr19v9bpTp07KzMy84njLly+/6jE9PDw0Z84czZkzp8w+QUFB+vzzz686FgAAAAAApbHrPd0AAAAAAFRmhG4AAAAAAAxC6AYAAAAAwCCEbgAAAAAADELoBgAAAADAIIRuAAAAAAAMQugGAAAAAMAghG4AAAAAAAxC6AYAAAAAwCCEbgAAAAAADELoBgAAAADAIIRuAAAAAAAMQugGAAAAAMAgVexdAP468s/9plZ+zvrv1o/leeYnm45dUFCgY8eO2XRMSSouLtaBffv05Yndcna2/e+Q/P395e7ubtMxs37+Wa38nOVUmG/TcQFULnl5eZKknTt32nzsCxcu6PDhwzYft6ioSBkZGTp79qxcXFxsPn5wcLA8PT1tNt6ePXtsNhYAAGUhdMMi+8dN2vm4t3RilnTC9uNH2H5ISVJvb0lHDRr8F9sP2URSzOPeOmI+bfvBAVQae/fulSTFx8fbuZLKr1q1avYuAQBQiRG6YXFX/2FavfrSmQQPDw+bjm3kme59+/apcePGDnOmW5KqVq2qBq262HxcAJVHv379JEnh4eHy8vKy6dhGn+mOiIhwiDPd0qXA3bBhQ5uOCQDAHxG6YVGnfqD6PzHFsPEjDBjTZDKp6PPPFR0TI1dXVwOOAAD2UadOHT366KOGjX/nnXfafEyTyaQaNWoohs9kAAAseJAaAAAAAAAGIXQDAAAAAGAQQjcAAAAAAAYhdAMAAAAAYBBCNwAAAAAABiF0AwAAAABgEEI3AAAAAAAGIXQDAAAAAGAQQjcAAAAAAAYhdAMAAAAAYBBCNwAAAAAABiF0AwAAAABgEEI3AAAAAAAGIXQDAAAAAGAQQjcAAAAAAAYhdAMAAAAAYBBCNwAAAAAABiF0AwAAAABgkL9E6J4zZ46Cg4Pl4eGhqKgobd++vcy+JpNJ06ZNU1hYmDw8PNSyZUulpKSU2f+ll16Sk5OTnn76aUvb4cOH5eTkVOrPhx9+aOlX2vbly5fb5D0DAAAAACo/u4fuFStWKCEhQZMnT9bOnTvVsmVLRUdH68SJE6X2T0xM1Lx58/T6668rMzNTw4cPV//+/bVr164SfXfs2KF58+apRYsWVu2BgYE6fvy41c/UqVPl7e2tnj17WvVduHChVb9+/frZ7L0DAAAAACo3u4fu5ORkxcfHKy4uTk2bNtXcuXPl5eWlBQsWlNp/yZIlmjhxomJiYhQaGqoRI0YoJiZGM2fOtOqXm5urIUOG6K233lLNmjWttrm4uMjPz8/qZ/Xq1Ro4cKC8vb2t+vr4+Fj18/DwsO0EAAAAAAAqrSr2PPjFixeVnp6uCRMmWNqcnZ3VtWtXbdmypdR9CgoKSgRfT09Pbdq0yapt5MiR6tWrl7p27aoXXnjhinWkp6crIyNDc+bMKbFt5MiRevTRRxUaGqrhw4crLi5OTk5OZdZWUFBgeZ2TkyPp0iXxJpPpijXg2lyeV+YXjox1jMqCtYzK4I/rmLUMR8ZnsvHKO7d2Dd2nTp1SUVGR6tWrZ9Ver1497d27t9R9oqOjlZycrI4dOyosLExpaWlatWqVioqKLH2WL1+unTt3aseOHeWq45133lGTJk10xx13WLVPmzZN99xzj7y8vLR27Vo98cQTys3N1ejRo0sdJykpSVOnTi3RvnbtWnl5eZWrFlyb1NRUe5cAXDfWMSoL1jIc2cGDByVJ27Zt06lTp+xcDXD9+Ew2Tl5eXrn62TV0X4tXX31V8fHxCg8Pl5OTk8LCwhQXF2e5HP2XX37RU089pdTU1HJdCn7hwgW99957ev7550ts+2Nbq1atdP78ef3jH/8oM3RPmDBBCQkJltc5OTkKDAxU9+7dVb169Yq+VZSDyWRSamqqunXrJldXV3uXA1wT1jEqC9YyKoPLD/SNiopSZGSknasBrh2fyca7fGXz1dg1dNepU0cuLi7Kzs62as/Ozpafn1+p+/j6+mrNmjXKz8/X6dOn5e/vr/Hjxys0NFTSpUvFT5w4odatW1v2KSoq0saNG/XGG2+ooKBALi4ulm0fffSR8vLyNHTo0KvWGxUVpenTp6ugoEDu7u4ltru7u5fa7urqykI3GHOMyoB1jMqCtQxHdnntso5RWbCWjVPeebXrg9Tc3NzUpk0bpaWlWdqKi4uVlpam9u3bX3FfDw8PBQQEqLCwUCtXrlTfvn0lSV26dNEPP/ygjIwMy0/btm01ZMgQZWRkWAVu6dKl5X/729/k6+t71XozMjJUs2bNUoM1AAAAAAB/ZvfLyxMSEhQbG6u2bdsqMjJSs2fP1vnz5xUXFydJGjp0qAICApSUlCTp0v01R48eVUREhI4ePaopU6aouLhY48aNkyRVq1ZNzZo1szpG1apVVbt27RLtBw4c0MaNG/X555+XqOuTTz5Rdna22rVrJw8PD6WmpmrGjBkaO3asEdMAAAAAAKiE7B66Bw0apJMnT2rSpEnKyspSRESEUlJSLA9XO3LkiJyd/3dCPj8/X4mJiTp06JC8vb0VExOjJUuWyMfHp8LHXrBggW655RZ17969xDZXV1fNmTNHY8aMkdls1q233mr5ejMAAAAAAMrD7qFbkkaNGqVRo0aVum39+vVWrzt16qTMzMwKjf/nMS6bMWOGZsyYUeq2Hj16qEePHhU6DgAAAAAAf2TXe7oBAAAAAKjMCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQf4SoXvOnDkKDg6Wh4eHoqKitH379jL7mkwmTZs2TWFhYfLw8FDLli2VkpJSZv+XXnpJTk5Oevrpp63aO3fuLCcnJ6uf4cOHW/U5cuSIevXqJS8vL9WtW1fPPPOMCgsLr+u9AgAAAABuHlXsXcCKFSuUkJCguXPnKioqSrNnz1Z0dLT27dununXrluifmJiopUuX6q233lJ4eLi+/PJL9e/fX5s3b1arVq2s+u7YsUPz5s1TixYtSj12fHy8pk2bZnnt5eVl+feioiL16tVLfn5+2rx5s44fP66hQ4fK1dVVM2bMsNG7BwAAAABUZnY/052cnKz4+HjFxcWpadOmmjt3rry8vLRgwYJS+y9ZskQTJ05UTEyMQkNDNWLECMXExGjmzJlW/XJzczVkyBC99dZbqlmzZqljeXl5yc/Pz/JTvXp1y7a1a9cqMzNTS5cuVUREhHr27Knp06drzpw5unjxou0mAAAAAABQadn1TPfFixeVnp6uCRMmWNqcnZ3VtWtXbdmypdR9CgoK5OHhYdXm6empTZs2WbWNHDlSvXr1UteuXfXCCy+UOtayZcu0dOlS+fn5qU+fPnr++ectZ7u3bNmi5s2bq169epb+0dHRGjFihH788ccSZ9Uv11ZQUGB5nZOTI+nSJfEmk+lKU4FrdHlemV84MtYxKgvWMiqDP65j1jIcGZ/Jxivv3No1dJ86dUpFRUVWwVaS6tWrp71795a6T3R0tJKTk9WxY0eFhYUpLS1Nq1atUlFRkaXP8uXLtXPnTu3YsaPMYz/44IMKCgqSv7+/vv/+ez377LPat2+fVq1aJUnKysoqta7L20qTlJSkqVOnlmhfu3at1aXrsL3U1FR7lwBcN9YxKgvWMhzZwYMHJUnbtm3TqVOn7FwNcP34TDZOXl5eufrZ/Z7uinr11VcVHx+v8PBwOTk5KSwsTHFxcZbL0X/55Rc99dRTSk1NLXFG/I8ee+wxy783b95c9evXV5cuXXTw4EGFhYVdU20TJkxQQkKC5XVOTo4CAwPVvXt3q0vXYTsmk0mpqanq1q2bXF1d7V0OcE1Yx6gsWMuoDC4/0DcqKkqRkZF2rga4dnwmG+/ylc1XY9fQXadOHbm4uCg7O9uqPTs7W35+fqXu4+vrqzVr1ig/P1+nT5+Wv7+/xo8fr9DQUElSenq6Tpw4odatW1v2KSoq0saNG/XGG2+ooKBALi4uJcaNioqSJB04cEBhYWHy8/Mr8RT1y3WWVZu7u7vc3d1LtLu6urLQDcYcozJgHaOyYC3DkV1eu6xjVBasZeOUd17t+iA1Nzc3tWnTRmlpaZa24uJipaWlqX379lfc18PDQwEBASosLNTKlSvVt29fSVKXLl30ww8/KCMjw/LTtm1bDRkyRBkZGaUGbknKyMiQJNWvX1+S1L59e/3www86ceKEpU9qaqqqV6+upk2bXs/bBgAAAADcJOx+eXlCQoJiY2PVtm1bRUZGavbs2Tp//rzi4uIkSUOHDlVAQICSkpIkXbq/5ujRo4qIiNDRo0c1ZcoUFRcXa9y4cZKkatWqqVmzZlbHqFq1qmrXrm1pP3jwoN577z3FxMSodu3a+v777zVmzBh17NjR8vVi3bt3V9OmTfXwww/rlVdeUVZWlhITEzVy5MhSz2YDAAAAAPBndg/dgwYN0smTJzVp0iRlZWUpIiJCKSkploeWHTlyRM7O/zshn5+fr8TERB06dEje3t6KiYnRkiVL5OPjU+5jurm5ad26dZaAHxgYqAEDBigxMdHSx8XFRZ9++qlGjBih9u3bq2rVqoqNjbX6Xm8AAAAAAK7E7qFbkkaNGqVRo0aVum39+vVWrzt16qTMzMwKjf/nMQIDA7Vhw4ar7hcUFKTPP/+8QscCAAAAAOAyu97TDQAAAABAZUboBgAAAADAIH+Jy8sBAACAisjLy9PevXttPu7lMffu3asqVYz5q3J4eLi8vLwMGRvAXw+hGwAAAA5n7969atOmjWHjx8bGGjZ2enq6Wrdubdj4AP5aCN0AAABwOOHh4UpPT7f5uOfOndO///1v9e3bV9WqVbP5+NKl2gHcPAjdAAAAcDheXl6GnC02mUw6c+aM7rjjDrm6utp8fAA3Hx6kBgAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBqti7gMrMbDZLknJycuxcSeVlMpmUl5ennJwcubq62rsc4JqwjlFZsJZRGbCOUVmwlo13Oeddzn1lIXQb6Ny5c5KkwMBAO1cCAAAAADDCuXPnVKNGjTK3O5mvFstxzYqLi3Xs2DFVq1ZNTk5O9i6nUsrJyVFgYKB++eUXVa9e3d7lANeEdYzKgrWMyoB1jMqCtWw8s9msc+fOyd/fX87OZd+5zZluAzk7O+uWW26xdxk3herVq/NhAofHOkZlwVpGZcA6RmXBWjbWlc5wX8aD1AAAAAAAMAihGwAAAAAAgxC64dDc3d01efJkubu727sU4JqxjlFZsJZRGbCOUVmwlv86eJAaAAAAAAAG4Uw3AAAAAAAGIXQDAAAAAGAQQjcAAABuCosWLZKPj891j+Pk5KQ1a9Zc9zjAjWarPwOoGEI3Kp05c+YoODhYHh4eioqK0vbt26+6z8aNG9WnTx/5+/vzP1L8JbCOURmwjmFrjzzyiPr162fV9tFHH8nDw0MzZ8686v6DBg3STz/9dN11HD9+XD179rzucYDLioqKdMcdd+jee++1aj979qwCAwP13HPP2eQ4tvozgIohdKNSWbFihRISEjR58mTt3LlTLVu2VHR0tE6cOHHF/c6fP6+WLVtqzpw5N6hSoGysY1QGrGPcCG+//baGDBmiN998U//3f/931f6enp6qW7fudR/Xz8+PJ0LDplxcXLRo0SKlpKRo2bJllvYnn3xStWrV0uTJk21yHFv8GTCZTDap5aZiBm6gLVu2mO+55x5zrVq1zJKsfs6ePXvd40dGRppHjhxpeV1UVGT29/c3JyUllXsMSebVq1dfdy2ovFjHqAxYx3BEsbGx5r59+5rNZrP55ZdfNnt4eJhXrVpl2T5z5kxzs2bNzF5eXuZbbrnFPGLECPO5c+cs2xcuXGiuUaOG5fXkyZPNLVu2NL/zzjvmwMBAc9WqVc0jRowwFxYWml9++WVzvXr1zL6+vuYXXnjBqo4/rs2ff/7ZLMm8cuVKc+fOnc2enp7mFi1amDdv3my1z/z588233HKL2dPT09yvXz/zzJkzrWoBzGaz+dVXXzXXrFnTfOzYMfOaNWvMrq6u5oyMDLPZbDYXFhaa//73v5uDg4PNHh4e5kaNGplnz55t2ffLL780u7u7m3///XerMUePHm2+++67zWZzyT8DZrPZvGbNGnOrVq3M7u7u5pCQEPOUKVPMJpPJsl2S+V//+pe5T58+Zi8vL/PkyZMNee+VGWe6ccN899136ty5s1q1aqX//Oc/SklJUa1atdSlSxetWLFC1atXt/SdMWOGvL29r/hz5MgRq/EvXryo9PR0de3a1dLm7Oysrl27asuWLTfsfaJyYx2jMmAdw9E9++yzmj59uj799FP179/f0u7s7KzXXntNP/74oxYvXqyvvvpK48aNu+JYBw8e1BdffKGUlBS9//77euedd9SrVy/9+uuv2rBhg15++WUlJiZq27ZtVxznueee09ixY5WRkaFGjRpp8ODBKiwslCR98803Gj58uJ566illZGSoW7duevHFF69/IlDpPPnkk2rZsqUefvhhPfbYY5o0aZJatmwpSSouLtYtt9yiDz/8UJmZmZo0aZImTpyoDz74QJLUpUsX+fj4aOXKlZbxioqKtGLFCg0ZMqTU4/3nP//R0KFD9dRTTykzM1Pz5s3TokWLSqzPKVOmqH///vrhhx/097//3aB3X4nZO/Xj5tGxY0fz4MGDrdpGjhxpbteuXYm+p0+fNu/fv/+KP3/8DZzZbDYfPXrULKnEb5afeeYZc2RkZLnrFGdWcAWsY1QGrGM4qtjYWLObm5tZkjktLe2q/T/88ENz7dq1La9LO9Pt5eVlzsnJsbRFR0ebg4ODzUVFRZa2xo0bW12loVLOdL/99tuW7T/++KNZknnPnj1ms9lsHjRokLlXr15WtQ0ZMoQz3SjVnj17zJLMzZs3L/H5+mcjR440DxgwwPL6qaeeMt9zzz2W138++/3nPwNdunQxz5gxw2rMJUuWmOvXr295Lcn89NNPX8c7QhX7RH3cbLKzs7Vp0yZt2LDBqr1q1apycnIq0b9WrVqqVavWjSoPKBfWMSoD1jEcXYsWLXTq1ClNnjxZkZGR8vb2tmxbt26dkpKStHfvXuXk5KiwsFD5+fnKy8uTl5dXqeMFBwerWrVqltf16tWTi4uLnJ2drdqu9jyCFi1aWP69fv36kqQTJ04oPDxc+/btszojL0mRkZH69NNPy//GcdNYsGCBvLy89PPPP+vXX39VcHCwZducOXO0YMECHTlyRBcuXNDFixcVERFh2T5kyBC1a9dOx44dk7+/v5YtW6ZevXqV+cTy7777Tt98843Vme2ioqISf27atm1rxFu9aXB5OW6I9PR0FRcXWy6P+WN7aX+Ir+Vyxjp16sjFxUXZ2dlW7dnZ2fLz87P9m8JNh3WMyoB1DEcXEBCg9evX6+jRo+rRo4fOnTsnSTp8+LB69+6tFi1aaOXKlUpPT7c8kO/ixYtljufq6mr12snJqdS24uLiK9b1x30u/wLravsAf7Z582bNmjVLn376qSIjIzVs2DCZzWZJ0vLlyzV27FgNGzZMa9euVUZGhuLi4qzW9+23366wsDAtX75cFy5c0OrVq8u8tFyScnNzNXXqVGVkZFh+fvjhB+3fv18eHh6WflWrVjXuTd8EONONG+Ly/3TOnz9v+W3y999/r40bN+qFF14o0X/48OEaOHDgFcf09/e3eu3m5qY2bdooLS3N8nUixcXFSktL06hRo2zwLnCzYx2jMmAdozIICgrShg0bdPfdd6tHjx5KSUmx/EJp5syZlrPUl+91tbfGjRtrx44dVm1/fg3k5eXpkUce0YgRI3T33XcrJCREzZs319y5czVixAh98803uuOOO/TEE09Y9jl48GCJcYYMGaJly5bplltukbOzs3r16lXmMVu3bq19+/bp1ltvNeQ94RJCN26IqKgoeXp66plnntFzzz2ngwcPauTIkRo5cqTatWtXov+1Xs6YkJCg2NhYtW3bVpGRkZo9e7bOnz+vuLg4S5833nhDq1evVlpamqUtNzdXBw4csLz++eeflZGRoVq1aqlBgwYVrgOVE+sYlQHrGJVFYGCg1q9fr7vvvlvR0dF68803ZTKZ9Prrr6tPnz765ptvNHfuXHuXKenSw7E6duyo5ORk9enTR1999ZW++OKLUm/pwM1rwoQJMpvNeumllyRduvXhn//8p8aOHauePXuqYcOGevfdd/Xll18qJCRES5Ys0Y4dOxQSEmI1zpAhQzRlyhS9+OKLuu+++6749XaTJk1S79691aBBA913331ydnbWd999p927d5f6i1hcI3vfVI6bxyeffGJu1KiR2dXV1RwWFmb+xz/+YfWQElt5/fXXzQ0aNDC7ubmZIyMjzVu3brXaPnnyZHNQUJBV29dff13iK3MkmWNjY21eHxwb6xiVAesYjuqPXxl22a+//mpu2LChuV27duYpU6aY69evb/b09DRHR0eb3333XbOkMh8idfkrw652jE6dOpmfeuopy2uV8iC1Xbt2Wbb//vvvZknmr7/+2tI2f/58c0BAgOUrw1544QWzn5/ftU0EKp3169ebXVxczP/5z39KbOvevbv5nnvuMefn55sfeeQRc40aNcw+Pj7mESNGmMePH19iDZvNl762UZL5q6++smov7SvDUlJSzHfccYfZ09PTXL16dXNkZKR5/vz5lu3ioZbXzcls/v83CQAAAAC4IeLj47V371795z//sXcpAAzG5eUAAACAwf75z3+qW7duqlq1qr744gstXrxY//rXv+xdFoAbgDPdAAAAgMEGDhyo9evX69y5cwoNDdWTTz6p4cOH27ssADcAoRsAAAAAAIPwPd0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAEAl5eTkpDVr1lyxzyOPPKJ+/fqVe8zDhw/LyclJGRkZkqT169fLyclJZ86cueY6yyM4OFizZ8829BgAABihir0LAAAA5fPII4/ozJkzVw3Slx0/flw1a9aUdCksh4SEaNeuXYqIiLD0efXVV3U93x56xx136Pjx46pRo8Y1j/FHixYt0tNPP10ixO/YsUNVq1a1yTEAALiRCN0AAFRSfn5+V+1zvWHZzc2tXMe5Xr6+voYfAwAAI3B5OQAADqhz584aPXq0xo0bp1q1asnPz09Tpkyx6vPHy8tDQkIkSa1atZKTk5M6d+4sqeTl5SkpKerQoYN8fHxUu3Zt9e7dWwcPHiyzjj9fXt65c2c5OTmV+Dl8+LAkKTk5Wc2bN1fVqlUVGBioJ554Qrm5uZax4uLidPbsWct+l9/Tny8vP3LkiPr27Stvb29Vr15dAwcOVHZ2tmX7lClTFBERoSVLlig4OFg1atTQAw88oHPnzlVsogEAuE6EbgAAHNTixYtVtWpVbdu2Ta+88oqmTZum1NTUUvtu375dkrRu3TodP35cq1atKrXf+fPnlZCQoG+//VZpaWlydnZW//79VVxcXK6aVq1apePHj1t+7r33XjVu3Fj16tWTJDk7O+u1117Tjz/+qMWLF+urr77SuHHjJF26VH327NmqXr26Zf+xY8eWOEZxcbH69u2r3377TRs2bFBqaqoOHTqkQYMGWfU7ePCg1qxZo08//VSffvqpNmzYoJdeeqlc7wMAAFvh8nIAABxUixYtNHnyZElSw4YN9cYbbygtLU3dunUr0ffy5dm1a9e+4uXgAwYMsHq9YMEC+fr6KjMzU82aNbtqTbVq1bL8+6xZs/TVV19p27Zt8vT0lCQ9/fTTlu3BwcF64YUXNHz4cP3rX/+Sm5ubatSoIScnpyvWmJaWph9++EE///yzAgMDJUnvvvuubrvtNu3YsUO33367pEvhfNGiRapWrZok6eGHH1ZaWppefPHFq74PAABshTPdAAA4qBYtWli9rl+/vk6cOHFdY+7fv1+DBw9WaGioqlevruDgYEmXLueuiC+++ELjx4/XihUr1KhRI0v7unXr1KVLFwUEBKhatWp6+OGHdfr0aeXl5ZV77D179igwMNASuCWpadOm8vHx0Z49eyxtwcHBlsAt2WZ+AACoKEI3AAAOytXV1eq1k5NTuS8DL0ufPn3022+/6a233tK2bdu0bds2SdLFixfLPUZmZqYeeOABvfTSS+revbul/fDhw+rdu7datGihlStXKj09XXPmzKnw+OVlxPwAAFBRXF4OAMBNwM3NTZJUVFRUZp/Tp09r3759euutt3TXXXdJkjZt2lSh45w6dUp9+vTRgAEDNGbMGKtt6enpKi4u1syZM+XsfOn3/h988EGJOq9UoyQ1adJEv/zyi3755RfL2e7MzEydOXNGTZs2rVC9AAAYjTPdAADcBOrWrStPT0+lpKQoOztbZ8+eLdGnZs2aql27tubPn68DBw7oq6++UkJCQoWOM2DAAHl5eWnKlCnKysqy/BQVFenWW2+VyWTS66+/rkOHDmnJkiWaO3eu1f7BwcHKzc1VWlqaTp06Vepl5127dlXz5s01ZMgQ7dy5U9u3b9fQoUPVqVMntW3btmITAwCAwQjdAADcBKpUqaLXXntN8+bNk7+/v/r27Vuij7Ozs5YvX6709HQ1a9ZMY8aM0T/+8Y8KHWfjxo3avXu3goKCVL9+fcvPL7/8opYtWyo5OVkvv/yymjVrpmXLlikpKclq/zvuuEPDhw/XoEGD5Ovrq1deeaXEMZycnPTvf/9bNWvWVMeOHdW1a1eFhoZqxYoVFZsUAABuACez2Wy2dxEAAAAAAFRGnOkGAAAAAMAghG4AAAAAAAxC6AYAAAAAwCCEbgAAAAAADELoBgAAAADAIIRuAAAAAAAMQugGAAAAAMAghG4AAAAAAAxC6AYAAAAAwCCEbgAAAAAADELoBgAAAADAIIRuAAAAAAAM8v8A36aC+E+NwpkAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_vars_for_plot = [(x if isinstance(x, str) else fr\"$\\sigma = {x}$\") for x in init_vars]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_test.T, labels=init_vars_for_plot, showfliers=False)\n",
    "\n",
    "ax.set_title(\"Test quality in 5 runs\")\n",
    "ax.set_xlabel(\"Initialization\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `4 слоя`\n",
    "\n",
    "Выполните тут тот же код, что и в предыдущем пункте, но только уже с 4 слоями в сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:36:42.846983600Z",
     "start_time": "2024-02-22T20:36:42.841670100Z"
    }
   },
   "outputs": [],
   "source": [
    "init_vars = [5e-3, 1e-2, 1e-1, 'Kaiming', 'Xavier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:36:42.851987Z",
     "start_time": "2024-02-22T20:36:42.844184Z"
    }
   },
   "outputs": [],
   "source": [
    "accs_train = np.zeros((5, 5))\n",
    "accs_test = np.zeros((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:37:01.606926100Z",
     "start_time": "2024-02-22T20:36:42.847984900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0\tj=0\tinitialization=0.005\n",
      "Mean abs grad value: 9.559657817249505e-06\tMax abs grad value: 0.006458617202591516\n",
      "Loss = 2.302585229058628\n",
      "Mean abs grad value: 6.707701275360539e-05\tMax abs grad value: 0.05155114520628095\n",
      "Loss = 2.3393123177987616\n",
      "Mean abs grad value: 9.435237731257514e-07\tMax abs grad value: 0.00015939585638346658\n",
      "Loss = 2.301851735437856\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 8.31643443694366e-07\tMax abs grad value: 1.3748192284922854e-05\n",
      "Loss = 2.3018512958430275\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 8.737029677500763e-07\tMax abs grad value: 3.2533876979763896e-05\n",
      "Loss = 2.3018511384890004\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 1.6171523908760934e-06\tMax abs grad value: 0.0003197167073984718\n",
      "Loss = 2.301849737706458\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 3.2452064693973245e-06\tMax abs grad value: 0.0004603266431600277\n",
      "Loss = 2.301847454854146\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 1.33258658913466e-05\tMax abs grad value: 0.0023925237658293016\n",
      "Loss = 2.301828739163247\n",
      "Mean abs grad value: 0.00010951123720383573\tMax abs grad value: 0.004754919850413852\n",
      "Loss = 2.301869997306136\n",
      "Mean abs grad value: 2.5759717481420174e-05\tMax abs grad value: 0.003871549304155095\n",
      "Loss = 2.3018310963789923\n",
      "Mean abs grad value: 1.806858094024575e-05\tMax abs grad value: 0.003008060621948637\n",
      "Loss = 2.3018260938108175\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 5.244559696399738e-05\tMax abs grad value: 0.00532511707055621\n",
      "Loss = 2.301794894195269\n",
      "Mean abs grad value: 0.0006322469877226444\tMax abs grad value: 0.026325040682203774\n",
      "Loss = 2.3006381618141067\n",
      "Mean abs grad value: 0.07521874400159506\tMax abs grad value: 5.323642497761548\n",
      "Loss = 4.205006236956173\n",
      "Mean abs grad value: 0.0019333577551199999\tMax abs grad value: 0.07954497716023018\n",
      "Loss = 2.300721066029256\n",
      "Mean abs grad value: 0.0011985519732078626\tMax abs grad value: 0.05024501286572973\n",
      "Loss = 2.299885322772765\n",
      "Mean abs grad value: 0.0013268744573081285\tMax abs grad value: 0.055378779848814175\n",
      "Loss = 2.2998645667218915\n",
      "Train accuracy: 0.099\t\tTest accuracy: 0.107\n",
      "Mean abs grad value: 0.45256224139842144\tMax abs grad value: 28.10169154961228\n",
      "Loss = 25.98972037478214\n",
      "Mean abs grad value: 0.0032123196441100755\tMax abs grad value: 0.15346778549216802\n",
      "Loss = 2.3069935542344315\n",
      "Mean abs grad value: 0.0013553211035312234\tMax abs grad value: 0.056528329704127966\n",
      "Loss = 2.2998632531026715\n",
      "Train accuracy: 0.099\t\tTest accuracy: 0.107\n",
      "Mean abs grad value: 0.0016363033052987205\tMax abs grad value: 0.06780083419393437\n",
      "Loss = 2.298661435572147\n",
      "Mean abs grad value: 0.002987942546323199\tMax abs grad value: 0.11838910810539578\n",
      "Loss = 2.2936244533886785\n",
      "Mean abs grad value: 0.022455884432808985\tMax abs grad value: 0.9565727387718213\n",
      "Loss = 2.3463340979751695\n",
      "Mean abs grad value: 0.005907292316699817\tMax abs grad value: 0.22614674867959417\n",
      "Loss = 2.287554818122685\n",
      "Mean abs grad value: 0.008949356621863545\tMax abs grad value: 0.33183517407247015\n",
      "Loss = 2.2865113740632017\n",
      "Train accuracy: 0.171\t\tTest accuracy: 0.160\n",
      "Mean abs grad value: nan\tMax abs grad value: nan\n",
      "Loss = 655.3013239335854\n",
      "Mean abs grad value: 0.008949356621863545\tMax abs grad value: 0.33183517407247015\n",
      "Loss = 2.2865113740632017\n",
      "Train accuracy: 0.171\t\tTest accuracy: 0.160\n",
      "i=0\tj=1\tinitialization=0.005\n",
      "Mean abs grad value: 1.0027355918952552e-05\tMax abs grad value: 0.00645907865684476\n",
      "Loss = 2.3025853156520713\n",
      "Mean abs grad value: 6.780909175636713e-05\tMax abs grad value: 0.05165831413432402\n",
      "Loss = 2.3393755790670534\n",
      "Mean abs grad value: 1.4138114616817051e-06\tMax abs grad value: 0.00048754802693298967\n",
      "Loss = 2.301851380415278\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 1.1619093417818624e-06\tMax abs grad value: 0.00012084644353732177\n",
      "Loss = 2.301850727435506\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 1.2605503843588733e-06\tMax abs grad value: 0.00015988352941333784\n",
      "Loss = 2.3018505201941415\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 1.3686699917731484e-06\tMax abs grad value: 5.943520628102537e-05\n",
      "Loss = 2.3018498085669874\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:29: RuntimeWarning: overflow encountered in exp\n",
      "  exp_arr = np.exp(self.input)\n",
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:34: RuntimeWarning: invalid value encountered in multiply\n",
      "  d_loss_d_x = grad_output - exp_arr * (grad_output_sum / exp_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean abs grad value: 3.30452644939177e-06\tMax abs grad value: 0.0016256489732838773\n",
      "Loss = 2.301844375210257\n",
      "Mean abs grad value: 1.4573674194605569e-05\tMax abs grad value: 0.0016999789875765837\n",
      "Loss = 2.3017983185561572\n",
      "Mean abs grad value: 0.00018879146244256065\tMax abs grad value: 0.00774331360041191\n",
      "Loss = 2.3006171040924888\n",
      "Mean abs grad value: 0.007273866968831777\tMax abs grad value: 0.23396652131724693\n",
      "Loss = 2.273802491991419\n",
      "Mean abs grad value: 0.0002801199931359256\tMax abs grad value: 0.008772510314238126\n",
      "Loss = 2.2998311259377378\n",
      "Mean abs grad value: 0.003636966602999687\tMax abs grad value: 0.10076918017668701\n",
      "Loss = 2.266206877447296\n",
      "Mean abs grad value: 0.004759376873425353\tMax abs grad value: 0.13572181873653666\n",
      "Loss = 2.263490583330033\n",
      "Train accuracy: 0.107\t\tTest accuracy: 0.089\n",
      "Mean abs grad value: 0.0021958407410861275\tMax abs grad value: 0.0766620717855724\n",
      "Loss = 2.2772332901930636\n",
      "Mean abs grad value: 0.004659186957316357\tMax abs grad value: 0.13176007687622665\n",
      "Loss = 2.2634762590714788\n",
      "Train accuracy: 0.107\t\tTest accuracy: 0.089\n",
      "Mean abs grad value: 0.672901085253908\tMax abs grad value: 24.788116796906216\n",
      "Loss = 22.924793690553713\n",
      "Mean abs grad value: 0.0051493988637164746\tMax abs grad value: 0.14561153348248246\n",
      "Loss = 2.2540617367995073\n",
      "Train accuracy: 0.107\t\tTest accuracy: 0.082\n",
      "Mean abs grad value: 0.008878592009801387\tMax abs grad value: 0.3096122963110243\n",
      "Loss = 2.20177562676157\n",
      "Mean abs grad value: 0.09261102993129237\tMax abs grad value: 5.5385446170376476\n",
      "Loss = 3.4929662060210873\n",
      "Mean abs grad value: 0.010795227180744516\tMax abs grad value: 0.4326855468148122\n",
      "Loss = 2.1869768143760058\n",
      "Train accuracy: 0.153\t\tTest accuracy: 0.127\n",
      "Mean abs grad value: 0.3646939391380588\tMax abs grad value: 20.846238524933785\n",
      "Loss = 12.841811074361493\n",
      "Mean abs grad value: 0.01372152576860331\tMax abs grad value: 0.6332091284818179\n",
      "Loss = 2.171563585581231\n",
      "Train accuracy: 0.223\t\tTest accuracy: 0.189\n",
      "Mean abs grad value: 0.014553042432250725\tMax abs grad value: 0.8424314734322839\n",
      "Loss = 2.0869643234828295\n",
      "Train accuracy: 0.245\t\tTest accuracy: 0.216\n",
      "Mean abs grad value: 0.11994868002614319\tMax abs grad value: 10.56290662741526\n",
      "Loss = 7.18240674926977\n",
      "Mean abs grad value: 0.014786406649661795\tMax abs grad value: 0.9784828757481512\n",
      "Loss = 2.004565891123918\n",
      "Train accuracy: 0.245\t\tTest accuracy: 0.240\n",
      "Mean abs grad value: 0.02952831537928816\tMax abs grad value: 2.096021712399038\n",
      "Loss = 2.3484955710756443\n",
      "Mean abs grad value: 0.010831544870861503\tMax abs grad value: 0.5056300511658895\n",
      "Loss = 1.91122094635345\n",
      "Train accuracy: 0.275\t\tTest accuracy: 0.267\n",
      "Mean abs grad value: 0.008860569612182118\tMax abs grad value: 0.28584347243542424\n",
      "Loss = 1.8016537151905274\n",
      "Train accuracy: 0.373\t\tTest accuracy: 0.349\n",
      "Mean abs grad value: 0.02079861353714546\tMax abs grad value: 1.125215363353782\n",
      "Loss = 1.7071891592501385\n",
      "Train accuracy: 0.358\t\tTest accuracy: 0.356\n",
      "Mean abs grad value: 0.007140539696297062\tMax abs grad value: 0.3609065289536683\n",
      "Loss = 1.604573789872002\n",
      "Train accuracy: 0.431\t\tTest accuracy: 0.440\n",
      "Mean abs grad value: 0.008280036443316336\tMax abs grad value: 0.34377166060913456\n",
      "Loss = 1.5484242975115683\n",
      "Train accuracy: 0.448\t\tTest accuracy: 0.451\n",
      "Mean abs grad value: 0.019494362329556952\tMax abs grad value: 1.1071855243761934\n",
      "Loss = 1.5195536665485367\n",
      "Mean abs grad value: 0.009726221297088307\tMax abs grad value: 0.3275544471825407\n",
      "Loss = 1.4399116732760138\n",
      "Train accuracy: 0.526\t\tTest accuracy: 0.509\n",
      "Mean abs grad value: 0.030327525979479436\tMax abs grad value: 2.143458102009713\n",
      "Loss = 1.554514287965732\n",
      "Mean abs grad value: 0.009461686986735182\tMax abs grad value: 0.5861506556099583\n",
      "Loss = 1.3525037594573468\n",
      "Train accuracy: 0.517\t\tTest accuracy: 0.502\n",
      "Mean abs grad value: 0.007473985573880265\tMax abs grad value: 0.40749877926199324\n",
      "Loss = 1.2541848674906044\n",
      "Train accuracy: 0.581\t\tTest accuracy: 0.569\n",
      "Mean abs grad value: 0.02166374385204763\tMax abs grad value: 1.0660869742969032\n",
      "Loss = 1.2058218482624987\n",
      "Train accuracy: 0.594\t\tTest accuracy: 0.580\n",
      "Mean abs grad value: 0.008094345884879584\tMax abs grad value: 0.4177010432459074\n",
      "Loss = 1.0927547689232338\n",
      "Train accuracy: 0.660\t\tTest accuracy: 0.642\n",
      "Mean abs grad value: 0.007490140385048578\tMax abs grad value: 0.297018271542679\n",
      "Loss = 1.0282118057530014\n",
      "Train accuracy: 0.653\t\tTest accuracy: 0.638\n",
      "Mean abs grad value: 0.011409762757260602\tMax abs grad value: 0.5242008613593057\n",
      "Loss = 0.95626068540009\n",
      "Train accuracy: 0.667\t\tTest accuracy: 0.647\n",
      "Mean abs grad value: 0.014210741238565727\tMax abs grad value: 0.5237539131041826\n",
      "Loss = 0.9052720596150498\n",
      "Train accuracy: 0.714\t\tTest accuracy: 0.673\n",
      "Mean abs grad value: 0.006102115164117028\tMax abs grad value: 0.3026946842754367\n",
      "Loss = 0.8492059754383529\n",
      "Train accuracy: 0.736\t\tTest accuracy: 0.702\n",
      "Mean abs grad value: 0.006195206705375022\tMax abs grad value: 0.23485170863903773\n",
      "Loss = 0.8263921295852252\n",
      "Train accuracy: 0.742\t\tTest accuracy: 0.709\n",
      "Mean abs grad value: 0.008931426018963797\tMax abs grad value: 0.23838032999422548\n",
      "Loss = 0.7768548186794717\n",
      "Train accuracy: 0.754\t\tTest accuracy: 0.713\n",
      "Mean abs grad value: 0.007264775414425576\tMax abs grad value: 0.2395089709288669\n",
      "Loss = 0.7438429794515656\n",
      "Train accuracy: 0.760\t\tTest accuracy: 0.713\n",
      "Mean abs grad value: 0.005786158141181805\tMax abs grad value: 0.25475164584397747\n",
      "Loss = 0.7146639834950257\n",
      "Train accuracy: 0.772\t\tTest accuracy: 0.722\n",
      "Mean abs grad value: 0.004959864512388321\tMax abs grad value: 0.18588499647684595\n",
      "Loss = 0.6753899624695159\n",
      "Train accuracy: 0.788\t\tTest accuracy: 0.733\n",
      "Mean abs grad value: 0.010654578914367788\tMax abs grad value: 0.3919752319396605\n",
      "Loss = 0.6364898744619377\n",
      "Train accuracy: 0.799\t\tTest accuracy: 0.742\n",
      "Mean abs grad value: 0.004820940680275154\tMax abs grad value: 0.1039323978427481\n",
      "Loss = 0.605577972514496\n",
      "Train accuracy: 0.813\t\tTest accuracy: 0.758\n",
      "Mean abs grad value: 0.004824245471831285\tMax abs grad value: 0.14547752188000182\n",
      "Loss = 0.5919447211290334\n",
      "Train accuracy: 0.811\t\tTest accuracy: 0.776\n",
      "Mean abs grad value: 0.005636807619342336\tMax abs grad value: 0.17434225168381037\n",
      "Loss = 0.5671590917293876\n",
      "Train accuracy: 0.810\t\tTest accuracy: 0.789\n",
      "Mean abs grad value: 0.005504981486612902\tMax abs grad value: 0.14936367835758088\n",
      "Loss = 0.5349711476088194\n",
      "Train accuracy: 0.822\t\tTest accuracy: 0.798\n",
      "Mean abs grad value: 0.012086044466281134\tMax abs grad value: 0.343655694199391\n",
      "Loss = 0.48985629672495273\n",
      "Train accuracy: 0.839\t\tTest accuracy: 0.818\n",
      "Mean abs grad value: 0.008898491108683543\tMax abs grad value: 0.22675613954982282\n",
      "Loss = 0.45870263369786723\n",
      "Train accuracy: 0.848\t\tTest accuracy: 0.818\n",
      "Mean abs grad value: 0.004682998772537299\tMax abs grad value: 0.1819762218738252\n",
      "Loss = 0.4387887250892982\n",
      "Train accuracy: 0.869\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.003602538026633669\tMax abs grad value: 0.09658058197580552\n",
      "Loss = 0.42259882592605463\n",
      "Train accuracy: 0.880\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.00403370938762439\tMax abs grad value: 0.10183599665000768\n",
      "Loss = 0.4048585457288646\n",
      "Train accuracy: 0.883\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.004234828085752471\tMax abs grad value: 0.14243397667487337\n",
      "Loss = 0.38145947504629896\n",
      "Train accuracy: 0.886\t\tTest accuracy: 0.860\n",
      "Mean abs grad value: 0.0038917987282837316\tMax abs grad value: 0.09674946781863031\n",
      "Loss = 0.35482485883692105\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.869\n",
      "Mean abs grad value: 0.005574423723542796\tMax abs grad value: 0.29058084087300495\n",
      "Loss = 0.3378280100522399\n",
      "Train accuracy: 0.901\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.003931126219437932\tMax abs grad value: 0.10230064785379667\n",
      "Loss = 0.3253952387220747\n",
      "Train accuracy: 0.901\t\tTest accuracy: 0.873\n",
      "Mean abs grad value: 0.0029621780835738538\tMax abs grad value: 0.06881280489134062\n",
      "Loss = 0.31938342824480487\n",
      "Train accuracy: 0.905\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.0030836134870181127\tMax abs grad value: 0.11155851622962273\n",
      "Loss = 0.30315933359101366\n",
      "Train accuracy: 0.907\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.0039956174566499695\tMax abs grad value: 0.09739084309765177\n",
      "Loss = 0.27981382032633606\n",
      "Train accuracy: 0.920\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.00878770968428756\tMax abs grad value: 0.17446179029554404\n",
      "Loss = 0.260431627809306\n",
      "Train accuracy: 0.918\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.010293044676910298\tMax abs grad value: 0.2647036633185149\n",
      "Loss = 0.2561992470193064\n",
      "Train accuracy: 0.913\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.0029609687348533557\tMax abs grad value: 0.07823471217570106\n",
      "Loss = 0.23719964061056695\n",
      "Train accuracy: 0.926\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.002437520290016885\tMax abs grad value: 0.06933381282902897\n",
      "Loss = 0.23203836054617002\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.898\n",
      "Mean abs grad value: 0.003293193084674372\tMax abs grad value: 0.09358371969286626\n",
      "Loss = 0.21888031696441507\n",
      "Train accuracy: 0.930\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.003942856941639673\tMax abs grad value: 0.17602156887479808\n",
      "Loss = 0.20577209843936484\n",
      "Train accuracy: 0.934\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.002778773054313496\tMax abs grad value: 0.06879741907251767\n",
      "Loss = 0.19295267008061037\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0029836807214057215\tMax abs grad value: 0.10121819241326022\n",
      "Loss = 0.18606928443814866\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0022586006093781694\tMax abs grad value: 0.0741389709885747\n",
      "Loss = 0.17898875878150933\n",
      "Train accuracy: 0.946\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002317744534444127\tMax abs grad value: 0.061817794981934536\n",
      "Loss = 0.16952931906681493\n",
      "Train accuracy: 0.950\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0027780694770180164\tMax abs grad value: 0.16403813226472258\n",
      "Loss = 0.15668052377661057\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.006276508431805314\tMax abs grad value: 0.2417405508717146\n",
      "Loss = 0.1541096592817306\n",
      "Mean abs grad value: 0.00316891110784466\tMax abs grad value: 0.1132284310407732\n",
      "Loss = 0.14952505721167111\n",
      "Train accuracy: 0.956\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0022818001873226184\tMax abs grad value: 0.07287530184571558\n",
      "Loss = 0.14324128782050063\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0020720702592415523\tMax abs grad value: 0.06066843999262552\n",
      "Loss = 0.13665375589763928\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0036178285337707863\tMax abs grad value: 0.08949742802164815\n",
      "Loss = 0.1270247813558577\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0019618943160082504\tMax abs grad value: 0.04934997037844805\n",
      "Loss = 0.11698068808057649\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0018815964951872498\tMax abs grad value: 0.04445638097893025\n",
      "Loss = 0.10986626424000483\n",
      "Train accuracy: 0.965\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002342730473181729\tMax abs grad value: 0.08295082027526589\n",
      "Loss = 0.10355237210414135\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.001636147909728201\tMax abs grad value: 0.052787728692303054\n",
      "Loss = 0.09952152830345946\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0016570945993334006\tMax abs grad value: 0.05346054107585108\n",
      "Loss = 0.09537704241684725\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.002117458341640471\tMax abs grad value: 0.06827858320605822\n",
      "Loss = 0.08846970393645652\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0025576313619808263\tMax abs grad value: 0.06919756810129438\n",
      "Loss = 0.08420665439584969\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0014764974542427996\tMax abs grad value: 0.06055497916971432\n",
      "Loss = 0.07980622639587068\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0015202529122112333\tMax abs grad value: 0.06664751127813094\n",
      "Loss = 0.07578768783815085\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0019316595443194765\tMax abs grad value: 0.08472706321412965\n",
      "Loss = 0.0716874301003228\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.002816440174546229\tMax abs grad value: 0.09050607590864546\n",
      "Loss = 0.0679988108989922\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0014830006517964577\tMax abs grad value: 0.039091686252758946\n",
      "Loss = 0.06464418317273432\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0012400392771888895\tMax abs grad value: 0.031405575310455035\n",
      "Loss = 0.06320902529393799\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.001433231650718737\tMax abs grad value: 0.03674634679246014\n",
      "Loss = 0.060414369088041556\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.001485742738744611\tMax abs grad value: 0.04552705053535014\n",
      "Loss = 0.05578750357347607\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.003971064347695507\tMax abs grad value: 0.12495589963469507\n",
      "Loss = 0.057085875962206684\n",
      "Mean abs grad value: 0.0017338688236345234\tMax abs grad value: 0.0558673302632829\n",
      "Loss = 0.05337398297175074\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0010260743794503814\tMax abs grad value: 0.026966977592970023\n",
      "Loss = 0.0517757768049087\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0009336709437120236\tMax abs grad value: 0.023880175824164036\n",
      "Loss = 0.05027964337595174\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0017308057276293302\tMax abs grad value: 0.052417557689041855\n",
      "Loss = 0.048386484954179854\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0014917271534124804\tMax abs grad value: 0.05589803471755956\n",
      "Loss = 0.04676687185628182\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0012021061237208214\tMax abs grad value: 0.0314136738109337\n",
      "Loss = 0.041392975872312956\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0012102995487061686\tMax abs grad value: 0.043295694727392635\n",
      "Loss = 0.03903600953590599\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.001976294309321709\tMax abs grad value: 0.067861423844574\n",
      "Loss = 0.037137780795439675\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001264983563458887\tMax abs grad value: 0.03670179475536192\n",
      "Loss = 0.03498472269054242\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0010290337949852046\tMax abs grad value: 0.023546745588421163\n",
      "Loss = 0.03318551706990312\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0014874740809529689\tMax abs grad value: 0.038070109955047296\n",
      "Loss = 0.03123999877783101\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001191592738738872\tMax abs grad value: 0.039953581352243736\n",
      "Loss = 0.029705469999574463\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0007605850774250152\tMax abs grad value: 0.018902362214726368\n",
      "Loss = 0.027911977697883908\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0010214072502340997\tMax abs grad value: 0.026785016660736866\n",
      "Loss = 0.026554581517181354\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002300724505101162\tMax abs grad value: 0.0852513897982808\n",
      "Loss = 0.02611717582185322\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0010388287484050776\tMax abs grad value: 0.04293914756080231\n",
      "Loss = 0.02454124742066785\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0006998153184939009\tMax abs grad value: 0.01927099825550578\n",
      "Loss = 0.02377704785483587\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0010138968121149118\tMax abs grad value: 0.030595436474308697\n",
      "Loss = 0.02278284505694465\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.001139905701795769\tMax abs grad value: 0.03250968142166403\n",
      "Loss = 0.020949036291749774\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.003674856031136028\tMax abs grad value: 0.12197174959049334\n",
      "Loss = 0.022167274747382906\n",
      "Mean abs grad value: 0.0016804793315573032\tMax abs grad value: 0.05775682181900863\n",
      "Loss = 0.019746676714039874\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0009853570140613184\tMax abs grad value: 0.027927576761499037\n",
      "Loss = 0.018203543543898203\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0006419405438858324\tMax abs grad value: 0.011762003404803135\n",
      "Loss = 0.017139571687481824\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0007048176885446978\tMax abs grad value: 0.0200986486163311\n",
      "Loss = 0.015673048199128903\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0009369281689272521\tMax abs grad value: 0.02595936343550854\n",
      "Loss = 0.014163871961708298\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0020813044728617783\tMax abs grad value: 0.05369308035103062\n",
      "Loss = 0.013993546174077458\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0008086184838413503\tMax abs grad value: 0.025327012074636016\n",
      "Loss = 0.012099724723802928\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0005863692047391986\tMax abs grad value: 0.012552000008151805\n",
      "Loss = 0.011429655006360631\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.000639281147344371\tMax abs grad value: 0.013514066636482254\n",
      "Loss = 0.01071876318948815\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0010822674997704482\tMax abs grad value: 0.031644407025504855\n",
      "Loss = 0.0093207056887265\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0008030792477883702\tMax abs grad value: 0.03091008969545341\n",
      "Loss = 0.008164551286889718\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0007174057265024496\tMax abs grad value: 0.017778768283619323\n",
      "Loss = 0.0071313353672212716\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0006649638175198074\tMax abs grad value: 0.02141680384022215\n",
      "Loss = 0.006374322449667537\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0005151703061671054\tMax abs grad value: 0.01471006500675165\n",
      "Loss = 0.005374247613789848\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.001608027483303505\tMax abs grad value: 0.03938829883217645\n",
      "Loss = 0.004613432782583416\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0005069595320165614\tMax abs grad value: 0.014100591205342784\n",
      "Loss = 0.0036834889091337487\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00033163362837819406\tMax abs grad value: 0.009015536726373561\n",
      "Loss = 0.003459321219380413\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0002772731703847932\tMax abs grad value: 0.005145471514093288\n",
      "Loss = 0.002983085585456991\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0002963207011763957\tMax abs grad value: 0.009022720558758841\n",
      "Loss = 0.002440763267708271\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0004931325422831746\tMax abs grad value: 0.011976074963162695\n",
      "Loss = 0.0023444230140259614\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.00018738070948246734\tMax abs grad value: 0.004408500740716\n",
      "Loss = 0.0020335878114163303\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0001454779750667356\tMax abs grad value: 0.003926192984638958\n",
      "Loss = 0.0018950144196558094\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.00016528794098192648\tMax abs grad value: 0.00616839087008996\n",
      "Loss = 0.0016595559161214305\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0005015529612055367\tMax abs grad value: 0.02668111095590127\n",
      "Loss = 0.0016442886836223758\n",
      "Mean abs grad value: 0.00026651154728076534\tMax abs grad value: 0.01274414799431865\n",
      "Loss = 0.0015272979374430478\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.00019369012429167637\tMax abs grad value: 0.00640170779458073\n",
      "Loss = 0.0013450103805908741\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.00013604172612473003\tMax abs grad value: 0.004781307779403427\n",
      "Loss = 0.0011457541868881691\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0002494500304422354\tMax abs grad value: 0.008942415291793408\n",
      "Loss = 0.0009793188732360465\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00010774482736618671\tMax abs grad value: 0.005064026604649065\n",
      "Loss = 0.0008191017772512986\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00011833430981863946\tMax abs grad value: 0.003954241804726099\n",
      "Loss = 0.0007422692123007286\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.00011409781939762368\tMax abs grad value: 0.002782996142299508\n",
      "Loss = 0.0006154198151102846\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.00013408258801974763\tMax abs grad value: 0.0035561325036302\n",
      "Loss = 0.0004612129288290593\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0001850772328549363\tMax abs grad value: 0.005416405818348129\n",
      "Loss = 0.0004350141546691291\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 4.9532141271763404e-05\tMax abs grad value: 0.001064508918660888\n",
      "Loss = 0.00036816299004765443\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 4.105718637680016e-05\tMax abs grad value: 0.0007328608704472308\n",
      "Loss = 0.0003531697165160373\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 5.335039302517621e-05\tMax abs grad value: 0.0011782338881434005\n",
      "Loss = 0.00030118141337023786\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 5.5333528365814974e-05\tMax abs grad value: 0.001128256801624692\n",
      "Loss = 0.0002522584043976194\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0001306712221924309\tMax abs grad value: 0.00460304112299929\n",
      "Loss = 0.00022303219123095467\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 4.90942221805753e-05\tMax abs grad value: 0.001010448842313251\n",
      "Loss = 0.00016283273649999965\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 3.4980939696028077e-05\tMax abs grad value: 0.0009013396197557608\n",
      "Loss = 0.00013946671292639436\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 2.6621785305308213e-05\tMax abs grad value: 0.0007595180955368055\n",
      "Loss = 9.835666373824692e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 5.253208566413579e-05\tMax abs grad value: 0.0017718643417532051\n",
      "Loss = 7.953514171504339e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 2.2564590095615895e-05\tMax abs grad value: 0.0005559963313634486\n",
      "Loss = 6.185719910757398e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 1.5248122348331294e-05\tMax abs grad value: 0.000522773661492223\n",
      "Loss = 5.350428786130662e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 1.0645290697477026e-05\tMax abs grad value: 0.00027980149111825797\n",
      "Loss = 4.5475308711959744e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 1.1427692031129391e-05\tMax abs grad value: 0.0003616009171290423\n",
      "Loss = 3.796440918485036e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 1.086983077484304e-05\tMax abs grad value: 0.0003254927270927132\n",
      "Loss = 2.93239250034849e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 7.5262406485249835e-06\tMax abs grad value: 0.0002713624293939918\n",
      "Loss = 1.9844261480460224e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 5.88415711636964e-06\tMax abs grad value: 0.0001374703654674026\n",
      "Loss = 1.454867215924518e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 2.4359984647390375e-06\tMax abs grad value: 6.486531021270632e-05\n",
      "Loss = 1.0595561389592723e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 2.49485562423454e-06\tMax abs grad value: 5.132082042390618e-05\n",
      "Loss = 8.180131095598171e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 2.579297688138687e-06\tMax abs grad value: 6.963664770141564e-05\n",
      "Loss = 5.924375366719943e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 2.6205805326178754e-06\tMax abs grad value: 7.357416969752744e-05\n",
      "Loss = 4.261029292980811e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 1.3718694965765212e-06\tMax abs grad value: 3.487963911833863e-05\n",
      "Loss = 3.194229552966361e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 8.343301147935363e-07\tMax abs grad value: 1.5394293978306398e-05\n",
      "Loss = 2.7254543458475144e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 6.567546657961372e-07\tMax abs grad value: 1.5147361374379195e-05\n",
      "Loss = 2.2018061165784553e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 6.026111267947311e-07\tMax abs grad value: 1.4691162751110158e-05\n",
      "Loss = 1.5650215339740577e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 7.269648709864104e-07\tMax abs grad value: 3.018995615239032e-05\n",
      "Loss = 9.427427213891157e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 4.634988592923237e-07\tMax abs grad value: 1.2870782028582349e-05\n",
      "Loss = 6.353177628808903e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 1.8169091059987747e-07\tMax abs grad value: 3.314032179056577e-06\n",
      "Loss = 4.848422176444765e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "i=0\tj=2\tinitialization=0.005\n",
      "Mean abs grad value: 9.594249231774638e-06\tMax abs grad value: 0.0064587745626978445\n",
      "Loss = 2.3025851509341027\n",
      "Mean abs grad value: 7.257855624595318e-05\tMax abs grad value: 0.051263691255776865\n",
      "Loss = 2.3389455776448584\n",
      "Mean abs grad value: 8.004126395804855e-07\tMax abs grad value: 0.00023597397944851524\n",
      "Loss = 2.3018515809584517\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 6.167742119920472e-07\tMax abs grad value: 1.5301223981386404e-05\n",
      "Loss = 2.301851145233548\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 6.337540736392819e-07\tMax abs grad value: 3.093454966493638e-05\n",
      "Loss = 2.301851061928001\n",
      "Mean abs grad value: 7.303153712767583e-07\tMax abs grad value: 4.419860364280809e-05\n",
      "Loss = 2.301850768962876\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 1.7435095158458674e-06\tMax abs grad value: 0.00025479569357783513\n",
      "Loss = 2.3018484826261125\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 1.662261508416647e-05\tMax abs grad value: 0.00283720191700897\n",
      "Loss = 2.3018114211208585\n",
      "Mean abs grad value: 0.00032997464606441125\tMax abs grad value: 0.059758622164209386\n",
      "Loss = 2.3006506328417298\n",
      "Mean abs grad value: 0.15448324369590435\tMax abs grad value: 23.054376128567302\n",
      "Loss = 11.557932824599757\n",
      "Mean abs grad value: 0.0009652699664533074\tMax abs grad value: 0.16585600955644164\n",
      "Loss = 2.3049082415395548\n",
      "Mean abs grad value: 0.00037400772353482525\tMax abs grad value: 0.06863480817540205\n",
      "Loss = 2.3006177479189778\n",
      "Train accuracy: 0.099\t\tTest accuracy: 0.098\n",
      "Mean abs grad value: nan\tMax abs grad value: nan\n",
      "Loss = 462609.0030233228\n",
      "Mean abs grad value: 0.00037400772353482525\tMax abs grad value: 0.06863480817540205\n",
      "Loss = 2.3006177479189778\n",
      "Train accuracy: 0.099\t\tTest accuracy: 0.098\n",
      "i=0\tj=3\tinitialization=0.005\n",
      "Mean abs grad value: 8.856414371036346e-06\tMax abs grad value: 0.006458736990240014\n",
      "Loss = 2.302584995192936\n",
      "Mean abs grad value: 6.635834469186341e-05\tMax abs grad value: 0.051609905792877546\n",
      "Loss = 2.3396526190353923\n",
      "Mean abs grad value: 9.032425149738141e-07\tMax abs grad value: 0.00045909753284517044\n",
      "Loss = 2.301851449890759\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 6.647799615029517e-07\tMax abs grad value: 1.0948255933934613e-05\n",
      "Loss = 2.3018511268476716\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 6.753498458015998e-07\tMax abs grad value: 1.5293318645548292e-05\n",
      "Loss = 2.3018510377367862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:29: RuntimeWarning: overflow encountered in exp\n",
      "  exp_arr = np.exp(self.input)\n",
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:34: RuntimeWarning: invalid value encountered in multiply\n",
      "  d_loss_d_x = grad_output - exp_arr * (grad_output_sum / exp_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean abs grad value: 9.076152779887153e-07\tMax abs grad value: 0.00032709831287917516\n",
      "Loss = 2.3018507194467026\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 4.0757791114890575e-06\tMax abs grad value: 0.0013599196640242527\n",
      "Loss = 2.3018497531028403\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 6.933354176461705e-06\tMax abs grad value: 0.0010538634224663789\n",
      "Loss = 2.301838893577546\n",
      "Mean abs grad value: 3.1495516100027246e-05\tMax abs grad value: 0.0028410942477260157\n",
      "Loss = 2.301766212325883\n",
      "Mean abs grad value: 0.0004921261724252818\tMax abs grad value: 0.017636653951470564\n",
      "Loss = 2.3007652436813184\n",
      "Mean abs grad value: 0.0002855415089387471\tMax abs grad value: 0.010543941372862495\n",
      "Loss = 2.301050360693931\n",
      "Mean abs grad value: 0.0004759354346157594\tMax abs grad value: 0.017140072761970465\n",
      "Loss = 2.300763352247016\n",
      "Train accuracy: 0.105\t\tTest accuracy: 0.082\n",
      "Mean abs grad value: 1.1334515973300405\tMax abs grad value: 69.76569419906161\n",
      "Loss = 74.73495391591482\n",
      "Mean abs grad value: 0.0022641461284867498\tMax abs grad value: 0.08270059437273133\n",
      "Loss = 2.314917220080689\n",
      "Mean abs grad value: 0.0005399654809922143\tMax abs grad value: 0.01914293807786774\n",
      "Loss = 2.3007820298522317\n",
      "Mean abs grad value: 0.0004864650493058133\tMax abs grad value: 0.01750102001625194\n",
      "Loss = 2.3007620778054707\n",
      "Train accuracy: 0.105\t\tTest accuracy: 0.082\n",
      "Mean abs grad value: 0.0005231342257206525\tMax abs grad value: 0.019676393725735757\n",
      "Loss = 2.300587752416345\n",
      "Train accuracy: 0.105\t\tTest accuracy: 0.082\n",
      "Mean abs grad value: 0.0009337225502567347\tMax abs grad value: 0.027007006580105925\n",
      "Loss = 2.2988979076344003\n",
      "Train accuracy: 0.105\t\tTest accuracy: 0.082\n",
      "Mean abs grad value: 0.23410287374827646\tMax abs grad value: 11.474895217948484\n",
      "Loss = 16.379096325252192\n",
      "Mean abs grad value: 0.0013747104819976362\tMax abs grad value: 0.0471155440162463\n",
      "Loss = 2.2988421431965302\n",
      "Mean abs grad value: 0.001098580125431637\tMax abs grad value: 0.033202972372223256\n",
      "Loss = 2.2984986138498344\n",
      "Train accuracy: 0.105\t\tTest accuracy: 0.082\n",
      "Mean abs grad value: 0.00141231889335492\tMax abs grad value: 0.0415866900723226\n",
      "Loss = 2.2960997540510766\n",
      "Train accuracy: 0.105\t\tTest accuracy: 0.082\n",
      "Mean abs grad value: 0.0033809184312295413\tMax abs grad value: 0.10587823555929522\n",
      "Loss = 2.2771918463838143\n",
      "Train accuracy: 0.102\t\tTest accuracy: 0.100\n",
      "Mean abs grad value: nan\tMax abs grad value: nan\n",
      "Loss = 51519.80364643229\n",
      "Mean abs grad value: 0.0033809184312295413\tMax abs grad value: 0.10587823555929522\n",
      "Loss = 2.2771918463838143\n",
      "Train accuracy: 0.102\t\tTest accuracy: 0.100\n",
      "i=0\tj=4\tinitialization=0.005\n",
      "Mean abs grad value: 8.839856312432022e-06\tMax abs grad value: 0.006458786015029648\n",
      "Loss = 2.3025851285400347\n",
      "Mean abs grad value: 6.230002263629727e-05\tMax abs grad value: 0.05181077611897522\n",
      "Loss = 2.339823191225065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:29: RuntimeWarning: overflow encountered in exp\n",
      "  exp_arr = np.exp(self.input)\n",
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:34: RuntimeWarning: invalid value encountered in multiply\n",
      "  d_loss_d_x = grad_output - exp_arr * (grad_output_sum / exp_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean abs grad value: 1.0736588168730298e-06\tMax abs grad value: 0.0003798363227092243\n",
      "Loss = 2.301851703097367\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 7.188525943431556e-07\tMax abs grad value: 0.00011425148792694267\n",
      "Loss = 2.3018512595183793\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 6.890789520958799e-07\tMax abs grad value: 1.8615665539679463e-05\n",
      "Loss = 2.3018511900366394\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 7.278544169287938e-07\tMax abs grad value: 1.3965352818156524e-05\n",
      "Loss = 2.301851003900721\n",
      "Mean abs grad value: 8.702898727005102e-07\tMax abs grad value: 3.298094331224216e-05\n",
      "Loss = 2.301850343125683\n",
      "Mean abs grad value: 2.1298421742161724e-06\tMax abs grad value: 0.0011872229404805443\n",
      "Loss = 2.301848058575692\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 2.2376762692036514e-05\tMax abs grad value: 0.00164361524982382\n",
      "Loss = 2.3018462829674595\n",
      "Mean abs grad value: 1.0191681590200078e-05\tMax abs grad value: 0.0020728488788839044\n",
      "Loss = 2.3018398612214708\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 2.4612987770457646e-05\tMax abs grad value: 0.0013317979146860632\n",
      "Loss = 2.3018290616060297\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 0.08659893971278296\tMax abs grad value: 8.021223850626344\n",
      "Loss = 3.993838667001282\n",
      "Mean abs grad value: 0.0006148076761205679\tMax abs grad value: 0.04751863218877358\n",
      "Loss = 2.3017426431015595\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:29: RuntimeWarning: overflow encountered in exp\n",
      "  exp_arr = np.exp(self.input)\n",
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:34: RuntimeWarning: invalid value encountered in multiply\n",
      "  d_loss_d_x = grad_output - exp_arr * (grad_output_sum / exp_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean abs grad value: nan\tMax abs grad value: nan\n",
      "Loss = 748.8439061132777\n",
      "Mean abs grad value: 0.0006148076761205679\tMax abs grad value: 0.04751863218877358\n",
      "Loss = 2.3017426431015595\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "i=1\tj=0\tinitialization=0.01\n",
      "Mean abs grad value: 1.7468803652620965e-05\tMax abs grad value: 0.006457497909941056\n",
      "Loss = 2.302583770318755\n",
      "Mean abs grad value: 8.758583581395266e-05\tMax abs grad value: 0.05080082197159587\n",
      "Loss = 2.3382387619116405\n",
      "Mean abs grad value: 8.160543862878769e-06\tMax abs grad value: 0.0010289698877134913\n",
      "Loss = 2.3018385192303588\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 9.303822162649571e-06\tMax abs grad value: 0.0002680908930898375\n",
      "Loss = 2.301824381474925\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 1.2458436922967516e-05\tMax abs grad value: 0.0004879979640950969\n",
      "Loss = 2.301795723613363\n",
      "Mean abs grad value: 3.166274376314093e-05\tMax abs grad value: 0.0022475276201851476\n",
      "Loss = 2.301641134684508\n",
      "Mean abs grad value: 0.0002171389717208792\tMax abs grad value: 0.004696081767199876\n",
      "Loss = 2.299876818402642\n",
      "Mean abs grad value: 0.0043738354175897574\tMax abs grad value: 0.13958321393186904\n",
      "Loss = 2.258801095747333\n",
      "Mean abs grad value: 0.0005700368676020208\tMax abs grad value: 0.012539436378614691\n",
      "Loss = 2.2949616184968376\n",
      "Mean abs grad value: 0.0032356257219829233\tMax abs grad value: 0.09793013945040546\n",
      "Loss = 2.2578475687512203\n",
      "Train accuracy: 0.103\t\tTest accuracy: 0.096\n",
      "Mean abs grad value: 0.07532217615976926\tMax abs grad value: 7.583291707707305\n",
      "Loss = 4.748973788926904\n",
      "Mean abs grad value: 0.007150508606987518\tMax abs grad value: 0.1351336779416035\n",
      "Loss = 2.2416935740767414\n",
      "Train accuracy: 0.124\t\tTest accuracy: 0.113\n",
      "Mean abs grad value: 0.07519531423081025\tMax abs grad value: 2.4852072816183526\n",
      "Loss = 3.2557995515818883\n",
      "Mean abs grad value: 0.006419985869371468\tMax abs grad value: 0.15207487373567716\n",
      "Loss = 2.1268192716298024\n",
      "Train accuracy: 0.193\t\tTest accuracy: 0.164\n",
      "Mean abs grad value: 2.1141234735007677\tMax abs grad value: 80.07057505971024\n",
      "Loss = 266.91327303063105\n",
      "Mean abs grad value: 0.007163163323538169\tMax abs grad value: 0.3031398369804858\n",
      "Loss = 2.0924950543187424\n",
      "Train accuracy: 0.203\t\tTest accuracy: 0.178\n",
      "Mean abs grad value: 0.004804586496087261\tMax abs grad value: 0.16506936514402934\n",
      "Loss = 2.023630691967277\n",
      "Train accuracy: 0.252\t\tTest accuracy: 0.236\n",
      "Mean abs grad value: 0.006746544775497405\tMax abs grad value: 0.26825721587476514\n",
      "Loss = 1.9363006771337579\n",
      "Train accuracy: 0.263\t\tTest accuracy: 0.269\n",
      "Mean abs grad value: 0.005958259517073961\tMax abs grad value: 0.16009286621308483\n",
      "Loss = 1.796638576446518\n",
      "Train accuracy: 0.413\t\tTest accuracy: 0.418\n",
      "Mean abs grad value: 0.03907197457473181\tMax abs grad value: 3.7277473614984498\n",
      "Loss = 2.334393360293325\n",
      "Mean abs grad value: 0.010853140915916059\tMax abs grad value: 0.3266810563039711\n",
      "Loss = 1.551211992736946\n",
      "Train accuracy: 0.413\t\tTest accuracy: 0.418\n",
      "Mean abs grad value: 0.05508835080643228\tMax abs grad value: 3.4960560482798297\n",
      "Loss = 2.2760331159630915\n",
      "Mean abs grad value: 0.011423359218164756\tMax abs grad value: 0.6156063589828737\n",
      "Loss = 1.4452628950058404\n",
      "Train accuracy: 0.490\t\tTest accuracy: 0.484\n",
      "Mean abs grad value: 0.026246503098937685\tMax abs grad value: 1.1993106348790405\n",
      "Loss = 1.4613174572843526\n",
      "Mean abs grad value: 0.01142847307727698\tMax abs grad value: 0.5452955720889853\n",
      "Loss = 1.322670244353567\n",
      "Train accuracy: 0.537\t\tTest accuracy: 0.518\n",
      "Mean abs grad value: 0.019756867693706773\tMax abs grad value: 0.8679209423726338\n",
      "Loss = 1.2663174126199133\n",
      "Train accuracy: 0.529\t\tTest accuracy: 0.513\n",
      "Mean abs grad value: 0.007982388880656282\tMax abs grad value: 0.3603967170557823\n",
      "Loss = 1.1845048203884851\n",
      "Train accuracy: 0.616\t\tTest accuracy: 0.611\n",
      "Mean abs grad value: 0.006432472678566861\tMax abs grad value: 0.16240337539525201\n",
      "Loss = 1.1411270705641507\n",
      "Train accuracy: 0.636\t\tTest accuracy: 0.622\n",
      "Mean abs grad value: 0.01219976965401014\tMax abs grad value: 0.4936133816824339\n",
      "Loss = 1.0714836980882216\n",
      "Train accuracy: 0.617\t\tTest accuracy: 0.600\n",
      "Mean abs grad value: 0.017587391506847027\tMax abs grad value: 0.9118431718893873\n",
      "Loss = 1.0479543788276184\n",
      "Train accuracy: 0.607\t\tTest accuracy: 0.607\n",
      "Mean abs grad value: 0.006588450426005638\tMax abs grad value: 0.34961959142245724\n",
      "Loss = 0.9879086857676826\n",
      "Train accuracy: 0.637\t\tTest accuracy: 0.631\n",
      "Mean abs grad value: 0.006123493470930987\tMax abs grad value: 0.18480514454684008\n",
      "Loss = 0.9689713226187627\n",
      "Train accuracy: 0.641\t\tTest accuracy: 0.620\n",
      "Mean abs grad value: 0.007285341567690335\tMax abs grad value: 0.3791668776914458\n",
      "Loss = 0.9329621002447349\n",
      "Train accuracy: 0.644\t\tTest accuracy: 0.640\n",
      "Mean abs grad value: 0.00849141655279703\tMax abs grad value: 0.27952898973647083\n",
      "Loss = 0.8640508080060906\n",
      "Train accuracy: 0.676\t\tTest accuracy: 0.662\n",
      "Mean abs grad value: 0.011046076627164824\tMax abs grad value: 0.3994964186772614\n",
      "Loss = 0.811033594963636\n",
      "Train accuracy: 0.704\t\tTest accuracy: 0.698\n",
      "Mean abs grad value: 0.005502979172980905\tMax abs grad value: 0.15676351956263504\n",
      "Loss = 0.7643801420159392\n",
      "Train accuracy: 0.741\t\tTest accuracy: 0.729\n",
      "Mean abs grad value: 0.007565328125239554\tMax abs grad value: 0.32273622199671936\n",
      "Loss = 0.7232353120953771\n",
      "Train accuracy: 0.739\t\tTest accuracy: 0.742\n",
      "Mean abs grad value: 0.007093912302693957\tMax abs grad value: 0.26808402408489973\n",
      "Loss = 0.6932744359871879\n",
      "Train accuracy: 0.756\t\tTest accuracy: 0.767\n",
      "Mean abs grad value: 0.01595926816656537\tMax abs grad value: 0.6537644383394532\n",
      "Loss = 0.6526664483326511\n",
      "Train accuracy: 0.778\t\tTest accuracy: 0.791\n",
      "Mean abs grad value: 0.010334888013975647\tMax abs grad value: 0.5651054706866595\n",
      "Loss = 0.6089564215969064\n",
      "Train accuracy: 0.807\t\tTest accuracy: 0.798\n",
      "Mean abs grad value: 0.005715272967674346\tMax abs grad value: 0.15690813143926488\n",
      "Loss = 0.5854166031170953\n",
      "Train accuracy: 0.808\t\tTest accuracy: 0.796\n",
      "Mean abs grad value: 0.004775271039275304\tMax abs grad value: 0.11350592823675726\n",
      "Loss = 0.5683949892310681\n",
      "Train accuracy: 0.814\t\tTest accuracy: 0.818\n",
      "Mean abs grad value: 0.007023268308782941\tMax abs grad value: 0.25497103870160165\n",
      "Loss = 0.5360875672856207\n",
      "Train accuracy: 0.823\t\tTest accuracy: 0.829\n",
      "Mean abs grad value: 0.006449417537680437\tMax abs grad value: 0.3193642932848335\n",
      "Loss = 0.5116762814412686\n",
      "Train accuracy: 0.831\t\tTest accuracy: 0.833\n",
      "Mean abs grad value: 0.004708118752198502\tMax abs grad value: 0.10856214013821582\n",
      "Loss = 0.49312127973386566\n",
      "Train accuracy: 0.840\t\tTest accuracy: 0.831\n",
      "Mean abs grad value: 0.0038708232501907663\tMax abs grad value: 0.1501991540394431\n",
      "Loss = 0.4873209957588698\n",
      "Train accuracy: 0.837\t\tTest accuracy: 0.833\n",
      "Mean abs grad value: 0.005294879653479841\tMax abs grad value: 0.15237136411377558\n",
      "Loss = 0.47657014938462716\n",
      "Train accuracy: 0.837\t\tTest accuracy: 0.840\n",
      "Mean abs grad value: 0.00885170585442823\tMax abs grad value: 0.25347258043826487\n",
      "Loss = 0.44641945433435787\n",
      "Train accuracy: 0.846\t\tTest accuracy: 0.849\n",
      "Mean abs grad value: 0.007289345262922415\tMax abs grad value: 0.21456720552212064\n",
      "Loss = 0.4244439303891525\n",
      "Train accuracy: 0.859\t\tTest accuracy: 0.842\n",
      "Mean abs grad value: 0.005468354882313343\tMax abs grad value: 0.22834972053242858\n",
      "Loss = 0.4100533834853028\n",
      "Train accuracy: 0.869\t\tTest accuracy: 0.840\n",
      "Mean abs grad value: 0.004082189324560045\tMax abs grad value: 0.09295875605710413\n",
      "Loss = 0.40063207487130004\n",
      "Train accuracy: 0.870\t\tTest accuracy: 0.851\n",
      "Mean abs grad value: 0.0047452125096697\tMax abs grad value: 0.12790901566865356\n",
      "Loss = 0.3921486718628457\n",
      "Train accuracy: 0.874\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.005742603277919838\tMax abs grad value: 0.14687580382132584\n",
      "Loss = 0.3797738057060409\n",
      "Train accuracy: 0.882\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.008625721602037865\tMax abs grad value: 0.47597570102126247\n",
      "Loss = 0.3704415985084773\n",
      "Train accuracy: 0.881\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.003912264690770478\tMax abs grad value: 0.11967450477045792\n",
      "Loss = 0.3541148597082043\n",
      "Train accuracy: 0.892\t\tTest accuracy: 0.858\n",
      "Mean abs grad value: 0.003977767262385833\tMax abs grad value: 0.1301483927841059\n",
      "Loss = 0.345163243582733\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.864\n",
      "Mean abs grad value: 0.00501347424916193\tMax abs grad value: 0.19538092935534482\n",
      "Loss = 0.33604483373008875\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.864\n",
      "Mean abs grad value: 0.004573298138632146\tMax abs grad value: 0.3153078536244034\n",
      "Loss = 0.3227133130987741\n",
      "Train accuracy: 0.901\t\tTest accuracy: 0.869\n",
      "Mean abs grad value: 0.006436626152535712\tMax abs grad value: 0.22150630236058386\n",
      "Loss = 0.30762157659360634\n",
      "Train accuracy: 0.901\t\tTest accuracy: 0.882\n",
      "Mean abs grad value: 0.0038822602228503317\tMax abs grad value: 0.1789539357812247\n",
      "Loss = 0.29280056399491067\n",
      "Train accuracy: 0.909\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.0033861471108876124\tMax abs grad value: 0.10956107559484751\n",
      "Loss = 0.28209491364082473\n",
      "Train accuracy: 0.913\t\tTest accuracy: 0.882\n",
      "Mean abs grad value: 0.007675585938882567\tMax abs grad value: 0.22782839532474758\n",
      "Loss = 0.2710516942935579\n",
      "Train accuracy: 0.912\t\tTest accuracy: 0.878\n",
      "Mean abs grad value: 0.004825782205680326\tMax abs grad value: 0.21766982328281542\n",
      "Loss = 0.2616012227959142\n",
      "Train accuracy: 0.912\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.004195210870465984\tMax abs grad value: 0.17356722895713902\n",
      "Loss = 0.2553711815695194\n",
      "Train accuracy: 0.914\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.0038848385729926766\tMax abs grad value: 0.13182811615050194\n",
      "Loss = 0.2424046659449125\n",
      "Train accuracy: 0.923\t\tTest accuracy: 0.898\n",
      "Mean abs grad value: 0.0040712633690076485\tMax abs grad value: 0.12319360069659073\n",
      "Loss = 0.2309972086182165\n",
      "Train accuracy: 0.928\t\tTest accuracy: 0.904\n",
      "Mean abs grad value: 0.003781281394453756\tMax abs grad value: 0.10595764775966225\n",
      "Loss = 0.20805163331993715\n",
      "Train accuracy: 0.935\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.012503967843793703\tMax abs grad value: 0.4432962083093683\n",
      "Loss = 0.2542451780908876\n",
      "Mean abs grad value: 0.004053706732275842\tMax abs grad value: 0.1399492472959665\n",
      "Loss = 0.19809539239099333\n",
      "Train accuracy: 0.936\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.002642700624419223\tMax abs grad value: 0.0879271379001765\n",
      "Loss = 0.18829786750265654\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0029962309747856054\tMax abs grad value: 0.0926461594216803\n",
      "Loss = 0.17972593117086555\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0032389751631147976\tMax abs grad value: 0.09435186330770963\n",
      "Loss = 0.17083270908345566\n",
      "Train accuracy: 0.948\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.005693860996211068\tMax abs grad value: 0.17619026115255107\n",
      "Loss = 0.16391739275558648\n",
      "Train accuracy: 0.951\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0029497483034333204\tMax abs grad value: 0.0891781238223602\n",
      "Loss = 0.1537866678331218\n",
      "Train accuracy: 0.953\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.003072998410136094\tMax abs grad value: 0.09292441029236449\n",
      "Loss = 0.1452835094573067\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002698342893903395\tMax abs grad value: 0.09221502410324478\n",
      "Loss = 0.14000525737731787\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.004439790063199757\tMax abs grad value: 0.12627055315755326\n",
      "Loss = 0.1352322788045277\n",
      "Train accuracy: 0.959\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.002206979856792895\tMax abs grad value: 0.047019533044304535\n",
      "Loss = 0.12993167441205333\n",
      "Train accuracy: 0.956\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.002359992443631702\tMax abs grad value: 0.05943536602343085\n",
      "Loss = 0.12608826574624707\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0028647291227429155\tMax abs grad value: 0.06963415025471048\n",
      "Loss = 0.12110811161004877\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0030170059295112146\tMax abs grad value: 0.07344061761328935\n",
      "Loss = 0.11561323217662549\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.00301023815171472\tMax abs grad value: 0.08891375788691123\n",
      "Loss = 0.1110313520329156\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.002097089091820249\tMax abs grad value: 0.06479303838389876\n",
      "Loss = 0.10631669526653403\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0020052638332873052\tMax abs grad value: 0.0504381068103348\n",
      "Loss = 0.09993542014132771\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002016579868314685\tMax abs grad value: 0.05268334670742376\n",
      "Loss = 0.09432591269184468\n",
      "Train accuracy: 0.972\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0025304140397440955\tMax abs grad value: 0.07590663864325772\n",
      "Loss = 0.08554275497078985\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0028533150556806688\tMax abs grad value: 0.07216134468939332\n",
      "Loss = 0.08013596567938924\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0012415633975643911\tMax abs grad value: 0.0314560544689535\n",
      "Loss = 0.07597865708357694\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.001251091253788799\tMax abs grad value: 0.02841862520022038\n",
      "Loss = 0.07351045586993728\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0016792146494465413\tMax abs grad value: 0.05577678594825221\n",
      "Loss = 0.07010799862899308\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.00320524164569115\tMax abs grad value: 0.07544515031532681\n",
      "Loss = 0.06714379998924982\n",
      "Train accuracy: 0.975\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0016130364583314984\tMax abs grad value: 0.03154253036419813\n",
      "Loss = 0.0627852375898801\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.00150461233717034\tMax abs grad value: 0.040909295116205724\n",
      "Loss = 0.05901827371065203\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0020595502183817496\tMax abs grad value: 0.050688258547115714\n",
      "Loss = 0.05532428089985016\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0027897655878886454\tMax abs grad value: 0.08191143471641596\n",
      "Loss = 0.05194093189749709\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0017942199972215784\tMax abs grad value: 0.04544197767846005\n",
      "Loss = 0.04754508110594382\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0014179850581759986\tMax abs grad value: 0.038325002290971154\n",
      "Loss = 0.043533325296244166\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0017547275388600314\tMax abs grad value: 0.053599167933327724\n",
      "Loss = 0.03945630354401134\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0018739193029498336\tMax abs grad value: 0.056271176231037244\n",
      "Loss = 0.035316343616800534\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0015031917267438642\tMax abs grad value: 0.046068490159222104\n",
      "Loss = 0.031677113986377896\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0012199315128707988\tMax abs grad value: 0.03831344214369154\n",
      "Loss = 0.029069426099198065\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0013009721451184163\tMax abs grad value: 0.03912072575317622\n",
      "Loss = 0.0258173553554588\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.001346118734331493\tMax abs grad value: 0.0406042337937088\n",
      "Loss = 0.023256082863601354\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0008938089179326013\tMax abs grad value: 0.021127227017839843\n",
      "Loss = 0.020319206830476732\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0010441567783745877\tMax abs grad value: 0.02588907131313119\n",
      "Loss = 0.01783217809013811\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.002079337084956183\tMax abs grad value: 0.05580094058941906\n",
      "Loss = 0.015481592708974652\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0009221433279955435\tMax abs grad value: 0.021857164093741572\n",
      "Loss = 0.01292299153956846\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0006109809825241663\tMax abs grad value: 0.010631794027348733\n",
      "Loss = 0.011535890652374248\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0005671851429057008\tMax abs grad value: 0.010674702996039507\n",
      "Loss = 0.010159513645187043\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0014954832430272172\tMax abs grad value: 0.046151315409397\n",
      "Loss = 0.00863267879225738\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0009815636271179487\tMax abs grad value: 0.024901148835633696\n",
      "Loss = 0.007225231843347849\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0005070528693087626\tMax abs grad value: 0.011312844818254451\n",
      "Loss = 0.006517930663484801\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00039271440276379113\tMax abs grad value: 0.009026942021709373\n",
      "Loss = 0.00584401806615189\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0005190370904923759\tMax abs grad value: 0.01032123008844632\n",
      "Loss = 0.004865057045670001\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0006496186742759444\tMax abs grad value: 0.013594501142131184\n",
      "Loss = 0.003948736129281794\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0003798463668663238\tMax abs grad value: 0.008321244132322714\n",
      "Loss = 0.0028711117413879037\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0003349139779458746\tMax abs grad value: 0.00925870496941771\n",
      "Loss = 0.0020224768896907512\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0003424450777800291\tMax abs grad value: 0.006484262684386695\n",
      "Loss = 0.0015882086424126775\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00018355235418090655\tMax abs grad value: 0.0033715047574386908\n",
      "Loss = 0.0013794578298328627\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0001245831319921658\tMax abs grad value: 0.003208896622498672\n",
      "Loss = 0.0012138491766244888\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.00012727514006940455\tMax abs grad value: 0.0032958289119968853\n",
      "Loss = 0.0010483106222085195\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.0002151266547776759\tMax abs grad value: 0.0054408235228886855\n",
      "Loss = 0.0008644717597990286\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00010316857968891032\tMax abs grad value: 0.003336299973828471\n",
      "Loss = 0.0007080398294388075\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 8.482194735638187e-05\tMax abs grad value: 0.0016316705569251468\n",
      "Loss = 0.0006453179751320904\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 6.888467260348446e-05\tMax abs grad value: 0.0015276540417628625\n",
      "Loss = 0.0005263881973798004\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 7.100414889897702e-05\tMax abs grad value: 0.002365024978129869\n",
      "Loss = 0.00037309549058844947\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 8.012039569746446e-05\tMax abs grad value: 0.001880936409661205\n",
      "Loss = 0.0002824728034058618\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 5.724269181633948e-05\tMax abs grad value: 0.0012144907905592402\n",
      "Loss = 0.00023662004672409553\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.726514468681581e-05\tMax abs grad value: 0.0007252014182022358\n",
      "Loss = 0.00018144088177193593\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.4141135652257217e-05\tMax abs grad value: 0.0005654822044217904\n",
      "Loss = 0.00013863170962709817\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 2.3628916523103005e-05\tMax abs grad value: 0.00040610924459408125\n",
      "Loss = 0.00010685391370868272\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.466197980689549e-05\tMax abs grad value: 0.0007741093262050566\n",
      "Loss = 8.510141779089141e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.6586404591223615e-05\tMax abs grad value: 0.00037367087208083543\n",
      "Loss = 6.774346290314838e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 1.061418408217974e-05\tMax abs grad value: 0.00019807478645638132\n",
      "Loss = 5.763618986950318e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.1381363182494527e-05\tMax abs grad value: 0.00026417480382058306\n",
      "Loss = 4.491682353383885e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.1913127216590885e-05\tMax abs grad value: 0.0003188986949004976\n",
      "Loss = 3.314346295146786e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 7.47944582653697e-06\tMax abs grad value: 0.00017144652745381523\n",
      "Loss = 2.2503710328720778e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 5.021791625162178e-06\tMax abs grad value: 0.00011357329796158827\n",
      "Loss = 1.6167750227407e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.809112208059119e-06\tMax abs grad value: 7.862531626569531e-05\n",
      "Loss = 1.0743049978953393e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 2.4336631378139056e-06\tMax abs grad value: 4.8021921557296714e-05\n",
      "Loss = 6.852726845301041e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 1.2413593668270405e-06\tMax abs grad value: 1.9789518301136547e-05\n",
      "Loss = 4.380685457079516e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 9.680749782909554e-07\tMax abs grad value: 1.8544700222107945e-05\n",
      "Loss = 2.782377347863203e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 5.910665310369533e-07\tMax abs grad value: 1.2756551488761804e-05\n",
      "Loss = 1.7768197405587174e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 3.5387331318667683e-07\tMax abs grad value: 6.731810207739707e-06\n",
      "Loss = 1.1616451886117643e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "i=1\tj=1\tinitialization=0.01\n",
      "Mean abs grad value: 1.5754360778369624e-05\tMax abs grad value: 0.006453886617736938\n",
      "Loss = 2.3025848292020448\n",
      "Mean abs grad value: 7.763395413410042e-05\tMax abs grad value: 0.05078793188624789\n",
      "Loss = 2.3382193689443524\n",
      "Mean abs grad value: 5.574543567704297e-06\tMax abs grad value: 0.0005368495540523134\n",
      "Loss = 2.3018441284027764\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 6.1083481346948295e-06\tMax abs grad value: 0.0002524830721323571\n",
      "Loss = 2.3018382957954056\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 7.639381876611932e-06\tMax abs grad value: 0.0003672540573537061\n",
      "Loss = 2.3018233725822848\n",
      "Mean abs grad value: 1.962251446353203e-05\tMax abs grad value: 0.0019074779705402284\n",
      "Loss = 2.301765841698592\n",
      "Mean abs grad value: 0.00013250396820079332\tMax abs grad value: 0.00791689771338071\n",
      "Loss = 2.3013030120788343\n",
      "Mean abs grad value: 0.0025803748422318436\tMax abs grad value: 0.09234732083217441\n",
      "Loss = 2.2764684669274575\n",
      "Mean abs grad value: 0.5749242391262555\tMax abs grad value: 35.51572358292442\n",
      "Loss = 25.13749546499883\n",
      "Mean abs grad value: 0.003458853510406187\tMax abs grad value: 0.1374918190912783\n",
      "Loss = 2.2756625529844072\n",
      "Train accuracy: 0.099\t\tTest accuracy: 0.107\n",
      "Mean abs grad value: 0.00034635120482005746\tMax abs grad value: 0.011562764635378866\n",
      "Loss = 2.2986497060155693\n",
      "Mean abs grad value: 0.0029913642855672793\tMax abs grad value: 0.10854154660979962\n",
      "Loss = 2.2755601962420755\n",
      "Train accuracy: 0.099\t\tTest accuracy: 0.107\n",
      "Mean abs grad value: 0.007435409231109367\tMax abs grad value: 0.3200797559435281\n",
      "Loss = 2.21954404147414\n",
      "Train accuracy: 0.190\t\tTest accuracy: 0.191\n",
      "Mean abs grad value: 0.017310637820204002\tMax abs grad value: 1.174323411553074\n",
      "Loss = 2.349081243737147\n",
      "Mean abs grad value: 0.009197261570327209\tMax abs grad value: 0.3624514261126583\n",
      "Loss = 2.175227925514453\n",
      "Train accuracy: 0.223\t\tTest accuracy: 0.218\n",
      "Mean abs grad value: 0.05028842932925927\tMax abs grad value: 3.0178370559178993\n",
      "Loss = 2.735359875267465\n",
      "Mean abs grad value: 0.00742568239540577\tMax abs grad value: 0.3682787115974209\n",
      "Loss = 2.1336625297523866\n",
      "Train accuracy: 0.231\t\tTest accuracy: 0.189\n",
      "Mean abs grad value: 0.009637362857024106\tMax abs grad value: 0.5334384625414245\n",
      "Loss = 2.0148481980861233\n",
      "Train accuracy: 0.257\t\tTest accuracy: 0.227\n",
      "Mean abs grad value: 0.010896783115412586\tMax abs grad value: 0.44780256571132004\n",
      "Loss = 1.9596280691586532\n",
      "Train accuracy: 0.290\t\tTest accuracy: 0.269\n",
      "Mean abs grad value: 0.008036376266371279\tMax abs grad value: 0.2843396849113987\n",
      "Loss = 1.9765597757540172\n",
      "Mean abs grad value: 0.0072848705876099994\tMax abs grad value: 0.281261720767137\n",
      "Loss = 1.9139790705206143\n",
      "Train accuracy: 0.299\t\tTest accuracy: 0.280\n",
      "Mean abs grad value: 0.006318088639586984\tMax abs grad value: 0.2564372754001418\n",
      "Loss = 1.8513698539331187\n",
      "Train accuracy: 0.327\t\tTest accuracy: 0.298\n",
      "Mean abs grad value: 0.028117740883694384\tMax abs grad value: 2.0408958027212187\n",
      "Loss = 2.0372297176377323\n",
      "Mean abs grad value: 0.006861328050819119\tMax abs grad value: 0.2362316343703108\n",
      "Loss = 1.810990510753924\n",
      "Train accuracy: 0.371\t\tTest accuracy: 0.324\n",
      "Mean abs grad value: 0.008846215631619598\tMax abs grad value: 0.43346854306524907\n",
      "Loss = 1.7613018776791198\n",
      "Train accuracy: 0.394\t\tTest accuracy: 0.358\n",
      "Mean abs grad value: 0.008354124865109357\tMax abs grad value: 0.5829227541388431\n",
      "Loss = 1.6860896587376948\n",
      "Train accuracy: 0.434\t\tTest accuracy: 0.404\n",
      "Mean abs grad value: 0.01489141391724207\tMax abs grad value: 0.9932492446146345\n",
      "Loss = 1.642026191516475\n",
      "Train accuracy: 0.420\t\tTest accuracy: 0.422\n",
      "Mean abs grad value: 0.008374471291225167\tMax abs grad value: 0.497919475157625\n",
      "Loss = 1.5746335099945188\n",
      "Train accuracy: 0.416\t\tTest accuracy: 0.409\n",
      "Mean abs grad value: 0.01172042849120671\tMax abs grad value: 0.5417799315237809\n",
      "Loss = 1.5565887049297304\n",
      "Train accuracy: 0.441\t\tTest accuracy: 0.373\n",
      "Mean abs grad value: 0.009760084974651398\tMax abs grad value: 0.3975538543747117\n",
      "Loss = 1.5194479676801604\n",
      "Train accuracy: 0.471\t\tTest accuracy: 0.449\n",
      "Mean abs grad value: 0.007497513652354773\tMax abs grad value: 0.2696184050554227\n",
      "Loss = 1.488827425622847\n",
      "Train accuracy: 0.483\t\tTest accuracy: 0.433\n",
      "Mean abs grad value: 0.011287851283181376\tMax abs grad value: 0.3411036555941682\n",
      "Loss = 1.4283632944918034\n",
      "Train accuracy: 0.500\t\tTest accuracy: 0.449\n",
      "Mean abs grad value: 0.013403657076359658\tMax abs grad value: 0.8268781966463409\n",
      "Loss = 1.3449737350696647\n",
      "Train accuracy: 0.534\t\tTest accuracy: 0.493\n",
      "Mean abs grad value: 0.026172984717043397\tMax abs grad value: 1.539917551238931\n",
      "Loss = 1.266662208993887\n",
      "Train accuracy: 0.523\t\tTest accuracy: 0.500\n",
      "Mean abs grad value: 0.013889632040020045\tMax abs grad value: 0.4444161299262267\n",
      "Loss = 1.1075929358550556\n",
      "Train accuracy: 0.679\t\tTest accuracy: 0.609\n",
      "Mean abs grad value: 0.01118626800988066\tMax abs grad value: 0.6463051591124872\n",
      "Loss = 1.0352797139681185\n",
      "Train accuracy: 0.690\t\tTest accuracy: 0.616\n",
      "Mean abs grad value: 0.011425750629932459\tMax abs grad value: 0.5656827662806763\n",
      "Loss = 0.9743167201550393\n",
      "Train accuracy: 0.698\t\tTest accuracy: 0.653\n",
      "Mean abs grad value: 0.01040770862642779\tMax abs grad value: 0.48622818387517613\n",
      "Loss = 0.9432542131979541\n",
      "Train accuracy: 0.719\t\tTest accuracy: 0.660\n",
      "Mean abs grad value: 0.011399542667683154\tMax abs grad value: 0.4267746094007527\n",
      "Loss = 0.9148626120481471\n",
      "Train accuracy: 0.707\t\tTest accuracy: 0.633\n",
      "Mean abs grad value: 0.01545921479784122\tMax abs grad value: 0.6644376787270018\n",
      "Loss = 0.8842326455260636\n",
      "Train accuracy: 0.728\t\tTest accuracy: 0.664\n",
      "Mean abs grad value: 0.007843516774403977\tMax abs grad value: 0.3179740948770253\n",
      "Loss = 0.8567425317070001\n",
      "Train accuracy: 0.739\t\tTest accuracy: 0.684\n",
      "Mean abs grad value: 0.0077024643677579725\tMax abs grad value: 0.2036774244327394\n",
      "Loss = 0.8461006979055506\n",
      "Train accuracy: 0.739\t\tTest accuracy: 0.689\n",
      "Mean abs grad value: 0.006883650828115639\tMax abs grad value: 0.24016193520729417\n",
      "Loss = 0.8140408717338115\n",
      "Train accuracy: 0.739\t\tTest accuracy: 0.693\n",
      "Mean abs grad value: 0.02592704751692557\tMax abs grad value: 1.3988846063479639\n",
      "Loss = 0.8158852667373999\n",
      "Mean abs grad value: 0.013244843278020913\tMax abs grad value: 0.6181961004969476\n",
      "Loss = 0.7885204636124427\n",
      "Train accuracy: 0.746\t\tTest accuracy: 0.693\n",
      "Mean abs grad value: 0.010446291068666519\tMax abs grad value: 0.5375015019026572\n",
      "Loss = 0.7339406352202852\n",
      "Train accuracy: 0.768\t\tTest accuracy: 0.716\n",
      "Mean abs grad value: 0.013915705133327353\tMax abs grad value: 0.7627106120699526\n",
      "Loss = 0.6835172829817445\n",
      "Train accuracy: 0.785\t\tTest accuracy: 0.758\n",
      "Mean abs grad value: 0.015552030107946136\tMax abs grad value: 0.9782155824589841\n",
      "Loss = 0.675482488032318\n",
      "Train accuracy: 0.794\t\tTest accuracy: 0.736\n",
      "Mean abs grad value: 0.007170033630291813\tMax abs grad value: 0.18185463552999612\n",
      "Loss = 0.6554767831762869\n",
      "Train accuracy: 0.798\t\tTest accuracy: 0.762\n",
      "Mean abs grad value: 0.0057899789835129155\tMax abs grad value: 0.13167808484451737\n",
      "Loss = 0.6464934782340666\n",
      "Train accuracy: 0.803\t\tTest accuracy: 0.780\n",
      "Mean abs grad value: 0.006153456576700412\tMax abs grad value: 0.19674786669975708\n",
      "Loss = 0.6306334974766495\n",
      "Train accuracy: 0.808\t\tTest accuracy: 0.776\n",
      "Mean abs grad value: 0.006238148020422883\tMax abs grad value: 0.2127672121199575\n",
      "Loss = 0.6184488335270176\n",
      "Train accuracy: 0.810\t\tTest accuracy: 0.787\n",
      "Mean abs grad value: 0.017969662253278063\tMax abs grad value: 0.8216588125263229\n",
      "Loss = 0.6313019997886119\n",
      "Mean abs grad value: 0.006825164697944015\tMax abs grad value: 0.31591674441134526\n",
      "Loss = 0.6113355646418938\n",
      "Train accuracy: 0.811\t\tTest accuracy: 0.776\n",
      "Mean abs grad value: 0.005273891907793357\tMax abs grad value: 0.1615373204082586\n",
      "Loss = 0.5989001048606899\n",
      "Train accuracy: 0.811\t\tTest accuracy: 0.782\n",
      "Mean abs grad value: 0.008160959873387146\tMax abs grad value: 0.29113387656306045\n",
      "Loss = 0.5774347693009126\n",
      "Train accuracy: 0.824\t\tTest accuracy: 0.776\n",
      "Mean abs grad value: 0.00988157566916997\tMax abs grad value: 0.43485382525525706\n",
      "Loss = 0.5652142279178191\n",
      "Train accuracy: 0.823\t\tTest accuracy: 0.796\n",
      "Mean abs grad value: 0.008357477817712828\tMax abs grad value: 0.33565583121416864\n",
      "Loss = 0.55087009366038\n",
      "Train accuracy: 0.829\t\tTest accuracy: 0.802\n",
      "Mean abs grad value: 0.009387629610438366\tMax abs grad value: 0.3807959912161528\n",
      "Loss = 0.5180500776467538\n",
      "Train accuracy: 0.842\t\tTest accuracy: 0.809\n",
      "Mean abs grad value: 0.00990573434309008\tMax abs grad value: 0.5182894166886637\n",
      "Loss = 0.506381296995942\n",
      "Train accuracy: 0.850\t\tTest accuracy: 0.820\n",
      "Mean abs grad value: 0.005411522094535088\tMax abs grad value: 0.23861746715138865\n",
      "Loss = 0.4987464896292662\n",
      "Train accuracy: 0.851\t\tTest accuracy: 0.824\n",
      "Mean abs grad value: 0.004640089093093729\tMax abs grad value: 0.0794207558843039\n",
      "Loss = 0.49177124732468214\n",
      "Train accuracy: 0.856\t\tTest accuracy: 0.827\n",
      "Mean abs grad value: 0.007747794255204221\tMax abs grad value: 0.28622515876460275\n",
      "Loss = 0.47395211047903457\n",
      "Train accuracy: 0.859\t\tTest accuracy: 0.827\n",
      "Mean abs grad value: 0.009330339497602078\tMax abs grad value: 0.4056162608617352\n",
      "Loss = 0.44782610224417213\n",
      "Train accuracy: 0.863\t\tTest accuracy: 0.833\n",
      "Mean abs grad value: 0.008219045995109864\tMax abs grad value: 0.38759632632685903\n",
      "Loss = 0.4073335014752511\n",
      "Train accuracy: 0.869\t\tTest accuracy: 0.840\n",
      "Mean abs grad value: 0.029942321475515565\tMax abs grad value: 1.2208845521150373\n",
      "Loss = 0.4773348138827041\n",
      "Mean abs grad value: 0.008132666551368387\tMax abs grad value: 0.5054852100739602\n",
      "Loss = 0.39475666896487804\n",
      "Train accuracy: 0.866\t\tTest accuracy: 0.847\n",
      "Mean abs grad value: 0.005168348701425294\tMax abs grad value: 0.15864785501978104\n",
      "Loss = 0.37913708436978927\n",
      "Train accuracy: 0.878\t\tTest accuracy: 0.856\n",
      "Mean abs grad value: 0.004483222107336718\tMax abs grad value: 0.12554668995948592\n",
      "Loss = 0.37110316316024217\n",
      "Train accuracy: 0.878\t\tTest accuracy: 0.864\n",
      "Mean abs grad value: 0.005315956429026824\tMax abs grad value: 0.13807881365866442\n",
      "Loss = 0.3614340280532522\n",
      "Train accuracy: 0.886\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.00510130962439073\tMax abs grad value: 0.12281891530973024\n",
      "Loss = 0.34768853652168574\n",
      "Train accuracy: 0.891\t\tTest accuracy: 0.864\n",
      "Mean abs grad value: 0.007234165442084017\tMax abs grad value: 0.2681086497430374\n",
      "Loss = 0.3235750017124272\n",
      "Train accuracy: 0.893\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.004473075824936275\tMax abs grad value: 0.12540387590533147\n",
      "Loss = 0.3073334892362806\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.878\n",
      "Mean abs grad value: 0.004433410811485953\tMax abs grad value: 0.13066756725062886\n",
      "Loss = 0.29509603756649133\n",
      "Train accuracy: 0.903\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.004748979204902812\tMax abs grad value: 0.18661909978581043\n",
      "Loss = 0.27934795541746255\n",
      "Train accuracy: 0.906\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.007495370408833199\tMax abs grad value: 0.26631272970874836\n",
      "Loss = 0.2659846277921933\n",
      "Train accuracy: 0.908\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.0036888383235161993\tMax abs grad value: 0.13798015826728388\n",
      "Loss = 0.2531653492607424\n",
      "Train accuracy: 0.912\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.0038135757003389505\tMax abs grad value: 0.17884019309273705\n",
      "Loss = 0.2437129512601042\n",
      "Train accuracy: 0.915\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.004473187633965373\tMax abs grad value: 0.19479253212032327\n",
      "Loss = 0.22847761556827667\n",
      "Train accuracy: 0.916\t\tTest accuracy: 0.882\n",
      "Mean abs grad value: 0.008209997243347596\tMax abs grad value: 0.1843560472687103\n",
      "Loss = 0.22089742932992326\n",
      "Train accuracy: 0.921\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.003169502437156517\tMax abs grad value: 0.0737464087772261\n",
      "Loss = 0.20949421528865475\n",
      "Train accuracy: 0.927\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.002500210371931415\tMax abs grad value: 0.05721570599094381\n",
      "Loss = 0.20567261218975585\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.0030901947318139476\tMax abs grad value: 0.1148744785504396\n",
      "Loss = 0.2004778498912456\n",
      "Train accuracy: 0.931\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.004507775594564453\tMax abs grad value: 0.1849893522563506\n",
      "Loss = 0.19501690715149259\n",
      "Train accuracy: 0.934\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.003135350216359426\tMax abs grad value: 0.11658685886160403\n",
      "Loss = 0.18811974207180526\n",
      "Train accuracy: 0.933\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.003004881537624368\tMax abs grad value: 0.07709547060838427\n",
      "Loss = 0.18195108937178656\n",
      "Train accuracy: 0.938\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.003340748841533012\tMax abs grad value: 0.06048366796155622\n",
      "Loss = 0.17375225119555182\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.0037344325335275223\tMax abs grad value: 0.08937434269955338\n",
      "Loss = 0.16772386728126368\n",
      "Train accuracy: 0.941\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.0034072439654856687\tMax abs grad value: 0.08243971837764179\n",
      "Loss = 0.1616192555401279\n",
      "Train accuracy: 0.944\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.0029434990590004447\tMax abs grad value: 0.10013510589580568\n",
      "Loss = 0.14818510108112015\n",
      "Train accuracy: 0.947\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.005892083310498353\tMax abs grad value: 0.19655942439674623\n",
      "Loss = 0.14088974482901453\n",
      "Train accuracy: 0.950\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.0030618364826208505\tMax abs grad value: 0.09173538654516263\n",
      "Loss = 0.133693975927177\n",
      "Train accuracy: 0.953\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.002287818112968692\tMax abs grad value: 0.06720775617676888\n",
      "Loss = 0.12832746727559005\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.924\n",
      "Mean abs grad value: 0.0025904671599116143\tMax abs grad value: 0.06483388072884494\n",
      "Loss = 0.12233041075136888\n",
      "Train accuracy: 0.961\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0045192254075091315\tMax abs grad value: 0.1341311832679637\n",
      "Loss = 0.11748395345994506\n",
      "Train accuracy: 0.962\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.003054590397744756\tMax abs grad value: 0.08095832869252606\n",
      "Loss = 0.11226985322484087\n",
      "Train accuracy: 0.964\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0021659068260834807\tMax abs grad value: 0.05316352428117391\n",
      "Loss = 0.10906216294830258\n",
      "Train accuracy: 0.966\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0018307819614955209\tMax abs grad value: 0.04389988134875181\n",
      "Loss = 0.1028463458164407\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0025540798923947626\tMax abs grad value: 0.057520296558329694\n",
      "Loss = 0.09516311367178816\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0043312566136531365\tMax abs grad value: 0.15516308833675244\n",
      "Loss = 0.09208011140236459\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0019355763495588583\tMax abs grad value: 0.03335713609273643\n",
      "Loss = 0.08534715235158945\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0016099821140567352\tMax abs grad value: 0.04976554557383149\n",
      "Loss = 0.08117593044995308\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0018946583651861682\tMax abs grad value: 0.05989031331919768\n",
      "Loss = 0.07587391291733235\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.003397928298525385\tMax abs grad value: 0.11207527155809327\n",
      "Loss = 0.0720685950580584\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.001968777168398995\tMax abs grad value: 0.04648366248445802\n",
      "Loss = 0.06766690204342665\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0014984241011813412\tMax abs grad value: 0.03843329205158809\n",
      "Loss = 0.0640013699204446\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0016924768172387704\tMax abs grad value: 0.05441083715501159\n",
      "Loss = 0.06144302510703652\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0037665202970661466\tMax abs grad value: 0.09094507477100226\n",
      "Loss = 0.058861903658763634\n",
      "Train accuracy: 0.982\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0020559799385714756\tMax abs grad value: 0.03895165728059434\n",
      "Loss = 0.05500993953933113\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0016874134609648182\tMax abs grad value: 0.03264847186652213\n",
      "Loss = 0.05132349591926303\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0021124540174552366\tMax abs grad value: 0.059973052550421596\n",
      "Loss = 0.04724230548062217\n",
      "Train accuracy: 0.986\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.002592628305449441\tMax abs grad value: 0.07512689879347635\n",
      "Loss = 0.04161176779894239\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.005815441751484688\tMax abs grad value: 0.12406797116131568\n",
      "Loss = 0.04389706787685664\n",
      "Mean abs grad value: 0.0024112466804498307\tMax abs grad value: 0.07234929800407017\n",
      "Loss = 0.03918642219119037\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0014687849479716481\tMax abs grad value: 0.024233631420943473\n",
      "Loss = 0.036187335718887846\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0012946489315459097\tMax abs grad value: 0.043266598965343836\n",
      "Loss = 0.03358916642118821\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0013426862681109504\tMax abs grad value: 0.03960908334913374\n",
      "Loss = 0.031432401096864994\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001964632365499587\tMax abs grad value: 0.08721415408902508\n",
      "Loss = 0.028597864307703575\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0010769127071816066\tMax abs grad value: 0.020322544144749873\n",
      "Loss = 0.025591183085277632\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0010075640741178656\tMax abs grad value: 0.027319953260480347\n",
      "Loss = 0.023981710550151244\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001216352603799547\tMax abs grad value: 0.04972796860982108\n",
      "Loss = 0.021802789368528495\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0013558351555890064\tMax abs grad value: 0.04249251528864701\n",
      "Loss = 0.019053482715653446\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0020742692976744863\tMax abs grad value: 0.04257076650548404\n",
      "Loss = 0.01717794942914428\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.001053393882598272\tMax abs grad value: 0.024735944127067\n",
      "Loss = 0.013849416783252843\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0006719552400810096\tMax abs grad value: 0.026291115507992898\n",
      "Loss = 0.012499403267733031\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0009254689476014431\tMax abs grad value: 0.035669464043481515\n",
      "Loss = 0.011074233187199961\n",
      "Train accuracy: 0.998\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0012567489539798235\tMax abs grad value: 0.0340091572188143\n",
      "Loss = 0.00982481286508081\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0010285361506097155\tMax abs grad value: 0.025165416896862865\n",
      "Loss = 0.008775925419363801\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0011223705857696278\tMax abs grad value: 0.03249226260175786\n",
      "Loss = 0.007429232038846467\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0010255768094778418\tMax abs grad value: 0.025839092687522543\n",
      "Loss = 0.005010944483657775\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0005409524309830118\tMax abs grad value: 0.013313367196601622\n",
      "Loss = 0.0033644278215987826\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.00025644590962712016\tMax abs grad value: 0.006170931058772312\n",
      "Loss = 0.002447370289536501\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00020624982261378607\tMax abs grad value: 0.0038933775165628025\n",
      "Loss = 0.0021055767095618204\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0003800737526904066\tMax abs grad value: 0.013532927664831218\n",
      "Loss = 0.0017483308451836186\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.000263978497484252\tMax abs grad value: 0.007820758291994771\n",
      "Loss = 0.0014378790867132782\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0001702713081156741\tMax abs grad value: 0.00399748261946842\n",
      "Loss = 0.0012592015321762418\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.00013227027909548918\tMax abs grad value: 0.004003820790724185\n",
      "Loss = 0.001022737865153649\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.00010776946233866172\tMax abs grad value: 0.0030506992021333027\n",
      "Loss = 0.0008630304697576447\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.00016629336398789194\tMax abs grad value: 0.00530539738248004\n",
      "Loss = 0.0006280977481497732\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.00022434052486607073\tMax abs grad value: 0.006657409108876571\n",
      "Loss = 0.00048275673341628813\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 7.86319789824301e-05\tMax abs grad value: 0.0019384605529868164\n",
      "Loss = 0.0003512753204843809\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 5.5806955330302625e-05\tMax abs grad value: 0.0013711125895693715\n",
      "Loss = 0.00031341107831730743\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 5.073996960348279e-05\tMax abs grad value: 0.0010554319050674885\n",
      "Loss = 0.00026215257540716043\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 3.838228289353966e-05\tMax abs grad value: 0.0008643277686932422\n",
      "Loss = 0.0002130781079917319\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 3.499143678742296e-05\tMax abs grad value: 0.0007737735056337798\n",
      "Loss = 0.00016894216815115597\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 2.2086912372476894e-05\tMax abs grad value: 0.0003900726336971289\n",
      "Loss = 0.0001277614811007715\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 1.9720397680737246e-05\tMax abs grad value: 0.00037188943443707613\n",
      "Loss = 0.00010029909324243825\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 2.682548569895196e-05\tMax abs grad value: 0.0007303869522760346\n",
      "Loss = 7.433168423669488e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 1.1756778852146255e-05\tMax abs grad value: 0.00022204496595289955\n",
      "Loss = 5.861429361948933e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 1.083155183274709e-05\tMax abs grad value: 0.00024686650691497743\n",
      "Loss = 5.055497307984905e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 9.727265233425912e-06\tMax abs grad value: 0.0002461218654923978\n",
      "Loss = 4.171307833587793e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 1.601198206029231e-05\tMax abs grad value: 0.0005600600998437145\n",
      "Loss = 2.992540596985962e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 7.006499261028135e-06\tMax abs grad value: 0.00012857683633052326\n",
      "Loss = 2.0056826401995096e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 3.8090732590212937e-06\tMax abs grad value: 7.730120427116046e-05\n",
      "Loss = 1.7776115118381906e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 3.589415706746263e-06\tMax abs grad value: 6.746759252688403e-05\n",
      "Loss = 1.5798612564022574e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 2.7505318155762247e-06\tMax abs grad value: 6.04258817396815e-05\n",
      "Loss = 1.1146153882924291e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 4.052313264343988e-06\tMax abs grad value: 0.00014582952024097708\n",
      "Loss = 7.75874770468065e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 1.3493060831136353e-06\tMax abs grad value: 2.8490004460058506e-05\n",
      "Loss = 4.8832926503091125e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 1.1257847962325849e-06\tMax abs grad value: 2.419166552246946e-05\n",
      "Loss = 3.910040964280535e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 1.1198799137164168e-06\tMax abs grad value: 3.848530413242425e-05\n",
      "Loss = 2.3059702201409886e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 3.121291696838763e-06\tMax abs grad value: 7.043662865628376e-05\n",
      "Loss = 2.3314708563073973e-06\n",
      "Mean abs grad value: 9.687302025313783e-07\tMax abs grad value: 2.5070373602469035e-05\n",
      "Loss = 1.5732988152770582e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 5.433606022445714e-07\tMax abs grad value: 1.2443274646237777e-05\n",
      "Loss = 1.147155548785423e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 3.3352436176552437e-07\tMax abs grad value: 7.281264025575084e-06\n",
      "Loss = 8.930472300949854e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.931\n",
      "i=1\tj=2\tinitialization=0.01\n",
      "Mean abs grad value: 1.6163620780532025e-05\tMax abs grad value: 0.006458032071708953\n",
      "Loss = 2.3025846672428845\n",
      "Mean abs grad value: 9.13305407316879e-05\tMax abs grad value: 0.05027665958887568\n",
      "Loss = 2.3375825566084965\n",
      "Mean abs grad value: 7.057937655362972e-06\tMax abs grad value: 0.00033212190318953943\n",
      "Loss = 2.3018414457722955\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 7.34427934848858e-06\tMax abs grad value: 0.00032525755600120235\n",
      "Loss = 2.30183207056966\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 1.72976420880586e-05\tMax abs grad value: 0.0013694474669655487\n",
      "Loss = 2.3017901623380945\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 6.195812483384215e-05\tMax abs grad value: 0.004035787190951219\n",
      "Loss = 2.3016437201258904\n",
      "Mean abs grad value: 0.0004803339199681955\tMax abs grad value: 0.018065687610965997\n",
      "Loss = 2.2988656051241967\n",
      "Mean abs grad value: 0.1588026685256451\tMax abs grad value: 14.929167008862114\n",
      "Loss = 7.92929214032563\n",
      "Mean abs grad value: 0.0012410048887257514\tMax abs grad value: 0.05265881774956802\n",
      "Loss = 2.29671868444104\n",
      "Mean abs grad value: 0.0008703188569782251\tMax abs grad value: 0.02852369768407891\n",
      "Loss = 2.296873120413733\n",
      "Mean abs grad value: 0.0010895436645087212\tMax abs grad value: 0.042403982916815165\n",
      "Loss = 2.296605585398264\n",
      "Train accuracy: 0.099\t\tTest accuracy: 0.107\n",
      "Mean abs grad value: 2.5515799203530554\tMax abs grad value: 259.37946268668526\n",
      "Loss = 309.72772396693546\n",
      "Mean abs grad value: 0.009491084863915882\tMax abs grad value: 0.7043295675115405\n",
      "Loss = 2.39072743757861\n",
      "Mean abs grad value: 0.0013298664874824271\tMax abs grad value: 0.058455087638369006\n",
      "Loss = 2.296791836649078\n",
      "Mean abs grad value: 0.0011207261035213528\tMax abs grad value: 0.04450847333150548\n",
      "Loss = 2.296599826609621\n",
      "Train accuracy: 0.099\t\tTest accuracy: 0.107\n",
      "Mean abs grad value: 0.0011946729739874108\tMax abs grad value: 0.04754718826689473\n",
      "Loss = 2.295387500455194\n",
      "Mean abs grad value: 0.0015643172726411054\tMax abs grad value: 0.062386289699413865\n",
      "Loss = 2.2903102144265532\n",
      "Mean abs grad value: 0.004962053346253479\tMax abs grad value: 0.1958604323672782\n",
      "Loss = 2.2710222480980855\n",
      "Train accuracy: 0.099\t\tTest accuracy: 0.107\n",
      "Mean abs grad value: 1.675596358722506\tMax abs grad value: 58.017715040364195\n",
      "Loss = 127.05658105425634\n",
      "Mean abs grad value: 0.03017916233897116\tMax abs grad value: 1.098796658525022\n",
      "Loss = 2.3499643606998073\n",
      "Mean abs grad value: 0.008417379941905993\tMax abs grad value: 0.314145757628967\n",
      "Loss = 2.2626476842329004\n",
      "Train accuracy: 0.100\t\tTest accuracy: 0.107\n",
      "Mean abs grad value: 0.022091626983628484\tMax abs grad value: 0.7808531074645457\n",
      "Loss = 2.203716832499139\n",
      "Mean abs grad value: 0.01438979595755136\tMax abs grad value: 0.43726875558796013\n",
      "Loss = 2.2232363160487165\n",
      "Mean abs grad value: 0.019898868673267303\tMax abs grad value: 0.5848758650111248\n",
      "Loss = 2.1917895466491006\n",
      "Train accuracy: 0.231\t\tTest accuracy: 0.198\n",
      "Mean abs grad value: 0.09626972448810334\tMax abs grad value: 3.568526925965214\n",
      "Loss = 3.626701221149918\n",
      "Mean abs grad value: 0.01976289152753549\tMax abs grad value: 0.6643883806753031\n",
      "Loss = 2.177516538604015\n",
      "Train accuracy: 0.210\t\tTest accuracy: 0.176\n",
      "Mean abs grad value: 0.010638657015175593\tMax abs grad value: 0.3235666384864482\n",
      "Loss = 2.0735284847252347\n",
      "Train accuracy: 0.207\t\tTest accuracy: 0.167\n",
      "Mean abs grad value: 0.009277464320539901\tMax abs grad value: 0.3449809123888301\n",
      "Loss = 1.9547822238446395\n",
      "Train accuracy: 0.275\t\tTest accuracy: 0.231\n",
      "Mean abs grad value: 0.05968666388069906\tMax abs grad value: 2.6733910671687133\n",
      "Loss = 2.3577722891593065\n",
      "Mean abs grad value: 0.019043317708658303\tMax abs grad value: 0.5022784473936432\n",
      "Loss = 1.751064633387655\n",
      "Train accuracy: 0.346\t\tTest accuracy: 0.327\n",
      "Mean abs grad value: 0.07040071713096174\tMax abs grad value: 6.294916758925236\n",
      "Loss = 2.439944562398427\n",
      "Mean abs grad value: 0.01574021512786453\tMax abs grad value: 0.4729614813097211\n",
      "Loss = 1.6708200969203029\n",
      "Train accuracy: 0.401\t\tTest accuracy: 0.396\n",
      "Mean abs grad value: 0.01695601633971234\tMax abs grad value: 1.399297707676896\n",
      "Loss = 1.5804017403853965\n",
      "Train accuracy: 0.486\t\tTest accuracy: 0.484\n",
      "Mean abs grad value: 0.016239562229747553\tMax abs grad value: 0.5975338296024186\n",
      "Loss = 1.4938924415538881\n",
      "Train accuracy: 0.536\t\tTest accuracy: 0.540\n",
      "Mean abs grad value: 0.018914379718740982\tMax abs grad value: 0.9017786370421595\n",
      "Loss = 1.3545762282084135\n",
      "Train accuracy: 0.583\t\tTest accuracy: 0.589\n",
      "Mean abs grad value: 0.026594756395776017\tMax abs grad value: 1.3436315850360478\n",
      "Loss = 1.2339829748813813\n",
      "Train accuracy: 0.537\t\tTest accuracy: 0.533\n",
      "Mean abs grad value: 0.011111752368340604\tMax abs grad value: 0.5137889896192279\n",
      "Loss = 1.1170808792713802\n",
      "Train accuracy: 0.595\t\tTest accuracy: 0.578\n",
      "Mean abs grad value: 0.011774482151105705\tMax abs grad value: 0.5032654436447972\n",
      "Loss = 1.0588135864539507\n",
      "Train accuracy: 0.628\t\tTest accuracy: 0.584\n",
      "Mean abs grad value: 0.013756591926598227\tMax abs grad value: 0.47754539321759903\n",
      "Loss = 1.0140971779412309\n",
      "Train accuracy: 0.622\t\tTest accuracy: 0.618\n",
      "Mean abs grad value: 0.010562587627446862\tMax abs grad value: 0.3362197346177414\n",
      "Loss = 0.9713418999302302\n",
      "Train accuracy: 0.667\t\tTest accuracy: 0.627\n",
      "Mean abs grad value: 0.01149071603710957\tMax abs grad value: 0.39642806579093204\n",
      "Loss = 0.9339163754371047\n",
      "Train accuracy: 0.699\t\tTest accuracy: 0.664\n",
      "Mean abs grad value: 0.012815105646476577\tMax abs grad value: 0.5045839487301839\n",
      "Loss = 0.9069695690089908\n",
      "Train accuracy: 0.705\t\tTest accuracy: 0.671\n",
      "Mean abs grad value: 0.013714695195617386\tMax abs grad value: 0.5148510006816112\n",
      "Loss = 0.8677435954996103\n",
      "Train accuracy: 0.731\t\tTest accuracy: 0.698\n",
      "Mean abs grad value: 0.007778572625581564\tMax abs grad value: 0.30560917088594625\n",
      "Loss = 0.8312400185318691\n",
      "Train accuracy: 0.748\t\tTest accuracy: 0.709\n",
      "Mean abs grad value: 0.008802109026907362\tMax abs grad value: 0.4540722597083516\n",
      "Loss = 0.803673638157202\n",
      "Train accuracy: 0.763\t\tTest accuracy: 0.724\n",
      "Mean abs grad value: 0.008610041138937234\tMax abs grad value: 0.34268358382248787\n",
      "Loss = 0.7521900960438859\n",
      "Train accuracy: 0.759\t\tTest accuracy: 0.740\n",
      "Mean abs grad value: 0.0083304637677718\tMax abs grad value: 0.20360862346411632\n",
      "Loss = 0.7139645523195346\n",
      "Train accuracy: 0.772\t\tTest accuracy: 0.751\n",
      "Mean abs grad value: 0.007186062848036062\tMax abs grad value: 0.1808028582564678\n",
      "Loss = 0.6828794445087253\n",
      "Train accuracy: 0.774\t\tTest accuracy: 0.742\n",
      "Mean abs grad value: 0.013723065290191329\tMax abs grad value: 0.3516184407690065\n",
      "Loss = 0.6438664437581123\n",
      "Train accuracy: 0.775\t\tTest accuracy: 0.758\n",
      "Mean abs grad value: 0.0073881530213950235\tMax abs grad value: 0.15547210075900347\n",
      "Loss = 0.6105372805812986\n",
      "Train accuracy: 0.794\t\tTest accuracy: 0.758\n",
      "Mean abs grad value: 0.00753068530097269\tMax abs grad value: 0.13111651222754117\n",
      "Loss = 0.5843270838051788\n",
      "Train accuracy: 0.803\t\tTest accuracy: 0.784\n",
      "Mean abs grad value: 0.008528963695573736\tMax abs grad value: 0.15400784236282178\n",
      "Loss = 0.5506121197686042\n",
      "Train accuracy: 0.816\t\tTest accuracy: 0.798\n",
      "Mean abs grad value: 0.025341982098739408\tMax abs grad value: 0.7832020130600742\n",
      "Loss = 0.525653390162858\n",
      "Train accuracy: 0.827\t\tTest accuracy: 0.811\n",
      "Mean abs grad value: 0.009130137301059356\tMax abs grad value: 0.23863890869314808\n",
      "Loss = 0.4703771080849365\n",
      "Train accuracy: 0.842\t\tTest accuracy: 0.820\n",
      "Mean abs grad value: 0.00598239646015803\tMax abs grad value: 0.09834773737350881\n",
      "Loss = 0.44785992285798354\n",
      "Train accuracy: 0.854\t\tTest accuracy: 0.829\n",
      "Mean abs grad value: 0.008453004431425892\tMax abs grad value: 0.19458278986652547\n",
      "Loss = 0.4298538292962697\n",
      "Train accuracy: 0.857\t\tTest accuracy: 0.849\n",
      "Mean abs grad value: 0.006639407477143311\tMax abs grad value: 0.15925278050262395\n",
      "Loss = 0.41083214360485626\n",
      "Train accuracy: 0.861\t\tTest accuracy: 0.853\n",
      "Mean abs grad value: 0.0062336699521375796\tMax abs grad value: 0.1532900416760441\n",
      "Loss = 0.3904872705462609\n",
      "Train accuracy: 0.867\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.011385089566262942\tMax abs grad value: 0.30986290539139466\n",
      "Loss = 0.3848175832011706\n",
      "Train accuracy: 0.870\t\tTest accuracy: 0.858\n",
      "Mean abs grad value: 0.005294553028467533\tMax abs grad value: 0.11899706160912107\n",
      "Loss = 0.37270130742799373\n",
      "Train accuracy: 0.872\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.005192559679504411\tMax abs grad value: 0.10601456952493034\n",
      "Loss = 0.36471977824291285\n",
      "Train accuracy: 0.872\t\tTest accuracy: 0.860\n",
      "Mean abs grad value: 0.0071142227465897405\tMax abs grad value: 0.1771065583442074\n",
      "Loss = 0.35525907950640867\n",
      "Train accuracy: 0.875\t\tTest accuracy: 0.862\n",
      "Mean abs grad value: 0.007820274967239242\tMax abs grad value: 0.2017567650373075\n",
      "Loss = 0.3347922559061976\n",
      "Train accuracy: 0.878\t\tTest accuracy: 0.876\n",
      "Mean abs grad value: 0.026594941564757998\tMax abs grad value: 0.6848552484471095\n",
      "Loss = 0.3435003359625881\n",
      "Mean abs grad value: 0.01343987370883943\tMax abs grad value: 0.3605509388257011\n",
      "Loss = 0.32288815956392436\n",
      "Train accuracy: 0.883\t\tTest accuracy: 0.880\n",
      "Mean abs grad value: 0.0071176904891866975\tMax abs grad value: 0.1588636132725104\n",
      "Loss = 0.3034497914235121\n",
      "Train accuracy: 0.889\t\tTest accuracy: 0.887\n",
      "Mean abs grad value: 0.003920392513100525\tMax abs grad value: 0.09269144651431824\n",
      "Loss = 0.293295145805568\n",
      "Train accuracy: 0.897\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.004763877925489589\tMax abs grad value: 0.0853530025411029\n",
      "Loss = 0.28513124378581317\n",
      "Train accuracy: 0.898\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.004388782838071825\tMax abs grad value: 0.09092796962067809\n",
      "Loss = 0.2793828400584638\n",
      "Train accuracy: 0.901\t\tTest accuracy: 0.893\n",
      "Mean abs grad value: 0.00478269849703987\tMax abs grad value: 0.10883152086295068\n",
      "Loss = 0.2689581171574806\n",
      "Train accuracy: 0.901\t\tTest accuracy: 0.884\n",
      "Mean abs grad value: 0.006145834431538066\tMax abs grad value: 0.13632033437078175\n",
      "Loss = 0.2596624583108992\n",
      "Train accuracy: 0.909\t\tTest accuracy: 0.891\n",
      "Mean abs grad value: 0.004591024438816584\tMax abs grad value: 0.10544795554836711\n",
      "Loss = 0.2506698382008249\n",
      "Train accuracy: 0.906\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.004251855087047835\tMax abs grad value: 0.08436014607287695\n",
      "Loss = 0.24060545349766682\n",
      "Train accuracy: 0.912\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.007816520663945073\tMax abs grad value: 0.2347376247063059\n",
      "Loss = 0.23181447115034645\n",
      "Train accuracy: 0.919\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.005058744314192239\tMax abs grad value: 0.1233074588138546\n",
      "Loss = 0.2243800841291771\n",
      "Train accuracy: 0.922\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.0029599638230386337\tMax abs grad value: 0.08161285359471353\n",
      "Loss = 0.22101037831486758\n",
      "Train accuracy: 0.922\t\tTest accuracy: 0.918\n",
      "Mean abs grad value: 0.002628506935491783\tMax abs grad value: 0.06663891656709879\n",
      "Loss = 0.21647220209453774\n",
      "Train accuracy: 0.924\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.003199948878878443\tMax abs grad value: 0.07448214290566979\n",
      "Loss = 0.21244353592883267\n",
      "Train accuracy: 0.927\t\tTest accuracy: 0.907\n",
      "Mean abs grad value: 0.008030077192532683\tMax abs grad value: 0.22813516668363898\n",
      "Loss = 0.20746633634232192\n",
      "Train accuracy: 0.923\t\tTest accuracy: 0.896\n",
      "Mean abs grad value: 0.0032956547881332083\tMax abs grad value: 0.08511833508447944\n",
      "Loss = 0.1974393391089152\n",
      "Train accuracy: 0.929\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.003136636097382507\tMax abs grad value: 0.06176552553094059\n",
      "Loss = 0.19222394760326098\n",
      "Train accuracy: 0.932\t\tTest accuracy: 0.913\n",
      "Mean abs grad value: 0.002715252584654155\tMax abs grad value: 0.0493548336681746\n",
      "Loss = 0.18799820587623686\n",
      "Train accuracy: 0.926\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.00307364061961477\tMax abs grad value: 0.07292890727748959\n",
      "Loss = 0.18000875157552254\n",
      "Train accuracy: 0.933\t\tTest accuracy: 0.920\n",
      "Mean abs grad value: 0.003909565997861678\tMax abs grad value: 0.1206433921483784\n",
      "Loss = 0.16729192401869333\n",
      "Train accuracy: 0.942\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.009998701489159987\tMax abs grad value: 0.3491978342254652\n",
      "Loss = 0.16964051838804473\n",
      "Mean abs grad value: 0.004284638393296583\tMax abs grad value: 0.10740030453161359\n",
      "Loss = 0.16083148441432377\n",
      "Train accuracy: 0.948\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.002819501236470811\tMax abs grad value: 0.09788238917759673\n",
      "Loss = 0.1545113011537294\n",
      "Train accuracy: 0.948\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0034790378803487843\tMax abs grad value: 0.12304819602176513\n",
      "Loss = 0.1504974429483332\n",
      "Train accuracy: 0.951\t\tTest accuracy: 0.922\n",
      "Mean abs grad value: 0.0027724753151825853\tMax abs grad value: 0.0651032643423931\n",
      "Loss = 0.14773610544359786\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.002938660133848408\tMax abs grad value: 0.07871906475420547\n",
      "Loss = 0.14452333175475293\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0031923679273853107\tMax abs grad value: 0.07740808933123629\n",
      "Loss = 0.1384323367696672\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0041408947463032995\tMax abs grad value: 0.10444500135249125\n",
      "Loss = 0.13293849395624183\n",
      "Train accuracy: 0.957\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.004223037398639921\tMax abs grad value: 0.10291353550782033\n",
      "Loss = 0.12746830518729077\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.002703768070713073\tMax abs grad value: 0.07342513599583755\n",
      "Loss = 0.12413147326628814\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0026541453321794217\tMax abs grad value: 0.06535472189921598\n",
      "Loss = 0.1216493500451044\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0027755420246513176\tMax abs grad value: 0.07778839202972239\n",
      "Loss = 0.11516856525769008\n",
      "Train accuracy: 0.963\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0033094133382994225\tMax abs grad value: 0.11433394649850179\n",
      "Loss = 0.10426770064247107\n",
      "Train accuracy: 0.968\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.012197374056389274\tMax abs grad value: 0.5553471631933041\n",
      "Loss = 0.11896695823112\n",
      "Mean abs grad value: 0.0034798835507704445\tMax abs grad value: 0.08877488376019006\n",
      "Loss = 0.10039764835176164\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.002191144639006783\tMax abs grad value: 0.04259518308971349\n",
      "Loss = 0.09591741859944193\n",
      "Train accuracy: 0.973\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0021345322264367944\tMax abs grad value: 0.058144689601516614\n",
      "Loss = 0.09235347310914188\n",
      "Train accuracy: 0.974\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.003537420416310454\tMax abs grad value: 0.0992623161430513\n",
      "Loss = 0.0876714831795448\n",
      "Train accuracy: 0.972\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0035082871397224386\tMax abs grad value: 0.09620589177178124\n",
      "Loss = 0.0833182780317819\n",
      "Train accuracy: 0.976\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0024002650278641315\tMax abs grad value: 0.05412328268423995\n",
      "Loss = 0.08004145891714624\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.927\n",
      "Mean abs grad value: 0.0025243609652811257\tMax abs grad value: 0.0701743367039123\n",
      "Loss = 0.0760420884270262\n",
      "Train accuracy: 0.977\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0028485678444280333\tMax abs grad value: 0.08877854247464895\n",
      "Loss = 0.07313058017683163\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0024574876817255362\tMax abs grad value: 0.06843150917952646\n",
      "Loss = 0.06910338946249729\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.002140771231681988\tMax abs grad value: 0.06653476014572272\n",
      "Loss = 0.06550377304815101\n",
      "Train accuracy: 0.981\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.002084805449094896\tMax abs grad value: 0.06823565507998827\n",
      "Loss = 0.0627510548581602\n",
      "Train accuracy: 0.985\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0020562318934181905\tMax abs grad value: 0.06105900026875171\n",
      "Loss = 0.05923780450114982\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0039008014481766587\tMax abs grad value: 0.11406425426269047\n",
      "Loss = 0.05721965663524345\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0016604934562122584\tMax abs grad value: 0.044939899890607767\n",
      "Loss = 0.053856646204412204\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0014219588238937393\tMax abs grad value: 0.04372363482367946\n",
      "Loss = 0.0520542417356191\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0016818440789780958\tMax abs grad value: 0.07358411211568154\n",
      "Loss = 0.04928282235740658\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0062966667844265465\tMax abs grad value: 0.21542670628736715\n",
      "Loss = 0.047892416007255766\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0023969760439003164\tMax abs grad value: 0.05499565693221901\n",
      "Loss = 0.0426587983810808\n",
      "Train accuracy: 0.989\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0014567996546487843\tMax abs grad value: 0.027358782622926174\n",
      "Loss = 0.04113473208191724\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001495027324958623\tMax abs grad value: 0.029006523736703742\n",
      "Loss = 0.039774086645042506\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.00265882500592234\tMax abs grad value: 0.07544272344821583\n",
      "Loss = 0.0387015957873539\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.001395220719205586\tMax abs grad value: 0.05465736662798219\n",
      "Loss = 0.03724407962286766\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.001484133184361402\tMax abs grad value: 0.04344814483015009\n",
      "Loss = 0.03599127353531878\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0012738020618117817\tMax abs grad value: 0.022703597887205412\n",
      "Loss = 0.03455318979080465\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.001955880682394404\tMax abs grad value: 0.06405606281261081\n",
      "Loss = 0.032575628337041015\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.0016400592225166663\tMax abs grad value: 0.07038281785124759\n",
      "Loss = 0.030588390119932737\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0017121855546566981\tMax abs grad value: 0.053754774371310356\n",
      "Loss = 0.02905780810303043\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.001560122465478495\tMax abs grad value: 0.0476835990928247\n",
      "Loss = 0.02457168863229433\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.005105707794013815\tMax abs grad value: 0.20824545798707977\n",
      "Loss = 0.02572254090765868\n",
      "Mean abs grad value: 0.002120150991502396\tMax abs grad value: 0.0605977887201526\n",
      "Loss = 0.02306886210780617\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0015410913329499264\tMax abs grad value: 0.056119769292441564\n",
      "Loss = 0.02160248903922889\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.001359947225014778\tMax abs grad value: 0.048540645551197394\n",
      "Loss = 0.02061120058623534\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0009843118292826374\tMax abs grad value: 0.03313650572615502\n",
      "Loss = 0.01961371007173907\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0015756437335546006\tMax abs grad value: 0.043982141867335636\n",
      "Loss = 0.01809370265611396\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0024013741090605513\tMax abs grad value: 0.06363036090276103\n",
      "Loss = 0.017201603872880118\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.001158089234366134\tMax abs grad value: 0.04536931207491562\n",
      "Loss = 0.016369500155162038\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0009404217943813772\tMax abs grad value: 0.03355899627378991\n",
      "Loss = 0.015853737101808492\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0010908124377472647\tMax abs grad value: 0.02621025626460157\n",
      "Loss = 0.015162716274530034\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0012371196165162075\tMax abs grad value: 0.026459735125315596\n",
      "Loss = 0.014093830634493654\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0022743946200923866\tMax abs grad value: 0.07001777335976671\n",
      "Loss = 0.012952597243768672\n",
      "Train accuracy: 0.997\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0011795091830171978\tMax abs grad value: 0.02667556514147146\n",
      "Loss = 0.011508144852320582\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.0011321743566954311\tMax abs grad value: 0.032445792770533464\n",
      "Loss = 0.010532496071790637\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0011362370067524708\tMax abs grad value: 0.022243935228487544\n",
      "Loss = 0.0097718654018338\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0019873292717059216\tMax abs grad value: 0.07382451764772574\n",
      "Loss = 0.008577388531705496\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0013123066943432015\tMax abs grad value: 0.06032939521933759\n",
      "Loss = 0.007661712967610949\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0010518966373117057\tMax abs grad value: 0.031904098129977874\n",
      "Loss = 0.007175974271743764\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.0007695458442122481\tMax abs grad value: 0.01738231619822866\n",
      "Loss = 0.006490124497950228\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.001017623490766965\tMax abs grad value: 0.02455431921085004\n",
      "Loss = 0.0060747069148825855\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0007671506102066065\tMax abs grad value: 0.02036944432717273\n",
      "Loss = 0.00550550835551032\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0006478726957442927\tMax abs grad value: 0.011641551699433752\n",
      "Loss = 0.005012183186417209\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0011209591756938836\tMax abs grad value: 0.032132225571764504\n",
      "Loss = 0.004612722126240946\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.929\n",
      "Mean abs grad value: 0.0004588862229119033\tMax abs grad value: 0.019726305046068558\n",
      "Loss = 0.004125789991363458\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0005159437851937811\tMax abs grad value: 0.021206587669904357\n",
      "Loss = 0.0038644590466223043\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0006661266698167929\tMax abs grad value: 0.02928891622467885\n",
      "Loss = 0.003391827143250191\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0006639928635741201\tMax abs grad value: 0.019216072595202804\n",
      "Loss = 0.0028209288699679565\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.0010576494571260218\tMax abs grad value: 0.03644307095070092\n",
      "Loss = 0.002704445356616127\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.00037185532920954464\tMax abs grad value: 0.008267410170869403\n",
      "Loss = 0.002268379036361429\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.931\n",
      "Mean abs grad value: 0.0003331104372338355\tMax abs grad value: 0.007383643969982117\n",
      "Loss = 0.0021127118372790995\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.933\n",
      "Mean abs grad value: 0.0003741309886813767\tMax abs grad value: 0.012683377612788871\n",
      "Loss = 0.0018159982107357493\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.936\n",
      "Mean abs grad value: 0.000983304466447574\tMax abs grad value: 0.0592702216271927\n",
      "Loss = 0.0018292505061518098\n",
      "Mean abs grad value: 0.00047366776283512687\tMax abs grad value: 0.022094637257592788\n",
      "Loss = 0.0016604060838320302\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.00030147166303347896\tMax abs grad value: 0.009539543992577261\n",
      "Loss = 0.001428312383114622\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.940\n",
      "Mean abs grad value: 0.00022684499362615867\tMax abs grad value: 0.0040028195883773056\n",
      "Loss = 0.0012490711129436915\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0003345948955726822\tMax abs grad value: 0.012854593714081836\n",
      "Loss = 0.001048446877265719\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.00018885381823676621\tMax abs grad value: 0.005659653939307437\n",
      "Loss = 0.0009069255340798803\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00014932220398482457\tMax abs grad value: 0.005394526352635333\n",
      "Loss = 0.0007820511999459624\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00014974392888285798\tMax abs grad value: 0.004251068033641059\n",
      "Loss = 0.000635254845916496\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 0.00014373849484358565\tMax abs grad value: 0.0037032620922240267\n",
      "Loss = 0.000558139067570251\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.0001263894435211429\tMax abs grad value: 0.004039312777175179\n",
      "Loss = 0.0005062664815115473\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.0001419879468908823\tMax abs grad value: 0.0048883659957194665\n",
      "Loss = 0.0004372523072179656\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.949\n",
      "Mean abs grad value: 8.342056321482348e-05\tMax abs grad value: 0.002487493601563955\n",
      "Loss = 0.00032140009840548965\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00010850600007752701\tMax abs grad value: 0.0030738177672055317\n",
      "Loss = 0.0002850187779392107\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 9.826002234709653e-05\tMax abs grad value: 0.004273432705667966\n",
      "Loss = 0.0002550634811342407\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 8.092540667450352e-05\tMax abs grad value: 0.0034481749151714716\n",
      "Loss = 0.00023171698352950922\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 4.250093357248111e-05\tMax abs grad value: 0.0013608839617916992\n",
      "Loss = 0.0001657022175771279\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.4386655339444047e-05\tMax abs grad value: 0.0009116216019474471\n",
      "Loss = 0.0001281633479573695\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.00029036730998476055\tMax abs grad value: 0.006879002783390226\n",
      "Loss = 0.00019652953550313446\n",
      "Mean abs grad value: 6.712902223794812e-05\tMax abs grad value: 0.0019159380012798272\n",
      "Loss = 0.0001125489286097751\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 3.9138699992077754e-05\tMax abs grad value: 0.0012972046396742582\n",
      "Loss = 8.687612452537317e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.6760085658390464e-05\tMax abs grad value: 0.0010904440389607646\n",
      "Loss = 7.014533452763979e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.280347016114573e-05\tMax abs grad value: 0.0005740485456136139\n",
      "Loss = 5.9742898042443853e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.8194454905634502e-05\tMax abs grad value: 0.00039422644258722947\n",
      "Loss = 5.458593074175786e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.2979695717364766e-05\tMax abs grad value: 0.0002776102726243844\n",
      "Loss = 4.815574058178523e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 1.4117211203478445e-05\tMax abs grad value: 0.000304151051339262\n",
      "Loss = 3.920304522580082e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.894790136774245e-05\tMax abs grad value: 0.002313731531143526\n",
      "Loss = 4.775906313852808e-05\n",
      "Mean abs grad value: 1.389930744808191e-05\tMax abs grad value: 0.0006473812931633307\n",
      "Loss = 3.6040542663892074e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.042176133664418e-05\tMax abs grad value: 0.00021767301684916436\n",
      "Loss = 3.139332705355267e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 7.966538627485383e-06\tMax abs grad value: 0.00024914543191002114\n",
      "Loss = 2.6365507772044927e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 8.588495164148741e-06\tMax abs grad value: 0.00015679671264693098\n",
      "Loss = 2.1202173934633425e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 9.930772090621116e-06\tMax abs grad value: 0.00026981370604325016\n",
      "Loss = 1.774894923929479e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 6.338195717378906e-06\tMax abs grad value: 0.00015711375437212725\n",
      "Loss = 1.5926527918787315e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.325868899747401e-06\tMax abs grad value: 0.00010780690110798729\n",
      "Loss = 1.235673094653469e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 4.2448780986668485e-06\tMax abs grad value: 0.00010997051851525698\n",
      "Loss = 9.738068307027155e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.3687239477487074e-05\tMax abs grad value: 0.00030678281932326805\n",
      "Loss = 8.858192878371385e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.04696980220895e-06\tMax abs grad value: 0.00012235932123603617\n",
      "Loss = 6.163838224994251e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 2.6307153716767154e-06\tMax abs grad value: 7.835652243344283e-05\n",
      "Loss = 5.465943564107992e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.92824229729063e-06\tMax abs grad value: 6.756575171217438e-05\n",
      "Loss = 4.413612763589215e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.4907871165680322e-06\tMax abs grad value: 3.206897679102717e-05\n",
      "Loss = 3.397936973967325e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 3.626433315085103e-06\tMax abs grad value: 0.00013426395698238412\n",
      "Loss = 2.7846573842858382e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.2774434953408043e-06\tMax abs grad value: 3.413037672501761e-05\n",
      "Loss = 1.795117077987301e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 9.008567686635331e-07\tMax abs grad value: 2.3546189346553113e-05\n",
      "Loss = 1.4640840780333853e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 4.919633064269845e-07\tMax abs grad value: 1.2715877272671873e-05\n",
      "Loss = 1.0097429057157174e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 1.4997139596897636e-06\tMax abs grad value: 6.664747459271116e-05\n",
      "Loss = 9.484452287670738e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 5.198071500565279e-07\tMax abs grad value: 2.1464537932729665e-05\n",
      "Loss = 6.208097525576412e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 3.1991531892857853e-07\tMax abs grad value: 1.0084628842209918e-05\n",
      "Loss = 5.148205503614725e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 2.1277864985863492e-07\tMax abs grad value: 4.479925203966395e-06\n",
      "Loss = 4.021054282502495e-07\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "i=1\tj=3\tinitialization=0.01\n",
      "Mean abs grad value: 1.444374893808097e-05\tMax abs grad value: 0.006457045787837428\n",
      "Loss = 2.302585403537117\n",
      "Mean abs grad value: 8.147650178124158e-05\tMax abs grad value: 0.05087768388242978\n",
      "Loss = 2.338672887239964\n",
      "Mean abs grad value: 5.648716609693584e-06\tMax abs grad value: 0.0006572430097210734\n",
      "Loss = 2.3018447709752192\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 5.983738067824288e-06\tMax abs grad value: 0.0006083979589654743\n",
      "Loss = 2.3018387704674876\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 7.63024353222495e-06\tMax abs grad value: 0.0006310236245973826\n",
      "Loss = 2.301825392863093\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 2.629524191612692e-05\tMax abs grad value: 0.003354376374769465\n",
      "Loss = 2.3017523182981585\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 0.00029626762410660295\tMax abs grad value: 0.014597611656923824\n",
      "Loss = 2.2992001823820543\n",
      "Mean abs grad value: 0.20525324038044673\tMax abs grad value: 15.042906942188797\n",
      "Loss = 12.744790823637354\n",
      "Mean abs grad value: 0.0006070527663508676\tMax abs grad value: 0.03144449322469274\n",
      "Loss = 2.2989001228016335\n",
      "Mean abs grad value: 0.0003807973294527655\tMax abs grad value: 0.020096593770392638\n",
      "Loss = 2.2986776976597634\n",
      "Mean abs grad value: 0.00045386725422218887\tMax abs grad value: 0.024411533819398416\n",
      "Loss = 2.2985496439080615\n",
      "Train accuracy: 0.099\t\tTest accuracy: 0.107\n",
      "Mean abs grad value: 0.092479503776614\tMax abs grad value: 6.732472275218484\n",
      "Loss = 5.296088378117421\n",
      "Mean abs grad value: 0.000983793362354586\tMax abs grad value: 0.04570980607758117\n",
      "Loss = 2.3012773065952588\n",
      "Mean abs grad value: 0.00046866980348917917\tMax abs grad value: 0.02515635464358172\n",
      "Loss = 2.2985443137758144\n",
      "Train accuracy: 0.099\t\tTest accuracy: 0.107\n",
      "Mean abs grad value: 0.000547972247305082\tMax abs grad value: 0.026701187492479836\n",
      "Loss = 2.2976445581133667\n",
      "Mean abs grad value: 0.0008925162874102247\tMax abs grad value: 0.033821363567660835\n",
      "Loss = 2.2933694515238576\n",
      "Mean abs grad value: 0.0045365896681046165\tMax abs grad value: 0.11745175171096872\n",
      "Loss = 2.2668005861514913\n",
      "Mean abs grad value: 0.14073512145245634\tMax abs grad value: 6.446996495472659\n",
      "Loss = 5.196986555428456\n",
      "Mean abs grad value: 0.0070724332488480545\tMax abs grad value: 0.2118468979935737\n",
      "Loss = 2.2605212042979677\n",
      "Train accuracy: 0.109\t\tTest accuracy: 0.120\n",
      "Mean abs grad value: nan\tMax abs grad value: nan\n",
      "Loss = 3519786537.727192\n",
      "Mean abs grad value: 0.0070724332488480545\tMax abs grad value: 0.2118468979935737\n",
      "Loss = 2.2605212042979677\n",
      "Train accuracy: 0.109\t\tTest accuracy: 0.120\n",
      "i=1\tj=4\tinitialization=0.01\n",
      "Mean abs grad value: 1.742473790308373e-05\tMax abs grad value: 0.006461576898008907\n",
      "Loss = 2.3025847099881394\n",
      "Mean abs grad value: 8.458558790149245e-05\tMax abs grad value: 0.049812456890637416\n",
      "Loss = 2.337079587456225\n",
      "Mean abs grad value: 8.766817816872984e-06\tMax abs grad value: 0.0003574214423331689\n",
      "Loss = 2.301836964547178\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 9.846015444994386e-06\tMax abs grad value: 0.0008357821091282759\n",
      "Loss = 2.301823885794255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:29: RuntimeWarning: overflow encountered in exp\n",
      "  exp_arr = np.exp(self.input)\n",
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:34: RuntimeWarning: invalid value encountered in multiply\n",
      "  d_loss_d_x = grad_output - exp_arr * (grad_output_sum / exp_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean abs grad value: 1.6140387667758695e-05\tMax abs grad value: 0.0012593871601884873\n",
      "Loss = 2.3017878270717786\n",
      "Train accuracy: 0.106\t\tTest accuracy: 0.084\n",
      "Mean abs grad value: 7.92909190704993e-05\tMax abs grad value: 0.0048037258978807515\n",
      "Loss = 2.301526475989673\n",
      "Mean abs grad value: 0.0008785059447433103\tMax abs grad value: 0.03383317496256079\n",
      "Loss = 2.2931659132675266\n",
      "Mean abs grad value: 0.06300911096207791\tMax abs grad value: 2.7795702656771795\n",
      "Loss = 2.528290340608949\n",
      "Mean abs grad value: 0.005026905734996625\tMax abs grad value: 0.16272714119096202\n",
      "Loss = 2.2223549099982063\n",
      "Mean abs grad value: 0.017564625036870247\tMax abs grad value: 0.7224712726573383\n",
      "Loss = 2.1541483436691062\n",
      "Train accuracy: 0.171\t\tTest accuracy: 0.178\n",
      "Mean abs grad value: nan\tMax abs grad value: nan\n",
      "Loss = 616956.1298354297\n",
      "Mean abs grad value: 0.017564625036870247\tMax abs grad value: 0.7224712726573383\n",
      "Loss = 2.1541483436691062\n",
      "Train accuracy: 0.171\t\tTest accuracy: 0.178\n",
      "i=2\tj=0\tinitialization=0.1\n",
      "Mean abs grad value: 0.008845698807106688\tMax abs grad value: 0.38705480869369513\n",
      "Loss = 2.425537255347444\n",
      "Mean abs grad value: 0.003882253730494852\tMax abs grad value: 0.09704082882429566\n",
      "Loss = 2.2264221609530184\n",
      "Train accuracy: 0.161\t\tTest accuracy: 0.140\n",
      "Mean abs grad value: 0.005820428495318323\tMax abs grad value: 0.14473984728188857\n",
      "Loss = 2.052053103619137\n",
      "Train accuracy: 0.321\t\tTest accuracy: 0.320\n",
      "Mean abs grad value: 0.061765053734563535\tMax abs grad value: 5.840898752491773\n",
      "Loss = 4.314803219853167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:29: RuntimeWarning: overflow encountered in exp\n",
      "  exp_arr = np.exp(self.input)\n",
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8532\\3318986900.py:34: RuntimeWarning: invalid value encountered in multiply\n",
      "  d_loss_d_x = grad_output - exp_arr * (grad_output_sum / exp_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean abs grad value: 0.010761253308638677\tMax abs grad value: 0.17862162186969407\n",
      "Loss = 1.912825376395587\n",
      "Train accuracy: 0.294\t\tTest accuracy: 0.293\n",
      "Mean abs grad value: 0.009142794788304803\tMax abs grad value: 0.18335203830701993\n",
      "Loss = 1.785584118412066\n",
      "Train accuracy: 0.290\t\tTest accuracy: 0.293\n",
      "Mean abs grad value: 0.006797060179516643\tMax abs grad value: 0.12917826324456427\n",
      "Loss = 1.6759330470995513\n",
      "Train accuracy: 0.350\t\tTest accuracy: 0.324\n",
      "Mean abs grad value: 0.008319141100218289\tMax abs grad value: 0.3106959745883373\n",
      "Loss = 1.505746847381473\n",
      "Train accuracy: 0.436\t\tTest accuracy: 0.424\n",
      "Mean abs grad value: 0.0076371233620929615\tMax abs grad value: 0.28542268245173746\n",
      "Loss = 1.3198489319408562\n",
      "Train accuracy: 0.566\t\tTest accuracy: 0.562\n",
      "Mean abs grad value: 0.03474356786717843\tMax abs grad value: 2.0967724413115834\n",
      "Loss = 1.4343975275127463\n",
      "Mean abs grad value: 0.010237227698634482\tMax abs grad value: 0.357803211687071\n",
      "Loss = 1.1704722919445956\n",
      "Train accuracy: 0.584\t\tTest accuracy: 0.576\n",
      "Mean abs grad value: 0.022043834304651427\tMax abs grad value: 0.8143839334289475\n",
      "Loss = 1.0872025632492608\n",
      "Mean abs grad value: 0.01143381908276904\tMax abs grad value: 0.48790207394447166\n",
      "Loss = 1.0261663066835955\n",
      "Train accuracy: 0.641\t\tTest accuracy: 0.629\n",
      "Mean abs grad value: 0.032780868954809916\tMax abs grad value: 2.520350974207249\n",
      "Loss = 1.1501404171663099\n",
      "Mean abs grad value: 0.011461801616506867\tMax abs grad value: 0.6442453861165298\n",
      "Loss = 0.9176324373122712\n",
      "Train accuracy: 0.640\t\tTest accuracy: 0.633\n",
      "Mean abs grad value: 0.009234528670858857\tMax abs grad value: 0.3929541226147387\n",
      "Loss = 0.7799569325467561\n",
      "Train accuracy: 0.728\t\tTest accuracy: 0.682\n",
      "Mean abs grad value: 0.019648067282683788\tMax abs grad value: 1.3023447392107488\n",
      "Loss = 0.7913699085331551\n",
      "Mean abs grad value: 0.008007595861441123\tMax abs grad value: 0.37509719219933113\n",
      "Loss = 0.7335611089822319\n",
      "Train accuracy: 0.763\t\tTest accuracy: 0.693\n",
      "Mean abs grad value: 0.007632467887922294\tMax abs grad value: 0.4551558118532201\n",
      "Loss = 0.6924939858835512\n",
      "Train accuracy: 0.759\t\tTest accuracy: 0.718\n",
      "Mean abs grad value: 0.007359571565575761\tMax abs grad value: 0.1766080159871794\n",
      "Loss = 0.6470077893725126\n",
      "Train accuracy: 0.786\t\tTest accuracy: 0.744\n",
      "Mean abs grad value: 0.006523960573146637\tMax abs grad value: 0.2585561405850355\n",
      "Loss = 0.5819936786160076\n",
      "Train accuracy: 0.823\t\tTest accuracy: 0.782\n",
      "Mean abs grad value: 0.006322968040954697\tMax abs grad value: 0.2490827505286836\n",
      "Loss = 0.5403653120946778\n",
      "Train accuracy: 0.838\t\tTest accuracy: 0.791\n",
      "Mean abs grad value: 0.004879527336960602\tMax abs grad value: 0.13069013114637829\n",
      "Loss = 0.5034122510935464\n",
      "Train accuracy: 0.855\t\tTest accuracy: 0.804\n",
      "Mean abs grad value: 0.005297218705309457\tMax abs grad value: 0.152011337160044\n",
      "Loss = 0.45537310351908405\n",
      "Train accuracy: 0.865\t\tTest accuracy: 0.816\n",
      "Mean abs grad value: 0.006423891689599718\tMax abs grad value: 0.21801047926607925\n",
      "Loss = 0.39163207248277193\n",
      "Train accuracy: 0.878\t\tTest accuracy: 0.844\n",
      "Mean abs grad value: 0.015107131696837724\tMax abs grad value: 0.5143207164332396\n",
      "Loss = 0.3614864587185869\n",
      "Train accuracy: 0.883\t\tTest accuracy: 0.867\n",
      "Mean abs grad value: 0.004437095406601842\tMax abs grad value: 0.16361015638839915\n",
      "Loss = 0.29182739784625106\n",
      "Train accuracy: 0.914\t\tTest accuracy: 0.889\n",
      "Mean abs grad value: 0.004034557628082689\tMax abs grad value: 0.09365642420393562\n",
      "Loss = 0.2710547935254077\n",
      "Train accuracy: 0.918\t\tTest accuracy: 0.900\n",
      "Mean abs grad value: 0.004788881475923104\tMax abs grad value: 0.15214945836671329\n",
      "Loss = 0.24520517178957688\n",
      "Train accuracy: 0.921\t\tTest accuracy: 0.896\n",
      "Mean abs grad value: 0.010202149631168105\tMax abs grad value: 0.44877138842796693\n",
      "Loss = 0.23863504685526965\n",
      "Train accuracy: 0.923\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.003356824414950701\tMax abs grad value: 0.10040996436228004\n",
      "Loss = 0.21175917559374063\n",
      "Train accuracy: 0.932\t\tTest accuracy: 0.911\n",
      "Mean abs grad value: 0.0032531066673907845\tMax abs grad value: 0.062389987095262465\n",
      "Loss = 0.20414880064032195\n",
      "Train accuracy: 0.931\t\tTest accuracy: 0.909\n",
      "Mean abs grad value: 0.003922901867180899\tMax abs grad value: 0.10670862490910443\n",
      "Loss = 0.19034832022218334\n",
      "Train accuracy: 0.937\t\tTest accuracy: 0.916\n",
      "Mean abs grad value: 0.00458957145089109\tMax abs grad value: 0.11011122200805558\n",
      "Loss = 0.1662764579287677\n",
      "Train accuracy: 0.949\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.012776384201012141\tMax abs grad value: 0.30563772882176443\n",
      "Loss = 0.17527112670640643\n",
      "Mean abs grad value: 0.005359949815750801\tMax abs grad value: 0.1445893796196922\n",
      "Loss = 0.15363501614520705\n",
      "Train accuracy: 0.952\t\tTest accuracy: 0.944\n",
      "Mean abs grad value: 0.003139156618653562\tMax abs grad value: 0.06804491272251563\n",
      "Loss = 0.14037429452171007\n",
      "Train accuracy: 0.955\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.002053991441036745\tMax abs grad value: 0.05945002707318836\n",
      "Loss = 0.12930382702356355\n",
      "Train accuracy: 0.954\t\tTest accuracy: 0.942\n",
      "Mean abs grad value: 0.0024894779904583303\tMax abs grad value: 0.07592492152501462\n",
      "Loss = 0.12170758651184184\n",
      "Train accuracy: 0.959\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.008042869472920527\tMax abs grad value: 0.2465254040035853\n",
      "Loss = 0.11664472214794853\n",
      "Train accuracy: 0.958\t\tTest accuracy: 0.938\n",
      "Mean abs grad value: 0.003079071628027063\tMax abs grad value: 0.09073083403214342\n",
      "Loss = 0.10190193626231232\n",
      "Train accuracy: 0.967\t\tTest accuracy: 0.947\n",
      "Mean abs grad value: 0.002193528043981858\tMax abs grad value: 0.05183586622103254\n",
      "Loss = 0.09441333317716386\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0020458383362852418\tMax abs grad value: 0.06716784054549038\n",
      "Loss = 0.08654561012782626\n",
      "Train accuracy: 0.969\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.003255319289744672\tMax abs grad value: 0.10074801292981563\n",
      "Loss = 0.07948582842785638\n",
      "Train accuracy: 0.970\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.003431170772272886\tMax abs grad value: 0.1265995653509074\n",
      "Loss = 0.07235272367541415\n",
      "Train accuracy: 0.978\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0023698145628564\tMax abs grad value: 0.07992657095076756\n",
      "Loss = 0.0649984729447421\n",
      "Train accuracy: 0.979\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0029173605442795337\tMax abs grad value: 0.0841259128879248\n",
      "Loss = 0.05321194803530566\n",
      "Train accuracy: 0.983\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0023163503402470727\tMax abs grad value: 0.08110160907758972\n",
      "Loss = 0.04723678684840069\n",
      "Train accuracy: 0.984\t\tTest accuracy: 0.953\n",
      "Mean abs grad value: 0.0027173344910199296\tMax abs grad value: 0.05690431293242559\n",
      "Loss = 0.0420287359533063\n",
      "Train accuracy: 0.987\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.00219300085328785\tMax abs grad value: 0.03943442025102597\n",
      "Loss = 0.03696615551377386\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0022335287776854805\tMax abs grad value: 0.04866574310994257\n",
      "Loss = 0.031601364240987875\n",
      "Train accuracy: 0.990\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0022552360667398423\tMax abs grad value: 0.06979325666830094\n",
      "Loss = 0.029770421205653205\n",
      "Train accuracy: 0.991\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.001378712910237759\tMax abs grad value: 0.028618808191844477\n",
      "Loss = 0.02821634425913085\n",
      "Train accuracy: 0.992\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0010825531545927392\tMax abs grad value: 0.02952535424299298\n",
      "Loss = 0.02626191566019338\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0013548515550507552\tMax abs grad value: 0.03841931783146562\n",
      "Loss = 0.024286847528505205\n",
      "Train accuracy: 0.993\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0015573393072593508\tMax abs grad value: 0.03141299595167935\n",
      "Loss = 0.01986525842297967\n",
      "Train accuracy: 0.995\t\tTest accuracy: 0.951\n",
      "Mean abs grad value: 0.001570452921046089\tMax abs grad value: 0.04846332717734224\n",
      "Loss = 0.01609737163975455\n",
      "Train accuracy: 0.994\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.001245616989897396\tMax abs grad value: 0.02674668369928002\n",
      "Loss = 0.013857353810192473\n",
      "Train accuracy: 0.996\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0009411124077591762\tMax abs grad value: 0.026517764994985846\n",
      "Loss = 0.012131958739214027\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.0010154613953100489\tMax abs grad value: 0.020942706518853403\n",
      "Loss = 0.010459074111654691\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.956\n",
      "Mean abs grad value: 0.0007968367599482186\tMax abs grad value: 0.021573377126842784\n",
      "Loss = 0.008466226828696606\n",
      "Train accuracy: 0.999\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.0008135402538017995\tMax abs grad value: 0.018513894505798812\n",
      "Loss = 0.006763040574381778\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0009603939281287513\tMax abs grad value: 0.03383793204715933\n",
      "Loss = 0.004701515737116648\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.967\n",
      "Mean abs grad value: 0.001308379054319778\tMax abs grad value: 0.031331107948546245\n",
      "Loss = 0.004116958177315603\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 0.0006668265608188319\tMax abs grad value: 0.017374454726968993\n",
      "Loss = 0.0035188604573586062\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0004218074050572418\tMax abs grad value: 0.009238279378342894\n",
      "Loss = 0.0030760756251100065\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.0003843506287686349\tMax abs grad value: 0.007191448566499756\n",
      "Loss = 0.002376380159006314\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.958\n",
      "Mean abs grad value: 0.000301755419440805\tMax abs grad value: 0.00615255054818088\n",
      "Loss = 0.0016831975663392288\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.001388959909772109\tMax abs grad value: 0.0519163051988547\n",
      "Loss = 0.0018559026372820435\n",
      "Mean abs grad value: 0.0003988341070948188\tMax abs grad value: 0.011902515665401266\n",
      "Loss = 0.001252545028813799\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00015327222934517122\tMax abs grad value: 0.0028460989715019614\n",
      "Loss = 0.0008764707958280332\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00010609923170415097\tMax abs grad value: 0.0016826723584614316\n",
      "Loss = 0.0007368816511696278\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 0.00011194546632891629\tMax abs grad value: 0.0024742287961628524\n",
      "Loss = 0.0005373933062930439\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 0.00011691146985518017\tMax abs grad value: 0.002478951962540912\n",
      "Loss = 0.0003442238563755803\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.964\n",
      "Mean abs grad value: 6.38389797263929e-05\tMax abs grad value: 0.0013127785231042426\n",
      "Loss = 0.00023312664900330097\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 4.764108482388865e-05\tMax abs grad value: 0.0009847199663294778\n",
      "Loss = 0.000167886032909523\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 6.800421824805157e-05\tMax abs grad value: 0.0019156378551351777\n",
      "Loss = 0.00012625754775406206\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 6.762567493110241e-05\tMax abs grad value: 0.0017623778549776083\n",
      "Loss = 0.00011406574584593075\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 3.3451398506235954e-05\tMax abs grad value: 0.0007220997069489867\n",
      "Loss = 9.2489577049746e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 2.133999216795675e-05\tMax abs grad value: 0.0004526554187557642\n",
      "Loss = 7.752476986900759e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.962\n",
      "Mean abs grad value: 1.721406735779399e-05\tMax abs grad value: 0.0002631966550995764\n",
      "Loss = 5.8842085778801254e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.6216110603358593e-05\tMax abs grad value: 0.00033039149824745455\n",
      "Loss = 3.96832540265194e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 1.4049254453761271e-05\tMax abs grad value: 0.00031423405841204407\n",
      "Loss = 2.1077292267678597e-05\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n",
      "Mean abs grad value: 6.647418614609603e-06\tMax abs grad value: 0.00020101272524766315\n",
      "Loss = 9.895854687651274e-06\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "layer_c = 4\n",
    "\n",
    "for i, initialization in enumerate(init_vars):\n",
    "    for j in range(5):\n",
    "        print(f\"{i=}\\t{j=}\\t{initialization=}\")\n",
    "        network = make_network(input_size, 32, output_size, layer_c, ReLU)\n",
    "        initialize_network(network, initialization)\n",
    "        network, cb = train_network(network, history=True)\n",
    "        \n",
    "        accs_train[i, j] = cb.train_acc[-1]\n",
    "        accs_test[i, j] = cb.test_acc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Построим боксплоты полученного качества (горизонтальная линия в каждом столбце — среднее, прямоугольник показывает разброс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.604929Z"
    }
   },
   "outputs": [],
   "source": [
    "init_vars_for_plot = [(x if isinstance(x, str) else fr\"$\\sigma = {x}$\") for x in init_vars]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_test.T, labels=init_vars_for_plot, showfliers=False)\n",
    "\n",
    "ax.set_title(\"Test quality in 5 runs\")\n",
    "ax.set_xlabel(\"Initialization\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `5 слоев`\n",
    "\n",
    "Выполните тут тот же код, что и в предыдущем пункте, но только уже с 5 слоями в сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.605926200Z"
    }
   },
   "outputs": [],
   "source": [
    "init_vars = [1e-2, 1e-1, 1e0, 'Kaiming', 'Xavier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:37:01.675925600Z",
     "start_time": "2024-02-22T20:37:01.606926100Z"
    }
   },
   "outputs": [],
   "source": [
    "accs_train = np.zeros((5, 5))\n",
    "accs_test = np.zeros((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.608925600Z"
    }
   },
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Построим боксплоты полученного качества (горизонтальная линия в каждом столбце — среднее, прямоугольник показывает разброс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.609925900Z"
    }
   },
   "outputs": [],
   "source": [
    "init_vars_for_plot = [(x if isinstance(x, str) else fr\"$\\sigma = {x}$\") for x in init_vars]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_test.T, labels=init_vars_for_plot, showfliers=False)\n",
    "\n",
    "ax.set_title(\"Test quality in 5 runs\")\n",
    "ax.set_xlabel(\"Initialization\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Дайте развёрнутый ответ на вопросы (в этой же ячейке):\n",
    "* Как отличаются качество на обучении и контроле и устойчивость процесса обучения при различных инициализациях?\n",
    "* Какие инициализации помогают обучать более глубокие сети?\n",
    "\n",
    "__Ответы:__\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь сравним скорость обучения при различных инициализациях. Создайте два списка списков `accs_test_on_iterations`, `accs_train_on_iterations` в каждом из которых в позиции `[i]` (см. описание `i` в предыдущем пункте) будет лежать список из значений `accuracy` на тестовой и обучающей выборках соотвественно, полученных во время обучения модели. Количество слоев в сети зафиксируйте равным 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.610926100Z"
    }
   },
   "outputs": [],
   "source": [
    "init_vars = [1e-3, 1e-2, 1e-1, 'Kaiming', 'Xavier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.611926Z"
    }
   },
   "outputs": [],
   "source": [
    "accs_test_on_iterations = []\n",
    "accs_train_on_iterations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.612925900Z"
    }
   },
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.613926700Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "for idx, label in enumerate(init_vars_for_plot):\n",
    "    ax.plot(accs_test_on_iterations[idx], label=label)\n",
    "\n",
    "ax.set_title(\"Test quality for different initializations\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:37:15.087902Z",
     "start_time": "2021-03-03T14:37:15.065996Z"
    },
    "hidden": true
   },
   "source": [
    "Дайте развёрнутый ответ на вопросы (в этой же ячейке):\n",
    "* Как меняется скорость обучения в зависимости от выбранной инициализации?\n",
    "\n",
    "__Ответы:__\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Эксперименты c различными функциями активации (0.6 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Проверим теперь, с какой функцией активации нейронная сеть будет обучаться лучше.\n",
    "\n",
    "В этом пункте вам предлагается попробовать обучить несколько нейронных сетей с различными функциями активации.\n",
    "\n",
    "Для этого нам нужно реализовать еще 2 слоя: для функций активации `Tanh` и `Sigmoid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:37:14.845236900Z",
     "start_time": "2024-02-22T20:37:14.830020300Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tanh(Layer):\n",
    "    \"\"\"\n",
    "    tanh(y) = (e^y - e^(-y)) / (e^y + e^(-y))\n",
    "    Используйте функцию np.tanh для подсчета гиперболического тангенса.\n",
    "    Вы можете сами реализовать подсчет tanh, но тогда вам нужно устойчиво его вычислять.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.params = [] # Tanh has no parameters\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Apply elementwise Tanh to [batch, num_units] matrix\n",
    "        \"\"\"\n",
    "        self.cosh = np.cosh(input)\n",
    "        return np.sinh(input) / self.cosh\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Compute gradient of loss w.r.t. Tanh input\n",
    "        grad_output shape: [batch, num_units]\n",
    "        output 1 shape: [batch, num_units]\n",
    "        output 2: []\n",
    "        \"\"\"\n",
    "        return -grad_output / np.power(self.cosh, 2)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Tanh()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:37:15.096507600Z",
     "start_time": "2024-02-22T20:37:15.056879100Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "    \n",
    "class Sigmoid(Layer):\n",
    "    \"\"\"\n",
    "    sigmoid(y) = 1 / (1 + e^(-y))\n",
    "    Используйте функцию expit для подсчета сигмоиды.\n",
    "    Вы можете сами реализовать подсчет сигмоиды, но тогда вам нужно устойчиво ее вычислять.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.params = [] # Sigmoid has no parameters\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Apply elementwise Sigmoid to [batch, num_units] matrix\n",
    "        \"\"\"\n",
    "        self.output = expit(input)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Compute gradient of loss w.r.t. Sigmoid input\n",
    "        grad_output shape: [batch, num_units]\n",
    "        output 1 shape: [batch, num_units]\n",
    "        output 2: []\n",
    "        \"\"\"\n",
    "        return self.output * (1 - self.output) * grad_output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Sigmoid()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь попробуйте для каждой из 3 функций активации обучить нейронную сеть несколько раз. Число слоев зафиксируйте равным 3. В случае `Tanh` и `Sigmoid` используйте инициализацию `Xavier`, а в случае `ReLU` используйте инициализацию `Kaiming`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Заполните матрицы `accs_train` и `accs_test`. В позиции `[i, j]` должна стоять величина доли правильных ответов сети при $j$-м запуске (все запуски идентичны) с функцией активации $ReLU$ при $i = 0$, с функцией активации $Tanh$ при $i = 1$ и с функцией активации $Sigmoid$ при $i = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:37:17.197965800Z",
     "start_time": "2024-02-22T20:37:17.185959700Z"
    }
   },
   "outputs": [],
   "source": [
    "act_func_vars = ['Tanh', 'Sigmoid', 'ReLU']\n",
    "init_for_act_funcs = ['Xavier', 'Xavier', 'Kaiming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.617926400Z"
    }
   },
   "outputs": [],
   "source": [
    "accs_train = np.zeros((3, 50))\n",
    "accs_test = np.zeros_like(accs_train)\n",
    "layer_c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.618927100Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for i, (act_func, init_strategy) in enumerate(zip(act_func_vars, init_for_act_funcs)):\n",
    "    for j in range(accs_train.shape[1]):\n",
    "        # print(f\"{i=}\\t{act_func=}\\t{init_strategy=}\")\n",
    "        network = make_network(input_size, 32, output_size, layer_c, ReLU)\n",
    "        initialize_network(network, init_strategy)\n",
    "        network, cb = train_network(network, history=True)\n",
    "        \n",
    "        accs_train[i, j] = cb.train_acc[-1]\n",
    "        accs_test[i, j] = cb.test_acc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Построим боксплоты полученного качества (горизонтальная линия в каждом столбце — среднее, прямоугольник показывает разброс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.620928400Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_test.T, labels=act_func_vars, showfliers=False)\n",
    "\n",
    "ax.set_title(f\"Test quality in {accs_train.shape[1]} runs with {layer_c} layers\")\n",
    "ax.set_xlabel(\"Activation function\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Дайте развёрнутый ответ на вопросы (в этой же ячейке):\n",
    "* Как отличаются качество на обучении и контроле и устойчивость процесса обучения при различных функциях активации?\n",
    "\n",
    "__Ответы:__\n",
    "\n",
    "При использовании в качестве функций активации сигмоиды и гиперболического тангенса среднее качество оказывается сравнимым. Однако, дисперсия при использовании сигмоиды оказывается выше. \n",
    "При использовании ReLU среднее качество оказывается ниже.\n",
    "\n",
    "Преимущества ReLU не реализуются при малом количестве слоев (3), так как затухание градиентов оказывается незначительным. \n",
    "Для проверки данной гипотезы будет поставлен *дополнительный* эксперимент с количеством слоев = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accs_train = np.zeros((3, 15))\n",
    "accs_test = np.zeros_like(accs_train)\n",
    "layer_c = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.621927100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for i, (act_func, init_strategy) in enumerate(zip(act_func_vars, init_for_act_funcs)):\n",
    "    for j in range(accs_train.shape[1]):\n",
    "        # print(f\"{i=}\\t{act_func=}\\t{init_strategy=}\")\n",
    "        network = make_network(input_size, 32, output_size, layer_c, ReLU)\n",
    "        initialize_network(network, init_strategy)\n",
    "        network, cb = train_network(network, history=True)\n",
    "        \n",
    "        accs_train[i, j] = cb.train_acc[-1]\n",
    "        accs_test[i, j] = cb.test_acc[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.622926900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assert False, \"READ TODO\"\n",
    "\n",
    "# TODO:\n",
    "#  Implement clear and stable realization for logSoftMax "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.623926400Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_test.T, labels=act_func_vars, showfliers=False)\n",
    "\n",
    "ax.set_title(f\"Test quality in {accs_train.shape[1]} runs\")\n",
    "ax.set_xlabel(\"Activation function\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:37:01.624926300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\* Несколько фрагментов кода в задании написаны на основе материалов [курса по глубинному обучению на ФКН НИУ ВШЭ](https://www.hse.ru/ba/ami/courses/205504078.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Реализация метода оптимизации (1.4 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части задания реализуйте метод оптимизации SGD + momentum. Упрощённая версия более общего алгоритма [отсюда](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    &\\rule{70mm}{0.4pt}                                                             \\\\\n",
    "    &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\theta_0 \\text{ (params)}, \\: X \\text{ (data)},       \\\\\n",
    "    &\\hspace{13mm} \\: f(\\theta) \\text{ (objective)}, \\:\\mu \\text{ (momentum)}       \\\\[-1.ex]\n",
    "    &\\rule{70mm}{0.4pt}                                                             \\\\\n",
    "    &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                    \\\\\n",
    "    &\\hspace{5mm}\\mathcal{X} \\leftarrow \\texttt{list\\_of\\_random\\_batches}(X)\\\\\n",
    "    &\\hspace{5mm}\\textbf{for} \\: i=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                    \\\\\n",
    "    &\\hspace{10mm}g_t\\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1},\\mathcal{X}_i)      \\\\\n",
    "    &\\hspace{10mm}\\textbf{if} \\: \\mu \\neq 0                                          \\\\\n",
    "    &\\hspace{15mm}\\textbf{if} \\: t > 1                                              \\\\\n",
    "    &\\hspace{20mm} \\textbf{b}_t \\leftarrow \\mu \\textbf{b}_{t-1} + g_t               \\\\\n",
    "    &\\hspace{15mm}\\textbf{else}                                                     \\\\\n",
    "    &\\hspace{20mm} \\textbf{b}_t \\leftarrow g_t                                      \\\\\n",
    "    &\\hspace{15mm} g_t  \\leftarrow  \\textbf{b}_t                                     \\\\\n",
    "    &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma g_t                      \\\\[-1.ex]\n",
    "    &\\rule{70mm}{0.4pt}                                                             \\\\[-1.ex]\n",
    "    &\\bf{return} \\:  \\theta_t                                                       \\\\[-1.ex]\n",
    "    &\\rule{70mm}{0.4pt}                                                             \\\\[-1.ex]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Проще всего будет написать `custom minimizer` (смотри [документацию scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T20:49:27.986608Z",
     "start_time": "2024-02-22T20:49:27.699598800Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import OptimizeResult\n",
    "\n",
    "\n",
    "def SGD(fun, x0, args, **kwargs) -> OptimizeResult:\n",
    "    callback = kwargs['callback']   # feed weights from each iteration to update network and log metrics\n",
    "    mu = kwargs['momentum']\n",
    "    n_iter = kwargs['n_iter']\n",
    "    gamma = kwargs['lr']\n",
    "    jac = kwargs['jac']\n",
    "    batch_size = kwargs['batch_size']\n",
    "    \n",
    "    net, X, y = args\n",
    "    \n",
    "    m = 0.0\n",
    "    weights = x0\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        batch_indxs = np.array_split(np.arange(X.shape[0]), X.shape[0] // batch_size)\n",
    "        loss_sum = 0.0\n",
    "        \n",
    "        for batch_ind in batch_indxs:\n",
    "            # print(batch_ind)\n",
    "            loss = fun(weights, (net, X[batch_ind, :], y[batch_ind]))\n",
    "            grad = fun.derivative(weights)\n",
    "            m = mu * m + grad\n",
    "            weights -= gamma * m\n",
    "            loss_sum += loss\n",
    "        \n",
    "        print(f\"Iteration {i}: loss = {loss_sum:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1. (0.5 балла)** Продемонстрируйте правильную работу метода оптимизации, получив `test_accuracy>=0.9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T20:52:04.482626400Z",
     "start_time": "2024-02-22T20:52:00.990937700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: loss = 60.252682\n",
      "Iteration 1: loss = 24.264407\n",
      "Iteration 2: loss = 18.692276\n",
      "Iteration 3: loss = 11.848819\n",
      "Iteration 4: loss = 7.065344\n",
      "Iteration 5: loss = 5.186252\n",
      "Iteration 6: loss = 3.666945\n",
      "Iteration 7: loss = 2.835087\n",
      "Iteration 8: loss = 2.230941\n",
      "Iteration 9: loss = 1.808874\n",
      "Iteration 10: loss = 1.516887\n",
      "Iteration 11: loss = 1.306235\n",
      "Iteration 12: loss = 1.142942\n",
      "Iteration 13: loss = 1.043059\n",
      "Iteration 14: loss = 0.903389\n",
      "Iteration 15: loss = 0.793428\n",
      "Iteration 16: loss = 0.740664\n",
      "Iteration 17: loss = 0.720671\n",
      "Iteration 18: loss = 0.706397\n",
      "Iteration 19: loss = 0.691032\n",
      "Iteration 20: loss = 0.688205\n",
      "Iteration 21: loss = 0.626603\n",
      "Iteration 22: loss = 0.547690\n",
      "Iteration 23: loss = 0.723083\n",
      "Iteration 24: loss = 0.662234\n",
      "Iteration 25: loss = 0.749568\n",
      "Iteration 26: loss = 0.804677\n",
      "Iteration 27: loss = 1.128857\n",
      "Iteration 28: loss = 1.420130\n",
      "Iteration 29: loss = 1.150240\n",
      "Iteration 30: loss = 0.738402\n",
      "Iteration 31: loss = 0.396303\n",
      "Iteration 32: loss = 0.313046\n",
      "Iteration 33: loss = 0.218698\n",
      "Iteration 34: loss = 0.129441\n",
      "Iteration 35: loss = 0.107239\n",
      "Iteration 36: loss = 0.088577\n",
      "Iteration 37: loss = 0.083499\n",
      "Iteration 38: loss = 0.074363\n",
      "Iteration 39: loss = 0.070774\n",
      "Iteration 40: loss = 0.066265\n",
      "Iteration 41: loss = 0.062967\n",
      "Iteration 42: loss = 0.060081\n",
      "Iteration 43: loss = 0.057410\n",
      "Iteration 44: loss = 0.055215\n",
      "Iteration 45: loss = 0.052887\n",
      "Iteration 46: loss = 0.050991\n",
      "Iteration 47: loss = 0.048987\n",
      "Iteration 48: loss = 0.047383\n",
      "Iteration 49: loss = 0.045663\n",
      "Iteration 50: loss = 0.044234\n",
      "Iteration 51: loss = 0.042672\n",
      "Iteration 52: loss = 0.041401\n",
      "Iteration 53: loss = 0.040124\n",
      "Iteration 54: loss = 0.038908\n",
      "Iteration 55: loss = 0.037787\n",
      "Iteration 56: loss = 0.036687\n",
      "Iteration 57: loss = 0.035638\n",
      "Iteration 58: loss = 0.034685\n",
      "Iteration 59: loss = 0.033734\n",
      "Iteration 60: loss = 0.032893\n",
      "Iteration 61: loss = 0.032065\n",
      "Iteration 62: loss = 0.031270\n",
      "Iteration 63: loss = 0.030546\n",
      "Iteration 64: loss = 0.029806\n",
      "Iteration 65: loss = 0.029140\n",
      "Iteration 66: loss = 0.028511\n",
      "Iteration 67: loss = 0.027857\n",
      "Iteration 68: loss = 0.027262\n",
      "Iteration 69: loss = 0.026674\n",
      "Iteration 70: loss = 0.026136\n",
      "Iteration 71: loss = 0.025579\n",
      "Iteration 72: loss = 0.025088\n",
      "Iteration 73: loss = 0.024571\n",
      "Iteration 74: loss = 0.024129\n",
      "Iteration 75: loss = 0.023627\n",
      "Iteration 76: loss = 0.023214\n",
      "Iteration 77: loss = 0.022785\n",
      "Iteration 78: loss = 0.022365\n",
      "Iteration 79: loss = 0.021977\n",
      "Iteration 80: loss = 0.021591\n",
      "Iteration 81: loss = 0.021222\n",
      "Iteration 82: loss = 0.020842\n",
      "Iteration 83: loss = 0.020507\n",
      "Iteration 84: loss = 0.020151\n",
      "Iteration 85: loss = 0.019807\n",
      "Iteration 86: loss = 0.019503\n",
      "Iteration 87: loss = 0.019184\n",
      "Iteration 88: loss = 0.018871\n",
      "Iteration 89: loss = 0.018593\n",
      "Iteration 90: loss = 0.018289\n",
      "Iteration 91: loss = 0.018027\n",
      "Iteration 92: loss = 0.017754\n",
      "Iteration 93: loss = 0.017483\n",
      "Iteration 94: loss = 0.017231\n",
      "Iteration 95: loss = 0.016991\n",
      "Iteration 96: loss = 0.016750\n",
      "Iteration 97: loss = 0.016507\n",
      "Iteration 98: loss = 0.016282\n",
      "Iteration 99: loss = 0.016053\n",
      "Iteration 100: loss = 0.015840\n",
      "Iteration 101: loss = 0.015634\n",
      "Iteration 102: loss = 0.015416\n",
      "Iteration 103: loss = 0.015217\n",
      "Iteration 104: loss = 0.015021\n",
      "Iteration 105: loss = 0.014829\n",
      "Iteration 106: loss = 0.014631\n",
      "Iteration 107: loss = 0.014448\n",
      "Iteration 108: loss = 0.014279\n",
      "Iteration 109: loss = 0.014090\n",
      "Iteration 110: loss = 0.013925\n",
      "Iteration 111: loss = 0.013752\n",
      "Iteration 112: loss = 0.013592\n",
      "Iteration 113: loss = 0.013425\n",
      "Iteration 114: loss = 0.013272\n",
      "Iteration 115: loss = 0.013103\n",
      "Iteration 116: loss = 0.012958\n",
      "Iteration 117: loss = 0.012808\n",
      "Iteration 118: loss = 0.012661\n",
      "Iteration 119: loss = 0.012511\n",
      "Iteration 120: loss = 0.012378\n",
      "Iteration 121: loss = 0.012232\n",
      "Iteration 122: loss = 0.012104\n",
      "Iteration 123: loss = 0.011972\n",
      "Iteration 124: loss = 0.011845\n",
      "Iteration 125: loss = 0.011721\n",
      "Iteration 126: loss = 0.011598\n",
      "Iteration 127: loss = 0.011475\n",
      "Iteration 128: loss = 0.011357\n",
      "Iteration 129: loss = 0.011244\n",
      "Iteration 130: loss = 0.011124\n",
      "Iteration 131: loss = 0.011008\n",
      "Iteration 132: loss = 0.010900\n",
      "Iteration 133: loss = 0.010791\n",
      "Iteration 134: loss = 0.010680\n",
      "Iteration 135: loss = 0.010576\n",
      "Iteration 136: loss = 0.010472\n",
      "Iteration 137: loss = 0.010371\n",
      "Iteration 138: loss = 0.010270\n",
      "Iteration 139: loss = 0.010174\n",
      "Iteration 140: loss = 0.010078\n",
      "Iteration 141: loss = 0.009980\n",
      "Iteration 142: loss = 0.009890\n",
      "Iteration 143: loss = 0.009799\n",
      "Iteration 144: loss = 0.009707\n",
      "Iteration 145: loss = 0.009617\n",
      "Iteration 146: loss = 0.009536\n",
      "Iteration 147: loss = 0.009446\n",
      "Iteration 148: loss = 0.009361\n",
      "Iteration 149: loss = 0.009283\n",
      "Iteration 150: loss = 0.009197\n",
      "Iteration 151: loss = 0.009118\n",
      "Iteration 152: loss = 0.009041\n",
      "Iteration 153: loss = 0.008962\n",
      "Iteration 154: loss = 0.008889\n",
      "Iteration 155: loss = 0.008812\n",
      "Iteration 156: loss = 0.008739\n",
      "Iteration 157: loss = 0.008665\n",
      "Iteration 158: loss = 0.008596\n",
      "Iteration 159: loss = 0.008526\n",
      "Iteration 160: loss = 0.008457\n",
      "Iteration 161: loss = 0.008388\n",
      "Iteration 162: loss = 0.008319\n",
      "Iteration 163: loss = 0.008255\n",
      "Iteration 164: loss = 0.008190\n",
      "Iteration 165: loss = 0.008123\n",
      "Iteration 166: loss = 0.008062\n",
      "Iteration 167: loss = 0.007998\n",
      "Iteration 168: loss = 0.007937\n",
      "Iteration 169: loss = 0.007875\n",
      "Iteration 170: loss = 0.007810\n",
      "Iteration 171: loss = 0.007759\n",
      "Iteration 172: loss = 0.007694\n",
      "Iteration 173: loss = 0.007638\n",
      "Iteration 174: loss = 0.007581\n",
      "Iteration 175: loss = 0.007525\n",
      "Iteration 176: loss = 0.007468\n",
      "Iteration 177: loss = 0.007414\n",
      "Iteration 178: loss = 0.007362\n",
      "Iteration 179: loss = 0.007306\n",
      "Iteration 180: loss = 0.007255\n",
      "Iteration 181: loss = 0.007203\n",
      "Iteration 182: loss = 0.007152\n",
      "Iteration 183: loss = 0.007101\n",
      "Iteration 184: loss = 0.007051\n",
      "Iteration 185: loss = 0.007003\n",
      "Iteration 186: loss = 0.006950\n",
      "Iteration 187: loss = 0.006908\n",
      "Iteration 188: loss = 0.006858\n",
      "Iteration 189: loss = 0.006808\n",
      "Iteration 190: loss = 0.006766\n",
      "Iteration 191: loss = 0.006717\n",
      "Iteration 192: loss = 0.006675\n",
      "Iteration 193: loss = 0.006628\n",
      "Iteration 194: loss = 0.006585\n",
      "Iteration 195: loss = 0.006542\n",
      "Iteration 196: loss = 0.006498\n",
      "Iteration 197: loss = 0.006457\n",
      "Iteration 198: loss = 0.006414\n",
      "Iteration 199: loss = 0.006374\n",
      "Iteration 200: loss = 0.006335\n",
      "Iteration 201: loss = 0.006291\n",
      "Iteration 202: loss = 0.006255\n",
      "Iteration 203: loss = 0.006213\n",
      "Iteration 204: loss = 0.006175\n",
      "Iteration 205: loss = 0.006137\n",
      "Iteration 206: loss = 0.006100\n",
      "Iteration 207: loss = 0.006061\n",
      "Iteration 208: loss = 0.006026\n",
      "Iteration 209: loss = 0.005988\n",
      "Iteration 210: loss = 0.005952\n",
      "Iteration 211: loss = 0.005914\n",
      "Iteration 212: loss = 0.005881\n",
      "Iteration 213: loss = 0.005847\n",
      "Iteration 214: loss = 0.005812\n",
      "Iteration 215: loss = 0.005775\n",
      "Iteration 216: loss = 0.005744\n",
      "Iteration 217: loss = 0.005710\n",
      "Iteration 218: loss = 0.005677\n",
      "Iteration 219: loss = 0.005642\n",
      "Iteration 220: loss = 0.005610\n",
      "Iteration 221: loss = 0.005578\n",
      "Iteration 222: loss = 0.005546\n",
      "Iteration 223: loss = 0.005513\n",
      "Iteration 224: loss = 0.005483\n",
      "Iteration 225: loss = 0.005451\n",
      "Iteration 226: loss = 0.005421\n",
      "Iteration 227: loss = 0.005392\n",
      "Iteration 228: loss = 0.005361\n",
      "Iteration 229: loss = 0.005332\n",
      "Iteration 230: loss = 0.005302\n",
      "Iteration 231: loss = 0.005270\n",
      "Iteration 232: loss = 0.005243\n",
      "Iteration 233: loss = 0.005214\n",
      "Iteration 234: loss = 0.005184\n",
      "Iteration 235: loss = 0.005157\n",
      "Iteration 236: loss = 0.005129\n",
      "Iteration 237: loss = 0.005100\n",
      "Iteration 238: loss = 0.005072\n",
      "Iteration 239: loss = 0.005047\n",
      "Iteration 240: loss = 0.005018\n",
      "Iteration 241: loss = 0.004993\n",
      "Iteration 242: loss = 0.004966\n",
      "Iteration 243: loss = 0.004940\n",
      "Iteration 244: loss = 0.004914\n",
      "Iteration 245: loss = 0.004889\n",
      "Iteration 246: loss = 0.004863\n",
      "Iteration 247: loss = 0.004838\n",
      "Iteration 248: loss = 0.004813\n",
      "Iteration 249: loss = 0.004790\n"
     ]
    }
   ],
   "source": [
    "layer_c = 3\n",
    "network = make_network(input_size, 32, output_size, layer_c, ReLU)\n",
    "weights = get_weights(network)\n",
    "\n",
    "res = minimize(\n",
    "    compute_loss_grad, weights,       # fun and start point\n",
    "    args=(network, X_train, y_train), # args passed to fun\n",
    "    method=SGD,                       # optimization method\n",
    "    jac=True,                         # says that gradient is computed in fun,\n",
    "    options={\n",
    "        'n_iter': 250,\n",
    "        'momentum': 0.9,\n",
    "        'lr': 1e-2,\n",
    "        'batch_size': 100,\n",
    "    },\n",
    "    callback=lambda *args: None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train NLL: 0.0003651\t\tTest NLL: 0.1949396\n",
      "Train accuracy: 1.000\t\tTest accuracy: 0.960\n"
     ]
    }
   ],
   "source": [
    "train_NLL = NLL(forward(network, X_train), y_train)\n",
    "test_NLL = NLL(forward(network, X_test), y_test)\n",
    "\n",
    "print(f\"Train NLL: {train_NLL:.7f}\\t\\tTest NLL: {test_NLL:.7f}\")\n",
    "\n",
    "train_accuracy = accuracy_score(y_true=y_train, y_pred=predict(network, X_train))\n",
    "test_accuracy = accuracy_score(y_true=y_test, y_pred=predict(network, X_test))\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy:.3f}\\t\\tTest accuracy: {test_accuracy:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:52:05.466550800Z",
     "start_time": "2024-02-22T20:52:05.334946800Z"
    }
   },
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2. (0.8 балла)** Сравните три алгоритма:\n",
    "1. LBFGS-B\n",
    "2. SGD\n",
    "3. SGD + momentum\n",
    "\n",
    "Для этого одновременно переберите следующие гиперпараметры:\n",
    "- значения `lr` на отрезке `[1e-3, 1e-1]` по логарифмической сетке\n",
    "- два значения `momentum`: `0` и `0.9`\n",
    "- значения `batch_size`: `8` и `32`\n",
    "\n",
    "В каждом запуске сохраняйте три метрики: итоговое accuracy на тесте и на трейне и время обучения.\n",
    "\n",
    "Для каждого из трёх алгоритмов выберите лучшие `lr` и `batch_size` по `test_accuracy`. Постройте для них кривые обучения (пример ниже). Сделайте выводы.\n",
    "\n",
    "![](comparison.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3. (0.1 балла)** Для отобранных в прошлом задании трёх алгоритмов ответье на вопрос: как меняются запуски для двух значений `batch_size`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `Бонусная часть`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### `Реализация метода оптимизации (1 балл)`\n",
    "\n",
    "Реализуйте метод оптимизации Adam и сравните его работу с SGD + momentum, проведя эксперимент, как в задании 2 (перебор гиперпараметров + кривые обучения)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### `Dropout (1 балл)`\n",
    "\n",
    "Реализуйте слой Dropout. Сравните обучение сети из большого числа слоёв при использовании Dropout и без его использования (предварительно подберите адекватный параметр $p$). Сделайте выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### `BatchNormalization (1 балл)`\n",
    "\n",
    "Реализуйте слой `BatchNormalization`. Сравните обучение сети из большого числа слоёв при использовании `BatchNormalization` и без его использования. Сделайте выводы."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
