{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Практикум по программированию на языке Python`\n",
    "\n",
    "## `Задание 1.5. Классификация изображений`.\n",
    "\n",
    "#### Фамилия, имя: Богачев Владимир\n",
    "\n",
    "Дата выдачи: <span style=\"color:red\">__5 марта__</span>.\n",
    "\n",
    "Мягкий дедлайн: <span style=\"color:red\">__12 марта 23:59__</span>.\n",
    "\n",
    "Стоимость: __10 баллов__ (основная часть заданий) + __3 балла__ (дополнительные задания).\n",
    "\n",
    "<span style=\"color:red\">__В ноутбуке все клетки должны выполняться без ошибок при последовательном их выполнении.__</span>\n",
    "\n",
    "#### `Москва, 2024`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:30:57.925211500Z",
     "start_time": "2024-03-13T19:30:55.213834100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Задание 1. Загрузка данных (0.5 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой домашке работа с данными будем максимально облегчённой. Мы скачаем MNIST с помощью [стандартных средств](https://pytorch.org/vision/0.8/datasets.html#mnist) торча. Посмотреть список других доступных датасетов можно [здесь](https://pytorch.org/vision/0.8/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:30:57.928010700Z",
     "start_time": "2024-03-13T19:30:57.925211500Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_mnist(train, transform=None):    \n",
    "    if transform is None:\n",
    "        transform = T.ToTensor()\n",
    "    return torchvision.datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=train,\n",
    "        transform=transform,\n",
    "        download=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пиксели изображений принимают значения [0,1]. Скачайте датасет и посчитайте выборочное среднее и выборочное стандартное отклонение для значения пикселя. Т.е. должно получиться число `mean` для среднего, и число `std` для стандартного отклонения.\n",
    "\n",
    "*Подсказка.* Подумайте, на какой части датасета нужно считать эти статистики (обучение или валидация), чтобы предотвратить утечку данных.\n",
    "\n",
    "*Подсказка.* У торч датасета реализован метод `__getitem__`, т.е. его можно индексировать `dataset[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:31:04.439259600Z",
     "start_time": "2024-03-13T19:30:57.928010700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.Size([60000, 1, 28, 28])\n",
      "mean = 0.13, std = 0.31\n"
     ]
    }
   ],
   "source": [
    "norm_transform = T.Compose([\n",
    "    T.PILToTensor(),\n",
    "    T.ConvertImageDtype(torch.float32)\n",
    "])\n",
    "\n",
    "data_train = load_mnist(True, transform=norm_transform)\n",
    "\n",
    "X_train = torch.stack([data_train[i][0] for i in range(len(data_train))])\n",
    "\n",
    "print(X_train.dtype, X_train.shape)\n",
    "\n",
    "mean =  torch.mean(X_train)\n",
    "std =  torch.std(X_train)\n",
    "print(f\"mean = {mean:.2f}, std = {std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные значения можно применить для нормализации изображений, когда будем подавать их в нейросеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:31:04.491888800Z",
     "start_time": "2024-03-13T19:31:04.440299400Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_mnist = load_mnist(True, norm_transform)\n",
    "val_mnist = load_mnist(False, norm_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время обучения данные подаются в нейросеть батчами.\n",
    "\n",
    "Обычно batch_size выбирается так, чтобы во время обучения получалась меньше дисперсия градиента (ну вы уже знакомы с sgd), также часто batch_size выбирается максимально возможным по ресурсам.\n",
    "\n",
    "Для этой задачи нам хватит batch_size = 64 во время обучения.\n",
    "\n",
    "*Ответьте на вопрос:* Почему в большинстве задач для валидации и тестирования можно выбирать batch_size больше? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:31:04.492888200Z",
     "start_time": "2024-03-13T19:31:04.468330900Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "train_mnist_loader = DataLoader(\n",
    "    dataset=train_mnist,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=6\n",
    ")\n",
    "\n",
    "val_mnist_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_mnist,\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:31:07.793285800Z",
     "start_time": "2024-03-13T19:31:04.470887600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(train_mnist_loader))\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:31:07.858886100Z",
     "start_time": "2024-03-13T19:31:07.793814100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 3\n",
    "plt.title(f'digit {labels[i]}')\n",
    "plt.imshow(images[i, 0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Задание 2. Цикл обучения (1.5 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже предоставлен базовый вариант цикла обучения, представленный тремя функциями: `train_epoch`, `val_epoch`, `train_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:31:07.862806700Z",
     "start_time": "2024-03-13T19:31:07.859935400Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    network,\n",
    "    train_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "):\n",
    "    \"\"\"train `network` with `optimizer` for one epoch with data from `train_loader` to minimize `criterion`\"\"\"\n",
    "    \n",
    "    network.train()  # switch network submodules to train mode, e.g. it influences on batch-norm, dropout\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)   # send data to device\n",
    "        optimizer.zero_grad()   # zero out grads, collected from previous batch\n",
    "        logits = network(images)  # forward pass\n",
    "        loss = criterion(logits, labels, reduction='mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:31:07.875001100Z",
     "start_time": "2024-03-13T19:31:07.864942800Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_epoch(\n",
    "    network,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "):\n",
    "    \"\"\"calculate loss and accuracy on validation data\"\"\"\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    network.eval()  # switch network submodules to test mode\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = network(images)\n",
    "        val_loss += criterion(logits, labels, reduction='sum').item()\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += torch.sum(pred == labels).item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accur = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        f'Test set: Avg. loss: {val_loss:.4f}\\t' + \\\n",
    "        f'Accuracy: {correct}/{len(val_loader.dataset)}\\t' +\\\n",
    "        f'({100. * val_accur:.0f}%)',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:31:07.876615300Z",
     "start_time": "2024-03-13T19:31:07.870256200Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_val(\n",
    "    network,\n",
    "    n_epochs,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "):\n",
    "    \"\"\"full cycle of neural network training\"\"\"\n",
    "\n",
    "    val_epoch(network, val_loader, criterion)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_epoch(network, train_loader, criterion, optimizer)\n",
    "        val_epoch(network, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки, что все работает, обучите бейзлайн -- однослойную [полносвязную](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) сеть на [кросс-энтропийный лосс](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html). \n",
    "\n",
    "\n",
    "*Заметьте*, что на вход этому лоссу нужно подавать сырой выход нейросети, а не результат применения софтмакса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:31:07.880334400Z",
     "start_time": "2024-03-13T19:31:07.872893Z"
    }
   },
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(in_features=input_size, out_features=output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:33:28.090515800Z",
     "start_time": "2024-03-13T19:31:07.876615300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 2.4114\tAccuracy: 843/10000\t(8%)\n",
      "Test set: Avg. loss: 0.4583\tAccuracy: 8855/10000\t(89%)\n",
      "Test set: Avg. loss: 0.3604\tAccuracy: 9037/10000\t(90%)\n",
      "Test set: Avg. loss: 0.3255\tAccuracy: 9083/10000\t(91%)\n",
      "Test set: Avg. loss: 0.3065\tAccuracy: 9149/10000\t(91%)\n",
      "Test set: Avg. loss: 0.2956\tAccuracy: 9182/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2887\tAccuracy: 9188/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2847\tAccuracy: 9202/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2810\tAccuracy: 9205/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2774\tAccuracy: 9209/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2761\tAccuracy: 9227/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2738\tAccuracy: 9224/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2720\tAccuracy: 9237/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2725\tAccuracy: 9238/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2718\tAccuracy: 9238/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2706\tAccuracy: 9216/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2694\tAccuracy: 9240/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2682\tAccuracy: 9257/10000\t(93%)\n",
      "Test set: Avg. loss: 0.2687\tAccuracy: 9249/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2667\tAccuracy: 9249/10000\t(92%)\n",
      "Test set: Avg. loss: 0.2666\tAccuracy: 9239/10000\t(92%)\n"
     ]
    }
   ],
   "source": [
    "model = LogReg(28 * 28, 10).to(device)\n",
    "\n",
    "train_val(\n",
    "    network=model,\n",
    "    criterion=nn.functional.cross_entropy,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-4),\n",
    "    train_loader=train_mnist_loader,\n",
    "    val_loader=val_mnist_loader,\n",
    "    n_epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test set: Avg. loss: 2.4114 Accuracy: 843/10000 (8%)\n",
    "Test set: Avg. loss: 0.2837 Accuracy: 9179/10000 (92%)\n",
    "Test set: Avg. loss: 0.2796 Accuracy: 9201/10000 (92%)\n",
    "Test set: Avg. loss: 0.2812 Accuracy: 9199/10000 (92%)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Задание 3. Логирование (3 балл)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопируйте и перепишите функции `train_epoch`, `val_epoch`, `train_val` таким образом, чтобы\n",
    "- во время обучения раз в `logging_interval` шагов оптимизации выводились лосс и аккураси на одном батче (пример ниже, но не обязательно делать идентично)\n",
    "- происходило сохранение весов лучшей (по аккураси на валидации) модели и состояния оптимизатора ([в помощь](https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-state-dict-recommended))\n",
    "- в конце обучения выводился и сохранялся график-саммари (пример ниже, но не обязательно делать идентично)\n",
    "\n",
    "*Ответьте на вопрос:* Что хранится в состоянии оптимизатора? Зачем нужно его сохранять? Приведите хотя бы один пример оптимизатора, для которого есть смысл сохранять состояние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:33:28.094965900Z",
     "start_time": "2024-03-13T19:33:28.091517300Z"
    }
   },
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_acc = []\n",
    "        self.val_acc = []\n",
    "        \n",
    "        self.model_state = None\n",
    "        self.optimizer_state = None\n",
    "    \n",
    "    def log_train(self, train_loss, train_acc):\n",
    "        self.train_loss.append(train_loss)\n",
    "        self.train_acc.append(train_acc)\n",
    "    \n",
    "    def log_val(self, val_loss, val_acc):\n",
    "        self.val_loss.append(val_loss)\n",
    "        self.val_acc.append(val_acc)\n",
    "    \n",
    "    def log_state(self, model_state = None, optimizer_state = None):\n",
    "        if model_state is not None:\n",
    "            self.model_state = model_state\n",
    "        if optimizer_state is not None:\n",
    "            self.optimizer_state = optimizer_state"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    network,\n",
    "    train_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    logger: Logger,\n",
    "    logging_interval: int = 1,\n",
    "):\n",
    "    \"\"\"train `network` with `optimizer` for one epoch with data from `train_loader` to minimize `criterion`\"\"\"\n",
    "    \n",
    "    network.train()  # switch network submodules to train mode, e.g. it influences on batch-norm, dropout\n",
    "    logger_step = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)   # send data to device\n",
    "        optimizer.zero_grad()   # zero out grads, collected from previous batch\n",
    "        logits = network(images)  # forward pass\n",
    "        loss = criterion(logits, labels, reduction='mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logger_step = (logger_step + 1) % logging_interval\n",
    "        \n",
    "        if logger_step == 0:\n",
    "            pred = logits.argmax(dim=1)\n",
    "            train_accuracy = torch.sum(pred == labels).item() / len(labels)\n",
    "            logger.log_train(loss.item(), train_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:33:28.102343100Z",
     "start_time": "2024-03-13T19:33:28.093965900Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_epoch(\n",
    "    network,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    logger: Logger\n",
    "):\n",
    "    \"\"\"calculate loss and accuracy on validation data\"\"\"\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    network.eval()  # switch network submodules to test mode\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = network(images)\n",
    "        val_loss += criterion(logits, labels, reduction='sum').item()\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += torch.sum(pred == labels).item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accur = correct / len(val_loader.dataset)\n",
    "\n",
    "    logger.log_val(val_loss, val_accur)\n",
    "\n",
    "    print(\n",
    "        f'Test set: Avg. loss: {val_loss:.4f}',\n",
    "        f'Accuracy: {correct}/{len(val_loader.dataset)}',\n",
    "        f'({100. * val_accur:.0f}%)',\n",
    "    )\n",
    "    \n",
    "    return val_loss, val_accur"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:33:28.103342900Z",
     "start_time": "2024-03-13T19:33:28.100123800Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_val(\n",
    "    network,\n",
    "    n_epochs,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    logger: Logger,\n",
    "    logging_interval: int = 5,\n",
    "):\n",
    "    \"\"\"full cycle of neural network training\"\"\"\n",
    "\n",
    "    best_loss, best_accur = val_epoch(network, val_loader, criterion, logger)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_epoch(network, train_loader, criterion, optimizer, logger, logging_interval)\n",
    "        val_loss, val_accur = val_epoch(network, val_loader, criterion, logger)\n",
    "        \n",
    "        if val_accur > best_accur:\n",
    "            best_accur = val_accur\n",
    "            logger.log_state(network.state_dict(), optimizer.state_dict())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:33:28.107758Z",
     "start_time": "2024-03-13T19:33:28.104341600Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:35:46.912609600Z",
     "start_time": "2024-03-13T19:33:28.106756400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 2.4668 Accuracy: 927/10000 (9%)\n",
      "Test set: Avg. loss: 0.4624 Accuracy: 8866/10000 (89%)\n",
      "Test set: Avg. loss: 0.3609 Accuracy: 9058/10000 (91%)\n",
      "Test set: Avg. loss: 0.3254 Accuracy: 9125/10000 (91%)\n",
      "Test set: Avg. loss: 0.3066 Accuracy: 9152/10000 (92%)\n",
      "Test set: Avg. loss: 0.2954 Accuracy: 9176/10000 (92%)\n",
      "Test set: Avg. loss: 0.2898 Accuracy: 9187/10000 (92%)\n",
      "Test set: Avg. loss: 0.2850 Accuracy: 9192/10000 (92%)\n",
      "Test set: Avg. loss: 0.2812 Accuracy: 9203/10000 (92%)\n",
      "Test set: Avg. loss: 0.2791 Accuracy: 9208/10000 (92%)\n",
      "Test set: Avg. loss: 0.2766 Accuracy: 9206/10000 (92%)\n",
      "Test set: Avg. loss: 0.2749 Accuracy: 9208/10000 (92%)\n",
      "Test set: Avg. loss: 0.2726 Accuracy: 9221/10000 (92%)\n",
      "Test set: Avg. loss: 0.2721 Accuracy: 9219/10000 (92%)\n",
      "Test set: Avg. loss: 0.2699 Accuracy: 9223/10000 (92%)\n",
      "Test set: Avg. loss: 0.2700 Accuracy: 9224/10000 (92%)\n",
      "Test set: Avg. loss: 0.2693 Accuracy: 9240/10000 (92%)\n",
      "Test set: Avg. loss: 0.2690 Accuracy: 9238/10000 (92%)\n",
      "Test set: Avg. loss: 0.2674 Accuracy: 9245/10000 (92%)\n",
      "Test set: Avg. loss: 0.2664 Accuracy: 9237/10000 (92%)\n",
      "Test set: Avg. loss: 0.2665 Accuracy: 9243/10000 (92%)\n"
     ]
    }
   ],
   "source": [
    "model = LogReg(28 * 28, 10).to(device)\n",
    "\n",
    "lg = Logger()\n",
    "\n",
    "train_val(\n",
    "    network=model,\n",
    "    criterion=nn.functional.cross_entropy,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-4),\n",
    "    train_loader=train_mnist_loader,\n",
    "    val_loader=val_mnist_loader,\n",
    "    n_epochs=20,\n",
    "    logger=lg,\n",
    "    logging_interval=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x19090353b50>]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lg.val_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:35:47.004747200Z",
     "start_time": "2024-03-13T19:35:46.913609600Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите лучшие веса модели и подсчитайте аккураси на валидации, чтобы подтвердить что веса сохранились корректно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:35:49.562732800Z",
     "start_time": "2024-03-13T19:35:47.004747200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 0.2665 Accuracy: 9243/10000 (92%)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.26652728500366213, 0.9243)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogReg(28 * 28, 10).to(device)\n",
    "model.load_state_dict(lg.model_state)\n",
    "\n",
    "val_epoch(model, val_mnist_loader, nn.functional.cross_entropy, Logger())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите сохранённое состояние оптимизатора и сделайте две эпохи обучения, чтобы подтвердить, что состояния оптимизатора были сохранены корректно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:36:05.470134Z",
     "start_time": "2024-03-13T19:35:49.561734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 0.2665 Accuracy: 9243/10000 (92%)\n",
      "Test set: Avg. loss: 0.2667 Accuracy: 9233/10000 (92%)\n",
      "Test set: Avg. loss: 0.2660 Accuracy: 9251/10000 (93%)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "optimizer.load_state_dict(lg.optimizer_state)\n",
    "\n",
    "train_val(\n",
    "    network=model,\n",
    "    criterion=nn.functional.cross_entropy,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_mnist_loader,\n",
    "    val_loader=val_mnist_loader,\n",
    "    n_epochs=2,\n",
    "    logger=lg,\n",
    "    logging_interval=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Задание 4. Логирование с помощью tensorboard (1 балл)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле это дурной тон логировать обучение нейросети так, как это сделали вы выше. Дело в том, что весь функционал уже реализован в [`tensorboard`](https://pytorch.org/docs/stable/tensorboard.html), а вы написали велосипед."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:36:07.422124500Z",
     "start_time": "2024-03-13T19:36:05.471133300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\python_venv\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\python_venv\\lib\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\python_venv\\lib\\site-packages (from tensorboard) (1.62.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python_venv\\lib\\site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\python_venv\\lib\\site-packages (from tensorboard) (1.24.3)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\python_venv\\lib\\site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python_venv\\lib\\site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\python_venv\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\python_venv\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python_venv\\lib\\site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python_venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у вас есть доступ к терминалу и браузеру, то удобнее всего ввести команду\n",
    "```bash\n",
    "tensorboard --logdir .\n",
    "```\n",
    "и открыть UI в выделенном локалхосте. \n",
    "\n",
    "Если вы работаете в гугл колабе, то можете запустить UI как виджет в Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T20:57:53.274092600Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как только вы начнете логировать в объект типа `SummaryWriter`, в UI начнут строиться кривые обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопируйте и перепишите функции обучения таким образом, чтобы логирование происходило в `tensorboard`.\n",
    "\n",
    "*Замечание.* Вам пригодится метод `add_scalar`, чтобы сохранять лосс и аккураси, и метод `add_hparams`, чтобы сохранить важные гиперпараметры (например, кодовое имя архитектуры сети) и финальное достигнутое качество."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from itertools import count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:36:07.426092400Z",
     "start_time": "2024-03-13T19:36:07.423577300Z"
    }
   },
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:36:07.433980200Z",
     "start_time": "2024-03-13T19:36:07.425093300Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    network,\n",
    "    train_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    writer: SummaryWriter,\n",
    "    logging_interval: int = 1,\n",
    "    logger_step_cntr: count = None,\n",
    "):\n",
    "    \"\"\"train `network` with `optimizer` for one epoch with data from `train_loader` to minimize `criterion`\"\"\"\n",
    "    \n",
    "    network.train()  # switch network submodules to train mode, e.g. it influences on batch-norm, dropout\n",
    "    logger_step_cntr = count() if logger_step_cntr is None else logger_step_cntr\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)   # send data to device\n",
    "        optimizer.zero_grad()   # zero out grads, collected from previous batch\n",
    "        logits = network(images)  # forward pass\n",
    "        loss = criterion(logits, labels, reduction='mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logger_step = next(logger_step_cntr)\n",
    "        \n",
    "        if logger_step % logging_interval == 0:\n",
    "            pred = logits.argmax(dim=1)\n",
    "            train_accuracy = torch.sum(pred == labels).item() / len(labels)\n",
    "            writer.add_scalar('Loss/train', loss.item(), logger_step // logging_interval)\n",
    "            writer.add_scalar('Accuracy/train', train_accuracy, logger_step // logging_interval)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_epoch(\n",
    "    network,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    writer: SummaryWriter,\n",
    "    epoch_no: int\n",
    "):\n",
    "    \"\"\"calculate loss and accuracy on validation data\"\"\"\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    network.eval()  # switch network submodules to test mode\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = network(images)\n",
    "        val_loss += criterion(logits, labels, reduction='sum').item()\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += torch.sum(pred == labels).item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accur = correct / len(val_loader.dataset)\n",
    "\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch_no)\n",
    "    writer.add_scalar('Accuracy/val', val_accur, epoch_no)\n",
    "\n",
    "    print(\n",
    "        f'Test set: Avg. loss: {val_loss:.4f}',\n",
    "        f'Accuracy: {correct}/{len(val_loader.dataset)}',\n",
    "        f'({100. * val_accur:.0f}%)',\n",
    "    )\n",
    "    \n",
    "    return val_loss, val_accur"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:36:07.461308200Z",
     "start_time": "2024-03-13T19:36:07.429599400Z"
    }
   },
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_val(\n",
    "    network,\n",
    "    n_epochs,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    writer: SummaryWriter,\n",
    "    logging_interval: int = 5,\n",
    "    best_dump_path: str = None,\n",
    "    accuracy_dump_threshold: float = 0.0,\n",
    "):\n",
    "    \"\"\"full cycle of neural network training\"\"\"\n",
    "\n",
    "    logger_step_cntr = count(0)\n",
    "    best_loss, best_accur = val_epoch(network, val_loader, criterion, writer, epoch_no=0)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_epoch(network, train_loader, criterion, optimizer, writer, logging_interval, logger_step_cntr)\n",
    "        val_loss, val_accur = val_epoch(network, val_loader, criterion, writer, epoch_no=epoch)\n",
    "        \n",
    "        if (val_accur > best_accur) and (best_dump_path is not None) and (val_accur > accuracy_dump_threshold):\n",
    "            with open(best_dump_path, \"wb\") as f:\n",
    "                torch.save(\n",
    "                    obj=(model.state_dict(), optimizer.state_dict(), val_loss, val_accur),\n",
    "                    f=f\n",
    "                )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:36:07.464307100Z",
     "start_time": "2024-03-13T19:36:07.433980200Z"
    }
   },
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 2.2553 Accuracy: 1771/10000 (18%)\n",
      "Test set: Avg. loss: 0.4595 Accuracy: 8871/10000 (89%)\n",
      "Test set: Avg. loss: 0.3599 Accuracy: 9045/10000 (90%)\n",
      "Test set: Avg. loss: 0.3244 Accuracy: 9105/10000 (91%)\n",
      "Test set: Avg. loss: 0.3064 Accuracy: 9141/10000 (91%)\n",
      "Test set: Avg. loss: 0.2962 Accuracy: 9163/10000 (92%)\n",
      "Test set: Avg. loss: 0.2897 Accuracy: 9192/10000 (92%)\n",
      "Test set: Avg. loss: 0.2861 Accuracy: 9201/10000 (92%)\n",
      "Test set: Avg. loss: 0.2819 Accuracy: 9202/10000 (92%)\n",
      "Test set: Avg. loss: 0.2796 Accuracy: 9213/10000 (92%)\n",
      "Test set: Avg. loss: 0.2758 Accuracy: 9221/10000 (92%)\n",
      "Test set: Avg. loss: 0.2749 Accuracy: 9219/10000 (92%)\n",
      "Test set: Avg. loss: 0.2742 Accuracy: 9241/10000 (92%)\n",
      "Test set: Avg. loss: 0.2727 Accuracy: 9223/10000 (92%)\n",
      "Test set: Avg. loss: 0.2712 Accuracy: 9234/10000 (92%)\n",
      "Test set: Avg. loss: 0.2713 Accuracy: 9227/10000 (92%)\n",
      "Test set: Avg. loss: 0.2697 Accuracy: 9235/10000 (92%)\n",
      "Test set: Avg. loss: 0.2692 Accuracy: 9251/10000 (93%)\n",
      "Test set: Avg. loss: 0.2681 Accuracy: 9233/10000 (92%)\n",
      "Test set: Avg. loss: 0.2672 Accuracy: 9248/10000 (92%)\n",
      "Test set: Avg. loss: 0.2669 Accuracy: 9243/10000 (92%)\n"
     ]
    }
   ],
   "source": [
    "model = LogReg(28 * 28, 10).to(device)\n",
    "\n",
    "writer = SummaryWriter(\"runs/MNIST_LogReg\")\n",
    "\n",
    "train_val(\n",
    "    network=model,\n",
    "    criterion=nn.functional.cross_entropy,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-4),\n",
    "    train_loader=train_mnist_loader,\n",
    "    val_loader=val_mnist_loader,\n",
    "    n_epochs=20,\n",
    "    writer=writer,\n",
    "    logging_interval=5,\n",
    ")\n",
    "\n",
    "writer.flush()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:38:24.490561900Z",
     "start_time": "2024-03-13T19:36:07.438308800Z"
    }
   },
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Задание 5. Побейте бейзлайн (2+2 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На датасете [`CIFAR-10`](https://pytorch.org/vision/0.8/datasets.html#torchvision.datasets.CIFAR10) обучите модель, которая выдает аккураси `>=0.7` (2 балла) и аккураси `>=0.8` (ещё 2 балла).\n",
    "- Можете использовать любые модули `pytorch`, любые оптимизаторы и шедулеры, можете использовать аугментации ([например](https://pytorch.org/vision/stable/transforms.html))\n",
    "- Для отслеживания экспериментов используйте логирование с `tensorboard`, не забывайте давать осмысленные имена эспериментам и логировать нужные гиперпараметры, сохранять веса сети и состояние оптимизатора."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from itertools import count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:38:55.052836200Z",
     "start_time": "2024-03-13T19:38:55.045320100Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    network,\n",
    "    train_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    writer: SummaryWriter,\n",
    "    logging_interval: int = 1,\n",
    "    logger_step_cntr: count = None,\n",
    "):\n",
    "    \"\"\"train `network` with `optimizer` for one epoch with data from `train_loader` to minimize `criterion`\"\"\"\n",
    "    \n",
    "    network.train()  # switch network submodules to train mode, e.g. it influences on batch-norm, dropout\n",
    "    logger_step_cntr = count() if logger_step_cntr is None else logger_step_cntr\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)   # send data to device\n",
    "        optimizer.zero_grad()   # zero out grads, collected from previous batch\n",
    "        logits = network(images)  # forward pass\n",
    "        loss = criterion(logits, labels, reduction='mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logger_step = next(logger_step_cntr)\n",
    "        \n",
    "        if logger_step % logging_interval == 0:\n",
    "            pred = logits.argmax(dim=1)\n",
    "            train_accuracy = torch.sum(pred == labels).item() / len(labels)\n",
    "            writer.add_scalar('Loss/train', loss.item(), logger_step // logging_interval)\n",
    "            writer.add_scalar('Accuracy/train', train_accuracy, logger_step // logging_interval)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:38:55.252674300Z",
     "start_time": "2024-03-13T19:38:55.246677700Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_epoch(\n",
    "    network,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    writer: SummaryWriter,\n",
    "    epoch_no: int\n",
    "):\n",
    "    \"\"\"calculate loss and accuracy on validation data\"\"\"\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    network.eval()  # switch network submodules to test mode\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = network(images)\n",
    "        val_loss += criterion(logits, labels, reduction='sum').item()\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += torch.sum(pred == labels).item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accur = correct / len(val_loader.dataset)\n",
    "\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch_no)\n",
    "    writer.add_scalar('Accuracy/val', val_accur, epoch_no)\n",
    "\n",
    "    print(\n",
    "        f'Test set: Avg. loss: {val_loss:.4f}',\n",
    "        f'Accuracy: {correct}/{len(val_loader.dataset)}',\n",
    "        f'({100. * val_accur:.0f}%)',\n",
    "    )\n",
    "    \n",
    "    return val_loss, val_accur"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:38:55.766195500Z",
     "start_time": "2024-03-13T19:38:55.758288100Z"
    }
   },
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_val(\n",
    "    network,\n",
    "    n_epochs,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    lr_scheduler,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    writer: SummaryWriter,\n",
    "    logging_interval: int = 5,\n",
    "    best_dump_path: str = None,\n",
    "    accuracy_dump_threshold: float = 0.0,\n",
    "):\n",
    "    \"\"\"full cycle of neural network training\"\"\"\n",
    "\n",
    "    logger_step_cntr = count(0)\n",
    "    val_loss, val_accur = val_epoch(network, val_loader, criterion, writer, epoch_no=0)\n",
    "    \n",
    "    best_val_loss = val_loss\n",
    "    best_val_acc = val_accur\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        writer.add_scalar('Params/LR', optimizer.state_dict()['param_groups'][0]['lr'], epoch)\n",
    "        train_epoch(network, train_loader, criterion, optimizer, writer, logging_interval, logger_step_cntr)\n",
    "        val_loss, val_accur = val_epoch(network, val_loader, criterion, writer, epoch_no=epoch)\n",
    "        lr_scheduler.step(val_loss)\n",
    "        \n",
    "        if (val_accur > best_val_acc) and (best_dump_path is not None) and (val_accur > accuracy_dump_threshold):\n",
    "            with open(best_dump_path, \"wb\") as f:\n",
    "                torch.save(\n",
    "                    obj=(model.state_dict(), optimizer.state_dict(), val_loss, val_accur),\n",
    "                    f=f\n",
    "                )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:38:56.207201300Z",
     "start_time": "2024-03-13T19:38:56.199202400Z"
    }
   },
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:38:57.341959Z",
     "start_time": "2024-03-13T19:38:57.333963100Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cifar10(train: bool, transform = None):\n",
    "    if transform is None:\n",
    "        transform = T.Compose([T.ToTensor()])\n",
    "    return torchvision.datasets.CIFAR10(\n",
    "        root='./data',\n",
    "        train=train,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([3, 32, 32])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_train = load_cifar10(True)\n",
    "cifar10_train[3][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:38:58.188883600Z",
     "start_time": "2024-03-13T19:38:57.597587100Z"
    }
   },
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1912ae97d10>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cifar10_train[1][0].transpose(0, 1).transpose(1, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:38:58.279596800Z",
     "start_time": "2024-03-13T19:38:58.189421800Z"
    }
   },
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:38:58.491098900Z",
     "start_time": "2024-03-13T19:38:58.480324200Z"
    }
   },
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "Аугментация позаимствована из [ноутбука](https://www.kaggle.com/code/vikasbhadoria/cifar10-high-accuracy-model-build-on-pytorch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5), \n",
    "    T.RandomRotation(10),\n",
    "    T.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    # T.GaussianBlur(kernel_size=(3, 3), sigma=(0.05, 0.5)),\n",
    "    # T.RandomEqualize(p=0.2),\n",
    "    # T.RandomGrayscale(p=0.1),\n",
    "    T.ToTensor(), \n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_val = T.Compose([\n",
    "    T.ToTensor(), \n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "cifar10_train = load_cifar10(True, transform = transform_train)\n",
    "cifar10_val = load_cifar10(False, transform = transform_val)\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 512\n",
    "\n",
    "train_cifar10_loader = DataLoader(\n",
    "    dataset=cifar10_train,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=9\n",
    ")\n",
    "\n",
    "val_cifar10_loader = torch.utils.data.DataLoader(\n",
    "    dataset=cifar10_val,\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=6\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:39:01.187499300Z",
     "start_time": "2024-03-13T19:38:59.884328300Z"
    }
   },
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:39:01.191029100Z",
     "start_time": "2024-03-13T19:39:01.188496600Z"
    }
   },
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучим LogReg. Данная модель послужит базовой линией для обучения более сложных моделей, а также позволит проверить корректность загрузки данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 2.3615 Accuracy: 1057/10000 (11%)\n",
      "Test set: Avg. loss: 1.8957 Accuracy: 3298/10000 (33%)\n",
      "Test set: Avg. loss: 1.8753 Accuracy: 3412/10000 (34%)\n",
      "Test set: Avg. loss: 1.8676 Accuracy: 3466/10000 (35%)\n",
      "Test set: Avg. loss: 1.8578 Accuracy: 3533/10000 (35%)\n",
      "Test set: Avg. loss: 1.8483 Accuracy: 3628/10000 (36%)\n",
      "Test set: Avg. loss: 1.8473 Accuracy: 3605/10000 (36%)\n",
      "Test set: Avg. loss: 1.8351 Accuracy: 3714/10000 (37%)\n",
      "Test set: Avg. loss: 1.8454 Accuracy: 3571/10000 (36%)\n",
      "Test set: Avg. loss: 1.8369 Accuracy: 3635/10000 (36%)\n",
      "Test set: Avg. loss: 1.8450 Accuracy: 3577/10000 (36%)\n",
      "Test set: Avg. loss: 1.8346 Accuracy: 3657/10000 (37%)\n",
      "Test set: Avg. loss: 1.8346 Accuracy: 3616/10000 (36%)\n",
      "Test set: Avg. loss: 1.8296 Accuracy: 3704/10000 (37%)\n",
      "Test set: Avg. loss: 1.8315 Accuracy: 3653/10000 (37%)\n",
      "Test set: Avg. loss: 1.8306 Accuracy: 3623/10000 (36%)\n",
      "Test set: Avg. loss: 1.8346 Accuracy: 3669/10000 (37%)\n",
      "Test set: Avg. loss: 1.8297 Accuracy: 3672/10000 (37%)\n",
      "Test set: Avg. loss: 1.8304 Accuracy: 3632/10000 (36%)\n",
      "Test set: Avg. loss: 1.8259 Accuracy: 3688/10000 (37%)\n",
      "Test set: Avg. loss: 1.8250 Accuracy: 3697/10000 (37%)\n",
      "Test set: Avg. loss: 1.8265 Accuracy: 3675/10000 (37%)\n",
      "Test set: Avg. loss: 1.8259 Accuracy: 3716/10000 (37%)\n",
      "Test set: Avg. loss: 1.8249 Accuracy: 3694/10000 (37%)\n",
      "Test set: Avg. loss: 1.8268 Accuracy: 3689/10000 (37%)\n",
      "Test set: Avg. loss: 1.8211 Accuracy: 3730/10000 (37%)\n",
      "Test set: Avg. loss: 1.8224 Accuracy: 3694/10000 (37%)\n",
      "Test set: Avg. loss: 1.8256 Accuracy: 3695/10000 (37%)\n",
      "Test set: Avg. loss: 1.8237 Accuracy: 3725/10000 (37%)\n",
      "Test set: Avg. loss: 1.8235 Accuracy: 3734/10000 (37%)\n",
      "Test set: Avg. loss: 1.8233 Accuracy: 3734/10000 (37%)\n"
     ]
    }
   ],
   "source": [
    "model = LogReg(32 * 32 * 3, 10).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=4, min_lr=1e-6)\n",
    "\n",
    "writer = SummaryWriter(\"runs/CIFAR_LogReg\")\n",
    "\n",
    "train_val(\n",
    "    network=model,\n",
    "    criterion=nn.functional.cross_entropy,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    train_loader=train_cifar10_loader,\n",
    "    val_loader=val_cifar10_loader,\n",
    "    n_epochs=30,\n",
    "    writer=writer,\n",
    "    logging_interval=100,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:56:12.595072400Z",
     "start_time": "2024-03-13T19:39:03.046324800Z"
    }
   },
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convolution network\n",
    "\n",
    "The architecture was derived from original [ResNet paper](https://arxiv.org/pdf/1512.03385.pdf). \n",
    "It was adapted for the current task, taking into consideration the low input size and small sample size."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, channels: int, pairs_cnt: int):\n",
    "        super().__init__()\n",
    "        self.conv_pairs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(channels),\n",
    "            )\n",
    "            for _ in range(pairs_cnt)\n",
    "        ])\n",
    "        \n",
    "        self.relu_blocks = nn.ModuleList([nn.ReLU() for _ in range(pairs_cnt)])\n",
    "        \n",
    "        self.pairs_cnt = pairs_cnt\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.pairs_cnt):\n",
    "            x = self.relu_blocks[i](x + self.conv_pairs[i](x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ConvDownsample(nn.Module):\n",
    "    def __init__(self, in_channels: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels * 2, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm2d(in_channels * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels * 2, in_channels * 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(in_channels * 2),\n",
    "        )\n",
    "        \n",
    "        self.downsample_id = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels * 2, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm2d(in_channels * 2),\n",
    "        )\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x) + self.downsample_id(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2), # 32 --> 16\n",
    "        )\n",
    "        \n",
    "        self.middle = nn.Sequential(\n",
    "            ConvBlock(32, 2),\n",
    "            \n",
    "            ConvDownsample(32), # 16 --> 8\n",
    "            ConvBlock(64, 1),\n",
    "            \n",
    "            ConvDownsample(64), # 8 --> 4\n",
    "            ConvBlock(128, 1),\n",
    "        )\n",
    "        \n",
    "        self.tail = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=2), # 4 --> 2\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(128 * 4),\n",
    "            nn.Linear(128 * 4, 10, bias=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.head(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.tail(x)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:56:12.606014Z",
     "start_time": "2024-03-13T19:56:12.600071300Z"
    }
   },
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "726250"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyResNet()\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:56:12.634808100Z",
     "start_time": "2024-03-13T19:56:12.604015700Z"
    }
   },
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 2.3039 Accuracy: 1403/10000 (14%)\n",
      "Test set: Avg. loss: 1.3591 Accuracy: 5164/10000 (52%)\n",
      "Test set: Avg. loss: 1.0582 Accuracy: 6227/10000 (62%)\n",
      "Test set: Avg. loss: 0.8427 Accuracy: 7044/10000 (70%)\n",
      "Test set: Avg. loss: 0.7773 Accuracy: 7265/10000 (73%)\n",
      "Test set: Avg. loss: 0.7096 Accuracy: 7540/10000 (75%)\n",
      "Test set: Avg. loss: 0.7580 Accuracy: 7472/10000 (75%)\n",
      "Test set: Avg. loss: 0.6807 Accuracy: 7652/10000 (77%)\n",
      "Test set: Avg. loss: 0.6673 Accuracy: 7664/10000 (77%)\n",
      "Test set: Avg. loss: 0.5969 Accuracy: 7933/10000 (79%)\n",
      "Test set: Avg. loss: 0.5682 Accuracy: 8048/10000 (80%)\n",
      "Test set: Avg. loss: 0.5527 Accuracy: 8123/10000 (81%)\n",
      "Test set: Avg. loss: 0.5209 Accuracy: 8185/10000 (82%)\n",
      "Test set: Avg. loss: 0.5060 Accuracy: 8277/10000 (83%)\n",
      "Test set: Avg. loss: 0.5107 Accuracy: 8285/10000 (83%)\n",
      "Test set: Avg. loss: 0.4918 Accuracy: 8349/10000 (83%)\n",
      "Test set: Avg. loss: 0.4915 Accuracy: 8339/10000 (83%)\n",
      "Test set: Avg. loss: 0.4865 Accuracy: 8322/10000 (83%)\n",
      "Test set: Avg. loss: 0.4762 Accuracy: 8382/10000 (84%)\n",
      "Test set: Avg. loss: 0.4397 Accuracy: 8483/10000 (85%)\n",
      "Test set: Avg. loss: 0.4372 Accuracy: 8522/10000 (85%)\n",
      "Test set: Avg. loss: 0.4408 Accuracy: 8484/10000 (85%)\n",
      "Test set: Avg. loss: 0.4436 Accuracy: 8512/10000 (85%)\n",
      "Test set: Avg. loss: 0.4439 Accuracy: 8515/10000 (85%)\n",
      "Test set: Avg. loss: 0.4359 Accuracy: 8538/10000 (85%)\n",
      "Test set: Avg. loss: 0.4227 Accuracy: 8564/10000 (86%)\n",
      "Test set: Avg. loss: 0.4437 Accuracy: 8529/10000 (85%)\n",
      "Test set: Avg. loss: 0.4129 Accuracy: 8606/10000 (86%)\n",
      "Test set: Avg. loss: 0.4089 Accuracy: 8673/10000 (87%)\n",
      "Test set: Avg. loss: 0.4068 Accuracy: 8653/10000 (87%)\n",
      "Test set: Avg. loss: 0.4092 Accuracy: 8635/10000 (86%)\n",
      "Test set: Avg. loss: 0.3902 Accuracy: 8674/10000 (87%)\n",
      "Test set: Avg. loss: 0.4039 Accuracy: 8701/10000 (87%)\n",
      "Test set: Avg. loss: 0.3903 Accuracy: 8687/10000 (87%)\n",
      "Test set: Avg. loss: 0.3970 Accuracy: 8639/10000 (86%)\n",
      "Test set: Avg. loss: 0.3874 Accuracy: 8696/10000 (87%)\n",
      "Test set: Avg. loss: 0.3971 Accuracy: 8675/10000 (87%)\n",
      "Test set: Avg. loss: 0.3995 Accuracy: 8673/10000 (87%)\n",
      "Test set: Avg. loss: 0.3868 Accuracy: 8737/10000 (87%)\n",
      "Test set: Avg. loss: 0.3833 Accuracy: 8718/10000 (87%)\n",
      "Test set: Avg. loss: 0.3571 Accuracy: 8834/10000 (88%)\n",
      "Test set: Avg. loss: 0.3681 Accuracy: 8786/10000 (88%)\n",
      "Test set: Avg. loss: 0.3712 Accuracy: 8748/10000 (87%)\n",
      "Test set: Avg. loss: 0.3773 Accuracy: 8757/10000 (88%)\n",
      "Test set: Avg. loss: 0.3600 Accuracy: 8811/10000 (88%)\n",
      "Test set: Avg. loss: 0.3809 Accuracy: 8751/10000 (88%)\n",
      "Test set: Avg. loss: 0.3449 Accuracy: 8863/10000 (89%)\n",
      "Test set: Avg. loss: 0.3291 Accuracy: 8929/10000 (89%)\n",
      "Test set: Avg. loss: 0.3411 Accuracy: 8871/10000 (89%)\n",
      "Test set: Avg. loss: 0.3447 Accuracy: 8889/10000 (89%)\n",
      "Test set: Avg. loss: 0.3379 Accuracy: 8902/10000 (89%)\n",
      "Test set: Avg. loss: 0.3429 Accuracy: 8881/10000 (89%)\n",
      "Test set: Avg. loss: 0.3442 Accuracy: 8888/10000 (89%)\n",
      "Test set: Avg. loss: 0.3280 Accuracy: 8925/10000 (89%)\n",
      "Test set: Avg. loss: 0.3262 Accuracy: 8950/10000 (90%)\n",
      "Test set: Avg. loss: 0.3238 Accuracy: 8944/10000 (89%)\n",
      "Test set: Avg. loss: 0.3232 Accuracy: 8956/10000 (90%)\n",
      "Test set: Avg. loss: 0.3203 Accuracy: 8945/10000 (89%)\n",
      "Test set: Avg. loss: 0.3232 Accuracy: 8948/10000 (89%)\n",
      "Test set: Avg. loss: 0.3343 Accuracy: 8946/10000 (89%)\n",
      "Test set: Avg. loss: 0.3255 Accuracy: 8955/10000 (90%)\n",
      "Test set: Avg. loss: 0.3288 Accuracy: 8916/10000 (89%)\n",
      "Test set: Avg. loss: 0.3350 Accuracy: 8932/10000 (89%)\n",
      "Test set: Avg. loss: 0.3264 Accuracy: 8969/10000 (90%)\n",
      "Test set: Avg. loss: 0.3238 Accuracy: 8979/10000 (90%)\n",
      "Test set: Avg. loss: 0.3271 Accuracy: 8985/10000 (90%)\n",
      "Test set: Avg. loss: 0.3224 Accuracy: 8977/10000 (90%)\n",
      "Test set: Avg. loss: 0.3279 Accuracy: 8982/10000 (90%)\n",
      "Test set: Avg. loss: 0.3273 Accuracy: 8974/10000 (90%)\n",
      "Test set: Avg. loss: 0.3191 Accuracy: 8991/10000 (90%)\n",
      "Test set: Avg. loss: 0.3222 Accuracy: 8987/10000 (90%)\n",
      "Test set: Avg. loss: 0.3200 Accuracy: 8991/10000 (90%)\n",
      "Test set: Avg. loss: 0.3192 Accuracy: 8982/10000 (90%)\n",
      "Test set: Avg. loss: 0.3205 Accuracy: 8998/10000 (90%)\n",
      "Test set: Avg. loss: 0.3234 Accuracy: 8989/10000 (90%)\n",
      "Test set: Avg. loss: 0.3213 Accuracy: 8988/10000 (90%)\n",
      "Test set: Avg. loss: 0.3254 Accuracy: 8990/10000 (90%)\n",
      "Test set: Avg. loss: 0.3217 Accuracy: 8985/10000 (90%)\n",
      "Test set: Avg. loss: 0.3216 Accuracy: 9004/10000 (90%)\n",
      "Test set: Avg. loss: 0.3230 Accuracy: 8999/10000 (90%)\n",
      "Test set: Avg. loss: 0.3218 Accuracy: 9009/10000 (90%)\n",
      "Test set: Avg. loss: 0.3170 Accuracy: 9016/10000 (90%)\n",
      "Test set: Avg. loss: 0.3212 Accuracy: 9011/10000 (90%)\n",
      "Test set: Avg. loss: 0.3180 Accuracy: 9015/10000 (90%)\n",
      "Test set: Avg. loss: 0.3205 Accuracy: 9005/10000 (90%)\n",
      "Test set: Avg. loss: 0.3221 Accuracy: 9006/10000 (90%)\n",
      "Test set: Avg. loss: 0.3238 Accuracy: 8997/10000 (90%)\n",
      "Test set: Avg. loss: 0.3188 Accuracy: 8991/10000 (90%)\n",
      "Test set: Avg. loss: 0.3205 Accuracy: 9016/10000 (90%)\n",
      "Test set: Avg. loss: 0.3261 Accuracy: 8992/10000 (90%)\n",
      "Test set: Avg. loss: 0.3193 Accuracy: 9003/10000 (90%)\n",
      "Test set: Avg. loss: 0.3239 Accuracy: 8997/10000 (90%)\n",
      "Test set: Avg. loss: 0.3227 Accuracy: 8996/10000 (90%)\n",
      "Test set: Avg. loss: 0.3198 Accuracy: 9010/10000 (90%)\n",
      "Test set: Avg. loss: 0.3212 Accuracy: 9013/10000 (90%)\n",
      "Test set: Avg. loss: 0.3234 Accuracy: 8986/10000 (90%)\n",
      "Test set: Avg. loss: 0.3238 Accuracy: 8998/10000 (90%)\n",
      "Test set: Avg. loss: 0.3199 Accuracy: 9004/10000 (90%)\n",
      "Test set: Avg. loss: 0.3205 Accuracy: 9015/10000 (90%)\n",
      "Test set: Avg. loss: 0.3249 Accuracy: 8985/10000 (90%)\n",
      "Test set: Avg. loss: 0.3208 Accuracy: 9010/10000 (90%)\n",
      "Test set: Avg. loss: 0.3213 Accuracy: 9003/10000 (90%)\n",
      "Test set: Avg. loss: 0.3225 Accuracy: 9006/10000 (90%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MyResNet().to(device)\n",
    "\n",
    "writer = SummaryWriter(\"MyResNet_final\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=4, min_lr=1e-6)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.75)\n",
    "\n",
    "train_val(\n",
    "    network=model,\n",
    "    criterion=nn.functional.cross_entropy,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_cifar10_loader,\n",
    "    val_loader=val_cifar10_loader,\n",
    "    n_epochs=350,\n",
    "    writer=writer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    logging_interval=100,\n",
    "    best_dump_path='cifar10_own_resnet_best.bin',\n",
    "    accuracy_dump_threshold=0.88,\n",
    ")\n",
    "\n",
    "writer.flush()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T21:21:39.838495100Z",
     "start_time": "2024-03-12T20:14:42.425691200Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pathlib\n",
    "path = pathlib.Path('./cifar10_own_resnet.bin')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:56:40.299821100Z",
     "start_time": "2024-03-13T19:56:40.287306Z"
    }
   },
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(path, \"wb\") as f:\n",
    "    torch.save(\n",
    "        obj=model.state_dict(),\n",
    "        f=f\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T20:01:32.261767600Z",
     "start_time": "2024-03-12T20:01:32.224161900Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ld = MyResNet()\n",
    "model_ld.load_state_dict(torch.load(path))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:56:42.786781500Z",
     "start_time": "2024-03-13T19:56:42.727074800Z"
    }
   },
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 0.3135 Accuracy: 9032/10000 (90%)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.3134802177429199, 0.9032)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_epoch(\n",
    "    model_ld.to(device),\n",
    "    val_cifar10_loader,\n",
    "    nn.functional.cross_entropy,\n",
    "    writer=SummaryWriter(\"test\"),\n",
    "    epoch_no=0,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T19:56:57.402803400Z",
     "start_time": "2024-03-13T19:56:43.788310300Z"
    }
   },
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `Бонус. Побейте бейзлайн (3 балла)`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На датасете `CIFAR-10` обучите модель, которая выдает аккураси `>=0.9`."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model presented in previous section reached an accuracy 0.905 on validation"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
