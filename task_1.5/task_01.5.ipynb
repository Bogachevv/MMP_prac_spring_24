{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Практикум по программированию на языке Python`\n",
    "\n",
    "## `Задание 1.5. Классификация изображений`.\n",
    "\n",
    "#### Фамилия, имя: Богачев Владимир\n",
    "\n",
    "Дата выдачи: <span style=\"color:red\">__5 марта__</span>.\n",
    "\n",
    "Мягкий дедлайн: <span style=\"color:red\">__12 марта 23:59__</span>.\n",
    "\n",
    "Стоимость: __10 баллов__ (основная часть заданий) + __3 балла__ (дополнительные задания).\n",
    "\n",
    "<span style=\"color:red\">__В ноутбуке все клетки должны выполняться без ошибок при последовательном их выполнении.__</span>\n",
    "\n",
    "#### `Москва, 2024`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:57:39.006615800Z",
     "start_time": "2024-02-28T20:57:36.467464200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Задание 1. Загрузка данных (0.5 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой домашке работа с данными будем максимально облегчённой. Мы скачаем MNIST с помощью [стандартных средств](https://pytorch.org/vision/0.8/datasets.html#mnist) торча. Посмотреть список других доступных датасетов можно [здесь](https://pytorch.org/vision/0.8/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:57:39.007615900Z",
     "start_time": "2024-02-28T20:57:39.003515500Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_mnist(train, transform=None):    \n",
    "    if transform is None:\n",
    "        transform = T.ToTensor()\n",
    "    # print(transform)\n",
    "    return torchvision.datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=train,\n",
    "        transform=transform,\n",
    "        download=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пиксели изображений принимают значения [0,1]. Скачайте датасет и посчитайте выборочное среднее и выборочное стандартное отклонение для значения пикселя. Т.е. должно получиться число `mean` для среднего, и число `std` для стандартного отклонения.\n",
    "\n",
    "*Подсказка.* Подумайте, на какой части датасета нужно считать эти статистики (обучение или валидация), чтобы предотвратить утечку данных.\n",
    "\n",
    "*Подсказка.* У торч датасета реализован метод `__getitem__`, т.е. его можно индексировать `dataset[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:57:44.346479500Z",
     "start_time": "2024-02-28T20:57:39.005615700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.Size([60000, 1, 28, 28])\n",
      "mean = 0.13, std = 0.31\n"
     ]
    }
   ],
   "source": [
    "norm_transform = T.Compose([\n",
    "    T.PILToTensor(),\n",
    "    T.ConvertImageDtype(torch.float32)\n",
    "])\n",
    "\n",
    "data_train = load_mnist(True, transform=norm_transform)\n",
    "\n",
    "X_train = torch.stack([data_train[i][0] for i in range(len(data_train))])\n",
    "# y_train = data_train.targets\n",
    "\n",
    "print(X_train.dtype, X_train.shape)\n",
    "\n",
    "mean =  torch.mean(X_train)\n",
    "std =  torch.std(X_train)\n",
    "print(f\"mean = {mean:.2f}, std = {std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные значения можно применить для нормализации изображений, когда будем подавать их в нейросеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:57:44.393128Z",
     "start_time": "2024-02-28T20:57:44.348481600Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_mnist = load_mnist(True, norm_transform)\n",
    "val_mnist = load_mnist(False, norm_transform)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([60000, 1, 28, 28]),\n torch.float32,\n torch.Size([10000, 1, 28, 28]),\n torch.float32)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.stack([train_mnist[i][0] for i in range(len(train_mnist))])\n",
    "y_train = train_mnist.targets\n",
    "\n",
    "X_val = torch.stack([val_mnist[i][0] for i in range(len(val_mnist))])\n",
    "y_val = val_mnist.targets\n",
    "\n",
    "X_train.shape, X_train.dtype, X_val.shape, X_val.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T20:57:52.726933500Z",
     "start_time": "2024-02-28T20:57:44.381128700Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время обучения данные подаются в нейросеть батчами.\n",
    "\n",
    "Обычно batch_size выбирается так, чтобы во время обучения получалась меньше дисперсия градиента (ну вы уже знакомы с sgd), также часто batch_size выбирается максимально возможным по ресурсам.\n",
    "\n",
    "Для этой задачи нам хватит batch_size = 64 во время обучения.\n",
    "\n",
    "*Ответьте на вопрос:* Почему в большинстве задач для валидации и тестирования можно выбирать batch_size больше? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:57:52.730750200Z",
     "start_time": "2024-02-28T20:57:52.727933400Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "train_mnist_loader = DataLoader(\n",
    "    dataset=train_mnist,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_mnist_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_mnist,\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:57:52.744475100Z",
     "start_time": "2024-02-28T20:57:52.730750200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(train_mnist_loader))\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:57:52.809490400Z",
     "start_time": "2024-02-28T20:57:52.744475100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 3\n",
    "plt.title(f'digit {labels[i]}')\n",
    "plt.imshow(images[i, 0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Задание 2. Цикл обучения (1.5 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже предоставлен базовый вариант цикла обучения, представленный тремя функциями: `train_epoch`, `val_epoch`, `train_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:57:52.813905600Z",
     "start_time": "2024-02-28T20:57:52.811491300Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    network,\n",
    "    train_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "):\n",
    "    \"\"\"train `network` with `optimizer` for one epoch with data from `train_loader` to minimize `criterion`\"\"\"\n",
    "    \n",
    "    network.train()  # switch network submodules to train mode, e.g. it influences on batch-norm, dropout\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)   # send data to device\n",
    "        optimizer.zero_grad()   # zero out grads, collected from previous batch\n",
    "        logits = network(images)  # forward pass\n",
    "        loss = criterion(logits, labels, reduction='mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:57:52.820015600Z",
     "start_time": "2024-02-28T20:57:52.816904300Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_epoch(\n",
    "    network,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "):\n",
    "    \"\"\"calculate loss and accuracy on validation data\"\"\"\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    network.eval()  # switch network submodules to test mode\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = network(images)\n",
    "        val_loss += criterion(logits, labels, reduction='sum').item()\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += torch.sum(pred == labels).item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accur = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        f'Test set: Avg. loss: {val_loss:.4f}',\n",
    "        f'Accuracy: {correct}/{len(val_loader.dataset)}',\n",
    "        f'({100. * val_accur:.0f}%)',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:57:52.823896800Z",
     "start_time": "2024-02-28T20:57:52.821017400Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_val(\n",
    "    network,\n",
    "    n_epochs,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "):\n",
    "    \"\"\"full cycle of neural network training\"\"\"\n",
    "\n",
    "    val_epoch(network, val_loader, criterion)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_epoch(network, train_loader, criterion, optimizer)\n",
    "        val_epoch(network, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки, что все работает, обучите бейзлайн -- однослойную [полносвязную](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) сеть на [кросс-энтропийный лосс](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html). \n",
    "\n",
    "\n",
    "*Заметьте*, что на вход этому лоссу нужно подавать сырой выход нейросети, а не результат применения софтмакса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:58:17.705246Z",
     "start_time": "2024-02-28T20:58:17.697005300Z"
    }
   },
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.linear = nn.Linear(in_features=input_size, out_features=output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.linear(x.view(-1, 1, self.input_size))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape(-1, 28 * 28).to(device)\n",
    "# X_val = X_val.reshape(-1, 28 * 28).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T20:58:18.110042800Z",
     "start_time": "2024-02-28T20:58:18.103412600Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:59:32.300441100Z",
     "start_time": "2024-02-28T20:59:31.756344400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (28000) to match target batch_size (1000).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m LogReg(X_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m X_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m], \u001B[38;5;241m10\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mtrain_val\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAdam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_mnist_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_mnist_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[11], line 11\u001B[0m, in \u001B[0;36mtrain_val\u001B[1;34m(network, n_epochs, criterion, optimizer, train_loader, val_loader)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_val\u001B[39m(\n\u001B[0;32m      2\u001B[0m     network,\n\u001B[0;32m      3\u001B[0m     n_epochs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      7\u001B[0m     val_loader,\n\u001B[0;32m      8\u001B[0m ):\n\u001B[0;32m      9\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"full cycle of neural network training\"\"\"\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m     \u001B[43mval_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m     13\u001B[0m         train_epoch(network, train_loader, criterion, optimizer)\n",
      "File \u001B[1;32mC:\\python_venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[10], line 15\u001B[0m, in \u001B[0;36mval_epoch\u001B[1;34m(network, val_loader, criterion)\u001B[0m\n\u001B[0;32m     13\u001B[0m images, labels \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     14\u001B[0m logits \u001B[38;5;241m=\u001B[39m network(images)\n\u001B[1;32m---> 15\u001B[0m val_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     16\u001B[0m pred \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     17\u001B[0m correct \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(pred \u001B[38;5;241m==\u001B[39m labels)\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32mC:\\python_venv\\Lib\\site-packages\\torch\\nn\\functional.py:3029\u001B[0m, in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[0;32m   3027\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3028\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 3029\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: Expected input batch_size (28000) to match target batch_size (1000)."
     ]
    }
   ],
   "source": [
    "model = LogReg(X_train.shape[1] * X_train.shape[2], 10).to(device)\n",
    "\n",
    "train_val(\n",
    "    network=model,\n",
    "    criterion=nn.functional.cross_entropy,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-4),\n",
    "    train_loader=train_mnist_loader,\n",
    "    val_loader=val_mnist_loader,\n",
    "    n_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test set: Avg. loss: 2.4114 Accuracy: 843/10000 (8%)\n",
    "Test set: Avg. loss: 0.2837 Accuracy: 9179/10000 (92%)\n",
    "Test set: Avg. loss: 0.2796 Accuracy: 9201/10000 (92%)\n",
    "Test set: Avg. loss: 0.2812 Accuracy: 9199/10000 (92%)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Задание 3. Логирование (3 балл)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопируйте и перепишите функции `train_epoch`, `val_epoch`, `train_val` таким образом, чтобы\n",
    "- во время обучения раз в `logging_interval` шагов оптимизации выводились лосс и аккураси на одном батче (пример ниже, но не обязательно делать идентично)\n",
    "- происходило сохранение весов лучшей (по аккураси на валидации) модели и состояния оптимизатора ([в помощь](https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-state-dict-recommended))\n",
    "- в конце обучения выводился и сохранялся график-саммари (пример ниже, но не обязательно делать идентично)\n",
    "\n",
    "*Ответьте на вопрос:* Что хранится в состоянии оптимизатора? Зачем нужно его сохранять? Приведите хотя бы один пример оптимизатора, для которого есть смысл сохранять состояние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T20:57:53.267092800Z"
    }
   },
   "outputs": [],
   "source": [
    "# your training functions are here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T20:57:53.269092700Z"
    }
   },
   "outputs": [],
   "source": [
    "# here you start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите лучшие веса модели и подсчитайте аккураси на валидации, чтобы подтвердить что веса сохранились корректно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T20:57:53.271093100Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите сохранённое состояние оптимизатора и сделайте две эпохи обучения, чтобы подтвердить, что состояния оптимизатора были сохранены корректно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T20:57:53.272092700Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Задание 4. Логирование с помощью tensorboard (1 балл)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле это дурной тон логировать обучение нейросети так, как это сделали вы выше. Дело в том, что весь функционал уже реализован в [`tensorboard`](https://pytorch.org/docs/stable/tensorboard.html), а вы написали велосипед."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T20:57:53.273093200Z"
    }
   },
   "outputs": [],
   "source": [
    "! pip3 install tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у вас есть доступ к терминалу и браузеру, то удобнее всего ввести команду\n",
    "```bash\n",
    "tensorboard --logdir .\n",
    "```\n",
    "и открыть UI в выделенном локалхосте. \n",
    "\n",
    "Если вы работаете в гугл колабе, то можете запустить UI как виджет в Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T20:57:53.274092600Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как только вы начнете логировать в объект типа `SummaryWriter`, в UI начнут строиться кривые обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопируйте и перепишите функции обучения таким образом, чтобы логирование происходило в `tensorboard`.\n",
    "\n",
    "*Замечание.* Вам пригодится метод `add_scalar`, чтобы сохранять лосс и аккураси, и метод `add_hparams`, чтобы сохранить важные гиперпараметры (например, кодовое имя архитектуры сети) и финальное достигнутое качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T20:57:53.274092600Z"
    }
   },
   "outputs": [],
   "source": [
    "# your training functions are here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Задание 5. Побейте бейзлайн (2+2 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На датасете [`CIFAR-10`](https://pytorch.org/vision/0.8/datasets.html#torchvision.datasets.CIFAR10) обучите модель, которая выдает аккураси `>=0.7` (2 балла) и аккураси `>=0.8` (ещё 2 балла).\n",
    "- Можете использовать любые модули `pytorch`, любые оптимизаторы и шедулеры, можете использовать аугментации ([например](https://pytorch.org/vision/stable/transforms.html))\n",
    "- Для отслеживания экспериментов используйте логирование с `tensorboard`, не забывайте давать осмысленные имена эспериментам и логировать нужные гиперпараметры, сохранять веса сети и состояние оптимизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T20:57:53.275092Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Бонус. Побейте бейзлайн (3 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На датасете `CIFAR-10` обучите модель, которая выдает аккураси `>=0.9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T20:57:53.276092900Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code is here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
